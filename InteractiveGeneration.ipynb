{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned language model for pictionary word list completion (topic/category phrase + example words -> list of 30 examples). For example, one may complete the list\n",
    "\n",
    "\"A list of round fruits: peach, apricot, lime, plum,\"\n",
    "\n",
    "with\n",
    "\n",
    "\"mango, cherry, pineapple, strawberry, pumpkin, watermelon, orange, pomegranate, melon, apple, pear, grapefruit, papaya, lemon, kiwi, passionfruit, blueberry, raspberry, blackberry, cantaloupe, nectarine, pitaya, persimmon, durian, guava, jackfruit, avocado, lychee, soursop, guarana, mangosteen, blackcurrant, cranberry\"\n",
    "\n",
    "using this model. These words should be compatible with pictionary/skribbl.io; i.e., \"sketchable\" within a few minutes, and easily recognisable. Scroll to the end for more examples, or see the file `data/examples.txt`. Sketchability parameter estimation examples can also be found in `data/data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, GPT2LMHeadModel, ReformerModelWithLMHead, \\\n",
    "                         get_linear_schedule_with_warmup\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from Learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ###   Options   ###\n",
    "\n",
    "model_name = \"ernst_one\"\n",
    "# gpt2_modelkey = \"gpt2\"               # Pretrained model to start from\n",
    "gpt2_modelkey = \"gpt2-xl\"            # Pretrained model to start from\n",
    "test_set_frac = 0.25                 # Fraction of samples to keep as separate test set (word lists)\n",
    "sample_test_n = 200                  # Number of randomly generated prompts for each sample when validating model\n",
    "log_period_batches = 10               # Batches per iteration\n",
    "# learning_rate = 5e-7                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "learning_rate = 7e-5                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "# learning_rate = 4e-6                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "adam_epsilon = 1e-8                  # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                   # Linear scheduler for optimizer number of warmup steps\n",
    "# batch_size = bsz = 8                 # Samples per batch\n",
    "batch_size = bsz = 64                # Samples per batch\n",
    "# batch_size = bsz = 128                # Samples per batch\n",
    "N_train_batches = int(1e7 / bsz)     # Total number of batches to show model\n",
    "min_nw, max_nw = 0.7, 0.9            # Minimum and maximum fraction of list to keep when truncating\n",
    "max_listlen = 15                     # Maximum number of words in the list when creating a prompt (at least prior to * max_nw)\n",
    "lidstone_e = 0.01                    # Smoothing for possible words/subwords which are not in the missing list words set\n",
    "max_len = 96                         # Max n. tokens specified in order to match a power of 2, applied prior to *max_nw (tokens)\n",
    "lastcomma_repl = ',' # 'EOS', ','    # Token optionally used to replace the final comma that ends the generated phrase\n",
    "use_correct_nouns = True             # Whether to use only correct singular or plural form of category nouns for the given prompt\n",
    "swap_noun = False                    # Whether to swap plural and singular nouns in prompt (diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "d = device = pt.device(dev)\n",
    "# world_size = 1\n",
    "# rank = 0\n",
    "# def setup(rank, world_size): \n",
    "#     os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "#     os.environ['MASTER_PORT'] = find_free_port()\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)  # initialize the process group\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "# # mp.spawn(setup, args=(rank, world_size), nprocs=world_size)\n",
    "# setup(rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(gpt2_modelkey.replace(\"-xl\", \"-large\"), padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    tokenizer.encode(\"oranges, pears,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[tokenizer.encode(prompt), \"types of\" in prompt] for prompt in lprompts]\n",
    "cats_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e = [[tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "comma_token = pt.tensor(tokenizer.encode(\",\")[0], device=d)\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "lprompts_sing = [(prmpt, typesof) for (prmpt, typesof) in lprompts_encoded if typesof ^ swap_noun]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "# lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "# cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "# cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "# phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "lidstone_e = pt.tensor(lidstone_e, device=d)\n",
    "lid_val = lidstone_e / N_tokens\n",
    "y_zero = (lid_val).repeat(N_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk, using nw_draw = 15. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p):  # prmt = prompt tokens, p = list word/phrase tokens\n",
    "    tkzs, sent, tkix = [], [], 0\n",
    "    max_ws = max_len - len(prmt)\n",
    "#     incl_words = pt.randperm(len(p))[:min(max_listlen, len(p))]\n",
    "    incl_words = np.random.choice(len(p), min(max_listlen, len(p)), replace=False)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc = p[phz_i]\n",
    "        tkzs.append((tkix, phz_enc))\n",
    "        tkix += len(phz_enc)\n",
    "        sent.append(phz_enc)\n",
    "        if tkix >= max_ws:\n",
    "            tkix = max_ws\n",
    "            break\n",
    "    sent = pt.hstack(sent)[:max_ws]\n",
    "    missing_w = [p[i] for i in range(len(p)) if i not in incl_words]\n",
    "    trunc_ix = np.random.randint(round(tkix * min_nw), round(tkix * max_nw))\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if len(enc) >= trunc_n and all(enc[:trunc_n] == partial_phr)]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_e)\n",
    "    tunit, y_ = pt.tensor(1 / norm, device=d), y_zero.clone()\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return pt.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def gen_samples_uniform(xcp, xcs, xp, nw, verbose=False):  # Weight testing samples (word lists) uniformly\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        for m in range(nw):\n",
    "#             prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "#             cat_ix = np.random.randint(len(cp))\n",
    "#             x_, y_ = gen_truncated_list(pt.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "            cat_ix = np.random.randint(len(cp_cs))  # First uniformly sample a category title\n",
    "            sing = cat_ix >= len(cp)\n",
    "            lprmpts = lprompts_sing if sing else lprompts_encoded\n",
    "            prmt, _ = lprmpts[np.random.randint(len(lprmpts))]\n",
    "            x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p)\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "            sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0:\n",
    "                sys_print(\"\\rDone: \" + str(j))\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        sqlens.append(sqlen)\n",
    "    if verbose: sys_print(\"\\rDone: \" + str(j) + \", finished!\\n\")\n",
    "    return xs, ys, sqlens\n",
    "def gen_samples(xcp, xcs, xp, n):  # Maximise training batch diversity by randomly sampling the word lists\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets = len(xcp)\n",
    "    for m in range(n):\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        cat_ix = np.random.randint(len(cp_cs))  # First uniformly sample a category title\n",
    "        sing = cat_ix >= len(cp)\n",
    "        lprmpts = lprompts_sing if sing else lprompts_encoded\n",
    "        prmt, _ = lprmpts[np.random.randint(len(lprmpts))]\n",
    "        x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "        sqlens.append(len(x_))\n",
    "    return xs, ys, sqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "['round fruits', 'wild animals', 'microorganisms', 'music', 'machine learning algorithms', 'outback experiences', 'scientific cycles', 'buildings', 'glassware']\n",
      "Test:\n",
      "['hats', 'chemical elements', 'dramatic and literature elements']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 600, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test = int(test_set_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "test_idx = np.random.choice(N_wordlists, N_test, replace=False)\n",
    "save_ld(test_idx, \"test.data\")\n",
    "# test_idx = load_ld(\"test.data\")\n",
    "# test_idx = np.array([0, 2])  # Round fruits and chemical elements\n",
    "train_idx = [i for i in range(N_wordlists) if i not in test_idx]\n",
    "print(\"Train:\")\n",
    "print([cats[i][0] for i in train_idx])\n",
    "print(\"Test:\")\n",
    "print([cats[i][0] for i in test_idx])\n",
    "cats_e_test, cats_sing_e_test = [cats_e[i] for i in test_idx], [cats_sing_e[i] for i in test_idx]\n",
    "phrases_e_test = [phrases_e[i] for i in test_idx]\n",
    "cats_e_train, cats_sing_e_train = [cats_e[i] for i in train_idx], [cats_sing_e[i] for i in train_idx]\n",
    "phrases_e_train = [phrases_e[i] for i in train_idx]\n",
    "test_cats = [cats[i][0] for i in test_idx]\n",
    "test_xs, test_ys, test_sqlens = gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, sample_test_n, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "def adapt_form(xs, ys, sqlens, repl_finalcomma=True):\n",
    "    xs = pt.vstack([F.pad(x, (0, max(0, max_len - len(x))), mode='constant', value=pad_token)[:max_len] for x in xs])\n",
    "    _ys = pt.vstack(ys)\n",
    "    if repl_finalcomma and (lastcomma_repl != ','):\n",
    "        _ys[:, repl_token] += _ys[:, comma_token] - lid_val\n",
    "        _ys[:, comma_token] = lid_val\n",
    "    return xs, _ys, pt.tensor(sqlens, device=d)\n",
    "def next_batch(sz):\n",
    "    global cats_e_train, cats_sing_e_train, phrases_e_train\n",
    "    return adapt_form(*gen_samples(cats_e_train, cats_sing_e_train, phrases_e_train, sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "GPT2 device: cuda:0\n",
      "Pretrained parameters loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1271"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "pt.cuda.empty_cache()\n",
    "print(gc.collect())\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2LMHead\")\n",
    "# model_ = GPT2ForSequenceClassification.from_pretrained('gpt2-large',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-xl',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-large',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-medium',\n",
    "model_ = GPT2LMHeadModel.from_pretrained(gpt2_modelkey,\n",
    "    output_hidden_states=False, output_attentions=False, \n",
    "    cache_dir=\"models/pretrained/GPT2LMHead\")\n",
    "if pt.cuda.device_count() > 1:\n",
    "    # model_.parallelize()\n",
    "    device_map = {0: [0, 1, 2],\n",
    "                  1: [3, 4, 5, 6, 7, 8],\n",
    "                  2: [9, 10, 11, 12, 13, 14],\n",
    "                  3: [15, 16, 17, 18, 19, 20],\n",
    "                  4: [21, 22, 23, 24, 25, 26, 27],\n",
    "                  5: [28, 29, 30, 31, 32, 33, 34],\n",
    "                  6: [35, 36, 37, 38, 39, 40, 41],\n",
    "                  7: [42, 43, 44, 45, 46, 47],\n",
    "                 }\n",
    "    # device_map = {0: [0, 1, 2],\n",
    "    #               1: [3, 4, 5, 6, 7, 8],\n",
    "    #               2: [9, 10, 11, 12, 13, 14],\n",
    "    #               3: [15, 16, 17, 18, 19, 20],\n",
    "    #               4: [21, 22, 23, 24, 25, 26, 27],\n",
    "    #               5: [28, 29, 30, 31, 32, 33, 34],\n",
    "    #               6: [35, 36, 37, 38, 39, 40, 41],\n",
    "    #               7: [42, 43, 44, 45, 46, 47],\n",
    "    #              }\n",
    "    model_.parallelize(device_map)\n",
    "else:\n",
    "    model_ = model_.to(d)\n",
    "print(\"GPT2 device:\", model_.device)\n",
    "model_.resize_token_embeddings(N_tokens)\n",
    "pad_token = model_.config.pad_token_id = model_.config.eos_token_id\n",
    "pad_token = pt.tensor(pad_token, device=d)\n",
    "repl_token = pt.tensor(tokenizer.encode(lastcomma_repl)[0], device=d) if lastcomma_repl != 'EOS' else pad_token\n",
    "n_embd = pt.tensor(model_.config.n_embd, device=d)\n",
    "# model = nn.parallel.DistributedDataParallel(model_, device_ids=[d])\n",
    "# model = nn.DataParallel(\n",
    "#     model_, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else model_\n",
    "model = model_\n",
    "print(\"Pretrained parameters loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = None #nn.Linear(n_embd, N_tokens, bias=False).to(d)#.cpu()\n",
    "# nn.init.xavier_uniform_(llayer.weight)\n",
    "# llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else llayer\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()#.to(d)#.cpu()\n",
    "# bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d) if dev != \"cpu\" else bcewl_loss\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1, device=d)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, bsz, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(bsz)\n",
    "\n",
    "#     for x in x_batch.cpu().detach().numpy():\n",
    "#         print(tokenizer.decode(x))\n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)  # Get logits\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens_batch - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     outs = outputs[0][:, -1]\n",
    "#     logits = llayer(outs)\n",
    "    logits = outs\n",
    "    \n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "\n",
    "def inference(x, sqlens):\n",
    "    global model, llayer\n",
    "\n",
    "    x, sqlens = x, sqlens\n",
    "#     for x_ in x.cpu().detach().numpy():\n",
    "#         print(tokenizer.decode(x_))\n",
    "    mask = sequence_mask(sqlens, max_len)\n",
    "    outputs = model(x.long(), attention_mask=mask)  # Get logits\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     outs = outputs[0][:, -1]\n",
    "#     logits = llayer(outs)\n",
    "    logits = outs\n",
    "    return logits\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())#.to(d)#.cpu()\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = -1  # Batch 0 is the first iteration, where testing occurs without any training\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "out_str = ''\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, test_loss, test_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, test_loss, test_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        if batch_i > 0:\n",
    "            gc.collect()\n",
    "            if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "            b_loss, b_accuracy = train_step()\n",
    "            if verbose:\n",
    "                sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                          ' @ batch '+ str(batch_i) + ' (' + str(batch_i * batch_size) + ' samples) complete.                  ')\n",
    "            iter_loss.append(b_loss)\n",
    "            iter_accuracy.append(b_accuracy)\n",
    "\n",
    "        if batch_i % log_period_batches == 0:  # Test on test set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            out_str = '\\n'\n",
    "            for i in range(N_test):\n",
    "                test_X, test_Y, test_Sqlens = adapt_form(test_xs[i], test_ys[i], test_sqlens[i], repl_finalcomma=batch_i > 0)\n",
    "                feed_batches = [range(len(test_X))[i * bsz:(i + 1) * bsz] for i in range((len(test_X) // bsz) + \\\n",
    "                                                                                        (1 if (len(test_X) % bsz) != 0 else 0))]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(test_X[inds], test_Y[inds], test_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls))\n",
    "                accuracy.append(np.mean(cs))\n",
    "                out_str += test_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]) + '\\n'\n",
    "            \n",
    "            test_l, test_a = np.mean(loss), np.mean(accuracy)\n",
    "            test_loss.append(test_l)\n",
    "            test_accuracy.append(test_a)\n",
    "            if batch_i == 0:\n",
    "                iter_loss, iter_accuracy = [test_l], [test_a]\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l)\n",
    "            train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "            \n",
    "            val_a = 0\n",
    "            if test_a > best_acc:      # Save best accuracy model\n",
    "                best_acc = test_a\n",
    "                best_loss = test_l\n",
    "                best_acc_idx = batch_i // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "#                          \"llayer\": llayer.state_dict(),\n",
    "#                          \"softrmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(out_str + \"Batch\", batch_i, ':', train_a, test_a, \"loss:\", train_l, test_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(test_accuracy, label='test acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                g.plot(test_loss, label='test loss')\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, test_accuracy, train_loss, test_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hats: 0.00010320337, 0.671875\n",
      "chemical elements: 8.422259e-05, 0.46875\n",
      "dramatic and literature elements: 0.0001090692, 0.84375\n",
      "Batch 650 : 0.9140625 0.6614583 loss: 5.7221092e-05 9.883172e-05 Best: 0.7135417 9.9054414e-05 idx: 37\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, accuracy: 5.4148517e-05, 0.9375 @ batch 652 (41728 samples) complete.                  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ff61b84ca1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miterate_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-b95603c8b01a>\u001b[0m in \u001b[0;36miterate_training\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mb_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
      "\u001b[0;32m<ipython-input-13-1d36f3133d92>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlens_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mout_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlens_batch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    919\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    758\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m                 )\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add cross attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model (checkpoint)\n",
    "pt.cuda.empty_cache()\n",
    "gc.collect()\n",
    "cpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 2k ts' + \"/\" + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 3k ts' + \"/\" + model_name)  # ~3000 training samples observed has current optimum\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 30k ts' + \"/\" + model_name)\n",
    "model.load_state_dict(cpoint['model'])\n",
    "bcewl_loss.load_state_dict(cpoint['bcewl_loss'])\n",
    "optimizer.load_state_dict(cpoint['optimizer'])\n",
    "scheduler.load_state_dict(cpoint['scheduler'])\n",
    "# llayer.load_state_dict(cpoint['llayer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = int(pad_token.detach().cpu().numpy())\n",
    "def append_next_token(sent, top_k=-1, top_p=0.9, temperature=1.0, olen=None):\n",
    "    print(\"k =\", top_k, \", p =\", top_p, \", temp =\", temperature)\n",
    "    global model\n",
    "    if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    ou = tokens.copy()\n",
    "    while len(tokens) < max_len:\n",
    "        tokens += [padder]\n",
    "    x = pt.tensor([tokens], device=d)\n",
    "    logits = inference(x, pt.tensor([len(ou)], device=d))[0]\n",
    "    logits /= temperature\n",
    "    logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "    probs = F.softmax(logits, dim=0)\n",
    "    token = pt.multinomial(probs, 1).detach().cpu().numpy()[0]\n",
    "    ou += [token]\n",
    "    prev_len = len(sent) if olen is None else olen\n",
    "    sent_new = tokenizer.decode(ou)\n",
    "    print(sent[:prev_len] + '' + sent_new[prev_len:])\n",
    "    return sent_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "\"reinterpretation, harmony, character progression, reading circle\")\n",
    "# \"monolith, elevator effect, time loop, survival, desert resort, town watchman\")\n",
    "# \"monolith, allegro, soundtrack, chord, classical, opera\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 25 , p = 0.6 , temp = 15.0\n",
      " A list of types of element of drama and writing: attention, surprise, fourth wall, diversion, fate, silence, pace, cliffhanger, character progression, monologuereinterpretation,, reading circle, cliffhaft-style character progression\n"
     ]
    }
   ],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.6, temperature=15.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "\"watermelon juice, cherry juice, blackcurrant mixture, kava, orangeade, lemon juice, cherryade, cranberry juice\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 , p = 0.8 , temp = 5.0\n",
      "A list of types of element of drama and writing: kava, lemonade, coffee, milkshakewatermelon juice, coke, orangeade, blackcurrant mixture, water, cherry juice, lemon juice,  black\n"
     ]
    }
   ],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=10, top_p=0.8, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "# \"\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider, yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider\" + \\\n",
    "# \", yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5pm: Using log_period=1 (max_len=96) reliably finds improvement, need more data and larger gpt2 (medium+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" milk, vodka, beer, ice water, soda, lassi, juice, alcohol, whiskey\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" wine, soda, alcohol, beer, liquor, apple cider, whiskey, milk, bourbon, vodka, cider, lemon juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:6])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=3.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" beer, milk, juice, wine, spirits, alcohol, soda, whiskey, brandy, apple juice, liquor, ice tea, watermelon juice, vodka,\" + \\\n",
    "# \" lemon tea, apple cider, ale, lager, fruit tea, lime cider, cocktail, mocha, red wine, apple soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5am: lr=1e-5, max_len=80, log_period_batches=5 increased accuracy by 8%. Need to add a bunch more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 5 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"soda, milk, juice, wine, vodka, gin, lime juice, beer, hot chocolate, cider, whiskey, fruit juice, cocktail, liquor, \" + \\\n",
    "# \"spirits, watermelon juice, martini, rum, chocolate milk, orangeade\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fine tuning (regular GPT-2):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model on 2nd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, juice, fruit juice, soda, wine, beer, hot chocolate, chocolate milk, alcohol, cider, ice tea, liquor, spirit\")\n",
    "# input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89, olen=olen) # k = 25 also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for too long (in this case ~6:30 hours) overfits\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"beer, juice, soda, liquor, wine, tequila, spirits, alcohol, cocktail, martini, whiskey, rum, vodka\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 15/04/2021 11am: Found learning rate 1e-7, max_listlen 15, min_nw 0.7, max_nw 0.9, lidstone_e 0.01 ACTUALLY WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No fine tuning (testing gpt2) (old append function):\n",
    "# input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake\"\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89)\n",
    "# A list of types of drink: juice, tea, cider, lemonade, milk, beer, hot chocolate, ice cold milk. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working (reproducible) examples using various non-fine-tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT3 (via AI Dungeon) (Randomness = 2.0, model = Dragon):\n",
    "# sentence = \"A list of ML algorithms: inverse reinforcement learning, ELMo, decision tree, LDA, \"\n",
    "# expected_completion = \"MLP, MLL, MMM. You can't believe you're actually using these things!\"\n",
    "\n",
    "# sentence = \"A list of animals seen in the wild: wolffish, woodlouse, sheep, zebra, yak, \"\n",
    "# expected_completion = \"goat, fox, dog, rat. You're guessing that a lot of other animals have been seen as well; maybe even all the animals on your list except for wolf and rat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 (via Write with Transformer) (Top-p = 0.67, temperature = 1.89, max time = 1.9):\n",
    "# sentence = \"A list of round fruits: peach, apricot, lime, plum, blackberry, cantaloupe, nectarine, pitaya, persimmon, \"\n",
    "# expected_completion = \"mango, papaya and raspberry, as also many\"\n",
    "\n",
    "# sentence = \"A list of chemical elements: hydrogen, carbon, oxygen, nitrogen, gold, \"\n",
    "# expected_completion = \"silver, aluminum, potassium and phosphorus; atomic number.\"\n",
    "\n",
    "# sentence = \"A list of microbes found on earth: bacteria, virus, prokaryote, amoeba, \"\n",
    "# expected_completion = \"archaea, algae, nematode, euk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
