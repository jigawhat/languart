{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned language model for pictionary word list completion (topic/category phrase + example words -> list of 30 examples). For example, one may complete the list\n",
    "\n",
    "\"A list of round fruits: peach, apricot, lime, plum,\"\n",
    "\n",
    "with\n",
    "\n",
    "\"mango, cherry, pineapple, strawberry, pumpkin, watermelon, orange, pomegranate, melon, apple, pear, grapefruit, papaya, lemon, kiwi, passionfruit, blueberry, raspberry, blackberry, cantaloupe, nectarine, pitaya, persimmon, durian, guava, jackfruit, avocado, lychee, soursop, guarana, mangosteen, blackcurrant, cranberry\"\n",
    "\n",
    "using this model. These words should be compatible with pictionary/skribbl.io; i.e., \"sketchable\" within a few minutes, and easily recognisable. Scroll to the end for more examples, or see the file `data/examples.txt`. Sketchability parameter estimation examples can also be found in `data/data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import openai\n",
    "# with open('../../openai-api-org.txt', 'r') as f: openai.organization = f.read()\n",
    "# with open('../../openai-api-key.txt', 'r') as f: openai.api_key      = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1007 02:57:28.455765 25356 modeling_bert.py:226] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I1007 02:57:28.466736 25356 modeling_xlnet.py:339] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alfew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import glob\n",
    "import string\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from bayes_opt import BayesianOptimization\n",
    "from IPython.utils import io\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, GPT2LMHeadModel, GPTNeoForCausalLM, ReformerModelWithLMHead, \\\n",
    "                         get_linear_schedule_with_warmup, GPT2TokenizerFast\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from Learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                  ###   Options   ###\n",
    "model_name = \"ernst_one\"\n",
    "# model_name = \"unfinetuned\"\n",
    "gpt2_modelkey = \"gpt2\"           # Pretrained model to start from\n",
    "# gpt2_modelkey = \"gpt2\"\n",
    "val_frac, test_frac = 0.25, 0.25    # Fraction of samples to keep as separate validation/test set (word lists)\n",
    "TsN = 200                           # Number of randomly generated prompts for each sample when validating model\n",
    "log_period_batches = 10             # Batches per iteration\n",
    "# learning_rate = 5e-7              # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "learning_rate = 7e-5\n",
    "# learning_rate = 4e-6\n",
    "adam_epsilon = 1e-8                 # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                  # Linear scheduler for optimizer number of warmup steps\n",
    "# batch_size = bsz = 64               # Samples per batch\n",
    "# batch_size = bsz = 32\n",
    "batch_size = bsz = 4\n",
    "# N_train_batches = int(1e7 / bsz)  # Total number of batches to show model\n",
    "N_train_batches = 600\n",
    "# max_len = 1024                    # Max n. tokens applied prior to rng_train (number of phrases range)\n",
    "max_len = 32\n",
    "train_phrase_lprob_pctile = 0.08    # Phrase generation probability percentile excluded from training dataset\n",
    "lidstone_eps = 0.01                 # Smoothing epsilon for possible words/subwords which are not in the missing list words set\n",
    "lastcomma_repl = ',' # 'EOS', ','   # Token optionally used to replace the final comma that ends the generated phrase\n",
    "use_correct_nouns = True            # Whether to use only correct singular or plural form of category nouns for the given prompt\n",
    "swap_noun = False                   # Whether to swap plural and singular nouns in prompt\n",
    "# rng_train = [0, 512]              # Range of prompt list lengths (number of phrases) to generate for training data\n",
    "rng_train = [3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda\" if pt.cuda.is_available() else \"cpu\"  # Setup torch device(s)\n",
    "d = device = pt.device(dev)\n",
    "# world_size = 1\n",
    "# rank = 0\n",
    "# def setup(rank, world_size): \n",
    "#     os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "#     os.environ['MASTER_PORT'] = find_free_port()\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)  # initialize the process group\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "# # mp.spawn(setup, args=(rank, world_size), nprocs=world_size)\n",
    "# setup(rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [273, 6231, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_tokenizer = GPT2TokenizerFast.from_pretrained((\"gpt2-large\"), padding=True)\n",
    "with io.capture_output() as captured:\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(gpt2_modelkey.replace(\"-xl\", \"-large\"), padding=True)\n",
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), tokenizer.encode(\"oranges, pears,\"), \\\n",
    "  gpt3_tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    gpt3_tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    gpt3_tokenizer.encode(\"oranges, pears,\") # Note: gpt-3 tokenizes words differently if they are at the start of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_sing = [p for p in lprompts if ((\"types of\" in p) ^ swap_noun)]\n",
    "enc_prompts = lambda tknzr, prmts: [pt.tensor(tknzr.encode(p)).to(d) for p in prmts]\n",
    "enc_listset = lambda tknzr, Xs: [[[pt.tensor(tknzr.encode(p + suffix)).to(d) for p in ps] for ps in X] for (X, suffix) in Xs]\n",
    "lprompts_encoded, lprompts_encoded3 = enc_prompts(tokenizer, lprompts), enc_prompts(gpt3_tokenizer, lprompts)\n",
    "lprompts_sing_encoded, lprompts_sing_encoded3 =enc_prompts(tokenizer, lprompts_sing),enc_prompts(gpt3_tokenizer, lprompts_sing)\n",
    "Xs = (cats, ': '), (cats_sing, ': '), (phrases, ', ')\n",
    "(cats_e,cats_sing_e,phrases_e), (cats_e3,cats_sing_e3,phrases_e3) = enc_listset(tokenizer, Xs), enc_listset(gpt3_tokenizer, Xs)\n",
    "comma_token = pt.tensor(tokenizer.encode(\"a,\")[1], device=d)\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)\n",
    "lidstone_eps = pt.tensor(lidstone_eps, device=d) if not isinstance(lidstone_eps, pt.Tensor) else lidstone_eps\n",
    "lidstone_value = lidstone_eps / N_tokens\n",
    "y_zero = (lidstone_value).repeat(N_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1105\n",
      "GPT2 device: cuda:0\n",
      "Pretrained parameters loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in locals():  # Load pretrained weights\n",
    "    del model\n",
    "print(gc.collect()), pt.cuda.empty_cache()\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2LMHead\")\n",
    "model_ = GPT2LMHeadModel.from_pretrained(gpt2_modelkey,\n",
    "    output_hidden_states=False, output_attentions=False, \n",
    "    cache_dir=\"models/pretrained/GPT2LMHead\")\n",
    "if pt.cuda.device_count() > 1:\n",
    "    device_map = {0: [0, 1, 2],\n",
    "                  1: [3, 4, 5, 6, 7, 8],\n",
    "                  2: [9, 10, 11, 12, 13, 14],\n",
    "                  3: [15, 16, 17, 18, 19, 20],\n",
    "                  4: [21, 22, 23, 24, 25, 26, 27],\n",
    "                  5: [28, 29, 30, 31, 32, 33, 34],\n",
    "                  6: [35, 36, 37, 38, 39, 40, 41],\n",
    "                  7: [42, 43, 44, 45, 46, 47],\n",
    "                 }\n",
    "    model_.parallelize(device_map)\n",
    "else:\n",
    "    model_ = model_.to(d)\n",
    "print(\"GPT2 device:\", model_.device)\n",
    "model_.resize_token_embeddings(N_tokens)\n",
    "pad_token = model_.config.pad_token_id = model_.config.eos_token_id\n",
    "pad_token = pt.tensor(pad_token, device=d)\n",
    "repl_token = pt.tensor(tokenizer.encode(lastcomma_repl)[0], device=d) if lastcomma_repl != 'EOS' else pad_token\n",
    "n_embd = pt.tensor(model_.config.n_embd, device=d)\n",
    "# model = nn.parallel.DistributedDataParallel(model_, device_ids=[d])\n",
    "# model = nn.DataParallel model_, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else model_\n",
    "model = model_\n",
    "mname_fn = gpt2_modelkey\n",
    "print(\"Pretrained parameters loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1, device=d)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def inference(x, sqlens, past=None, return_states=False, seq_maxlen=max_len, add=0, return_fulloutput=False):\n",
    "    global model\n",
    "\n",
    "    multitoken = x.shape[1] > 1\n",
    "    mask = sequence_mask(sqlens, seq_maxlen) if (multitoken or add != 0) else None\n",
    "    if add > 0: mask = pt.cat([mask, pt.ones(mask.shape[0], add).to(d)], dim=1)  # Append mask entry for new stream token\n",
    "    outputs = model(x.long(), attention_mask=mask, use_cache=None if not return_states else True, past_key_values=past)\n",
    "    if return_fulloutput: return outputs\n",
    "    logits = outputs[0][[pt.arange(x.shape[0]), sqlens - 1]] if multitoken else outputs[0].squeeze(1)\n",
    "\n",
    "    return (logits, outputs[1]) if return_states else logits  # Optionally return the past states needed to restore the stream\n",
    "def adapt_form(xs, ys, sqlens, mlen=max_len, repl_finalcomma=True):\n",
    "    xs = pt.vstack([F.pad(x, (0, max(0, mlen - len(x))), mode='constant', value=pad_token)[:mlen] for x in xs])\n",
    "    _ys = pt.vstack(ys) if ys is not None else None\n",
    "    if repl_finalcomma and (lastcomma_repl != ',') and ys is not None:\n",
    "        _ys[:, repl_token] += _ys[:, comma_token] - lidstone_value\n",
    "        _ys[:, comma_token] = lidstone_value\n",
    "    return xs, _ys, pt.tensor(sqlens, device=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s_avglogs(X, use_log_probs=True):\n",
    "    tokens = [pt.tensor(tokenizer.encode(x)).to(d) for x in X]\n",
    "    sqlens = [len(x) for x in tokens]\n",
    "    n_bats = (len(sqlens) // batch_size) + 1\n",
    "    res = []\n",
    "    for i in range(n_bats):\n",
    "        tokens_b, sqlens_b = tokens[i * bsz:(i + 1) * bsz], sqlens[i * bsz:(i + 1) * bsz]\n",
    "        xs, _, sqlen = adapt_form(tokens_b, None, sqlens_b, mlen=max(sqlens_b))\n",
    "        logits = inference(xs, sqlen, seq_maxlen=max(sqlens_b), return_fulloutput=True)[0]\n",
    "        pt.cuda.empty_cache()\n",
    "        logits = pt.stack(logits, 0)\n",
    "        for i in range(len(sqlens_b)):\n",
    "            x_logits = [logits[i][j] for j in range(sqlens_b[i])]\n",
    "            x_logs = ([F.softmax(logits[i][j])[tokens_b[i][j]] for j in range(sqlens_b[i])] if \\\n",
    "                      use_log_probs else x_logits).cpu().detach().numpy()\n",
    "            res.append(np.mean(x_logs[1:]))  # ignore initial prefix token 'A'/'An'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phrases = list(set(sum(phrases, [])))\n",
    "vowels = 'aeiuo'\n",
    "phrase_lprobs = get_s_avglogs([('An' if p[0].lower() in vowels else 'A') + ' ' + p for p in all_phrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "phrase_lprob = dict(zip(all_phrases, phrase_lprobs))\n",
    "all_phrases_enc = sum([[tuple(p_.cpu().detach().numpy().tolist()) for p_ in p] for p in phrases_e], [])\n",
    "enc_phrase_lprob = dict(zip(list(set(all_phrases_enc)), phrase_lprobs))\n",
    "max_phrase_lprob = np.percentile(phrase_lprobs, 100 * (1.0 - train_phrase_lprob_pctile))\n",
    "plt.hist(phrase_probs, bins=250)\n",
    "plt.axvline(x=min_phrase_lprob, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p, ra=True, rng=rng_train, mlen=max_len):  # prmt = prompt tokens, p = list phrase/word tokens\n",
    "    tkzs, sent, tkix, wordix = [], [], 0, -1   # rng is the inclusive range of list lengths to generate (number of phrases)\n",
    "    min_nw, max_nw, min_nt, max_nt = rng[0], int(rng[1]), 0, int(mlen) - len(prmt)\n",
    "    p_ra = [i for i in range(len(p)) if enc_phrase_lprob[tuple(p[i].cpu().detach().numpy().tolist())] > max_phrase_lprob]\n",
    "    p_incl = [i for i in range(len(p)) if i not in p_ra]\n",
    "    incl_words = np.random.choice(len(p), min(len(p), max_nw), replace=False)\n",
    "    p_ra_chosen = [i for i in incl_words if i in p_ra]\n",
    "    min_nw -= len(p_ra_chosen)\n",
    "    incl_words = [i for i in incl_words if i in p_incl]\n",
    "    if len(incl_words) == 0:  # rare when train_phrase_lprob_pctile is low enough and min_nw is high enough\n",
    "        return gen_truncated_list(prmt, p, ra=ra, rng=rng, mlen=mlen)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc, wordix = p[phz_i], wordix + 1\n",
    "        tkzs.append((tkix, phz_enc)), sent.append(phz_enc)\n",
    "        tkix += len(phz_enc)\n",
    "        if wordix < min_nw: min_nt = tkix\n",
    "        if tkix >= max_nt:\n",
    "            tkix = max_nt\n",
    "            break\n",
    "    if min_nt - 1 >= tkix:  # rare when max_len is large enough (0.5x max possible total list length) (temporary optimisation)\n",
    "        return gen_truncated_list(prmt, p, ra=ra, rng=rng, mlen=mlen)\n",
    "    sent = pt.hstack(sent)[:max_nt]                                       # If we don't want to include outliers in target\n",
    "    missing_w = [p[i] for i in range(len(p)) if (i not in incl_words) and (True if ra else (i not in p_ra))]\n",
    "    trunc_ix = np.random.randint(min_nt - 1, tkix)\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if len(enc) >= trunc_n and all(enc[:trunc_n] == partial_phr)]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_eps)\n",
    "    tunit, y_ = pt.tensor(1 / norm, device=d), y_zero.clone()\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return pt.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def stac_sample(stac, n):   # Create batches by random permutations (maximise diversity and uniformity) (shuffling done later)\n",
    "    r, mode, total = [], tuple(np.unique(stac)), stac.shape[0]\n",
    "    while n > 0:\n",
    "        if mode == (0,) or mode == (1,) or mode == (-1,):\n",
    "            if n >= total:\n",
    "                new = sum([list(range(total)) for _ in range(n // total)], [])\n",
    "                r += new\n",
    "                n -= len(new)\n",
    "            else:\n",
    "                new = np.random.choice(total, n, replace=False)\n",
    "                stac[new] = (mode[0] + 1) if mode != (1,) else -1\n",
    "                r += new.tolist()\n",
    "                n = 0\n",
    "        else:\n",
    "            old_val, new_val = mode[0] if mode != (-1, 1) else 1, mode[1] if mode != (-1, 1) else -1\n",
    "            old_i = np.nonzero(stac == old_val)[0]\n",
    "            if n >= old_i.shape[0]:\n",
    "                stac[old_i] = new_val\n",
    "                r += old_i.tolist()\n",
    "                n -= old_i.shape[0]\n",
    "            else:\n",
    "                new = np.random.choice(old_i, n, replace=False)\n",
    "                stac[new] = new_val\n",
    "                r += new.tolist()\n",
    "                n = 0\n",
    "        mode = tuple(np.unique(stac))\n",
    "    return r\n",
    "def gen_listname(cp, cp_cs, prompt, prmt, tknzr=tokenizer):\n",
    "    cat_ix = np.random.randint(len(cp_cs))            # First uniformly sample a category title\n",
    "    sing = use_correct_nouns and (cat_ix >= len(cp))  # Singular vs plural prompt prefix\n",
    "    if prompt is None:                                # Uniformly sample a list beginning phrase (\"A list of...\") if not given\n",
    "        lprmpts = ((lprompts_sing_encoded if sing else lprompts_encoded) if tknzr is tokenizer else \\\n",
    "                   (lprompts_sing_encoded3 if sing else lprompts_encoded3)) if tknzr is not None else \\\n",
    "                   (lprompts_sing if sing else lprompts)\n",
    "        prmt = lprmpts[np.random.randint(len(lprmpts))]\n",
    "    return cp_cs[cat_ix], prmt\n",
    "def gen_listnames_uniform(xcp, xcs, xp, n, prompt=None, tknzr=tokenizer, verbose=False, stac=None):\n",
    "    prmts, cats, ps, j, prmt = [], [], [], 0, None\n",
    "    if prompt is not None and tknzr is not None: prmt = pt.tensor(tknzr.encode(prompt), device=d)\n",
    "    stac_, stac = stac_sample(stac, n) if (stac is not None) else None, stac is not None\n",
    "    if stac: np.random.shuffle(stac_)\n",
    "    for i in (range(len(xcp)) if not stac else stac_):\n",
    "        prmts_, cats_ = [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        for m in range(n if not stac else 1):\n",
    "            cat, prmt = gen_listname(cp, cp_cs, prompt, prmt, tknzr=tknzr)\n",
    "            prmts_.append(prmt), cats_.append(cat)\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0: sys_print(\"\\rGenerating list names, done: \" + str(j))\n",
    "        ps.append(p), prmts.append(prmts_), cats.append(cats_)\n",
    "    if verbose: sys_print(\"\\rGenerating list names, done: \" + str(j) + \", finished!\\n\")\n",
    "    return prmts, cats, ps, stac\n",
    "def gen_samples_uniform(xcp, xcs, xp, n,              # Weight testing samples (word lists) exactly uniformly\n",
    "                        ra=True, rng=rng_train, prompt=None, tknzr=tokenizer, verbose=False, inds=False, stac=None, mlen=1e9):\n",
    "    xs, ys, sqlens, j, prmt = [], [], [], 0, None\n",
    "    prmts, cats, ps, stac = gen_listnames_uniform(xcp, xcs, xp, n, prompt=prompt, tknzr=tknzr, verbose=verbose, stac=stac)\n",
    "    for i in range(len(prmts)):\n",
    "        x, y, sqlen, p = [], [], [], ps[i]\n",
    "        for k in range(len(prmts[i])):\n",
    "            x_, y_ = gen_truncated_list(pt.hstack([prmts[i][k], cats[i][k]]), p, ra=ra, rng=rng, mlen=mlen)\n",
    "            x.append(x_), y.append(y_), sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0: sys_print(\"\\rGenerating list elements, done: \" + str(j))\n",
    "        xs.append(x), ys.append(y), sqlens.append(sqlen)\n",
    "    if inds or stac: xs, ys, sqlens = sum(xs, []), sum(ys, []), sum(sqlens, [])\n",
    "    if verbose: sys_print(\"\\rGenerating list elements, done: \" + str(j) + \", finished!\\n\")\n",
    "    return (xs, ys, sqlens, np.arange(len(xcp)).repeat(n)) if inds else (xs, ys, sqlens)\n",
    "def gen_samples(xcp, xcs, xp, n,\n",
    "                ra=True, rng=rng_train, prompt=None, tknzr=tokenizer, inds=False, mlen=1e9):\n",
    "    xs, ys, sqlens, j, prmt = [], [], [], 0, None   \n",
    "    if prompt is not None and tknzr is not None: prmt = pt.tensor(tknzr.encode(prompt), device=d)\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets, indices = len(xcp), []\n",
    "    for m in range(n):  # Maximise per-batch training diversity by randomly sampling the word lists\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        cat_ix, prmt = gen_listname(cp, cp_cs, prompt, prmt)\n",
    "        x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p, ra=ra, rng=rng, mlen=mlen)\n",
    "        xs.append(x_), ys.append(y_), sqlens.append(len(x_)), indices.append(i)\n",
    "    return (xs, ys, sqlens, np.asarray(indices)) if inds else (xs, ys, sqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  8 21  4  7  5 10 25] [14 11  1 19 24 31 18 32]\n",
      "Train\n",
      " ['round fruits', 'microorganisms', 'outback experiences', 'buildings', 'holed pasta', 'rod shaped pasta', 'sounds of a building', 'biological examples of math in nature', 'non-biological examples of math in nature', 'handcrafts', 'communication media', 'storage media', 'scientific principles behind showers', 'scientific principles behind rain showers', 'spacecraft types', 'real spacecrafts', 'interpersonal tokens of trust'] \n",
      "Validation\n",
      " ['construction sounds', 'hats', 'wild animals', 'woodland ecoregions', 'winds', 'physical tokens that confer trust', 'timbers', 'digital tokens that confer trust'] \n",
      "Test\n",
      " ['chemical elements', 'dramatic and literature elements', 'vehicles referred to as crafts', 'music', 'scientific cycles', 'machine learning algorithms', 'glassware', 'windings']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-ef2accd587bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mcats_e_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcats_sing_e_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphrases_e_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphase_listsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"default\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mval_cats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mtest_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sqlens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_samples_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcats_e_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcats_sing_e_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphrases_e_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTsN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mval_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sqlens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_samples_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcats_e_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcats_sing_e_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphrases_e_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTsN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-84-e23b9556a9e0>\u001b[0m in \u001b[0;36mgen_samples_uniform\u001b[1;34m(xcp, xcs, xp, n, ra, rng, prompt, tknzr, verbose, inds, stac, mlen)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprmts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mx_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_truncated_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprmts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqlen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mj\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-84-e23b9556a9e0>\u001b[0m in \u001b[0;36mgen_truncated_list\u001b[1;34m(prmt, p, ra, rng, mlen)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mmissing_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mincl_words\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mra\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mp_ra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mtrunc_ix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_nt\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtkix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mtrunc_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrunc_ix\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtkzs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mix\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mtrunc_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# N. end phrase tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mmissing_w\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0menc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtkzs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mix\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrunc_ix\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrunc_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mmissing_matches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing_w\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "N_test, N_val = int(test_frac * N_wordlists), int(val_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "# test_idx = np.random.choice(N_train, N_test, replace=False)\n",
    "test_idx = np.asarray([ 2,  8, 21,  4,  7,  5, 10, 25])\n",
    "save_ld(test_idx, \"test_idx\")\n",
    "# test_idx = load_ld(\"test_idx\")\n",
    "trval_idx = np.asarray([i for i in range(N_wordlists) if i not in test_idx])\n",
    "# val_idx = np.random.choice(trval_idx, N_val, replace=False)\n",
    "val_idx = np.asarray([14, 11,  1, 19, 24, 31, 18, 32])\n",
    "save_ld(val_idx, \"val_idx\")\n",
    "# val_idx = load_ld(\"val_idx\")\n",
    "train_idx = np.asarray([i for i in trval_idx if i not in val_idx])\n",
    "print(test_idx, val_idx)\n",
    "print(*sum([[c+'\\n',[cats[i][0] for i in ix]]for(c,ix)in[[\"Train\",train_idx],[\"\\nValidation\",val_idx],[\"\\nTest\",test_idx]]],[]))\n",
    "index_listset, listset_iXs = lambda inds, Xs: [[X[i] for i in inds] for X in Xs],(\"trval_idx\",\"train_idx\",\"val_idx\",\"test_idx\")\n",
    "phase_listsets = {None: {k[:-4]: index_listset(globals()[k], (cats, cats_sing, phrases)) for k in listset_iXs},\n",
    "             \"default\": {k[:-4]: index_listset(globals()[k], (cats_e, cats_sing_e, phrases_e)) for k in listset_iXs},\n",
    "                \"gpt3\": {k[:-4]: index_listset(globals()[k], (cats_e3, cats_sing_e3, phrases_e3)) for k in listset_iXs}}\n",
    "cats_e_test, cats_sing_e_test, phrases_e_test = phase_listsets[\"default\"][\"test\"]\n",
    "cats_e_val, cats_sing_e_val, phrases_e_val = phase_listsets[\"default\"][\"val\"]\n",
    "val_cats = [cats[i][0] for i in val_idx]\n",
    "test_xs, test_ys, test_sqlens = gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, TsN, mlen=max_len)\n",
    "val_xs, val_ys, val_sqlens = gen_samples_uniform(cats_e_val, cats_sing_e_val, phrases_e_val, TsN, mlen=max_len, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function that takes a prompt, existing list and sampling params and returns gpt3's next token probs\n",
    "default_msp = {\n",
    "  \"best_of\": 1,\n",
    "}\n",
    "default_sp = {\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "#   \"top_k\": -1.0,                 # todo: add code to apply this to gpt3 output (top100), max k ~=90, min = 2?\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "}\n",
    "default_params = {\n",
    "  \"engine\": \"davinci\",\n",
    "  \"model\": None,\n",
    "  \"max_tokens\": 1,\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "#   \"top_k\": -1.0,\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "  \"n\": 1,\n",
    "  \"stream\": False,\n",
    "  \"logprobs\": 100,\n",
    "#       \"logit_bias\": {\"50256\": -100},\n",
    "  \"stop\": [\",\", \"\\n\"],\n",
    "}\n",
    "# Define and test the OpenAI API next token probability request (response-token-efficient streaming version)\n",
    "def format_gpt3_probs(choice, tokenize):\n",
    "    res, r = [], sorted([(np.e**v, k) for (k, v) in choice[\"logprobs\"][\"top_logprobs\"][0].items()])[::-1]\n",
    "    for i in range(len(r)):\n",
    "        k = gpt3_tokenizer.encode(r[i][1])\n",
    "        if len(k) == 1: res.append((r[i][0], k if tokenize else r[i][1]))\n",
    "    return res\n",
    "def p_req(s, tokenize=False, **kwargs):\n",
    "    use_stream = \"max_tokens\" in kwargs and kwargs[\"max_tokens\"] != 1\n",
    "    kwargs[\"prompt\"], kwargs[\"stream\"] = s, use_stream\n",
    "    with io.capture_output() as captured:\n",
    "        response, result = openai.Completion.create(**{**default_params, **kwargs}), []\n",
    "    return [(np.e**resp[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0], resp[\"choices\"][0][\"logprobs\"][\"tokens\"][0],\n",
    "             format_gpt3_probs(resp[\"choices\"][0], tokenize)) for resp in (response if use_stream else [response])]\n",
    "# todo: version to handle multiple choices for phrase level evaluation (response-token-expensive)\n",
    "def p_req_m(s, tokenize=False, **kwargs):\n",
    "    if \"max_tokens\" not in kwargs: kwargs[\"max_tokens\"] = 8\n",
    "    if \"n\" not in kwargs: kwargs[\"n\"] = 5\n",
    "    if \"best_of\" in kwargs:\n",
    "        kwargs[\"best_of\"] = int(round(kwargs[\"best_of\"]))\n",
    "        if kwargs[\"n\"] != 1: kwargs[\"best_of\"], kwargs[\"n\"] = kwargs[\"n\"], kwargs[\"best_of\"]\n",
    "    kwargs[\"prompt\"] = s\n",
    "    with io.capture_output() as captured:\n",
    "        response, tokens, probs = openai.Completion.create(**{**default_params, **kwargs}), [], []\n",
    "    for choice in response[\"choices\"]:\n",
    "        tks = [np.e**v for v in choice[\"logprobs\"][\"token_logprobs\"]]\n",
    "        tks = [(choice[\"logprobs\"][\"tokens\"][i], tks[i]) for i in range(len(tks))]\n",
    "        tokens.append(tks), probs.append(format_gpt3_probs(choice, tokenize))\n",
    "    return tokens, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = p_req(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "# b = p_req_m(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "# print(sum([a_[0] for a_ in a[0][2]]))\n",
    "# print(','.join([''.join([b__[0] for b__ in b_]) for b_ in b[0]] + [''.join([a_[1] for a_ in a])]).replace('\\n', '⏎'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a completion distribution (top 100) and target next token distribution (multinomial) and computes the\n",
    "# probability that the completion produces a desired output token\n",
    "def prob_corr(pred_p, target_p):\n",
    "    r = 0\n",
    "    if isinstance(pred_p, list):\n",
    "        for (p, token) in pred_p:\n",
    "            if target_p[token] > (lidstone_value + 1e-10): r += p\n",
    "    else:\n",
    "        r = np.sum(target_p[np.nonzero(pred_p > (lidstone_value + 1e-10))[0]])\n",
    "    return r\n",
    "# directly computes the similarity between target and predicted token distributions\n",
    "def score_corr(pred_p, target_p, distance=\"cross-entropy\", redistribute_mass=False, include_negatives=False):  \n",
    "    r = 0\n",
    "    if isinstance(pred_p, list) and not redistribute_mass:\n",
    "        for (p, token) in pred_p:\n",
    "            targ = target_p[token]\n",
    "            if targ > (lidstone_value + 1e-10) or include_negatives:\n",
    "                if   distance == \"unnormalized\":  r -= p * targ\n",
    "                elif distance == \"cross-entropy\": r -= p * np.log(targ)\n",
    "                elif distance == \"kl-divergence\": r += p * np.log(p / targ)\n",
    "                elif distance == \"bhattacharyya\": r += np.sqrt(p * targ)\n",
    "        if distance == \"bhattacharyya\": r = -np.log(r)\n",
    "    else:\n",
    "        p = pred_p\n",
    "        if isinstance(pred_p, list):\n",
    "            p_ = np.asarray([p for (p, _) in pred_p])\n",
    "            ts = np.asarray([t for (_, t) in pred_p])\n",
    "            unaccounted_mass = 1.0 - sum(p_)\n",
    "            n_missing_tokens = N_tokens - len(pred_p)\n",
    "            p = np.repeat(unaccounted_mass / n_missing_tokens, N_tokens)\n",
    "            p[ts] = p_\n",
    "        if not include_negatives:\n",
    "            pos = np.nonzero(target_p > (lidstone_value + 1e-10))[0]\n",
    "            p, target_p = p[pos], target_p[pos]\n",
    "        if   distance == \"unnormalized\":  r = -np.sum(p * targ)\n",
    "        elif distance == \"cross-entropy\": r = -np.sum(p * np.log(target_p))\n",
    "        elif distance == \"kl-divergence\": r =  np.sum(p * np.log(p / target_p))\n",
    "        elif distance == \"bhattacharyya\": r = -np.log(np.sum(np.sqrt(p * target_p)))\n",
    "    return -r\n",
    "# probability that a completion phrase is a desired missing list entry\n",
    "def prob_msp(outs, missing):\n",
    "    correct = 0\n",
    "    missing = set([phrase.lower() for phrase in missing])\n",
    "    for i in range(len(outs)):\n",
    "        out = outs[i].strip().lower()\n",
    "        if out not in missing and (out[:4] == 'the '): out = out[4:]\n",
    "        if out in missing: correct += 1\n",
    "    return correct / len(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   ' Fermi-Pasta-Ulam problem,',\n",
      "        array([  376,  7780,    72,    12, 34533,    64,    12,    52,  2543,\n",
      "        1917,    11]),\n",
      "        11),\n",
      "    (   ' maccheroncini di campofilone,',\n",
      "        array([8352, 2044,  261,   66, 5362, 2566, 1413, 1659,  346,  505,   11]),\n",
      "        11)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = sum([[len(p) for p in p_ if len(p) < 1000] for p_ in phrases_e], [])  # Print longest list elements in dataset, get max\n",
    "phrs = sum([[p for p in p_ if len(p) < 1000] for p_ in phrases_e], [])\n",
    "m = np.max(lens)\n",
    "inds = [i for i in range(len(phrs)) if lens[i] == m]\n",
    "ree = [(tokenizer.decode(phrs[i].cpu().detach().numpy()), phrs[i].cpu().detach().numpy(), lens[i]) for i in inds]\n",
    "phrl_max = len(ree[0][1]) - 1\n",
    "pr(ree)\n",
    "phrl_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes sampling parameters, then generates n random incomplete list prompts (of length l), obtains completion\n",
    "# distributions (top 100 tokens or full multinomial) and evaluates the average score across the n prompts. n = 20 by default\n",
    "# All samples generated are stored fully for later training of sample-dependent sampling parameter (mixture) distribution\n",
    "sps_ = [\"top_p\", \"temperature\", \"presence_penalty\", \"frequency_penalty\"]  # sampling params                          #top_k\n",
    "msps_= sps_#[\"best_of\"] + sps_                                                 # meta sampling params\n",
    "create_folder(data_dir + learning_data_dir)\n",
    "create_folder(data_dir + learning_data_dir + \"sp_samples\")\n",
    "create_folder(data_dir + learning_data_dir + \"sp_samples_test\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_samples_nb\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_samples_nb_test\")\n",
    "phaseIx = lambda phase: globals()[phase + '_idx']\n",
    "def save_modeloutput(idx, dname, pnames, params, r, min_l, max_l, mdl, xs=None, ys=None, sqlens=None, inds=None, d=None):\n",
    "    engine_str = ','.join([str(params[k]) for k in [\"engine\", \"model\"] if k in params])\n",
    "    for i_raw in range(len(idx)):\n",
    "        i = idx[i_raw]\n",
    "        create_folder(data_dir + learning_data_dir + dname + \"/\" + str(i))\n",
    "        ix, mdl_name = np.nonzero(inds == i_raw)[0], mdl if isinstance(mdl, str) else mdl[\"name\"]\n",
    "        fn = str(time.time()) + '_' + '_'.join([str(v) for v in [params[k] for k in pnames] + [min_l, max_l]]) + '_' + mdl_name\n",
    "        input_data = [d[j] for j in ix] if d else [xs[ix], ys[ix], sqlens[ix]]\n",
    "        save_ld((params, input_data, ix, [r[j] for j in ix], str(mdl)), dname + \"/\" + str(i) + \"/\" + fn, compress=9)\n",
    "def eval_sp(params, min_l=0, max_l=1e9, n=20, prmt=None, phase=\"train\", uniform=True, mdl='gpt3'):\n",
    "    res, max_l = [], int(max_l), \n",
    "    tknzr = gpt3_tokenizer if mdl == \"gpt3\" else tokenizer\n",
    "    xcp, xcs, xp = phase_listsets[\"gpt3\" if mdl == \"gpt3\" else \"default\"][phase]\n",
    "    xs, ys, sqlens, inds = gen_samples_uniform(xcp, xcs, xp, n, prompt=prmt, tknzr=tknzr, inds=True, rng=[min_l, max_l]) \\\n",
    "           if uniform else gen_samples        (xcp, xcs, xp, n, prompt=prmt, tknzr=tknzr, inds=True, rng=[min_l, max_l])\n",
    "    if mdl == 'gpt3': r = [p_req(gpt3_tokenizer.decode(x_.detach().cpu().numpy()), **params) for x_ in xs] \n",
    "    else:             r = mdl[\"probabilities\"](xs, ys, sqlens, **params)\n",
    "    save_modeloutput(phaseIx[phase][np.unique(inds)], \"sp_samples\", sps_, params, r, min_l, max_l, mdl, xs, ys, sqlens, inds)\n",
    "    return np.mean([score_corr(r[i], ys[i]) for i in range(len(r))])\n",
    "def eval_sp_conv(params, tol=0.01, **kwargs):\n",
    "    center, samples = np.inf, []\n",
    "    while True:\n",
    "        samples.append(eval_sp(params, n=2, **kwargs))\n",
    "        new_center = np.mean(samples)\n",
    "        if abs(center - new_center) < tol: return new_center, samples\n",
    "        new_center = center\n",
    "# This metric differs depending on tokenisation, so for the testing of models, a full phrase accuracy function is required\n",
    "def gen_phraselevel_samples_uniform(phase, min_l, max_l, n, prmt):\n",
    "    xcp, xcs, xp = phase_listsets[None][phase]\n",
    "    d, (prmts, cats, ps, _) = [], gen_listnames_uniform(xcp, xcs, xp, n, prompt=prmt, tknzr=None)\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen, p = [], [], [], ps[i]\n",
    "        for m in range(n):\n",
    "            prompt, cat = prmts[i][m], cats[i][m]\n",
    "            phr_ix = np.random.choice(len(p), np.random.randint(min_l, min(max_l, len(p) - 1)), replace=False)\n",
    "            missing_ix = [i for i in range(len(p)) if i not in phr_ix]\n",
    "            prompt = (prompt + ' ' + cat + ': ' + ''.join([p[j] + ', ' for j in phr_ix]))[:-1]\n",
    "            d.append([prompt, [p[j] for j in missing_ix]])\n",
    "    return d, np.arange(len(xcp)).repeat(n)\n",
    "strip_the = lambda x: x[4:] if x.lower()[:4] == 'the ' else x\n",
    "strip_tl = lambda x: strip_the(x.strip().lower())\n",
    "strip_comma = lambda x: [x_.strip() for x_ in (x[:-1] if len(x) > 1 else x)]\n",
    "strip_lower = lambda x: [strip_tl(x_) for x_ in (x[:-1] if len(x) > 1 else x)]\n",
    "def ensemble_two_models_results(m2ensemble_frac, r, r2):\n",
    "    bof = len(r[0])\n",
    "    n_replace = int(bof * m2ensemble_frac)\n",
    "    r_new = [[strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_] for r_ in r]\n",
    "    for i in range(len(r)):\n",
    "        cur_pool = set(sum([strip_lower(''.join([r__[0] for r__ in r_]).split(',')) for r_ in r[i][:bof - n_replace]], []))\n",
    "        new_pool = sum([strip_comma(''.join([r__[0] for r__ in r_]).split(',')) for r_ in r2[i]], [])\n",
    "        for j in range(n_replace):\n",
    "            n_phrases = len(r[i][j])\n",
    "            add = []\n",
    "            while len(add) < n_phrases and len(new_pool) > 0:\n",
    "                new_phr = new_pool[0]\n",
    "                stripped_new_phr = strip_tl(new_phr)\n",
    "                if stripped_new_phr not in cur_pool:\n",
    "                    add.append(new_phr), cur_pool.add(stripped_new_phr)\n",
    "                new_pool = new_pool[1:]\n",
    "            if len(add) > 0:\n",
    "                r_new[i][j + bof - n_replace] = add\n",
    "    return [sum(r_, []) for r_ in r_new]\n",
    "def test_sp(params, min_l=0, max_l=1e9, n1=3, n2=10, prmt=None, phase=\"train\", uniform=True, max_tokens=phrl_max,\n",
    "            mdl='gpt3', mdl2=None, d=None, d_test=None, inds=None, inds_test=None, m2ensemble_frac=0.4, return_test_acc=True):\n",
    "    max_l, test_acc, dn = int(max_l), None, \"msp_samples_nb\"\n",
    "    if d is None: d, inds = gen_phraselevel_samples_uniform(phase, min_l, max_l, n1, prmt)\n",
    "    params = {**default_sp, **params, **{'n': n2, 'max_tokens': max_tokens}} #**default_msp,\n",
    "    if mdl == 'gpt3': r = [p_req_m(d_[0], **params)[0] for d_ in d]  # Request predictions from OpenAI\n",
    "    else:             r = mdl[\"completions\"]([d_[0] for d_ in d], **params)\n",
    "    save_modeloutput(phaseIx(phase), dn, msps_, params, r, min_l, max_l, mdl, d=d, inds=inds)\n",
    "    if mdl2 is not None:\n",
    "        if mdl2 == 'gpt3': r2 = [p_req_m(d_[0], **params)[0] for d_ in d]# Ensemble with 2nd model according to m2ensemble_frac\n",
    "        else:              r2 = mdl2[\"completions\"]([d_[0] for d_ in d], **params)# This loads precomputed outputs so no resave\n",
    "        r = ensemble_two_models_results(m2ensemble_frac, r, r2)\n",
    "    else:\n",
    "        r = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_], []) for r_ in r]\n",
    "    #     r = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(','))[:max_l - min_l] for r__ in r_], []) for r_ in r]\n",
    "    acc = np.mean([prob_msp(r[i], d[i][1]) for i in range(len(r))])\n",
    "\n",
    "    if phase != \"test\":  # if not testing finalised parameters, also output the test set accuracy\n",
    "        listset_fracs = {\"train\": 1 - (val_frac + test_frac), \"trval\": 1 - test_frac, \"val\": val_frac, \"test\": test_frac}\n",
    "        n1_ = n1 * int(listset_fracs[phase] / test_frac)  # Use approximately enough samples to converge\n",
    "        if d_test is None: d_test, inds_test = gen_phraselevel_samples_uniform(\"test\", min_l, max_l, n1_, prmt)\n",
    "        if mdl == 'gpt3': r_test = [p_req_m(d_[0], **params)[0] for d_ in d_test]\n",
    "        else:             r_test = mdl[\"completions\"]([d_[0] for d_ in d_test], **params)\n",
    "        save_modeloutput(phaseIx(\"test\"), dn+\"_test\", msps_, params, r_test, min_l, max_l, mdl, d=d_test, inds=inds_test)\n",
    "        if mdl2 is not None:\n",
    "            if mdl2 == 'gpt3': r2_test = [p_req_m(d_[0], **params)[0] for d_ in d_test]\n",
    "            else:              r2_test = mdl2[\"completions\"]([d_[0] for d_ in d_test], **params)\n",
    "            r_test = ensemble_two_models_results(m2ensemble_frac, r_test, r2_test)\n",
    "        else:\n",
    "            r_test = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_], []) for r_ in r_test]\n",
    "#r_test =[sum([strip_comma(''.join([r___[0] for r___ in r__]).split(','))[:max_l - min_l] for r__ in r_], []) for r_ in r_test]\n",
    "        samps = np.asarray([prob_msp(r_test[i], d_test[i][1]) for i in range(len(r_test))])\n",
    "        test_sd = np.std(100*samps)\n",
    "        test_acc = np.mean(samps)\n",
    "        if not return_test_acc:\n",
    "            print(\"Test acc:\", 100*test_acc, \"sd:\", test_sd)\n",
    "\n",
    "    return (acc, test_acc) if return_test_acc else acc\n",
    "def test_sp_conv(params, tol=0.01, **kwargs):\n",
    "    center, ys, i, steps_nochange = np.inf, [], 1, 0\n",
    "    while True:\n",
    "        ys.append(test_sp(params, n1=1, **kwargs))\n",
    "        new_center = np.mean([s[0] for s in ys])\n",
    "        if abs(center - new_center) < tol: steps_nochange += 1\n",
    "        else:                              steps_nochange = 0\n",
    "        if steps_nochange >= 3 and i >= 5:\n",
    "            if ys[0][1] is not None: print([s[1] for s in ys])\n",
    "            print([s[0] for s in ys])\n",
    "            j = 1 if ys[0][1] is not None else 0\n",
    "            sys_print(str((\"Test acc:\", 100*np.mean([s[j] for s in ys]), \"sd:\", np.std([100*s[j] for s in ys])))+\"\\n\", False)\n",
    "            return new_center, ys\n",
    "        center = new_center\n",
    "        i += 1\n",
    "# eval_sp(default_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "curr_ri = np.zeros(len(train_idx), dtype=int)\n",
    "def next_batch(sz):\n",
    "    global phase_listsets, curr_ri\n",
    "    cats_, cats_sing_, phrases_ = phase_listsets[\"default\"][\"train\"]\n",
    "    return adapt_form(*gen_samples_uniform(cats_, cats_sing_, phrases_, sz, ra=False, stac=curr_ri, mlen=max_len))\n",
    "#     return adapt_form(*gen_samples(cats_, cats_sing_, phrases_, sz, ra=False, mlen=max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also create a gpt3 prompt-completion-based regression model to predict values/densities of sampling parameters (might work if\n",
    "# it's possible to find a humanlike transliteration of the problem statement that gpt3 can bootstrap on to find the params, or\n",
    "# to find some (possibly entirely textual) representation of a params-correlating multidimensional metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = None #nn.Linear(n_embd, N_tokens, bias=False).to(d)#.cpu()                  # Model definition\n",
    "# nn.init.xavier_uniform_(llayer.weight)\n",
    "# llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else llayer\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()#.to(d)#.cpu()\n",
    "# bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d) if dev != \"cpu\" else bcewl_loss\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, bsz, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(bsz)\n",
    "\n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)  # Get logits\n",
    "    logits = outputs[0][[pt.arange(x_batch.shape[0]), sqlens_batch - 1]]\n",
    "\n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lidstone_value + 1e-10)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lidstone_value + 1e-10)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = -1  # Batch 0 is the first iteration, where validation occurs without any training\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "out_str = ''\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, val_loss, val_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):  # Training loop function\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, val_loss, val_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        if batch_i > 0:\n",
    "            gc.collect()\n",
    "            if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "            b_loss, b_accuracy = train_step()\n",
    "            mname_fn = model_name\n",
    "            if verbose:\n",
    "                sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                          ' @ batch '+ str(batch_i) + ' (' + str(batch_i * batch_size) + ' samples) complete.                  ')\n",
    "            iter_loss.append(b_loss), iter_accuracy.append(b_accuracy)\n",
    "\n",
    "        if batch_i % log_period_batches == 0:  # Test on val set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            out_str = '\\n'\n",
    "            for i in range(N_val):\n",
    "                val_X, val_Y, val_Sqlens = adapt_form(val_xs[i], val_ys[i], val_sqlens[i], repl_finalcomma=batch_i > 0)\n",
    "                feed_batches = [range(len(val_X))[i * bsz:(i + 1) * bsz] for i in range((len(val_X) // bsz) + \\\n",
    "                                                                                        (1 if (len(val_X) % bsz) != 0 else 0))]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(val_X[inds], val_Y[inds], val_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls)), accuracy.append(np.mean(cs))\n",
    "                out_str += val_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]) + '\\n'\n",
    "            \n",
    "            val_l, val_a = np.mean(loss), np.mean(accuracy)\n",
    "            val_loss.append(val_l), val_accuracy.append(val_a)\n",
    "            if batch_i == 0: iter_loss, iter_accuracy = [val_l], [val_a]\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l), train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "\n",
    "#             if ((val_a > best_acc and val_a >= train_a) or \\\n",
    "            if ((val_a > best_acc) or \\\n",
    "              (batch_i // log_period_batches) == 1) and batch_i > 0:      # Save best accuracy model\n",
    "                best_acc = val_a\n",
    "                best_loss = val_l\n",
    "                best_acc_idx = batch_i // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "#                          \"llayer\": llayer.state_dict(),\n",
    "#                          \"softmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(out_str + \"Batch\", batch_i, ':', train_a, val_a, \"loss:\", train_l, val_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(val_accuracy, label='val acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                plt.yscale(\"log\")\n",
    "                g.plot(val_loss, label='val loss')\n",
    "                plt.yscale(\"log\")\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, val_accuracy, train_loss, val_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "construction sounds: 9.511158e-05, 0.86328125\n",
      "hats: 8.7992914e-05, 0.74609375\n",
      "wild animals: 7.336627e-05, 0.8359375\n",
      "woodland ecoregions: 8.869854e-05, 0.65234375\n",
      "winds: 9.004153e-05, 0.640625\n",
      "physical tokens that confer trust: 8.948342e-05, 0.5078125\n",
      "timbers: 9.020545e-05, 0.77734375\n",
      "digital tokens that confer trust: 9.287207e-05, 0.5\n",
      "Batch 600 : 0.7828125 0.6904297 loss: 7.390388e-05 8.847147e-05 Best: 0.7050781 8.916583e-05 idx: 47\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.7050781, 8.916583e-05)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gc.collect())  # Train ernst model\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pt.cuda.empty_cache(), gc.collect()  # Load best model (checkpoint)\n",
    "cpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "model.load_state_dict(cpoint['model'])\n",
    "bcewl_loss.load_state_dict(cpoint['bcewl_loss'])\n",
    "optimizer.load_state_dict(cpoint['optimizer'])\n",
    "scheduler.load_state_dict(cpoint['scheduler'])\n",
    "# llayer.load_state_dict(cpoint['llayer'])\n",
    "mname_fn = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_filtering(logits, tcounts=None, filter_value=-float('Inf'),  # Function to tune the output token distribution\n",
    "                  top_k=0, top_p=0.0, temperature=1.0, frequency_penalty=0.0, presence_penalty=0.0):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if tcounts is not None: logits -= (tcounts * frequency_penalty) + ((tcounts > 0) * presence_penalty)\n",
    "    logits /= temperature\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gprobs(s, past=None, return_sts=False, tcounts=None, add=0, **kwargs):  # Inference and sampling for tokens\n",
    "    global model\n",
    "    xs, mlen = None, None\n",
    "    if isinstance(s, tuple):    # s either list of token tensors or tuple of preformatted 2d tensors\n",
    "        xs, _, sqlen = s\n",
    "        mlen = max(sqlen)\n",
    "    else:\n",
    "        sqlen = [len(s_) for s_ in s]\n",
    "        mlen = max(sqlen)\n",
    "        xs, _, sqlen = adapt_form([pt.tensor(s_).to(d) for s_ in s], None, sqlen, mlen=mlen)\n",
    "    model.eval()\n",
    "    y_hat = inference(xs, sqlen, seq_maxlen=mlen, add=add, past=past, return_states=return_sts)\n",
    "    if return_sts: y_hat, states = y_hat\n",
    "    y_hat = pt.vstack([F.softmax(top_filtering(y_hat[i], tcounts[i] if tcounts is not None else None,\n",
    "                                               **kwargs), dim=0) for i in range(len(xs))])\n",
    "    return (y_hat, states) if return_sts else y_hat\n",
    "def append_next_token(sent, olen=None, top_k=-1, top_p=0.9, temperature=1.0):  # Interface for field testing\n",
    "    print(\"k =\", top_k, \", p =\", top_p, \", temp =\", temperature)\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    ou = tokens.copy()\n",
    "    tcounts = pt.zeros(N_tokens, dtype=int).to(d)\n",
    "    for token in tokens: tcounts[token] += 1\n",
    "    probs = gprobs([tokens], top_k=top_k, top_p=top_p, temperature=temperature, tcounts=[tcounts])[0]\n",
    "    token = pt.multinomial(probs, 1).detach().cpu().numpy()[0]\n",
    "    ou += [token]\n",
    "    prev_len = len(sent) if olen is None else olen\n",
    "    sent_new = tokenizer.decode(ou)\n",
    "    print(sent[:prev_len] + '➡' + sent_new[prev_len:])\n",
    "    return sent_new\n",
    "def gen_probs(s, **kwargs):  # Adapter for strings\n",
    "    inp = [tokenizer.encode(s_) for s_ in s]\n",
    "    return gprobs(inp, **kwargs)\n",
    "def gen_completions(s, n=1, max_tokens=8, best_of=1, **kwargs):  # Completion generator equivalent to OpenAI's for GPT3\n",
    "    gpu_multiplier = 0.25\n",
    "    n_bats, best_of, outputs = int(np.ceil(len(s) / int(bsz * gpu_multiplier))), int(round(best_of)), []\n",
    "    if n == 1 and best_of != 1: n, best_of = best_of, n\n",
    "    if best_of == 1 and n != 1: best_of = n\n",
    "    gc.collect()\n",
    "    for i in range(n_bats):\n",
    "        s_batch, tc_b = s[i * int(bsz * gpu_multiplier):(i + 1) * int(bsz * gpu_multiplier)], []\n",
    "        for s_ in s_batch:\n",
    "            tc = pt.zeros(N_tokens, dtype=int).to(d)\n",
    "            for t in tokenizer.encode(s_): tc[t] += 1\n",
    "            tc_b.append(tc)\n",
    "        p, sts = gen_probs(s_batch, return_sts=True, tcounts=tc_b, **kwargs)\n",
    "        sql_b = [len(tokenizer.encode(s_)) for s_ in s_batch]\n",
    "        mlen = max(sql_b)\n",
    "        sql_b = pt.tensor(sql_b).to(d)\n",
    "        tokens = pt.multinomial(p, n, replacement=True) \n",
    "        outs, avg_logprobs = [], [] # first use the (as yet undiverged) token distribution to generate n tokens for each sample\n",
    "        for j in range(n):\n",
    "            tks, tc_b_itr = tokens[:, j], [t.clone() for t in tc_b]\n",
    "            for j in range(len(tc_b_itr)): tc_b_itr[j][tks[j]] += 1\n",
    "            gc.collect(), pt.cuda.empty_cache()\n",
    "            p, st = gprobs((pt.unsqueeze(tks, -1), None, sql_b), past=sts, return_sts=True, tcounts=tc_b_itr, add=1, **kwargs)\n",
    "            su, ls, out = pt.log(p[pt.arange(p.shape[0]), tks]), pt.ones(p.shape[0]).to(d), [tks]\n",
    "            for token_i in range(max_tokens - 1):\n",
    "                t = pt.multinomial(p, 1).to(d)[:, 0]\n",
    "                out.append(t)\n",
    "                for j in range(len(tc_b_itr)): tc_b_itr[j][t[j]] += 1\n",
    "                cont = t != pad_token\n",
    "                ls += cont.int()\n",
    "                su += cont * pt.log(p[pt.arange(p.shape[0]), t])\n",
    "                if token_i == max_tokens - 1: break\n",
    "                p, st = gprobs((pt.unsqueeze(t,-1),None,sql_b), past=st,return_sts=True,tcounts=tc_b_itr,add=token_i+2,**kwargs)\n",
    "            outs.append(pt.vstack(out).T), avg_logprobs.append(su / ls)\n",
    "        gc.collect(), pt.cuda.empty_cache()\n",
    "        outs = pt.stack(outs, 1)\n",
    "        avg_logprobs = pt.vstack(avg_logprobs).T\n",
    "        s1 = outs.shape[0]\n",
    "        idx = pt.argsort(avg_logprobs, axis=1)[:, :best_of].repeat_interleave(max_tokens, 1).reshape(s1, best_of, max_tokens)\n",
    "        outs = pt.gather(outs, 1, idx)\n",
    "        outputs += [[[(tokenizer.decode([x_]),) for x_ in x] for x in o] for o in outs.cpu().detach().numpy()]\n",
    "#     pr([[''.join([x_[0] for x_ in x]) for x in o] for o in outputs])\n",
    "    return outputs\n",
    "mdl = {\"completions\": gen_completions, \"probabilities\": gprobs, \"name\": mname_fn + ',' + gpt2_modelkey, \"mstr\": str(model)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "[0.4270833333333333, 0.375, 0.3645833333333333, 0.59375, 0.26041666666666663, 0.40625, 0.28125, 0.21874999999999997, 0.25, 0.2604166666666667, 0.28125, 0.3020833333333333, 0.40625, 0.3854166666666667, 0.3333333333333333, 0.21875, 0.3333333333333333, 0.20833333333333331, 0.3020833333333333, 0.3333333333333333, 0.26041666666666663, 0.29166666666666663, 0.44791666666666663, 0.3958333333333333]\n",
      "[0.2916666666666667, 0.3333333333333333, 0.3333333333333333, 0.24999999999999997, 0.34375, 0.3020833333333333, 0.375, 0.3333333333333333, 0.20833333333333331, 0.3645833333333333, 0.40625, 0.5208333333333333, 0.375, 0.125, 0.2916666666666667, 0.16666666666666666, 0.5, 0.3125, 0.3229166666666667, 0.6458333333333333, 0.10416666666666666, 0.28125, 0.3333333333333333, 0.4375]\n",
      "('Test acc:', 33.07291666666667, 'sd:', 8.742401214372146)\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.3316  \u001b[0m | \u001b[0m 0.07272 \u001b[0m | \u001b[0m 0.3911  \u001b[0m | \u001b[0m 0.05755 \u001b[0m | \u001b[0m 0.2593  \u001b[0m |\n",
      "[0.15590277777777778, 0.19232954545454545, 0.08055555555555556, 0.0763888888888889, 0.10422979797979798, 0.17708333333333334, 0.1018939393939394, 0.2388888888888889, 0.20965909090909093, 0.11346153846153846, 0.18450854700854702, 0.16455662393162393, 0.18888888888888888]\n",
      "[0.203125, 0.17332251082251082, 0.14545454545454545, 0.16982323232323232, 0.25104166666666666, 0.0826388888888889, 0.23894993894993893, 0.14722222222222223, 0.14875992063492063, 0.22792658730158732, 0.22743055555555552, 0.1753472222222222, 0.14633838383838382]\n",
      "('Test acc:', 15.294980126710897, 'sd:', 5.023623849632714)\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.1798  \u001b[0m | \u001b[0m 1.115   \u001b[0m | \u001b[0m 0.8071  \u001b[0m | \u001b[0m 0.8257  \u001b[0m | \u001b[0m 0.2155  \u001b[0m |\n",
      "[0.129235347985348, 0.18916396103896105, 0.21476301476301476, 0.1553342490842491, 0.2938301282051282, 0.1580357142857143, 0.12406343656343657, 0.22689393939393937, 0.2839556277056277, 0.18055555555555552, 0.1590909090909091, 0.1644570707070707, 0.28195415695415693, 0.15384615384615385, 0.25757575757575757]\n",
      "[0.19166666666666665, 0.04285714285714286, 0.2736426767676768, 0.20680465367965367, 0.14791666666666667, 0.19962121212121214, 0.11416361416361416, 0.23510101010101012, 0.12662337662337664, 0.20066964285714287, 0.16496940559440562, 0.28103146853146854, 0.2211094461094461, 0.13368506493506493, 0.1353174603174603]\n",
      "('Test acc:', 19.818366818366815, 'sd:', 5.589776512244954)\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.1783  \u001b[0m | \u001b[0m 0.8285  \u001b[0m | \u001b[0m 1.411   \u001b[0m | \u001b[0m 0.8313  \u001b[0m | \u001b[0m 0.1731  \u001b[0m |\n",
      "[0.2142857142857143, 0.3889194139194139, 0.2963141025641026, 0.19182692307692312, 0.1517857142857143, 0.2824494949494949, 0.2882575757575757, 0.22395833333333331, 0.2878370098039215, 0.15018939393939396, 0.2353021978021978, 0.33047785547785546]\n",
      "[0.32708333333333334, 0.1625, 0.26969696969696966, 0.20397727272727273, 0.1855921855921856, 0.23344155844155845, 0.2244047619047619, 0.11965811965811965, 0.28806818181818183, 0.2711080586080586, 0.23579545454545456, 0.1875]\n",
      "('Test acc:', 25.346697743297003, 'sd:', 6.885147705016923)\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.2257  \u001b[0m | \u001b[0m 0.8664  \u001b[0m | \u001b[0m 0.3433  \u001b[0m | \u001b[0m 0.5915  \u001b[0m | \u001b[0m 0.1672  \u001b[0m |\n",
      "[0.3, 0.30892857142857144, 0.2375, 0.221875, 0.17708333333333331, 0.35008434547908235, 0.3770833333333333, 0.20833333333333331, 0.052083333333333336, 0.175, 0.4081730769230769, 0.20961538461538462, 0.5787280701754386, 0.21666666666666667, 0.4899509803921568, 0.1871031746031746, 0.2058080808080808, 0.2901785714285714, 0.4903186274509804, 0.29375, 0.3885302197802198]\n",
      "[0.125, 0.3509469696969697, 0.3333333333333333, 0.26912878787878786, 0.2727941176470588, 0.159375, 0.1875, 0.12916666666666665, 0.3333333333333333, 0.3625, 0.5583333333333333, 0.43958333333333327, 0.2625, 0.37499999999999994, 0.4200980392156862, 0.39469696969696966, 0.3375, 0.6413690476190477, 0.41875, 0.29734848484848486, 0.23958333333333331]\n",
      "('Test acc:', 29.365686205165414, 'sd:', 12.434434623057468)\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.3289  \u001b[0m | \u001b[0m 0.07691 \u001b[0m | \u001b[0m 0.4166  \u001b[0m | \u001b[0m 0.1755  \u001b[0m | \u001b[0m 0.5029  \u001b[0m |\n",
      "[0.017857142857142856, 0.25, 0.4583333333333333, 0.53125, 0.1875, 0.4166666666666667, 0.2, 0.5208333333333333, 0.125, 0.3875, 0.34375, 0.5, 0.3125, 0.15384615384615385, 0.47291666666666665, 0.59375, 0.5625, 0.15625]\n",
      "[0.59375, 0.3125, 0.29166666666666663, 0.375, 0.4375, 0.125, 0.5, 0.3125, 0.29166666666666663, 0.21875, 0.3333333333333333, 0.29166666666666663, 0.25, 0.09375, 0.4375, 0.2708333333333333, 0.3020833333333333, 0.375]\n",
      "('Test acc:', 34.39140720390721, 'sd:', 16.97130512635182)\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.3229  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0.21875, 0.22916666666666666, 0.16666666666666666, 0.21874999999999997, 0.34374999999999994, 0.3333333333333333, 0.35416666666666663, 0.16666666666666666, 0.2708333333333333, 0.53125, 0.3229166666666667, 0.20833333333333331, 0.44791666666666663, 0.47916666666666663, 0.15625, 0.16666666666666666, 0.29166666666666663, 0.20833333333333331, 0.15625, 0.23958333333333331]\n",
      "[0.3125, 0.21875, 0.375, 0.3020833333333333, 0.2708333333333333, 0.15625, 0.2708333333333333, 0.3125, 0.2708333333333333, 0.1875, 0.5104166666666666, 0.2708333333333333, 0.22916666666666666, 0.0625, 0.35416666666666663, 0.3020833333333333, 0.41666666666666663, 0.20833333333333331, 0.2708333333333333, 0.20833333333333331]\n",
      "('Test acc:', 27.552083333333332, 'sd:', 10.86770888247227)\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.2755  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.617   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0.02222222222222222, 0.06969246031746032, 0.037500000000000006, 0.07088432400932401, 0.03392857142857143, 0.02291666666666667, 0.022115384615384617, 0.0125]\n",
      "[0.10270979020979021, 0.05, 0.07692307692307693, 0.06118881118881119, 0.023863636363636365, 0.055113636363636365, 0.029513888888888888, 0.05138888888888889]\n",
      "('Test acc:', 3.646995365745366, 'sd:', 2.080536356513649)\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.05634 \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0.22916666666666666, 0.13541666666666666, 0.31249999999999994, 0.125, 0.375, 0.09375, 0.2708333333333333, 0.17708333333333331, 0.1875, 0.20833333333333331, 0.21874999999999997, 0.29166666666666663, 0.20833333333333331, 0.41666666666666663, 0.26041666666666663, 0.25]\n",
      "[0.1875, 0.1875, 0.1875, 0.35416666666666663, 0.20833333333333331, 0.3125, 0.25, 0.1875, 0.16666666666666666, 0.22916666666666666, 0.3958333333333333, 0.22916666666666666, 0.16666666666666666, 0.25, 0.25, 0.29166666666666663]\n",
      "('Test acc:', 23.502604166666664, 'sd:', 8.414068141956223)\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.2409  \u001b[0m | \u001b[0m 0.6899  \u001b[0m | \u001b[0m 0.5617  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0.15625, 0.35416666666666663, 0.3020833333333333, 0.35416666666666663, 0.28125, 0.17708333333333331, 0.16666666666666666, 0.28125, 0.29166666666666663, 0.25, 0.13541666666666666, 0.4270833333333333, 0.1875, 0.1875, 0.375, 0.28125, 0.23958333333333331, 0.3333333333333333, 0.15625, 0.3125, 0.39583333333333326, 0.28125, 0.16666666666666666, 0.32291666666666663, 0.2708333333333333, 0.22916666666666666]\n",
      "[0.35416666666666663, 0.3020833333333333, 0.21875, 0.3020833333333333, 0.34375, 0.34375, 0.19791666666666666, 0.3229166666666667, 0.375, 0.28125, 0.28125, 0.3958333333333333, 0.38541666666666663, 0.11458333333333333, 0.3020833333333333, 0.35416666666666663, 0.41666666666666663, 0.20833333333333331, 0.47916666666666663, 0.25, 0.44791666666666663, 0.26041666666666663, 0.5208333333333333, 0.42708333333333326, 0.23958333333333331, 0.3333333333333333]\n",
      "('Test acc:', 26.602564102564102, 'sd:', 8.002397066504098)\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.3253  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.184   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "[0.0, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0625, 0.125, 0.0, 0.0, 0.125]\n",
      "[0.0, 0.0625, 0.125, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0]\n",
      "('Test acc:', 6.25, 'sd:', 7.995026863335392)\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.02841 \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0.0, 0.0, 0.1875, 0.0, 0.1875, 0.25, 0.0625, 0.0625, 0.1875, 0.25, 0.0625, 0.0, 0.0625, 0.25, 0.0625, 0.0625, 0.1875, 0.0, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.0]\n",
      "[0.125, 0.0, 0.25, 0.125, 0.0, 0.125, 0.0625, 0.1875, 0.0625, 0.125, 0.0625, 0.1875, 0.25, 0.25, 0.0, 0.1875, 0.0, 0.0, 0.1875, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('Test acc:', 8.5, 'sd:', 8.993052874302474)\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.0925  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3020833333333333, 0.19791666666666666, 0.3229166666666667, 0.2708333333333333, 0.375, 0.20833333333333331, 0.16666666666666666, 0.3333333333333333, 0.3333333333333333, 0.32291666666666663, 0.3333333333333333, 0.1875, 0.3125, 0.26041666666666663, 0.35416666666666663, 0.2708333333333333, 0.21875, 0.3229166666666667, 0.29166666666666663, 0.3020833333333333, 0.28125, 0.26041666666666663]\n",
      "[0.08333333333333333, 0.375, 0.1875, 0.24999999999999997, 0.20833333333333331, 0.1875, 0.20833333333333331, 0.2708333333333333, 0.16666666666666666, 0.15625, 0.4583333333333333, 0.32291666666666663, 0.14583333333333331, 0.22916666666666666, 0.125, 0.2708333333333333, 0.3958333333333333, 0.22916666666666666, 0.3645833333333333, 0.29166666666666663, 0.23958333333333331, 0.23958333333333331]\n",
      "('Test acc:', 28.314393939393938, 'sd:', 5.579893887369786)\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.2457  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "[0.16666666666666666, 0.38541666666666663, 0.5104166666666666, 0.41666666666666663, 0.46875, 0.28125, 0.19791666666666666, 0.25, 0.19791666666666666, 0.3020833333333333]\n",
      "[0.46875, 0.34375, 0.1875, 0.3125, 0.34375, 0.23958333333333331, 0.20833333333333331, 0.3125, 0.3333333333333333, 0.3125]\n",
      "('Test acc:', 31.770833333333332, 'sd:', 11.489068627032683)\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.3063  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.7849  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.8575  \u001b[0m |\n",
      "[0.3645833333333333, 0.34375, 0.3958333333333333, 0.3020833333333333, 0.48958333333333326, 0.41666666666666663, 0.22916666666666666, 0.35416666666666663, 0.21875, 0.22916666666666666]\n",
      "[0.20833333333333331, 0.10416666666666666, 0.26041666666666663, 0.375, 0.37499999999999994, 0.375, 0.45833333333333326, 0.3333333333333333, 0.29166666666666663, 0.3125]\n",
      "('Test acc:', 33.4375, 'sd:', 8.519406971080139)\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.3094  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.885   \u001b[0m | \u001b[0m 0.623   \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# optimise fine-tuned model sampling params\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_gptxlf = {\n",
    "  \"temperature\": [0.0001, 1.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.0001, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_gpt2xlf, results_gpt2xlf = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.005, phase=\"val\", uniform=True, mdl=mdl, max_tokens=8)[0]\n",
    "    optimizers_gpt2xlf.append(BayesianOptimization(f=fun, pbounds=bounds_gptxlf, verbose=1000))\n",
    "#     optimizers_gpt2xlf[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0})\n",
    "    optimizers_gpt2xlf[-1].maximize(init_points=5, n_iter=10)\n",
    "    results_gpt2xlf.append(optimizers_gpt2xlf[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.3315972222222222,\n",
       " 'params': {'frequency_penalty': 0.0727219392109375,\n",
       "  'presence_penalty': 0.3910543467725913,\n",
       "  'temperature': 0.057551002098534226,\n",
       "  'top_p': 0.25933633649499327}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers_gpt2xlf[-1].max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # optimise fine-tuned model params with refined bounds\n",
    "# lgroups_ft = [[4, 5]]\n",
    "# bounds_gptxlf_rf = {\n",
    "#   \"temperature\": [0.0001, 0.003],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "#   \"top_p\": [0.001, 1.0],        # same with this but more obvious\n",
    "# #   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "#   \"presence_penalty\": [0.1, 1.0],   # both presence and frequency penalty have optimal values\n",
    "# #   \"frequency_penalty\": [0.0, 1.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "# #   \"best_of\": [0.51, 5.49], # to do\n",
    "# }\n",
    "# optimizers_gpt2xlf_rf, results_gpt2xlf_rf = [], []\n",
    "# for lgroup in lgroups_ft:\n",
    "#     min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "#     def fun(temperature, top_p, presence_penalty):\n",
    "#         global min_l, max_l\n",
    "#         ps = locals()\n",
    "#         ps[\"best_of\"] = 5.0\n",
    "#         return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.002, phase=\"val\", uniform=True, mdl=mdl, max_tokens=8)[0]\n",
    "#     optimizers_gpt2xlf_rf.append(BayesianOptimization(f=fun, pbounds=bounds_gptxlf_rf, verbose=1000))\n",
    "#     optimizers_gpt2xlf_rf[-1].probe(params={\"temperature\": 0.001, \"top_p\": 0.001, \"presence_penalty\": 0.4052})\n",
    "#     optimizers_gpt2xlf_rf[-1].maximize(init_points=2, n_iter=8)\n",
    "#     results_gpt2xlf_rf.append(optimizers_gpt2xlf_rf[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers_gpt2xlf_rf[-1].probe(params={\"temperature\": 0.001, \"top_p\": 0.001, \"presence_penalty\": 0.4052})\n",
    "# optimizers_gpt2xlf_rf[-1].maximize(n_iter=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers_gpt2xlf[-1].max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load predictions from the top performing fine-tuned model, and create the ensemble mdl object\n",
    "# optimal_params = {\"temperature\": ?, \"top_p\": ?, \"presence_penalty\": ?, \"frequency_penalty\": ?}\n",
    "# optimal_params = optimizers_gpt2xlf[-1].max[\"params\"]\n",
    "optimal_params = {**default_sp, **{'frequency_penalty': 0.0727219392109375,\n",
    "                                   'presence_penalty': 0.3910543467725913,\n",
    "                                   'temperature': 0.057551002098534226,\n",
    "                                   'top_p': 0.25933633649499327}}\n",
    "def approx_eq(x, y, tol=1e-7):\n",
    "    return abs(x - y) < tol\n",
    "def get_sp_samples(params, test=False):  # Get all datapoints which match these parameters (todo: for each length group)\n",
    "    dn = 'msp_samples_nb' + (\"_test\" if test else '') + '/'\n",
    "    dname = 'data/learning_data/' + dn\n",
    "    D, R, inds = [], [], []  # Gathered input data and model results\n",
    "    for i in range(len(cats)):\n",
    "        idx_set = train_idx if i in train_idx else (val_idx if i in val_idx else test_idx)\n",
    "        D_ = []\n",
    "        fns = glob.glob(dname + str(i) + '/*')\n",
    "        if len(fns) == 0: continue\n",
    "        fns = [fn.split('/')[-1].split('\\\\')[-1] for fn in fns][::-1]  # Most recent first\n",
    "        load_fns = []\n",
    "        for fn in fns:\n",
    "            fn_split = fn.split('_')\n",
    "            params = {sps_[i]: float(fn_split[i + 1]) for i in range(len(sps_))}\n",
    "            if (\"ernst_one\" in fn) and all([approx_eq(params[k], optimal_params[k]) for k in sps_]): load_fns.append(fn)\n",
    "        for fn in load_fns[:15]:\n",
    "            params, d, _, r, mdl_str = load_ld(dn + str(i) + '/' + fn.split('.data')[0])\n",
    "            D_ += d\n",
    "            R += r\n",
    "        D += D_\n",
    "        i_in_set = idx_set.tolist().index(i)\n",
    "        inds += [i_in_set for _ in range(len(D_))]\n",
    "    return D, R, np.asarray(inds)\n",
    "mdl2_d, mdl2_r, mdl2_inds = get_sp_samples(optimal_params)\n",
    "mdl2_d_test, mdl2_r_test, mdl2_inds_test = get_sp_samples(optimal_params, test=True)\n",
    "mdl2_d_x, mdl2_d_test_x = [d_[0] for d_ in mdl2_d], [d_[0] for d_ in mdl2_d_test]\n",
    "def precomputed_completions(d_x, **kwargs):\n",
    "    return mdl2_r if (d_x == mdl2_d_x) else (mdl2_r_test if d_x == mdl2_d_test_x else None)\n",
    "mdl2 = {\"completions\": precomputed_completions, \"name\": \"precomputed_one\", \"mstr\": \"precomputed_one_mstr\"}\n",
    "len(mdl2_d), len(mdl2_d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "Test acc: 18.818716006216004 sd: 19.936895010181622\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.1674  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Test acc: 14.77453102453102 sd: 18.856136694838423\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.1358  \u001b[0m | \u001b[0m 0.8711  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.2817  \u001b[0m | \u001b[0m 0.2481  \u001b[0m |\n",
      "Test acc: 11.171356421356421 sd: 11.286211338580697\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.1058  \u001b[0m | \u001b[0m 0.9056  \u001b[0m | \u001b[0m 1.629   \u001b[0m | \u001b[0m 0.4863  \u001b[0m | \u001b[0m 0.1001  \u001b[0m |\n",
      "Test acc: 11.590277777777775 sd: 11.654115331317248\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.1058  \u001b[0m | \u001b[0m 1.55    \u001b[0m | \u001b[0m 1.283   \u001b[0m | \u001b[0m 0.8669  \u001b[0m | \u001b[0m 0.7813  \u001b[0m |\n",
      "Test acc: 11.347222222222221 sd: 11.294800183287798\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.1058  \u001b[0m | \u001b[0m 1.884   \u001b[0m | \u001b[0m 0.8325  \u001b[0m | \u001b[0m 0.5171  \u001b[0m | \u001b[0m 0.9039  \u001b[0m |\n",
      "Test acc: 37.88740327797991 sd: 35.70788802511655\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.3698  \u001b[0m | \u001b[95m 0.1169  \u001b[0m | \u001b[95m 0.1147  \u001b[0m | \u001b[95m 0.1745  \u001b[0m | \u001b[95m 0.5062  \u001b[0m |\n",
      "Test acc: 11.362103174603174 sd: 11.33271219112578\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 1.786   \u001b[0m | \u001b[0m 1.1     \u001b[0m | \u001b[0m 0.9626  \u001b[0m | \u001b[0m 0.7045  \u001b[0m |\n",
      "Test acc: 11.171356421356421 sd: 11.286211338580697\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.1058  \u001b[0m | \u001b[0m 1.738   \u001b[0m | \u001b[0m 1.204   \u001b[0m | \u001b[0m 0.4952  \u001b[0m | \u001b[0m 0.6155  \u001b[0m |\n",
      "Test acc: 17.259920634920636 sd: 16.531959755036656\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.1799  \u001b[0m | \u001b[0m 0.7282  \u001b[0m | \u001b[0m 0.9161  \u001b[0m | \u001b[0m 0.8847  \u001b[0m | \u001b[0m 0.6235  \u001b[0m |\n",
      "Test acc: 36.980513942685 sd: 34.933472069535206\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.3545  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.04998 \u001b[0m |\n",
      "Test acc: 36.980513942685 sd: 34.933472069535206\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.3545  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Test acc: 39.554708266879324 sd: 36.55256982347982\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.3776  \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.6827  \u001b[0m | \u001b[95m 0.0001  \u001b[0m | \u001b[95m 0.7724  \u001b[0m |\n",
      "Test acc: 38.943239752450275 sd: 36.36546111256192\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.3387  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Test acc: 15.936026936026934 sd: 15.38774938063801\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.1368  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Test acc: 34.77654521404522 sd: 34.3038462949238\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.3056  \u001b[0m | \u001b[0m 0.608   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.8001  \u001b[0m |\n",
      "Test acc: 39.27693048910154 sd: 36.7250429390263\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.3747  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.6262  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.207   \u001b[0m |\n",
      "Test acc: 38.943239752450275 sd: 36.36546111256192\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.3387  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "Test acc: 40.81669627886733 sd: 36.68622095523258\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.366   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.325   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Test acc: 40.79330446600184 sd: 36.656071416829995\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.366   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.398   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.4347  \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# evaluate ensemble of fine-tuned and original model\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_gptxlfe = {\n",
    "  \"temperature\": [0.0001, 1.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.0001, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_gpt2xlfe, results_gpt2xlfe = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp(ps, n1=1, min_l=min_l, max_l=max_l, phase=\"val\", uniform=True, mdl=mdl, mdl2=mdl2, return_test_acc=False,\n",
    "                       d=mdl2_d, d_test=mdl2_d_test, inds=mdl2_inds, inds_test=mdl2_inds_test, max_tokens=8)\n",
    "    optimizers_gpt2xlfe.append(BayesianOptimization(f=fun, pbounds=bounds_gptxlfe, verbose=1000))\n",
    "    optimizers_gpt2xlfe[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0})\n",
    "    optimizers_gpt2xlfe[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_gpt2xlfe.append(optimizers_gpt2xlfe[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.3776479076479077,\n",
       " 'params': {'frequency_penalty': 0.0,\n",
       "  'presence_penalty': 0.6826773005263892,\n",
       "  'temperature': 0.0001,\n",
       "  'top_p': 0.7723760255748774}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers_gpt2xlfe[-1].max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 0.1674104367854368,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 0.0,\n",
       "   'temperature': 1.0,\n",
       "   'top_p': 1.0}},\n",
       " {'target': 0.1358333333333333,\n",
       "  'params': {'frequency_penalty': 0.8711056869611193,\n",
       "   'presence_penalty': 0.9175027822849351,\n",
       "   'temperature': 0.28166594880239576,\n",
       "   'top_p': 0.24814697270196176}},\n",
       " {'target': 0.10583333333333332,\n",
       "  'params': {'frequency_penalty': 0.9055600392722987,\n",
       "   'presence_penalty': 1.6292026746717285,\n",
       "   'temperature': 0.4862853433151288,\n",
       "   'top_p': 0.10006268800987392}},\n",
       " {'target': 0.10583333333333332,\n",
       "  'params': {'frequency_penalty': 1.5498253868894298,\n",
       "   'presence_penalty': 1.2832269448593987,\n",
       "   'temperature': 0.8669491149883246,\n",
       "   'top_p': 0.781349642522042}},\n",
       " {'target': 0.10583333333333332,\n",
       "  'params': {'frequency_penalty': 1.8839249053568738,\n",
       "   'presence_penalty': 0.8324946021108477,\n",
       "   'temperature': 0.517134514952664,\n",
       "   'top_p': 0.9039030633298701}},\n",
       " {'target': 0.3697888916638917,\n",
       "  'params': {'frequency_penalty': 0.11685899995653815,\n",
       "   'presence_penalty': 0.11472674569320462,\n",
       "   'temperature': 0.17446698215615375,\n",
       "   'top_p': 0.506239958747463}},\n",
       " {'target': 0.10682539682539684,\n",
       "  'params': {'frequency_penalty': 1.7863719454292961,\n",
       "   'presence_penalty': 1.0998130253729257,\n",
       "   'temperature': 0.9626294632699759,\n",
       "   'top_p': 0.704532514033267}},\n",
       " {'target': 0.10583333333333332,\n",
       "  'params': {'frequency_penalty': 1.7380127471109066,\n",
       "   'presence_penalty': 1.2036106192598868,\n",
       "   'temperature': 0.49522994022680095,\n",
       "   'top_p': 0.6154994602863306}},\n",
       " {'target': 0.1798611111111111,\n",
       "  'params': {'frequency_penalty': 0.7282138092968031,\n",
       "   'presence_penalty': 0.9161331393232395,\n",
       "   'temperature': 0.8846838218985477,\n",
       "   'top_p': 0.6234977422680228}},\n",
       " {'target': 0.35453788901157324,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 0.0,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.049983458947994726}},\n",
       " {'target': 0.35453788901157324,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 0.0,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 1.0}},\n",
       " {'target': 0.3776479076479077,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 0.6826773005263892,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.7723760255748774}},\n",
       " {'target': 0.3386832611832612,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 2.0,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 1.0}},\n",
       " {'target': 0.1367559523809524,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 2.0,\n",
       "   'temperature': 1.0,\n",
       "   'top_p': 1.0}},\n",
       " {'target': 0.3056165131165131,\n",
       "  'params': {'frequency_penalty': 0.6080069631763159,\n",
       "   'presence_penalty': 0.0,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.8001087882574378}},\n",
       " {'target': 0.37465090465090467,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 0.6262183311918568,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.2070101788848195}},\n",
       " {'target': 0.3386832611832612,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 2.0,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.0001}},\n",
       " {'target': 0.365981240981241,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 1.32541339128544,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 1.0}},\n",
       " {'target': 0.365981240981241,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 1.3976158236504674,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.4347355267648904}}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers_gpt2xlfe[-1].res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
    "# -------------------------------------------------------------------------\n",
    "# [0.14608262108262107, 0.1544311013061013, 0.1774588258963259]\n",
    "# [0.5712862692862692, 0.5167355977355977, 0.5436751026751027]\n",
    "# ('Test acc:', 15.932418276168276, 'sd:', 1.326833930141234)\n",
    "# |  1        |  0.5439   |  0.7545   |  0.8837   |  1.164    |  0.1678   |\n",
    "# [0.006944444444444444, 0.008333333333333333, 0.025000000000000005]\n",
    "# [0.008, 0.0, 0.014666666666666668]\n",
    "# ('Test acc:', 1.3425925925925926, 'sd:', 0.8203724604939516)\n",
    "# |  2        |  0.007556 |  1.563    |  1.115    |  1.345    |  0.4973   |\n",
    "# [0.21354131979131977, 0.173926362988863, 0.13297558922558925, 0.25522775835275835]\n",
    "# [0.5312100122100122, 0.6170219780219779, 0.5921578421578422, 0.5759225219225219]\n",
    "# ('Test acc:', 19.39177575896326, 'sd:', 4.543568017003007)\n",
    "# |  3        |  0.5791   |  1.185    |  1.479    |  0.3418   |  0.9886   |\n",
    "# [0.35648148148148145, 0.3520833333333333, 0.3180147058823529, 0.332175925925926, 0.2954656862745098]\n",
    "# [0.6432820512820513, 0.7113333333333333, 0.7075555555555556, 0.8067179487179486, 0.738952380952381]\n",
    "# ('Test acc:', 33.08442265795207, 'sd:', 2.247834350297864)\n",
    "# |  4        |  0.7216   |  0.5497   |  0.4131   |  0.04958  |  0.5878   |\n",
    "# [0.24212986087986085, 0.20677008177008174, 0.2121680402930403, 0.24574632543382546]\n",
    "# [0.5814134754134754, 0.5753290043290044, 0.6005385725385726, 0.5997070707070707]\n",
    "# ('Test acc:', 22.67035770942021, 'sd:', 1.73869387881864)\n",
    "# |  5        |  0.5892   |  0.989    |  1.323    |  0.6668   |  0.5829   |\n",
    "# [0.006944444444444444, 0.0, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.23148148148148145, 'sd:', 0.32736425054932755)\n",
    "# |  6        |  0.0      |  1.268    |  1.645    |  1.636    |  0.3853   |\n",
    "# [0.029563492063492066, 0.05555555555555556, 0.03511904761904762, 0.024537037037037038, 0.01636904761904762]\n",
    "# [0.07957142857142857, 0.13923809523809524, 0.07619047619047618, 0.15666666666666665, 0.1219047619047619]\n",
    "# ('Test acc:', 3.222883597883598, 'sd:', 1.319310339155671)\n",
    "# |  7        |  0.1147   |  1.617    |  0.524    |  0.9253   |  0.9548   |\n",
    "# [0.0, 0.0, 0.0]\n",
    "# [0.0, 0.008, 0.008]\n",
    "# ('Test acc:', 0.0, 'sd:', 0.0)\n",
    "# |  8        |  0.005333 |  1.573    |  0.1914   |  1.962    |  0.2006   |\n",
    "# [0.29166666666666663, 0.3055555555555555, 0.3819444444444444, 0.24305555555555555, 0.3506944444444444]\n",
    "# [0.6366666666666666, 0.7466666666666666, 0.7399999999999999, 0.7999999999999998, 0.73]\n",
    "# ('Test acc:', 31.458333333333332, 'sd:', 4.809247136994663)\n",
    "# |  9        |  0.7307   |  0.001    |  1.477    |  0.001    |  0.001    |\n",
    "# [0.2643718553548275, 0.2827585030710031, 0.27731273356273356, 0.2543742511573394]\n",
    "# [0.5516450836744954, 0.5830235059058588, 0.544432178932179, 0.5589042819925172]\n",
    "# ('Test acc:', 26.97043357864759, 'sd:', 1.1087671560167434)\n",
    "# |  10       |  0.5595   |  0.001    |  1.146    |  0.5046   |  1.0      |\n",
    "# [0.40625, 0.2916666666666667, 0.34722222222222215]\n",
    "# [0.55, 0.6666666666666665, 0.6066666666666667]\n",
    "# ('Test acc:', 34.83796296296296, 'sd:', 4.678560863751791)\n",
    "# |  11       |  0.6078   |  0.001    |  0.001    |  0.4932   |  0.001    |\n",
    "# [0.32638888888888884, 0.2222222222222222, 0.2916666666666667, 0.2534722222222222, 0.34722222222222215, 0.20138888888888887, 0.21527777777777776, 0.23611111111111108, 0.2847222222222222]\n",
    "# [0.74, 0.6666666666666665, 0.6866666666666665, 0.6133333333333333, 0.7266666666666666, 0.7866666666666666, 0.78, 0.6466666666666666, 0.6933333333333332]\n",
    "# ('Test acc:', 26.427469135802472, 'sd:', 4.8236109901505495)\n",
    "# |  12       |  0.7044   |  1.045    |  1.107    |  0.001    |  0.001    |\n",
    "# [0.2708333333333333, 0.2569444444444444, 0.25, 0.18055555555555555]\n",
    "# [0.62, 0.7666666666666666, 0.6266666666666666, 0.6666666666666665]\n",
    "# ('Test acc:', 23.958333333333332, 'sd:', 3.4895401462225317)\n",
    "# |  13       |  0.67     |  0.7444   |  2.0      |  0.001    |  0.001    |\n",
    "# [0.3333333333333333, 0.3263888888888889, 0.37152777777777773, 0.3020833333333333]\n",
    "# [0.6166666666666667, 0.72, 0.7941025641025641, 0.7266666666666666]\n",
    "# ('Test acc:', 33.33333333333333, 'sd:', 2.4917882108346023)\n",
    "# |  14       |  0.7144   |  0.2284   |  2.0      |  0.001    |  1.0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "[0.25, 0.16025641025641024, 0.3194444444444444, 0.5, 0.0625, 0.3382352941176471, 0.3402777777777778, 0.171875, 0.1875, 0.2976190476190476, 0.375, 0.19642857142857142, 0.375, 0.39583333333333337, 0.4, 0.5625, 0.2708333333333333, 0.15, 0.525, 0.375, 0.25, 0.203125, 0.4583333333333333, 0.3270833333333333, 0.375, 0.484375, 0.3727272727272727, 0.22916666666666666, 0.5208333333333333, 0.25]\n",
      "[0.375, 0.125, 0.3958333333333333, 0.45555555555555555, 0.25, 0.23214285714285715, 0.375, 0.125, 0.375, 0.375, 0.375, 0.4, 0.07738095238095238, 0.4, 0.4, 0.2625, 0.1125, 0.0, 0.35, 0.325, 0.125, 0.6, 0.25, 0.0, 0.125, 0.125, 0.025, 0.125, 0.375, 0.34375]\n",
      "('Test acc:', 32.41315717234835, 'sd:', 12.4103941038018)\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.2627  \u001b[0m | \u001b[0m 0.3582  \u001b[0m | \u001b[0m 0.8393  \u001b[0m | \u001b[0m 0.06305 \u001b[0m | \u001b[0m 0.7254  \u001b[0m |\n",
      "[0.4375, 0.39583333333333337, 0.5576923076923077, 0.5986842105263158, 0.1875, 0.43333333333333335, 0.525, 0.3125, 0.4305555555555556, 0.375, 0.34375, 0.5, 0.4375, 0.44362745098039214, 0.5520833333333333, 0.2919642857142857, 0.20833333333333331, 0.375, 0.4794642857142857, 0.3125, 0.6875]\n",
      "[0.125, 0.3125, 0.125, 0.2519230769230769, 0.375, 0.45833333333333337, 0.3125, 0.25, 0.41666666666666663, 0.275, 0.525, 0.375, 0.5, 0.625, 0.4444444444444444, 0.7517857142857143, 0.125, 0.0625, 0.26666666666666666, 0.2857142857142857, 0.25]\n",
      "('Test acc:', 42.31105442626893, 'sd:', 12.167873544905257)\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.3387  \u001b[0m | \u001b[95m 0.2233  \u001b[0m | \u001b[95m 0.6086  \u001b[0m | \u001b[95m 0.07457 \u001b[0m | \u001b[95m 0.7005  \u001b[0m |\n",
      "[0.0, 0.025, 0.025, 0.125, 0.1]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('Test acc:', 5.500000000000001, 'sd:', 4.847679857416329)\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.181   \u001b[0m | \u001b[0m 0.8761  \u001b[0m | \u001b[0m 0.9505  \u001b[0m | \u001b[0m 0.301   \u001b[0m |\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('Test acc:', 0.0, 'sd:', 0.0)\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.97    \u001b[0m | \u001b[0m 1.772   \u001b[0m | \u001b[0m 0.2702  \u001b[0m | \u001b[0m 0.5597  \u001b[0m |\n",
      "[0.0, 0.025, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('Test acc:', 0.5, 'sd:', 1.0)\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.208   \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 0.7537  \u001b[0m | \u001b[0m 0.3159  \u001b[0m |\n",
      "[0.05, 0.16666666666666666, 0.19999999999999998, 0.15, 0.1, 0.28750000000000003, 0.3770833333333334, 0.3486111111111111, 0.3, 0.15833333333333333, 0.31698717948717947, 0.2, 0.15000000000000002, 0.15714285714285714, 0.12916666666666668, 0.13214285714285715]\n",
      "[0.15, 0.025, 0.15, 0.1, 0.125, 0.175, 0.0, 0.3, 0.1, 0.275, 0.175, 0.3833333333333333, 0.05, 0.1, 0.125, 0.15833333333333333]\n",
      "('Test acc:', 20.14771253052503, 'sd:', 9.238405535174753)\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.1495  \u001b[0m | \u001b[0m 0.7498  \u001b[0m | \u001b[0m 0.5206  \u001b[0m | \u001b[0m 0.891   \u001b[0m | \u001b[0m 0.3153  \u001b[0m |\n",
      "[0.07500000000000001, 0.05625, 0.175, 0.225, 0.1875, 0.05, 0.15, 0.075, 0.175, 0.10833333333333334, 0.05, 0.07500000000000001, 0.1, 0.0, 0.25, 0.15000000000000002]\n",
      "[0.1, 0.0, 0.0, 0.275, 0.025, 0.025, 0.1, 0.05, 0.025, 0.05, 0.0, 0.0, 0.275, 0.125, 0.125, 0.15000000000000002]\n",
      "('Test acc:', 11.888020833333332, 'sd:', 6.855032853544691)\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.08281 \u001b[0m | \u001b[0m 0.9256  \u001b[0m | \u001b[0m 0.4487  \u001b[0m | \u001b[0m 0.7391  \u001b[0m | \u001b[0m 0.3264  \u001b[0m |\n",
      "[0.06666666666666667, 0.025, 0.04583333333333334, 0.025, 0.05, 0.04583333333333334, 0.05, 0.075, 0.0, 0.05, 0.07500000000000001, 0.05]\n",
      "[0.15000000000000002, 0.1, 0.025, 0.1464285714285714, 0.05, 0.05, 0.05, 0.06666666666666667, 0.025, 0.07500000000000001, 0.060714285714285714, 0.025]\n",
      "('Test acc:', 4.652777777777778, 'sd:', 2.0752156663172134)\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.06865 \u001b[0m | \u001b[0m 0.8929  \u001b[0m | \u001b[0m 0.9369  \u001b[0m | \u001b[0m 0.9781  \u001b[0m | \u001b[0m 0.6755  \u001b[0m |\n",
      "[0.4779265873015873, 0.23584054834054835, 0.38057359307359306, 0.3700280112044818, 0.2864583333333333, 0.19480519480519481, 0.34436813186813187, 0.2164835164835165, 0.38055555555555554, 0.40625, 0.36354166666666665, 0.45069444444444445, 0.3317775974025974, 0.47141645119586295, 0.5114583333333333, 0.274156746031746, 0.4168942577030812, 0.4406926406926407, 0.3737745098039216, 0.4179446778711484, 0.45277777777777783, 0.489781746031746, 0.43058155080213906, 0.33904151404151406, 0.4192095588235294]\n",
      "[0.29374999999999996, 0.3654513888888889, 0.31994047619047616, 0.2793154761904762, 0.4344742063492063, 0.35218253968253965, 0.3611111111111111, 0.5271214896214896, 0.42995129870129867, 0.4140512265512265, 0.43849206349206343, 0.5229471916971917, 0.4701388888888889, 0.3743506493506493, 0.36221590909090906, 0.49181547619047616, 0.29673520923520924, 0.5037112193362193, 0.508901515151515, 0.6568108974358974, 0.4351686507936508, 0.5582792207792207, 0.4678571428571428, 0.47291666666666665, 0.41704094516594514]\n",
      "('Test acc:', 37.90813177835236, 'sd:', 8.3970120139775)\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.4302  \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.08144 \u001b[0m | \u001b[95m 0.5063  \u001b[0m | \u001b[95m 0.9403  \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.0, 0.0, 0.18249905925769086, 0.0001)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-afd90453a189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds_gptxl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mresults_gpt2xl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizers_gpt2xl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-afd90453a189>\u001b[0m in \u001b[0;36mfun\u001b[0;34m(temperature, top_p, presence_penalty, frequency_penalty)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"best_of\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds_gptxl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-7ca5afbedeb6>\u001b[0m in \u001b[0;36mtest_sp_conv\u001b[0;34m(params, tol, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_nochange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mnew_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msteps_nochange\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-7ca5afbedeb6>\u001b[0m in \u001b[0;36mtest_sp\u001b[0;34m(params, min_l, max_l, n1, n2, prmt, phase, uniform, max_tokens, mdl, mdl2, d, d_test, inds, inds_test, m2ensemble_frac, return_test_acc)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_sp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#**default_msp,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gpt3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Request predictions from OpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"completions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0msave_modeloutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphaseIx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsps_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdl2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-f4ec06d07fde>\u001b[0m in \u001b[0;36mgen_completions\u001b[0;34m(s, n, max_tokens, best_of, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtc_b_itr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtc_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtc_b_itr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtc_b_itr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgprobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcounts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtc_b_itr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0msu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluate un-fine-tuned model\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_gptxl = {\n",
    "  \"temperature\": [0.0001, 1.1],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.0001, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_gpt2xl, results_gpt2xl = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.005, phase=\"val\", uniform=True, mdl=mdl, max_tokens=8)[0]\n",
    "    optimizers_gpt2xl.append(BayesianOptimization(f=fun, pbounds=bounds_gptxl, verbose=1000))\n",
    "    optimizers_gpt2xl[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_gpt2xl.append(optimizers_gpt2xl[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test accuracy for the top performing (training accuracy ) sampling parameters for gpt2-\n",
    "# \n",
    "# |   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
    "# -------------------------------------------------------------------------\n",
    "# [0.049999999999999996, 0.025000000000000005, 0.061111111111111116]\n",
    "# [0.008, 0.03333333333333333, 0.029333333333333336]\n",
    "# ('Test acc:', 4.537037037037037, 'sd:', 1.5101394842870455)\n",
    "# |  1        |  0.02356  |  0.7232   |  0.9207   |  1.792    |  0.1562   |\n",
    "# [0.2111111111111111, 0.13333333333333333, 0.23576388888888888, 0.3333333333333333]\n",
    "# [0.1965714285714286, 0.11199999999999999, 0.111, 0.12]\n",
    "# ('Test acc:', 22.838541666666668, 'sd:', 7.141744752411932)\n",
    "# |  2        |  0.1349   |  0.6561   |  0.6181   |  0.6707   |  0.1418   |\n",
    "# [0.0, 0.016666666666666666, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.5555555555555556, 'sd:', 0.7856742013183862)\n",
    "# |  3        |  0.0      |  1.035    |  0.6253   |  1.287    |  0.9439   |\n",
    "# [0.5208333333333334, 0.375, 0.3854166666666667, 0.4930555555555555, 0.34027777777777773, 0.40625, 0.3194444444444444]\n",
    "# [0.32, 0.38, 0.21333333333333332, 0.28, 0.16666666666666663, 0.2, 0.2733333333333333]\n",
    "# ('Test acc:', 40.57539682539682, 'sd:', 6.965317270864225)\n",
    "# |  4        |  0.2619   |  0.4573   |  0.1734   |  0.6163   |  0.02537  |\n",
    "# [0.025000000000000005, 0.0, 0.03333333333333333]\n",
    "# [0.008, 0.024000000000000004, 0.008]\n",
    "# ('Test acc:', 1.9444444444444444, 'sd:', 1.4163943093313291)\n",
    "# |  5        |  0.01333  |  1.27     |  1.156    |  1.195    |  0.7833   |\n",
    "# [0.008333333333333333, 0.0, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.2777777777777778, 'sd:', 0.3928371006591931)\n",
    "# |  6        |  0.0      |  1.297    |  1.846    |  1.938    |  0.7382   |\n",
    "# [0.013888888888888888, 0.0, 0.0]\n",
    "# [0.014666666666666668, 0.008, 0.0]\n",
    "# ('Test acc:', 0.4629629629629629, 'sd:', 0.6547285010986551)\n",
    "# |  7        |  0.007556 |  0.2306   |  1.936    |  1.592    |  0.7024   |\n",
    "# [0.2511354386354386, 0.3434765466015466, 0.30643372830872834, 0.3152858715358715]\n",
    "# [0.32786868686868686, 0.3295645530939648, 0.3073928293928294, 0.3104887334887335]\n",
    "# ('Test acc:', 30.408289627039625, 'sd:', 3.349002098569766)\n",
    "# |  8        |  0.3188   |  0.1998   |  0.08897  |  0.9428   |  0.6384   |\n",
    "# [0.4106481481481481, 0.26304563492063493, 0.31493055555555555, 0.3008207070707071, 0.37310600279350276, 0.38941300733580136]\n",
    "# [0.3358236208236208, 0.1989130869130869, 0.21833333333333332, 0.34352380952380945, 0.3320714285714286, 0.3045044955044955]\n",
    "# ('Test acc:', 34.19940093040583, 'sd:', 5.258394155542585)\n",
    "# |  9        |  0.2889   |  0.01     |  0.01     |  0.1864   |  0.669    |\n",
    "# [0.4861111111111111, 0.3020833333333333, 0.2604166666666667, 0.2916666666666667, 0.3055555555555555, 0.34722222222222215, 0.3541666666666667, 0.2708333333333333]\n",
    "# [0.3833333333333333, 0.20666666666666664, 0.3161904761904762, 0.38, 0.3466666666666666, 0.4137777777777778, 0.29333333333333333, 0.35]\n",
    "# ('Test acc:', 32.72569444444444, 'sd:', 6.743512364375678)\n",
    "# |  10       |  0.3362   |  0.01     |  0.01     |  1.212    |  0.01     |\n",
    "# [0.0, 0.0, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.0, 'sd:', 0.0)\n",
    "# |  11       |  0.0      |  0.01     |  0.01     |  2.0      |  1.0      |\n",
    "# [0.5181517556517556, 0.2377946127946128, 0.4213624338624338, 0.3735119047619048]\n",
    "# [0.27763369963369966, 0.32315873015873015, 0.23523076923076924, 0.2697142857142857]\n",
    "# ('Test acc:', 38.77051767676768, 'sd:', 10.102443647288354)\n",
    "# |  12       |  0.2764   |  0.01     |  0.01     |  0.6837   |  0.1847   |\n",
    "# [0.19999999999999998, 0.23750000000000002, 0.2722222222222222, 0.375, 0.20833333333333334, 0.0625, 0.16666666666666666, 0.325]\n",
    "# [0.22, 0.08, 0.10400000000000001, 0.264, 0.12, 0.096, 0.2, 0.16]\n",
    "# ('Test acc:', 23.09027777777778, 'sd:', 9.035987186191242)\n",
    "# |  13       |  0.1555   |  0.8694   |  0.01     |  0.01     |  1.0      |\n",
    "# [0.5590277777777778, 0.3819444444444444, 0.31527777777777777, 0.3541666666666667, 0.37152777777777773, 0.375, 0.518287037037037, 0.34027777777777773, 0.4236111111111111]\n",
    "# [0.2338095238095238, 0.19422222222222224, 0.26, 0.25666666666666665, 0.3053333333333333, 0.31, 0.305, 0.36, 0.256]\n",
    "# ('Test acc:', 40.434670781893004, 'sd:', 7.765741054904079)\n",
    "# |  14       |  0.2757   |  0.01     |  0.8582   |  0.01     |  1.0      |\n",
    "# [0.35763888888888884, 0.3756944444444444, 0.33796296296296297, 0.38055555555555554, 0.2824074074074074, 0.3171296296296296, 0.43402777777777773]\n",
    "# [0.3680952380952381, 0.23466666666666666, 0.2222222222222222, 0.22, 0.32, 0.14, 0.22666666666666666]\n",
    "# ('Test acc:', 35.50595238095238, 'sd:', 4.524186608251292)\n",
    "# |  15       |  0.2474   |  0.01     |  2.0      |  0.01     |  1.0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test accuracy for the top performing (training accuracy 0.2026) sampling parameters for gpt2-small (after the full 18 runs)\n",
    "# np.mean([0.3353320494864612,0.3277777777777778,0.21805555555555556,0.3402514152514152,0.28348214285714285,0.13194444444444445])# = 0.27280723089546616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "\"reinterpretation, harmony, character progression, reading circle\")\n",
    "# \"monolith, elevator effect, time loop, survival, desert resort, town watchman\")\n",
    "# \"monolith, allegro, soundtrack, chord, classical, opera\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.6, temperature=15.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "# \"reinterpretation, harmony, character progression, reading circle\")\n",
    "# # \"monolith, elevator effect, time loop, survival, desert resort, town watchman\")\n",
    "# # \"monolith, allegro, soundtrack, chord, classical, opera\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "# olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.6, temperature=15.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"watermelon juice, cherry juice, blackcurrant mixture, kava, orangeade, lemon juice, cherryade, cranberry juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "# olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_sentence = append_next_token(input_sentence, top_k=10, top_p=0.8, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "# \"\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider, yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider\" + \\\n",
    "# \", yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5pm: Using log_period=1 (max_len=96) reliably finds improvement, need more data and larger gpt2 (medium+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" milk, vodka, beer, ice water, soda, lassi, juice, alcohol, whiskey\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" wine, soda, alcohol, beer, liquor, apple cider, whiskey, milk, bourbon, vodka, cider, lemon juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:6])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=3.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" beer, milk, juice, wine, spirits, alcohol, soda, whiskey, brandy, apple juice, liquor, ice tea, watermelon juice, vodka,\" + \\\n",
    "# \" lemon tea, apple cider, ale, lager, fruit tea, lime cider, cocktail, mocha, red wine, apple soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5am: lr=1e-5, max_len=80, log_period_batches=5 increased accuracy by 8%. Need to add a bunch more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 5 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"soda, milk, juice, wine, vodka, gin, lime juice, beer, hot chocolate, cider, whiskey, fruit juice, cocktail, liquor, \" + \\\n",
    "# \"spirits, watermelon juice, martini, rum, chocolate milk, orangeade\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fine tuning (regular GPT-2):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model on 2nd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, juice, fruit juice, soda, wine, beer, hot chocolate, chocolate milk, alcohol, cider, ice tea, liquor, spirit\")\n",
    "# input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89, olen=olen) # k = 25 also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for too long (in this case ~6:30 hours) overfits\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"beer, juice, soda, liquor, wine, tequila, spirits, alcohol, cocktail, martini, whiskey, rum, vodka\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 15/04/2021 11am: Found learning rate 1e-7, max_listlen 15, min_nw 0.7, max_nw 0.9, lidstone_eps 0.01 works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No fine tuning (testing gpt2) (old append function):\n",
    "# input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake\"\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89)\n",
    "# A list of types of drink: juice, tea, cider, lemonade, milk, beer, hot chocolate,➡ ice cold milk. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working (reproducible) examples using various non-fine-tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT3 (via AI Dungeon) (Randomness = 2.0, model = Dragon):\n",
    "# sentence = \"A list of ML algorithms: inverse reinforcement learning, ELMo, decision tree, LDA, \"\n",
    "# expected_completion = \"MLP, MLL, MMM. You can't believe you're actually using these things!\"\n",
    "\n",
    "# sentence = \"A list of animals seen in the wild: wolffish, woodlouse, sheep, zebra, yak, \"\n",
    "# expected_completion = \"goat, fox, dog, rat. You're guessing that a lot of other animals have been seen as well; maybe even all the animals on your list except for wolf and rat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 (via Write with Transformer) (Top-p = 0.67, temperature = 1.89, max time = 1.9):\n",
    "# sentence = \"A list of round fruits: peach, apricot, lime, plum, blackberry, cantaloupe, nectarine, pitaya, persimmon, \"\n",
    "# expected_completion = \"mango, papaya and raspberry, as also many\"\n",
    "\n",
    "# sentence = \"A list of chemical elements: hydrogen, carbon, oxygen, nitrogen, gold, \"\n",
    "# expected_completion = \"silver, aluminum, potassium and phosphorus; atomic number.\"\n",
    "\n",
    "# sentence = \"A list of microbes found on earth: bacteria, virus, prokaryote, amoeba, \"\n",
    "# expected_completion = \"archaea, algae, nematode, euk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This result shows why we need not redistribute the mass when evaluating gpt3 accuracy\n",
    "# response = openai.Completion.create(**{**default_params,\n",
    "#   \"prompt\": \"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\",\n",
    "#   \"temperature\": 1.5,\n",
    "#   \"top_p\": 1.0,\n",
    "#   \"n\": 5,\n",
    "#   \"best_of\": 20,\n",
    "#   \"max_tokens\": 7,\n",
    "#   \"stop\": [\",\", \"\\n\"],\n",
    "# })\n",
    "# for choice in response[\"choices\"]:\n",
    "#     d = {}\n",
    "#     tokens = choice[\"logprobs\"][\"tokens\"]\n",
    "#     t_i = -1\n",
    "#     for t in tokens:\n",
    "#         t_i += 1\n",
    "#         r = [(np.e**v, k) for (k, v) in choice[\"logprobs\"][\"top_logprobs\"][t_i].items()]\n",
    "#         r.sort(reverse=True)\n",
    "#         print(sum([v for (v, k) in r]))\n",
    "#         rd = dict([(k, v) for (v, k) in r])\n",
    "#         r = [k for (v, k) in r]\n",
    "#         d[t] = (rd, r, np.e**choice[\"logprobs\"][\"token_logprobs\"][t_i])\n",
    "#     print('|'.join([' '.join((s.replace(\"\\n\", \"⏎\"),'%.2f' % (d[s][2] * 100),\n",
    "#                               str(d[s][1].index(s) + 1) if s in d[s][1] else \"<100\")) for s in tokens]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
