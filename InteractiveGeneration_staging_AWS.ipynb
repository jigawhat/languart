{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned language model for pictionary word list completion (topic/category phrase + example words -> list of 30 examples). For example, one may complete the list\n",
    "\n",
    "\"A list of round fruits: peach, apricot, lime, plum,\"\n",
    "\n",
    "with\n",
    "\n",
    "\"mango, cherry, pineapple, strawberry, pumpkin, watermelon, orange, pomegranate, melon, apple, pear, grapefruit, papaya, lemon, kiwi, passionfruit, blueberry, raspberry, blackberry, cantaloupe, nectarine, pitaya, persimmon, durian, guava, jackfruit, avocado, lychee, soursop, guarana, mangosteen, blackcurrant, cranberry\"\n",
    "\n",
    "using this model. These words should be compatible with pictionary/skribbl.io; i.e., \"sketchable\" within a few minutes, and easily recognisable. Scroll to the end for more examples, or see the file `data/examples.txt`. Sketchability parameter estimation examples can also be found in `data/data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import openai\n",
    "# with open('../../openai-api-org.txt', 'r') as f: openai.organization = f.read()\n",
    "# with open('../../openai-api-key.txt', 'r') as f: openai.api_key      = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1007 02:57:28.455765 25356 modeling_bert.py:226] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I1007 02:57:28.466736 25356 modeling_xlnet.py:339] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alfew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import glob\n",
    "import string\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from bayes_opt import BayesianOptimization\n",
    "from IPython.utils import io\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, GPT2LMHeadModel, GPTNeoForCausalLM, ReformerModelWithLMHead, \\\n",
    "                         get_linear_schedule_with_warmup, GPT2TokenizerFast\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from Learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                  ###   Options   ###\n",
    "model_name = \"ernst_one\"\n",
    "# model_name = \"unfinetuned\"\n",
    "gpt2_modelkey = \"gpt2\"           # Pretrained model to start from\n",
    "# gpt2_modelkey = \"gpt2\"\n",
    "val_frac, test_frac = 0.25, 0.25    # Fraction of samples to keep as separate validation/test set (word lists)\n",
    "TsN = 200                           # Number of randomly generated prompts for each sample when validating model\n",
    "log_period_batches = 10             # Batches per iteration\n",
    "# learning_rate = 5e-7              # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "learning_rate = 7e-5\n",
    "# learning_rate = 4e-6\n",
    "adam_epsilon = 1e-8                 # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                  # Linear scheduler for optimizer number of warmup steps\n",
    "# batch_size = bsz = 64               # Samples per batch\n",
    "# batch_size = bsz = 32\n",
    "batch_size = bsz = 4\n",
    "# N_train_batches = int(1e7 / bsz)  # Total number of batches to show model\n",
    "N_train_batches = 600\n",
    "# max_len = 1024                    # Max n. tokens applied prior to rng_train (number of phrases range)\n",
    "max_len = 32\n",
    "train_phrase_log_pctile = 0.42      # Phrase generation probability percentile excluded from training dataset\n",
    "lidstone_eps = 0.01                 # Smoothing epsilon for possible words/subwords which are not in the missing list words set\n",
    "lastcomma_repl = ',' # 'EOS', ','   # Token optionally used to replace the final comma that ends the generated phrase\n",
    "use_correct_nouns = True            # Whether to use only correct singular or plural form of category nouns for the given prompt\n",
    "swap_noun = False                   # Whether to swap plural and singular nouns in prompt\n",
    "# rng_train = [0, 512]              # Range of prompt list lengths (number of phrases) to generate for training data\n",
    "rng_train = [3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda\" if pt.cuda.is_available() else \"cpu\"  # Setup torch device(s)\n",
    "d = device = pt.device(dev)\n",
    "# world_size = 1\n",
    "# rank = 0\n",
    "# def setup(rank, world_size): \n",
    "#     os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "#     os.environ['MASTER_PORT'] = find_free_port()\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)  # initialize the process group\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "# # mp.spawn(setup, args=(rank, world_size), nprocs=world_size)\n",
    "# setup(rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [273, 6231, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_tokenizer = GPT2TokenizerFast.from_pretrained((\"gpt2-large\"), padding=True)\n",
    "with io.capture_output() as captured:\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(gpt2_modelkey.replace(\"-xl\", \"-large\"), padding=True)\n",
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), tokenizer.encode(\"oranges, pears,\"), \\\n",
    "  gpt3_tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    gpt3_tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    gpt3_tokenizer.encode(\"oranges, pears,\") # Note: gpt-3 tokenizes words differently if they are at the start of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_sing = [p for p in lprompts if ((\"types of\" in p) ^ swap_noun)]\n",
    "enc_prompts = lambda tknzr, prmts: [pt.tensor(tknzr.encode(p)).to(d) for p in prmts]\n",
    "enc_listset = lambda tknzr, Xs: [[[pt.tensor(tknzr.encode(p + suffix)).to(d) for p in ps] for ps in X] for (X, suffix) in Xs]\n",
    "lprompts_encoded, lprompts_encoded3 = enc_prompts(tokenizer, lprompts), enc_prompts(gpt3_tokenizer, lprompts)\n",
    "lprompts_sing_encoded, lprompts_sing_encoded3 =enc_prompts(tokenizer, lprompts_sing),enc_prompts(gpt3_tokenizer, lprompts_sing)\n",
    "Xs = (cats, ': '), (cats_sing, ': '), (phrases, ', ')\n",
    "(cats_e,cats_sing_e,phrases_e), (cats_e3,cats_sing_e3,phrases_e3) = enc_listset(tokenizer, Xs), enc_listset(gpt3_tokenizer, Xs)\n",
    "comma_token = pt.tensor(tokenizer.encode(\"a,\")[1], device=d)\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)\n",
    "lidstone_eps = pt.tensor(lidstone_eps, device=d) if not isinstance(lidstone_eps, pt.Tensor) else lidstone_eps\n",
    "lidstone_value = lidstone_eps / N_tokens\n",
    "y_zero = (lidstone_value).repeat(N_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1105\n",
      "GPT2 device: cuda:0\n",
      "Pretrained parameters loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in locals():  # Load pretrained weights\n",
    "    del model\n",
    "print(gc.collect()), pt.cuda.empty_cache()\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2LMHead\")\n",
    "model_ = GPT2LMHeadModel.from_pretrained(gpt2_modelkey,\n",
    "    output_hidden_states=False, output_attentions=False, \n",
    "    cache_dir=\"models/pretrained/GPT2LMHead\")\n",
    "if pt.cuda.device_count() > 1:\n",
    "    device_map = {0: [0, 1, 2],\n",
    "                  1: [3, 4, 5, 6, 7, 8],\n",
    "                  2: [9, 10, 11, 12, 13, 14],\n",
    "                  3: [15, 16, 17, 18, 19, 20],\n",
    "                  4: [21, 22, 23, 24, 25, 26, 27],\n",
    "                  5: [28, 29, 30, 31, 32, 33, 34],\n",
    "                  6: [35, 36, 37, 38, 39, 40, 41],\n",
    "                  7: [42, 43, 44, 45, 46, 47],\n",
    "                 }\n",
    "    model_.parallelize(device_map)\n",
    "else:\n",
    "    model_ = model_.to(d)\n",
    "print(\"GPT2 device:\", model_.device)\n",
    "model_.resize_token_embeddings(N_tokens)\n",
    "pad_token = model_.config.pad_token_id = model_.config.eos_token_id\n",
    "pad_token = pt.tensor(pad_token, device=d)\n",
    "repl_token = pt.tensor(tokenizer.encode(lastcomma_repl)[0], device=d) if lastcomma_repl != 'EOS' else pad_token\n",
    "n_embd = pt.tensor(model_.config.n_embd, device=d)\n",
    "# model = nn.parallel.DistributedDataParallel(model_, device_ids=[d])\n",
    "# model = nn.DataParallel model_, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else model_\n",
    "model = model_\n",
    "mname_fn = gpt2_modelkey\n",
    "print(\"Pretrained parameters loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1, device=d)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def inference(x, sqlens, past=None, return_states=False, seq_maxlen=max_len, add=0, return_fulloutput=False):\n",
    "    global model\n",
    "\n",
    "    multitoken = x.shape[1] > 1\n",
    "    mask = sequence_mask(sqlens, seq_maxlen) if (multitoken or add != 0) else None\n",
    "    if add > 0: mask = pt.cat([mask, pt.ones(mask.shape[0], add).to(d)], dim=1)  # Append mask entry for new stream token\n",
    "    outputs = model(x.long(), attention_mask=mask, use_cache=None if not return_states else True, past_key_values=past)\n",
    "    if return_fulloutput: return outputs\n",
    "    logits = outputs[0][[pt.arange(x.shape[0]), sqlens - 1]] if multitoken else outputs[0].squeeze(1)\n",
    "\n",
    "    return (logits, outputs[1]) if return_states else logits  # Optionally return the past states needed to restore the stream\n",
    "def adapt_form(xs, ys, sqlens, mlen=max_len, repl_finalcomma=True):\n",
    "    xs = pt.vstack([F.pad(x, (0, max(0, mlen - len(x))), mode='constant', value=pad_token)[:mlen] for x in xs])\n",
    "    _ys = pt.vstack(ys) if ys is not None else None\n",
    "    if repl_finalcomma and (lastcomma_repl != ',') and ys is not None:\n",
    "        _ys[:, repl_token] += _ys[:, comma_token] - lidstone_value\n",
    "        _ys[:, comma_token] = lidstone_value\n",
    "    return xs, _ys, pt.tensor(sqlens, device=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s_avglogs(X, use_log_probs=True):\n",
    "    tokens = [pt.tensor(tokenizer.encode(x)).to(d) for x in X]\n",
    "    sqlens = [len(x) for x in tokens]\n",
    "    n_bats = (len(sqlens) // batch_size) + 1\n",
    "    res = []\n",
    "    for i in range(n_bats):\n",
    "        tokens_b, sqlens_b = tokens[i * bsz:(i + 1) * bsz], sqlens[i * bsz:(i + 1) * bsz]\n",
    "        xs, _, sqlen = adapt_form(tokens_b, None, sqlens_b, mlen=max(sqlens_b))\n",
    "        logits = inference(xs, sqlen, seq_maxlen=max(sqlens_b), return_fulloutput=True)[0]\n",
    "        pt.cuda.empty_cache()\n",
    "#         logits = pt.stack(logits, 0)\n",
    "        for i in range(len(sqlens_b)):\n",
    "            x_logits = [logits[i][j] for j in range(sqlens_b[i])]\n",
    "            x_logs = ([pt.log(F.softmax(logits[i][j]))[tokens_b[i][j]].cpu().detach().numpy() for j in range(sqlens_b[i])] if \\\n",
    "                      use_log_probs else \\\n",
    "                      [logits[i][j][tokens_b[i][j]].cpu().detach().numpy() for j in range(sqlens_b[i])])\n",
    "            res.append(np.mean(x_logs[1:]))  # ignore initial prefix token 'A'/'An'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "all_phrases = list(set(sum(phrases, [])))\n",
    "vowels = 'aeiuo'\n",
    "phrase_logs = get_s_avglogs([('An' if p[0].lower() in vowels else 'A') + ' ' + p for p in all_phrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "phrase_log = dict(zip(all_phrases, phrase_logs))\n",
    "all_phrases_enc = sum([[tuple(p_.cpu().detach().numpy().tolist()) for p_ in p] for p in phrases_e], [])\n",
    "enc_phrase_log = dict(zip(list(set(all_phrases_enc)), phrase_logs))\n",
    "max_phrase_log = np.percentile(phrase_logs, 100 * (1.0 - train_phrase_log_pctile))\n",
    "plt.hist(phrase_logs, bins=250)\n",
    "plt.axvline(x=max_phrase_log, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p, ra=True, rng=rng_train, mlen=max_len):  # prmt = prompt tokens, p = list phrase/word tokens\n",
    "    tkzs, sent, tkix, wordix = [], [], 0, -1   # rng is the inclusive range of list lengths to generate (number of phrases)\n",
    "    min_nw, max_nw, min_nt, max_nt = rng[0], int(rng[1]), 0, int(mlen) - len(prmt)\n",
    "    p_ra = [i for i in range(len(p)) if enc_phrase_lprob[tuple(p[i].cpu().detach().numpy().tolist())] > max_phrase_lprob]\n",
    "    p_incl = [i for i in range(len(p)) if i not in p_ra]\n",
    "    incl_words = np.random.choice(len(p), min(len(p), max_nw), replace=False)\n",
    "    p_ra_chosen = [i for i in incl_words if i in p_ra]\n",
    "    min_nw -= len(p_ra_chosen)\n",
    "    incl_words = [i for i in incl_words if i in p_incl]\n",
    "    if len(incl_words) == 0 # rare when train_phrase_log_pctile is low enough and min_nw is high enough (temporary optimisation)\n",
    "        return gen_truncated_list(prmt, p, ra=ra, rng=rng, mlen=mlen)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc, wordix = p[phz_i], wordix + 1\n",
    "        tkzs.append((tkix, phz_enc)), sent.append(phz_enc)\n",
    "        tkix += len(phz_enc)\n",
    "        if wordix < min_nw: min_nt = tkix\n",
    "        if tkix >= max_nt:\n",
    "            tkix = max_nt\n",
    "            break\n",
    "    if min_nt - 1 >= tkix:  # rare when max_len is large enough (0.5x max possible total list length) (temporary optimisation)\n",
    "        return gen_truncated_list(prmt, p, ra=ra, rng=rng, mlen=mlen)\n",
    "    sent = pt.hstack(sent)[:max_nt]\n",
    "    # If we don't want to include outliers in target\n",
    "    missing_w = [p[i] for i in range(len(p)) if (i not in incl_words) and (True if ra else (i in p_incl))]\n",
    "    trunc_ix = np.random.randint(max(min_nt - 1, 0), tkix)\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if len(enc) >= trunc_n and all(enc[:trunc_n] == partial_phr)]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_eps)\n",
    "    tunit, y_ = pt.tensor(1 / norm, device=d), y_zero.clone()\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return pt.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def stac_sample(stac, n):   # Create batches by random permutations (maximise diversity and uniformity) (shuffling done later)\n",
    "    r, mode, total = [], tuple(np.unique(stac)), stac.shape[0]\n",
    "    while n > 0:\n",
    "        if mode == (0,) or mode == (1,) or mode == (-1,):\n",
    "            if n >= total:\n",
    "                new = sum([list(range(total)) for _ in range(n // total)], [])\n",
    "                r += new\n",
    "                n -= len(new)\n",
    "            else:\n",
    "                new = np.random.choice(total, n, replace=False)\n",
    "                stac[new] = (mode[0] + 1) if mode != (1,) else -1\n",
    "                r += new.tolist()\n",
    "                n = 0\n",
    "        else:\n",
    "            old_val, new_val = mode[0] if mode != (-1, 1) else 1, mode[1] if mode != (-1, 1) else -1\n",
    "            old_i = np.nonzero(stac == old_val)[0]\n",
    "            if n >= old_i.shape[0]:\n",
    "                stac[old_i] = new_val\n",
    "                r += old_i.tolist()\n",
    "                n -= old_i.shape[0]\n",
    "            else:\n",
    "                new = np.random.choice(old_i, n, replace=False)\n",
    "                stac[new] = new_val\n",
    "                r += new.tolist()\n",
    "                n = 0\n",
    "        mode = tuple(np.unique(stac))\n",
    "    return r\n",
    "def gen_listname(cp, cp_cs, prompt, prmt, tknzr=tokenizer):\n",
    "    cat_ix = np.random.randint(len(cp_cs))            # First uniformly sample a category title\n",
    "    sing = use_correct_nouns and (cat_ix >= len(cp))  # Singular vs plural prompt prefix\n",
    "    if prompt is None:                                # Uniformly sample a list beginning phrase (\"A list of...\") if not given\n",
    "        lprmpts = ((lprompts_sing_encoded if sing else lprompts_encoded) if tknzr is tokenizer else \\\n",
    "                   (lprompts_sing_encoded3 if sing else lprompts_encoded3)) if tknzr is not None else \\\n",
    "                   (lprompts_sing if sing else lprompts)\n",
    "        prmt = lprmpts[np.random.randint(len(lprmpts))]\n",
    "    return cp_cs[cat_ix], prmt\n",
    "def gen_listnames_uniform(xcp, xcs, xp, n, prompt=None, tknzr=tokenizer, verbose=False, stac=None):\n",
    "    prmts, cats, ps, j, prmt = [], [], [], 0, None\n",
    "    if prompt is not None and tknzr is not None: prmt = pt.tensor(tknzr.encode(prompt), device=d)\n",
    "    stac_, stac = stac_sample(stac, n) if (stac is not None) else None, stac is not None\n",
    "    if stac: np.random.shuffle(stac_)\n",
    "    for i in (range(len(xcp)) if not stac else stac_):\n",
    "        prmts_, cats_ = [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        for m in range(n if not stac else 1):\n",
    "            cat, prmt = gen_listname(cp, cp_cs, prompt, prmt, tknzr=tknzr)\n",
    "            prmts_.append(prmt), cats_.append(cat)\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0: sys_print(\"\\rGenerating list names, done: \" + str(j))\n",
    "        ps.append(p), prmts.append(prmts_), cats.append(cats_)\n",
    "    if verbose: sys_print(\"\\rGenerating list names, done: \" + str(j) + \", finished!\\n\")\n",
    "    return prmts, cats, ps, stac\n",
    "def gen_samples_uniform(xcp, xcs, xp, n,              # Weight testing samples (word lists) exactly uniformly\n",
    "                        ra=True, rng=rng_train, prompt=None, tknzr=tokenizer, verbose=False, inds=False, stac=None, mlen=1e9):\n",
    "    xs, ys, sqlens, j, prmt = [], [], [], 0, None\n",
    "    prmts, cats, ps, stac = gen_listnames_uniform(xcp, xcs, xp, n, prompt=prompt, tknzr=tknzr, verbose=verbose, stac=stac)\n",
    "    for i in range(len(prmts)):\n",
    "        x, y, sqlen, p = [], [], [], ps[i]\n",
    "        for k in range(len(prmts[i])):\n",
    "            x_, y_ = gen_truncated_list(pt.hstack([prmts[i][k], cats[i][k]]), p, ra=ra, rng=rng, mlen=mlen)\n",
    "            x.append(x_), y.append(y_), sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0: sys_print(\"\\rGenerating list elements, done: \" + str(j))\n",
    "        xs.append(x), ys.append(y), sqlens.append(sqlen)\n",
    "    if inds or stac: xs, ys, sqlens = sum(xs, []), sum(ys, []), sum(sqlens, [])\n",
    "    if verbose: sys_print(\"\\rGenerating list elements, done: \" + str(j) + \", finished!\\n\")\n",
    "    return (xs, ys, sqlens, np.arange(len(xcp)).repeat(n)) if inds else (xs, ys, sqlens)\n",
    "def gen_samples(xcp, xcs, xp, n,\n",
    "                ra=True, rng=rng_train, prompt=None, tknzr=tokenizer, inds=False, mlen=1e9):\n",
    "    xs, ys, sqlens, j, prmt = [], [], [], 0, None   \n",
    "    if prompt is not None and tknzr is not None: prmt = pt.tensor(tknzr.encode(prompt), device=d)\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets, indices = len(xcp), []\n",
    "    for m in range(n):  # Maximise per-batch training diversity by randomly sampling the word lists\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        cat_ix, prmt = gen_listname(cp, cp_cs, prompt, prmt)\n",
    "        x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p, ra=ra, rng=rng, mlen=mlen)\n",
    "        xs.append(x_), ys.append(y_), sqlens.append(len(x_)), indices.append(i)\n",
    "    return (xs, ys, sqlens, np.asarray(indices)) if inds else (xs, ys, sqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  8 21  4  7  5 10 25] [14 11  1 19 24 31 18 32]\n",
      "Train\n",
      " ['round fruits', 'microorganisms', 'outback experiences', 'buildings', 'holed pasta', 'rod shaped pasta', 'sounds of a building', 'biological examples of math in nature', 'non-biological examples of math in nature', 'handcrafts', 'communication media', 'storage media', 'scientific principles behind showers', 'scientific principles behind rain showers', 'spacecraft types', 'real spacecrafts', 'interpersonal tokens of trust'] \n",
      "Validation\n",
      " ['construction sounds', 'hats', 'wild animals', 'woodland ecoregions', 'winds', 'physical tokens that confer trust', 'timbers', 'digital tokens that confer trust'] \n",
      "Test\n",
      " ['chemical elements', 'dramatic and literature elements', 'vehicles referred to as crafts', 'music', 'scientific cycles', 'machine learning algorithms', 'glassware', 'windings']\n",
      "Generating list names, done: 1600, finished!\n",
      "Generating list elements, done: 1600, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test, N_val = int(test_frac * N_wordlists), int(val_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "# test_idx = np.random.choice(N_train, N_test, replace=False)\n",
    "test_idx = np.asarray([ 2,  8, 21,  4,  7,  5, 10, 25])\n",
    "save_ld(test_idx, \"test_idx\")\n",
    "# test_idx = load_ld(\"test_idx\")\n",
    "trval_idx = np.asarray([i for i in range(N_wordlists) if i not in test_idx])\n",
    "# val_idx = np.random.choice(trval_idx, N_val, replace=False)\n",
    "val_idx = np.asarray([14, 11,  1, 19, 24, 31, 18, 32])\n",
    "save_ld(val_idx, \"val_idx\")\n",
    "# val_idx = load_ld(\"val_idx\")\n",
    "train_idx = np.asarray([i for i in trval_idx if i not in val_idx])\n",
    "print(test_idx, val_idx)\n",
    "print(*sum([[c+'\\n',[cats[i][0] for i in ix]]for(c,ix)in[[\"Train\",train_idx],[\"\\nValidation\",val_idx],[\"\\nTest\",test_idx]]],[]))\n",
    "index_listset, listset_iXs = lambda inds, Xs: [[X[i] for i in inds] for X in Xs],(\"trval_idx\",\"train_idx\",\"val_idx\",\"test_idx\")\n",
    "phase_listsets = {None: {k[:-4]: index_listset(globals()[k], (cats, cats_sing, phrases)) for k in listset_iXs},\n",
    "             \"default\": {k[:-4]: index_listset(globals()[k], (cats_e, cats_sing_e, phrases_e)) for k in listset_iXs},\n",
    "                \"gpt3\": {k[:-4]: index_listset(globals()[k], (cats_e3, cats_sing_e3, phrases_e3)) for k in listset_iXs}}\n",
    "cats_e_test, cats_sing_e_test, phrases_e_test = phase_listsets[\"default\"][\"test\"]\n",
    "cats_e_val, cats_sing_e_val, phrases_e_val = phase_listsets[\"default\"][\"val\"]\n",
    "val_cats = [cats[i][0] for i in val_idx]\n",
    "test_xs,test_ys,test_sqlens= gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, TsN, mlen=max_len, verbose=True)\n",
    "val_xs, val_ys, val_sqlens = gen_samples_uniform(cats_e_val, cats_sing_e_val, phrases_e_val, TsN, mlen=max_len, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function that takes a prompt, existing list and sampling params and returns gpt3's next token probs\n",
    "default_msp = {\n",
    "  \"best_of\": 1,\n",
    "}\n",
    "default_sp = {\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "#   \"top_k\": -1.0,                 # todo: add code to apply this to gpt3 output (top100), max k ~=90, min = 2?\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "}\n",
    "default_params = {\n",
    "  \"engine\": \"davinci\",\n",
    "  \"model\": None,\n",
    "  \"max_tokens\": 1,\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "#   \"top_k\": -1.0,\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "  \"n\": 1,\n",
    "  \"stream\": False,\n",
    "  \"logprobs\": 100,\n",
    "#       \"logit_bias\": {\"50256\": -100},\n",
    "  \"stop\": [\",\", \"\\n\"],\n",
    "}\n",
    "# Define and test the OpenAI API next token probability request (response-token-efficient streaming version)\n",
    "def format_gpt3_probs(choice, tokenize):\n",
    "    res, r = [], sorted([(np.e**v, k) for (k, v) in choice[\"logprobs\"][\"top_logprobs\"][0].items()])[::-1]\n",
    "    for i in range(len(r)):\n",
    "        k = gpt3_tokenizer.encode(r[i][1])\n",
    "        if len(k) == 1: res.append((r[i][0], k if tokenize else r[i][1]))\n",
    "    return res\n",
    "def p_req(s, tokenize=False, **kwargs):\n",
    "    use_stream = \"max_tokens\" in kwargs and kwargs[\"max_tokens\"] != 1\n",
    "    kwargs[\"prompt\"], kwargs[\"stream\"] = s, use_stream\n",
    "    with io.capture_output() as captured:\n",
    "        response, result = openai.Completion.create(**{**default_params, **kwargs}), []\n",
    "    return [(np.e**resp[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0], resp[\"choices\"][0][\"logprobs\"][\"tokens\"][0],\n",
    "             format_gpt3_probs(resp[\"choices\"][0], tokenize)) for resp in (response if use_stream else [response])]\n",
    "# todo: version to handle multiple choices for phrase level evaluation (response-token-expensive)\n",
    "def p_req_m(s, tokenize=False, **kwargs):\n",
    "    if \"max_tokens\" not in kwargs: kwargs[\"max_tokens\"] = 8\n",
    "    if \"n\" not in kwargs: kwargs[\"n\"] = 5\n",
    "    if \"best_of\" in kwargs:\n",
    "        kwargs[\"best_of\"] = int(round(kwargs[\"best_of\"]))\n",
    "        if kwargs[\"n\"] != 1: kwargs[\"best_of\"], kwargs[\"n\"] = kwargs[\"n\"], kwargs[\"best_of\"]\n",
    "    kwargs[\"prompt\"] = s\n",
    "    with io.capture_output() as captured:\n",
    "        response, tokens, probs = openai.Completion.create(**{**default_params, **kwargs}), [], []\n",
    "    for choice in response[\"choices\"]:\n",
    "        tks = [np.e**v for v in choice[\"logprobs\"][\"token_logprobs\"]]\n",
    "        tks = [(choice[\"logprobs\"][\"tokens\"][i], tks[i]) for i in range(len(tks))]\n",
    "        tokens.append(tks), probs.append(format_gpt3_probs(choice, tokenize))\n",
    "    return tokens, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = p_req(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "# b = p_req_m(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "# print(sum([a_[0] for a_ in a[0][2]]))\n",
    "# print(','.join([''.join([b__[0] for b__ in b_]) for b_ in b[0]] + [''.join([a_[1] for a_ in a])]).replace('\\n', 'âŽ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a completion distribution (top 100) and target next token distribution (multinomial) and computes the\n",
    "# probability that the completion produces a desired output token\n",
    "def prob_corr(pred_p, target_p):\n",
    "    r = 0\n",
    "    if isinstance(pred_p, list):\n",
    "        for (p, token) in pred_p:\n",
    "            if target_p[token] > (lidstone_value + 1e-10): r += p\n",
    "    else:\n",
    "        r = np.sum(target_p[np.nonzero(pred_p > (lidstone_value + 1e-10))[0]])\n",
    "    return r\n",
    "# directly computes the similarity between target and predicted token distributions\n",
    "def score_corr(pred_p, target_p, distance=\"cross-entropy\", redistribute_mass=False, include_negatives=False):  \n",
    "    r = 0\n",
    "    if isinstance(pred_p, list) and not redistribute_mass:\n",
    "        for (p, token) in pred_p:\n",
    "            targ = target_p[token]\n",
    "            if targ > (lidstone_value + 1e-10) or include_negatives:\n",
    "                if   distance == \"unnormalized\":  r -= p * targ\n",
    "                elif distance == \"cross-entropy\": r -= p * np.log(targ)\n",
    "                elif distance == \"kl-divergence\": r += p * np.log(p / targ)\n",
    "                elif distance == \"bhattacharyya\": r += np.sqrt(p * targ)\n",
    "        if distance == \"bhattacharyya\": r = -np.log(r)\n",
    "    else:\n",
    "        p = pred_p\n",
    "        if isinstance(pred_p, list):\n",
    "            p_ = np.asarray([p for (p, _) in pred_p])\n",
    "            ts = np.asarray([t for (_, t) in pred_p])\n",
    "            unaccounted_mass = 1.0 - sum(p_)\n",
    "            n_missing_tokens = N_tokens - len(pred_p)\n",
    "            p = np.repeat(unaccounted_mass / n_missing_tokens, N_tokens)\n",
    "            p[ts] = p_\n",
    "        if not include_negatives:\n",
    "            pos = np.nonzero(target_p > (lidstone_value + 1e-10))[0]\n",
    "            p, target_p = p[pos], target_p[pos]\n",
    "        if   distance == \"unnormalized\":  r = -np.sum(p * targ)\n",
    "        elif distance == \"cross-entropy\": r = -np.sum(p * np.log(target_p))\n",
    "        elif distance == \"kl-divergence\": r =  np.sum(p * np.log(p / target_p))\n",
    "        elif distance == \"bhattacharyya\": r = -np.log(np.sum(np.sqrt(p * target_p)))\n",
    "    return -r\n",
    "# probability that a completion phrase is a desired missing list entry\n",
    "def prob_msp(outs, missing):\n",
    "    correct = 0\n",
    "    missing = set([phrase.lower() for phrase in missing])\n",
    "    for i in range(len(outs)):\n",
    "        out = outs[i].strip().lower()\n",
    "        if out not in missing and (out[:4] == 'the '): out = out[4:]\n",
    "        if out in missing: correct += 1\n",
    "    return correct / len(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   ' Fermi-Pasta-Ulam problem,',\n",
      "        array([  376,  7780,    72,    12, 34533,    64,    12,    52,  2543,\n",
      "        1917,    11], dtype=int64),\n",
      "        11),\n",
      "    (   ' maccheroncini di campofilone,',\n",
      "        array([8352, 2044,  261,   66, 5362, 2566, 1413, 1659,  346,  505,   11],\n",
      "      dtype=int64),\n",
      "        11)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = sum([[len(p) for p in p_ if len(p) < 1000] for p_ in phrases_e], [])  # Print longest list elements in dataset, get max\n",
    "phrs = sum([[p for p in p_ if len(p) < 1000] for p_ in phrases_e], [])\n",
    "m = np.max(lens)\n",
    "inds = [i for i in range(len(phrs)) if lens[i] == m]\n",
    "ree = [(tokenizer.decode(phrs[i].cpu().detach().numpy()), phrs[i].cpu().detach().numpy(), lens[i]) for i in inds]\n",
    "phrl_max = len(ree[0][1]) - 1\n",
    "pr(ree)\n",
    "phrl_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes sampling parameters, then generates n random incomplete list prompts (of length l), obtains completion\n",
    "# distributions (top 100 tokens or full multinomial) and evaluates the average score across the n prompts. n = 20 by default\n",
    "# All samples generated are stored fully for later training of sample-dependent sampling parameter (mixture) distribution\n",
    "sps_ = [\"top_p\", \"temperature\", \"presence_penalty\", \"frequency_penalty\"]  # sampling params                          #top_k\n",
    "msps_= sps_#[\"best_of\"] + sps_                                                 # meta sampling params\n",
    "create_folder(data_dir + learning_data_dir)\n",
    "create_folder(data_dir + learning_data_dir + \"sp_samples\")\n",
    "create_folder(data_dir + learning_data_dir + \"sp_samples_test\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_samples_nb\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_samples_nb_test\")\n",
    "phaseIx = lambda phase: globals()[phase + '_idx']\n",
    "def save_modeloutput(idx, dname, pnames, params, r, min_l, max_l, mdl, xs=None, ys=None, sqlens=None, inds=None, d=None):\n",
    "    engine_str = ','.join([str(params[k]) for k in [\"engine\", \"model\"] if k in params])\n",
    "    for i_raw in range(len(idx)):\n",
    "        i = idx[i_raw]\n",
    "        create_folder(data_dir + learning_data_dir + dname + \"/\" + str(i))\n",
    "        ix, mdl_name = np.nonzero(inds == i_raw)[0], mdl if isinstance(mdl, str) else mdl[\"name\"]\n",
    "        fn = str(time.time()) + '_' + '_'.join([str(v) for v in [params[k] for k in pnames] + [min_l, max_l]]) + '_' + mdl_name\n",
    "        input_data = [d[j] for j in ix] if d else [xs[ix], ys[ix], sqlens[ix]]\n",
    "        save_ld((params, input_data, ix, [r[j] for j in ix], str(mdl)), dname + \"/\" + str(i) + \"/\" + fn, compress=9)\n",
    "def eval_sp(params, min_l=0, max_l=1e9, n=20, prmt=None, phase=\"train\", uniform=True, mdl='gpt3'):\n",
    "    res, max_l = [], int(max_l), \n",
    "    tknzr = gpt3_tokenizer if mdl == \"gpt3\" else tokenizer\n",
    "    xcp, xcs, xp = phase_listsets[\"gpt3\" if mdl == \"gpt3\" else \"default\"][phase]\n",
    "    xs, ys, sqlens, inds = gen_samples_uniform(xcp, xcs, xp, n, prompt=prmt, tknzr=tknzr, inds=True, rng=[min_l, max_l]) \\\n",
    "           if uniform else gen_samples        (xcp, xcs, xp, n, prompt=prmt, tknzr=tknzr, inds=True, rng=[min_l, max_l])\n",
    "    if mdl == 'gpt3': r = [p_req(gpt3_tokenizer.decode(x_.detach().cpu().numpy()), **params) for x_ in xs] \n",
    "    else:             r = mdl[\"probabilities\"](xs, ys, sqlens, **params)\n",
    "    save_modeloutput(phaseIx[phase][np.unique(inds)], \"sp_samples\", sps_, params, r, min_l, max_l, mdl, xs, ys, sqlens, inds)\n",
    "    return np.mean([score_corr(r[i], ys[i]) for i in range(len(r))])\n",
    "def eval_sp_conv(params, tol=0.01, **kwargs):\n",
    "    center, samples = np.inf, []\n",
    "    while True:\n",
    "        samples.append(eval_sp(params, n=2, **kwargs))\n",
    "        new_center = np.mean(samples)\n",
    "        if abs(center - new_center) < tol: return new_center, samples\n",
    "        new_center = center\n",
    "# This metric differs depending on tokenisation, so for the testing of models, a full phrase accuracy function is required\n",
    "def gen_phraselevel_samples_uniform(phase, min_l, max_l, n, prmt):\n",
    "    xcp, xcs, xp = phase_listsets[None][phase]\n",
    "    d, (prmts, cats, ps, _) = [], gen_listnames_uniform(xcp, xcs, xp, n, prompt=prmt, tknzr=None)\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen, p = [], [], [], ps[i]\n",
    "        for m in range(n):\n",
    "            prompt, cat = prmts[i][m], cats[i][m]\n",
    "            phr_ix = np.random.choice(len(p), np.random.randint(min_l, min(max_l, len(p) - 1)), replace=False)\n",
    "            missing_ix = [i for i in range(len(p)) if i not in phr_ix]\n",
    "            prompt = (prompt + ' ' + cat + ': ' + ''.join([p[j] + ', ' for j in phr_ix]))[:-1]\n",
    "            d.append([prompt, [p[j] for j in missing_ix]])\n",
    "    return d, np.arange(len(xcp)).repeat(n)\n",
    "strip_the = lambda x: x[4:] if x.lower()[:4] == 'the ' else x\n",
    "strip_tl = lambda x: strip_the(x.strip().lower())\n",
    "strip_comma = lambda x: [x_.strip() for x_ in (x[:-1] if len(x) > 1 else x)]\n",
    "strip_lower = lambda x: [strip_tl(x_) for x_ in (x[:-1] if len(x) > 1 else x)]\n",
    "def ensemble_two_models_results(m2ensemble_frac, r, r2):\n",
    "    bof = len(r[0])\n",
    "    n_replace = int(bof * m2ensemble_frac)\n",
    "    r_new = [[strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_] for r_ in r]\n",
    "    for i in range(len(r)):\n",
    "        cur_pool = set(sum([strip_lower(''.join([r__[0] for r__ in r_]).split(',')) for r_ in r[i][:bof - n_replace]], []))\n",
    "        new_pool = sum([strip_comma(''.join([r__[0] for r__ in r_]).split(',')) for r_ in r2[i]], [])\n",
    "        for j in range(n_replace):\n",
    "            n_phrases = len(r[i][j])\n",
    "            add = []\n",
    "            while len(add) < n_phrases and len(new_pool) > 0:\n",
    "                new_phr = new_pool[0]\n",
    "                stripped_new_phr = strip_tl(new_phr)\n",
    "                if stripped_new_phr not in cur_pool:\n",
    "                    add.append(new_phr), cur_pool.add(stripped_new_phr)\n",
    "                new_pool = new_pool[1:]\n",
    "            if len(add) > 0:\n",
    "                r_new[i][j + bof - n_replace] = add\n",
    "    return [sum(r_, []) for r_ in r_new]\n",
    "def test_sp(params, min_l=0, max_l=1e9, n1=3, n2=10, prmt=None, phase=\"train\", uniform=True, max_tokens=phrl_max,\n",
    "            mdl='gpt3', mdl2=None, d=None, d_test=None, inds=None, inds_test=None, m2ensemble_frac=0.4, return_test_acc=True):\n",
    "    max_l, test_acc, dn = int(max_l), None, \"msp_samples_nb\"\n",
    "    if d is None: d, inds = gen_phraselevel_samples_uniform(phase, min_l, max_l, n1, prmt)\n",
    "    params = {**default_sp, **params, **{'n': n2, 'max_tokens': max_tokens}} #**default_msp,\n",
    "    if mdl == 'gpt3': r = [p_req_m(d_[0], **params)[0] for d_ in d]  # Request predictions from OpenAI\n",
    "    else:             r = mdl[\"completions\"]([d_[0] for d_ in d], **params)\n",
    "    save_modeloutput(phaseIx(phase), dn, msps_, params, r, min_l, max_l, mdl, d=d, inds=inds)\n",
    "    if mdl2 is not None:\n",
    "        if mdl2 == 'gpt3': r2 = [p_req_m(d_[0], **params)[0] for d_ in d]# Ensemble with 2nd model according to m2ensemble_frac\n",
    "        else:              r2 = mdl2[\"completions\"]([d_[0] for d_ in d], **params)# This loads precomputed outputs so no resave\n",
    "        r = ensemble_two_models_results(m2ensemble_frac, r, r2)\n",
    "    else:\n",
    "        r = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_], []) for r_ in r]\n",
    "    #     r = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(','))[:max_l - min_l] for r__ in r_], []) for r_ in r]\n",
    "    acc = np.mean([prob_msp(r[i], d[i][1]) for i in range(len(r))])\n",
    "\n",
    "    if phase != \"test\":  # if not testing finalised parameters, also output the test set accuracy\n",
    "        listset_fracs = {\"train\": 1 - (val_frac + test_frac), \"trval\": 1 - test_frac, \"val\": val_frac, \"test\": test_frac}\n",
    "        n1_ = n1 * int(listset_fracs[phase] / test_frac)  # Use approximately enough samples to converge\n",
    "        if d_test is None: d_test, inds_test = gen_phraselevel_samples_uniform(\"test\", min_l, max_l, n1_, prmt)\n",
    "        if mdl == 'gpt3': r_test = [p_req_m(d_[0], **params)[0] for d_ in d_test]\n",
    "        else:             r_test = mdl[\"completions\"]([d_[0] for d_ in d_test], **params)\n",
    "        save_modeloutput(phaseIx(\"test\"), dn+\"_test\", msps_, params, r_test, min_l, max_l, mdl, d=d_test, inds=inds_test)\n",
    "        if mdl2 is not None:\n",
    "            if mdl2 == 'gpt3': r2_test = [p_req_m(d_[0], **params)[0] for d_ in d_test]\n",
    "            else:              r2_test = mdl2[\"completions\"]([d_[0] for d_ in d_test], **params)\n",
    "            r_test = ensemble_two_models_results(m2ensemble_frac, r_test, r2_test)\n",
    "        else:\n",
    "            r_test = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_], []) for r_ in r_test]\n",
    "#r_test =[sum([strip_comma(''.join([r___[0] for r___ in r__]).split(','))[:max_l - min_l] for r__ in r_], []) for r_ in r_test]\n",
    "        samps = np.asarray([prob_msp(r_test[i], d_test[i][1]) for i in range(len(r_test))])\n",
    "        test_sd = np.std(100*samps)\n",
    "        test_acc = np.mean(samps)\n",
    "        if not return_test_acc:\n",
    "            print(\"Test acc:\", 100*test_acc, \"sd:\", test_sd)\n",
    "\n",
    "    return (acc, test_acc) if return_test_acc else acc\n",
    "def test_sp_conv(params, tol=0.01, **kwargs):\n",
    "    center, ys, i, steps_nochange = np.inf, [], 1, 0\n",
    "    while True:\n",
    "        ys.append(test_sp(params, n1=1, **kwargs))\n",
    "        new_center = np.mean([s[0] for s in ys])\n",
    "        if abs(center - new_center) < tol: steps_nochange += 1\n",
    "        else:                              steps_nochange = 0\n",
    "        if steps_nochange >= 3 and i >= 5:\n",
    "            if ys[0][1] is not None: print([s[1] for s in ys])\n",
    "            print([s[0] for s in ys])\n",
    "            j = 1 if ys[0][1] is not None else 0\n",
    "            sys_print(str((\"Test acc:\", 100*np.mean([s[j] for s in ys]), \"sd:\", np.std([100*s[j] for s in ys])))+\"\\n\", False)\n",
    "            return new_center, ys\n",
    "        center = new_center\n",
    "        i += 1\n",
    "# eval_sp(default_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "curr_ri = np.zeros(len(train_idx), dtype=int)\n",
    "def next_batch(sz):\n",
    "    global phase_listsets, curr_ri\n",
    "    cats_, cats_sing_, phrases_ = phase_listsets[\"default\"][\"train\"]\n",
    "    return adapt_form(*gen_samples_uniform(cats_, cats_sing_, phrases_, sz, ra=False, stac=curr_ri, mlen=max_len))\n",
    "#     return adapt_form(*gen_samples(cats_, cats_sing_, phrases_, sz, ra=False, mlen=max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also create a gpt3 prompt-completion-based regression model to predict values/densities of sampling parameters (might work if\n",
    "# it's possible to find a humanlike transliteration of the problem statement that gpt3 can bootstrap on to find the params, or\n",
    "# to find some (possibly entirely textual) representation of a params-correlating multidimensional metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = None #nn.Linear(n_embd, N_tokens, bias=False).to(d)#.cpu()                  # Model definition\n",
    "# nn.init.xavier_uniform_(llayer.weight)\n",
    "# llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else llayer\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()#.to(d)#.cpu()\n",
    "# bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d) if dev != \"cpu\" else bcewl_loss\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, bsz, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(bsz)\n",
    "\n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)  # Get logits\n",
    "    logits = outputs[0][[pt.arange(x_batch.shape[0]), sqlens_batch - 1]]\n",
    "\n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lidstone_value + 1e-10)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lidstone_value + 1e-10)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = -1  # Batch 0 is the first iteration, where validation occurs without any training\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "out_str = ''\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, val_loss, val_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):  # Training loop function\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, val_loss, val_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        if batch_i > 0:\n",
    "            gc.collect()\n",
    "            if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "            b_loss, b_accuracy = train_step()\n",
    "            mname_fn = model_name\n",
    "            if verbose:\n",
    "                sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                          ' @ batch '+ str(batch_i) + ' (' + str(batch_i * batch_size) + ' samples) complete.                  ')\n",
    "            iter_loss.append(b_loss), iter_accuracy.append(b_accuracy)\n",
    "\n",
    "        if batch_i % log_period_batches == 0:  # Test on val set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            out_str = '\\n'\n",
    "            for i in range(N_val):\n",
    "                val_X, val_Y, val_Sqlens = adapt_form(val_xs[i], val_ys[i], val_sqlens[i], repl_finalcomma=batch_i > 0)\n",
    "                feed_batches = [range(len(val_X))[i * bsz:(i + 1) * bsz] for i in range((len(val_X) // bsz) + \\\n",
    "                                                                                        (1 if (len(val_X) % bsz) != 0 else 0))]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(val_X[inds], val_Y[inds], val_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls)), accuracy.append(np.mean(cs))\n",
    "                out_str += val_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]) + '\\n'\n",
    "            \n",
    "            val_l, val_a = np.mean(loss), np.mean(accuracy)\n",
    "            val_loss.append(val_l), val_accuracy.append(val_a)\n",
    "            if batch_i == 0: iter_loss, iter_accuracy = [val_l], [val_a]\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l), train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "\n",
    "#             if ((val_a > best_acc and val_a >= train_a) or \\\n",
    "            if ((val_a > best_acc) or \\\n",
    "              (batch_i // log_period_batches) == 1) and batch_i > 0:      # Save best accuracy model\n",
    "                best_acc = val_a\n",
    "                best_loss = val_l\n",
    "                best_acc_idx = batch_i // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "#                          \"llayer\": llayer.state_dict(),\n",
    "#                          \"softmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(out_str + \"Batch\", batch_i, ':', train_a, val_a, \"loss:\", train_l, val_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(val_accuracy, label='val acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                plt.yscale(\"log\")\n",
    "                g.plot(val_loss, label='val loss')\n",
    "                plt.yscale(\"log\")\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, val_accuracy, train_loss, val_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "construction sounds: 0.00040853702, 0.545\n",
      "hats: 0.00041798817, 0.42\n",
      "wild animals: 0.000412389, 0.53\n",
      "woodland ecoregions: 0.00041198463, 0.475\n",
      "winds: 0.00035722856, 0.475\n",
      "physical tokens that confer trust: 0.00040518842, 0.44\n",
      "timbers: 0.0004517778, 0.42\n",
      "digital tokens that confer trust: 0.00047774368, 0.44\n",
      "Batch 220 : 0.45 0.468125 loss: 0.00043057307 0.00041785464 Best: 0.529375 0.0008698267 idx: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\matplotlib\\axis.py:1096: UserWarning: Unable to find pixel distance along axis for interval padding of ticks; assuming no interval padding needed.\n",
      "  warnings.warn(\"Unable to find pixel distance along axis \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, accuracy: 0.00040255798, 0.5 @ batch 230 (920 samples) complete.                   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-7a2c578e04bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Train ernst model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0miterate_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-125-2ff2d9053d9e>\u001b[0m in \u001b[0;36miterate_training\u001b[1;34m(verbose)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mfeed_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m                                                                                         \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdev\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_Sqlens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minds\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeed_batches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mout_str\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mval_cats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-125-2ff2d9053d9e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mfeed_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m                                                                                         \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdev\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_Sqlens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minds\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeed_batches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mout_str\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mval_cats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-123-8383877a1ff1>\u001b[0m in \u001b[0;36meval_test\u001b[1;34m(x, y, sqlens)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbcewl_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-b90aca1e2375>\u001b[0m in \u001b[0;36minference\u001b[1;34m(x, sqlens, past, return_states, seq_maxlen, add, return_fulloutput)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreturn_states\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_fulloutput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqlens\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmultitoken\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_states\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlogits\u001b[0m  \u001b[1;31m# Optionally return the past states needed to restore the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(gc.collect())  # Train ernst model\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "construction sounds: 9.511158e-05, 0.86328125\n",
      "hats: 8.7992914e-05, 0.74609375\n",
      "wild animals: 7.336627e-05, 0.8359375\n",
      "woodland ecoregions: 8.869854e-05, 0.65234375\n",
      "winds: 9.004153e-05, 0.640625\n",
      "physical tokens that confer trust: 8.948342e-05, 0.5078125\n",
      "timbers: 9.020545e-05, 0.77734375\n",
      "digital tokens that confer trust: 9.287207e-05, 0.5\n",
      "Batch 600 : 0.7828125 0.6904297 loss: 7.390388e-05 8.847147e-05 Best: 0.7050781 8.916583e-05 idx: 47\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.7050781, 8.916583e-05)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gc.collect())  # Train ernst model\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pt.cuda.empty_cache(), gc.collect()  # Load best model (checkpoint)\n",
    "cpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "model.load_state_dict(cpoint['model'])\n",
    "bcewl_loss.load_state_dict(cpoint['bcewl_loss'])\n",
    "optimizer.load_state_dict(cpoint['optimizer'])\n",
    "scheduler.load_state_dict(cpoint['scheduler'])\n",
    "# llayer.load_state_dict(cpoint['llayer'])\n",
    "mname_fn = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_filtering(logits, tcounts=None, filter_value=-float('Inf'),  # Function to tune the output token distribution\n",
    "                  top_k=0, top_p=0.0, temperature=1.0, frequency_penalty=0.0, presence_penalty=0.0):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if tcounts is not None: logits -= (tcounts * frequency_penalty) + ((tcounts > 0) * presence_penalty)\n",
    "    logits /= temperature\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gprobs(s, past=None, return_sts=False, tcounts=None, add=0, **kwargs):  # Inference and sampling for tokens\n",
    "    global model\n",
    "    xs, mlen = None, None\n",
    "    if isinstance(s, tuple):    # s either list of token tensors or tuple of preformatted 2d tensors\n",
    "        xs, _, sqlen = s\n",
    "        mlen = max(sqlen)\n",
    "    else:\n",
    "        sqlen = [len(s_) for s_ in s]\n",
    "        mlen = max(sqlen)\n",
    "        xs, _, sqlen = adapt_form([pt.tensor(s_).to(d) for s_ in s], None, sqlen, mlen=mlen)\n",
    "    model.eval()\n",
    "    y_hat = inference(xs, sqlen, seq_maxlen=mlen, add=add, past=past, return_states=return_sts)\n",
    "    if return_sts: y_hat, states = y_hat\n",
    "    y_hat = pt.vstack([F.softmax(top_filtering(y_hat[i], tcounts[i] if tcounts is not None else None,\n",
    "                                               **kwargs), dim=0) for i in range(len(xs))])\n",
    "    return (y_hat, states) if return_sts else y_hat\n",
    "def append_next_token(sent, olen=None, top_k=-1, top_p=0.9, temperature=1.0):  # Interface for field testing\n",
    "    print(\"k =\", top_k, \", p =\", top_p, \", temp =\", temperature)\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    ou = tokens.copy()\n",
    "    tcounts = pt.zeros(N_tokens, dtype=int).to(d)\n",
    "    for token in tokens: tcounts[token] += 1\n",
    "    probs = gprobs([tokens], top_k=top_k, top_p=top_p, temperature=temperature, tcounts=[tcounts])[0]\n",
    "    token = pt.multinomial(probs, 1).detach().cpu().numpy()[0]\n",
    "    ou += [token]\n",
    "    prev_len = len(sent) if olen is None else olen\n",
    "    sent_new = tokenizer.decode(ou)\n",
    "    print(sent[:prev_len] + 'âž¡' + sent_new[prev_len:])\n",
    "    return sent_new\n",
    "def gen_probs(s, **kwargs):  # Adapter for strings\n",
    "    inp = [tokenizer.encode(s_) for s_ in s]\n",
    "    return gprobs(inp, **kwargs)\n",
    "def gen_completions(s, n=1, max_tokens=8, best_of=1, **kwargs):  # Completion generator equivalent to OpenAI's for GPT3\n",
    "    gpu_multiplier = 0.25\n",
    "    n_bats, best_of, outputs = int(np.ceil(len(s) / int(bsz * gpu_multiplier))), int(round(best_of)), []\n",
    "    if n == 1 and best_of != 1: n, best_of = best_of, n\n",
    "    if best_of == 1 and n != 1: best_of = n\n",
    "    gc.collect()\n",
    "    for i in range(n_bats):\n",
    "        s_batch, tc_b = s[i * int(bsz * gpu_multiplier):(i + 1) * int(bsz * gpu_multiplier)], []\n",
    "        for s_ in s_batch:\n",
    "            tc = pt.zeros(N_tokens, dtype=int).to(d)\n",
    "            for t in tokenizer.encode(s_): tc[t] += 1\n",
    "            tc_b.append(tc)\n",
    "        p, sts = gen_probs(s_batch, return_sts=True, tcounts=tc_b, **kwargs)\n",
    "        sql_b = [len(tokenizer.encode(s_)) for s_ in s_batch]\n",
    "        mlen = max(sql_b)\n",
    "        sql_b = pt.tensor(sql_b).to(d)\n",
    "        # First use the (as yet undiverged) token distribution (multinomial) to generate n tokens for each sample\n",
    "        tokens = pt.multinomial(p, n, replacement=True) \n",
    "        outs, avg_logprobs = [], []\n",
    "        for j in range(n):\n",
    "            tks, tc_b_itr = tokens[:, j], [t.clone() for t in tc_b]\n",
    "            for j in range(len(tc_b_itr)): tc_b_itr[j][tks[j]] += 1\n",
    "            gc.collect(), pt.cuda.empty_cache()\n",
    "            p, st = gprobs((pt.unsqueeze(tks, -1), None, sql_b), past=sts, return_sts=True, tcounts=tc_b_itr, add=1, **kwargs)\n",
    "            su, ls, out = pt.log(p[pt.arange(p.shape[0]), tks]), pt.ones(p.shape[0]).to(d), [tks]\n",
    "            for token_i in range(max_tokens - 1):\n",
    "                t = pt.multinomial(p, 1).to(d)[:, 0]\n",
    "                out.append(t)\n",
    "                for j in range(len(tc_b_itr)): tc_b_itr[j][t[j]] += 1\n",
    "                cont = t != pad_token\n",
    "                ls += cont.int()\n",
    "                su += cont * pt.log(p[pt.arange(p.shape[0]), t])\n",
    "                if token_i == max_tokens - 1: break\n",
    "                p, st = gprobs((pt.unsqueeze(t,-1),None,sql_b), past=st,return_sts=True,tcounts=tc_b_itr,add=token_i+2,**kwargs)\n",
    "            outs.append(pt.vstack(out).T), avg_logprobs.append(su / ls)\n",
    "        gc.collect(), pt.cuda.empty_cache()\n",
    "        outs = pt.stack(outs, 1)\n",
    "        avg_logprobs = pt.vstack(avg_logprobs).T\n",
    "        s1 = outs.shape[0]\n",
    "        idx = pt.argsort(avg_logprobs, axis=1)[:, :best_of].repeat_interleave(max_tokens, 1).reshape(s1, best_of, max_tokens)\n",
    "        outs = pt.gather(outs, 1, idx)\n",
    "        outputs += [[[(tokenizer.decode([x_]),) for x_ in x] for x in o] for o in outs.cpu().detach().numpy()]\n",
    "#     pr([[''.join([x_[0] for x_ in x]) for x in o] for o in outputs])\n",
    "    return outputs\n",
    "mdl = {\"completions\": gen_completions, \"probabilities\": gprobs, \"name\": mname_fn + ',' + gpt2_modelkey, \"mstr\": str(model)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "[0.4270833333333333, 0.375, 0.3645833333333333, 0.59375, 0.26041666666666663, 0.40625, 0.28125, 0.21874999999999997, 0.25, 0.2604166666666667, 0.28125, 0.3020833333333333, 0.40625, 0.3854166666666667, 0.3333333333333333, 0.21875, 0.3333333333333333, 0.20833333333333331, 0.3020833333333333, 0.3333333333333333, 0.26041666666666663, 0.29166666666666663, 0.44791666666666663, 0.3958333333333333]\n",
      "[0.2916666666666667, 0.3333333333333333, 0.3333333333333333, 0.24999999999999997, 0.34375, 0.3020833333333333, 0.375, 0.3333333333333333, 0.20833333333333331, 0.3645833333333333, 0.40625, 0.5208333333333333, 0.375, 0.125, 0.2916666666666667, 0.16666666666666666, 0.5, 0.3125, 0.3229166666666667, 0.6458333333333333, 0.10416666666666666, 0.28125, 0.3333333333333333, 0.4375]\n",
      "('Test acc:', 33.07291666666667, 'sd:', 8.742401214372146)\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.3316  \u001b[0m | \u001b[0m 0.07272 \u001b[0m | \u001b[0m 0.3911  \u001b[0m | \u001b[0m 0.05755 \u001b[0m | \u001b[0m 0.2593  \u001b[0m |\n",
      "[0.15590277777777778, 0.19232954545454545, 0.08055555555555556, 0.0763888888888889, 0.10422979797979798, 0.17708333333333334, 0.1018939393939394, 0.2388888888888889, 0.20965909090909093, 0.11346153846153846, 0.18450854700854702, 0.16455662393162393, 0.18888888888888888]\n",
      "[0.203125, 0.17332251082251082, 0.14545454545454545, 0.16982323232323232, 0.25104166666666666, 0.0826388888888889, 0.23894993894993893, 0.14722222222222223, 0.14875992063492063, 0.22792658730158732, 0.22743055555555552, 0.1753472222222222, 0.14633838383838382]\n",
      "('Test acc:', 15.294980126710897, 'sd:', 5.023623849632714)\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.1798  \u001b[0m | \u001b[0m 1.115   \u001b[0m | \u001b[0m 0.8071  \u001b[0m | \u001b[0m 0.8257  \u001b[0m | \u001b[0m 0.2155  \u001b[0m |\n",
      "[0.129235347985348, 0.18916396103896105, 0.21476301476301476, 0.1553342490842491, 0.2938301282051282, 0.1580357142857143, 0.12406343656343657, 0.22689393939393937, 0.2839556277056277, 0.18055555555555552, 0.1590909090909091, 0.1644570707070707, 0.28195415695415693, 0.15384615384615385, 0.25757575757575757]\n",
      "[0.19166666666666665, 0.04285714285714286, 0.2736426767676768, 0.20680465367965367, 0.14791666666666667, 0.19962121212121214, 0.11416361416361416, 0.23510101010101012, 0.12662337662337664, 0.20066964285714287, 0.16496940559440562, 0.28103146853146854, 0.2211094461094461, 0.13368506493506493, 0.1353174603174603]\n",
      "('Test acc:', 19.818366818366815, 'sd:', 5.589776512244954)\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.1783  \u001b[0m | \u001b[0m 0.8285  \u001b[0m | \u001b[0m 1.411   \u001b[0m | \u001b[0m 0.8313  \u001b[0m | \u001b[0m 0.1731  \u001b[0m |\n",
      "[0.2142857142857143, 0.3889194139194139, 0.2963141025641026, 0.19182692307692312, 0.1517857142857143, 0.2824494949494949, 0.2882575757575757, 0.22395833333333331, 0.2878370098039215, 0.15018939393939396, 0.2353021978021978, 0.33047785547785546]\n",
      "[0.32708333333333334, 0.1625, 0.26969696969696966, 0.20397727272727273, 0.1855921855921856, 0.23344155844155845, 0.2244047619047619, 0.11965811965811965, 0.28806818181818183, 0.2711080586080586, 0.23579545454545456, 0.1875]\n",
      "('Test acc:', 25.346697743297003, 'sd:', 6.885147705016923)\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.2257  \u001b[0m | \u001b[0m 0.8664  \u001b[0m | \u001b[0m 0.3433  \u001b[0m | \u001b[0m 0.5915  \u001b[0m | \u001b[0m 0.1672  \u001b[0m |\n",
      "[0.3, 0.30892857142857144, 0.2375, 0.221875, 0.17708333333333331, 0.35008434547908235, 0.3770833333333333, 0.20833333333333331, 0.052083333333333336, 0.175, 0.4081730769230769, 0.20961538461538462, 0.5787280701754386, 0.21666666666666667, 0.4899509803921568, 0.1871031746031746, 0.2058080808080808, 0.2901785714285714, 0.4903186274509804, 0.29375, 0.3885302197802198]\n",
      "[0.125, 0.3509469696969697, 0.3333333333333333, 0.26912878787878786, 0.2727941176470588, 0.159375, 0.1875, 0.12916666666666665, 0.3333333333333333, 0.3625, 0.5583333333333333, 0.43958333333333327, 0.2625, 0.37499999999999994, 0.4200980392156862, 0.39469696969696966, 0.3375, 0.6413690476190477, 0.41875, 0.29734848484848486, 0.23958333333333331]\n",
      "('Test acc:', 29.365686205165414, 'sd:', 12.434434623057468)\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.3289  \u001b[0m | \u001b[0m 0.07691 \u001b[0m | \u001b[0m 0.4166  \u001b[0m | \u001b[0m 0.1755  \u001b[0m | \u001b[0m 0.5029  \u001b[0m |\n",
      "[0.017857142857142856, 0.25, 0.4583333333333333, 0.53125, 0.1875, 0.4166666666666667, 0.2, 0.5208333333333333, 0.125, 0.3875, 0.34375, 0.5, 0.3125, 0.15384615384615385, 0.47291666666666665, 0.59375, 0.5625, 0.15625]\n",
      "[0.59375, 0.3125, 0.29166666666666663, 0.375, 0.4375, 0.125, 0.5, 0.3125, 0.29166666666666663, 0.21875, 0.3333333333333333, 0.29166666666666663, 0.25, 0.09375, 0.4375, 0.2708333333333333, 0.3020833333333333, 0.375]\n",
      "('Test acc:', 34.39140720390721, 'sd:', 16.97130512635182)\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.3229  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0.21875, 0.22916666666666666, 0.16666666666666666, 0.21874999999999997, 0.34374999999999994, 0.3333333333333333, 0.35416666666666663, 0.16666666666666666, 0.2708333333333333, 0.53125, 0.3229166666666667, 0.20833333333333331, 0.44791666666666663, 0.47916666666666663, 0.15625, 0.16666666666666666, 0.29166666666666663, 0.20833333333333331, 0.15625, 0.23958333333333331]\n",
      "[0.3125, 0.21875, 0.375, 0.3020833333333333, 0.2708333333333333, 0.15625, 0.2708333333333333, 0.3125, 0.2708333333333333, 0.1875, 0.5104166666666666, 0.2708333333333333, 0.22916666666666666, 0.0625, 0.35416666666666663, 0.3020833333333333, 0.41666666666666663, 0.20833333333333331, 0.2708333333333333, 0.20833333333333331]\n",
      "('Test acc:', 27.552083333333332, 'sd:', 10.86770888247227)\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.2755  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.617   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0.02222222222222222, 0.06969246031746032, 0.037500000000000006, 0.07088432400932401, 0.03392857142857143, 0.02291666666666667, 0.022115384615384617, 0.0125]\n",
      "[0.10270979020979021, 0.05, 0.07692307692307693, 0.06118881118881119, 0.023863636363636365, 0.055113636363636365, 0.029513888888888888, 0.05138888888888889]\n",
      "('Test acc:', 3.646995365745366, 'sd:', 2.080536356513649)\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.05634 \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0.22916666666666666, 0.13541666666666666, 0.31249999999999994, 0.125, 0.375, 0.09375, 0.2708333333333333, 0.17708333333333331, 0.1875, 0.20833333333333331, 0.21874999999999997, 0.29166666666666663, 0.20833333333333331, 0.41666666666666663, 0.26041666666666663, 0.25]\n",
      "[0.1875, 0.1875, 0.1875, 0.35416666666666663, 0.20833333333333331, 0.3125, 0.25, 0.1875, 0.16666666666666666, 0.22916666666666666, 0.3958333333333333, 0.22916666666666666, 0.16666666666666666, 0.25, 0.25, 0.29166666666666663]\n",
      "('Test acc:', 23.502604166666664, 'sd:', 8.414068141956223)\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.2409  \u001b[0m | \u001b[0m 0.6899  \u001b[0m | \u001b[0m 0.5617  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0.15625, 0.35416666666666663, 0.3020833333333333, 0.35416666666666663, 0.28125, 0.17708333333333331, 0.16666666666666666, 0.28125, 0.29166666666666663, 0.25, 0.13541666666666666, 0.4270833333333333, 0.1875, 0.1875, 0.375, 0.28125, 0.23958333333333331, 0.3333333333333333, 0.15625, 0.3125, 0.39583333333333326, 0.28125, 0.16666666666666666, 0.32291666666666663, 0.2708333333333333, 0.22916666666666666]\n",
      "[0.35416666666666663, 0.3020833333333333, 0.21875, 0.3020833333333333, 0.34375, 0.34375, 0.19791666666666666, 0.3229166666666667, 0.375, 0.28125, 0.28125, 0.3958333333333333, 0.38541666666666663, 0.11458333333333333, 0.3020833333333333, 0.35416666666666663, 0.41666666666666663, 0.20833333333333331, 0.47916666666666663, 0.25, 0.44791666666666663, 0.26041666666666663, 0.5208333333333333, 0.42708333333333326, 0.23958333333333331, 0.3333333333333333]\n",
      "('Test acc:', 26.602564102564102, 'sd:', 8.002397066504098)\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.3253  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.184   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "[0.0, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0625, 0.125, 0.0, 0.0, 0.125]\n",
      "[0.0, 0.0625, 0.125, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0]\n",
      "('Test acc:', 6.25, 'sd:', 7.995026863335392)\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.02841 \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0.0, 0.0, 0.1875, 0.0, 0.1875, 0.25, 0.0625, 0.0625, 0.1875, 0.25, 0.0625, 0.0, 0.0625, 0.25, 0.0625, 0.0625, 0.1875, 0.0, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.0]\n",
      "[0.125, 0.0, 0.25, 0.125, 0.0, 0.125, 0.0625, 0.1875, 0.0625, 0.125, 0.0625, 0.1875, 0.25, 0.25, 0.0, 0.1875, 0.0, 0.0, 0.1875, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('Test acc:', 8.5, 'sd:', 8.993052874302474)\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.0925  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3020833333333333, 0.19791666666666666, 0.3229166666666667, 0.2708333333333333, 0.375, 0.20833333333333331, 0.16666666666666666, 0.3333333333333333, 0.3333333333333333, 0.32291666666666663, 0.3333333333333333, 0.1875, 0.3125, 0.26041666666666663, 0.35416666666666663, 0.2708333333333333, 0.21875, 0.3229166666666667, 0.29166666666666663, 0.3020833333333333, 0.28125, 0.26041666666666663]\n",
      "[0.08333333333333333, 0.375, 0.1875, 0.24999999999999997, 0.20833333333333331, 0.1875, 0.20833333333333331, 0.2708333333333333, 0.16666666666666666, 0.15625, 0.4583333333333333, 0.32291666666666663, 0.14583333333333331, 0.22916666666666666, 0.125, 0.2708333333333333, 0.3958333333333333, 0.22916666666666666, 0.3645833333333333, 0.29166666666666663, 0.23958333333333331, 0.23958333333333331]\n",
      "('Test acc:', 28.314393939393938, 'sd:', 5.579893887369786)\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.2457  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "[0.16666666666666666, 0.38541666666666663, 0.5104166666666666, 0.41666666666666663, 0.46875, 0.28125, 0.19791666666666666, 0.25, 0.19791666666666666, 0.3020833333333333]\n",
      "[0.46875, 0.34375, 0.1875, 0.3125, 0.34375, 0.23958333333333331, 0.20833333333333331, 0.3125, 0.3333333333333333, 0.3125]\n",
      "('Test acc:', 31.770833333333332, 'sd:', 11.489068627032683)\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.3063  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.7849  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.8575  \u001b[0m |\n",
      "[0.3645833333333333, 0.34375, 0.3958333333333333, 0.3020833333333333, 0.48958333333333326, 0.41666666666666663, 0.22916666666666666, 0.35416666666666663, 0.21875, 0.22916666666666666]\n",
      "[0.20833333333333331, 0.10416666666666666, 0.26041666666666663, 0.375, 0.37499999999999994, 0.375, 0.45833333333333326, 0.3333333333333333, 0.29166666666666663, 0.3125]\n",
      "('Test acc:', 33.4375, 'sd:', 8.519406971080139)\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.3094  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.885   \u001b[0m | \u001b[0m 0.623   \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# optimise fine-tuned model sampling params\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_gptxlf = {\n",
    "  \"temperature\": [0.0001, 1.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.0001, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_gpt2xlf, results_gpt2xlf = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.005, phase=\"val\", uniform=True, mdl=mdl, max_tokens=8)[0]\n",
    "    optimizers_gpt2xlf.append(BayesianOptimization(f=fun, pbounds=bounds_gptxlf, verbose=1000))\n",
    "#     optimizers_gpt2xlf[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0})\n",
    "    optimizers_gpt2xlf[-1].maximize(init_points=5, n_iter=10)\n",
    "    results_gpt2xlf.append(optimizers_gpt2xlf[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.3315972222222222,\n",
       " 'params': {'frequency_penalty': 0.0727219392109375,\n",
       "  'presence_penalty': 0.3910543467725913,\n",
       "  'temperature': 0.057551002098534226,\n",
       "  'top_p': 0.25933633649499327}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers_gpt2xlf[-1].max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # optimise fine-tuned model params with refined bounds\n",
    "# lgroups_ft = [[4, 5]]\n",
    "# bounds_gptxlf_rf = {\n",
    "#   \"temperature\": [0.0001, 0.003],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "#   \"top_p\": [0.001, 1.0],        # same with this but more obvious\n",
    "# #   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "#   \"presence_penalty\": [0.1, 1.0],   # both presence and frequency penalty have optimal values\n",
    "# #   \"frequency_penalty\": [0.0, 1.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "# #   \"best_of\": [0.51, 5.49], # to do\n",
    "# }\n",
    "# optimizers_gpt2xlf_rf, results_gpt2xlf_rf = [], []\n",
    "# for lgroup in lgroups_ft:\n",
    "#     min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "#     def fun(temperature, top_p, presence_penalty):\n",
    "#         global min_l, max_l\n",
    "#         ps = locals()\n",
    "#         ps[\"best_of\"] = 5.0\n",
    "#         return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.002, phase=\"val\", uniform=True, mdl=mdl, max_tokens=8)[0]\n",
    "#     optimizers_gpt2xlf_rf.append(BayesianOptimization(f=fun, pbounds=bounds_gptxlf_rf, verbose=1000))\n",
    "#     optimizers_gpt2xlf_rf[-1].probe(params={\"temperature\": 0.001, \"top_p\": 0.001, \"presence_penalty\": 0.4052})\n",
    "#     optimizers_gpt2xlf_rf[-1].maximize(init_points=2, n_iter=8)\n",
    "#     results_gpt2xlf_rf.append(optimizers_gpt2xlf_rf[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers_gpt2xlf_rf[-1].probe(params={\"temperature\": 0.001, \"top_p\": 0.001, \"presence_penalty\": 0.4052})\n",
    "# optimizers_gpt2xlf_rf[-1].maximize(n_iter=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers_gpt2xlf[-1].max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load predictions from the top performing fine-tuned model, and create the ensemble mdl object\n",
    "# optimal_params = {\"temperature\": ?, \"top_p\": ?, \"presence_penalty\": ?, \"frequency_penalty\": ?}\n",
    "# optimal_params = optimizers_gpt2xlf[-1].max[\"params\"]\n",
    "optimal_params = {**default_sp, **{'frequency_penalty': 0.0727219392109375,\n",
    "                                   'presence_penalty': 0.3910543467725913,\n",
    "                                   'temperature': 0.057551002098534226,\n",
    "                                   'top_p': 0.25933633649499327}}\n",
    "def approx_eq(x, y, tol=1e-7):\n",
    "    return abs(x - y) < tol\n",
    "def get_sp_samples(params, test=False):  # Get all datapoints which match these parameters (todo: for each length group)\n",
    "    dn = 'msp_samples_nb' + (\"_test\" if test else '') + '/'\n",
    "    dname = 'data/learning_data/' + dn\n",
    "    D, R, inds = [], [], []  # Gathered input data and model results\n",
    "    for i in range(len(cats)):\n",
    "        idx_set = train_idx if i in train_idx else (val_idx if i in val_idx else test_idx)\n",
    "        D_ = []\n",
    "        fns = glob.glob(dname + str(i) + '/*')\n",
    "        if len(fns) == 0: continue\n",
    "        fns = [fn.split('/')[-1].split('\\\\')[-1] for fn in fns][::-1]  # Most recent first\n",
    "        load_fns = []\n",
    "        for fn in fns:\n",
    "            fn_split = fn.split('_')\n",
    "            params = {sps_[i]: float(fn_split[i + 1]) for i in range(len(sps_))}\n",
    "            if (\"ernst_one\" in fn) and all([approx_eq(params[k], optimal_params[k]) for k in sps_]): load_fns.append(fn)\n",
    "        for fn in load_fns[:15]:\n",
    "            params, d, _, r, mdl_str = load_ld(dn + str(i) + '/' + fn.split('.data')[0])\n",
    "            D_ += d\n",
    "            R += r\n",
    "        D += D_\n",
    "        i_in_set = idx_set.tolist().index(i)\n",
    "        inds += [i_in_set for _ in range(len(D_))]\n",
    "    return D, R, np.asarray(inds)\n",
    "mdl2_d, mdl2_r, mdl2_inds = get_sp_samples(optimal_params)\n",
    "mdl2_d_test, mdl2_r_test, mdl2_inds_test = get_sp_samples(optimal_params, test=True)\n",
    "mdl2_d_x, mdl2_d_test_x = [d_[0] for d_ in mdl2_d], [d_[0] for d_ in mdl2_d_test]\n",
    "def precomputed_completions(d_x, **kwargs):\n",
    "    return mdl2_r if (d_x == mdl2_d_x) else (mdl2_r_test if d_x == mdl2_d_test_x else None)\n",
    "mdl2 = {\"completions\": precomputed_completions, \"name\": \"precomputed_one\", \"mstr\": \"precomputed_one_mstr\"}\n",
    "len(mdl2_d), len(mdl2_d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "Test acc: 18.818716006216004 sd: 19.936895010181622\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.1674  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Test acc: 14.77453102453102 sd: 18.856136694838423\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.1358  \u001b[0m | \u001b[0m 0.8711  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.2817  \u001b[0m | \u001b[0m 0.2481  \u001b[0m |\n",
      "Test acc: 11.171356421356421 sd: 11.286211338580697\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.1058  \u001b[0m | \u001b[0m 0.9056  \u001b[0m | \u001b[0m 1.629   \u001b[0m | \u001b[0m 0.4863  \u001b[0m | \u001b[0m 0.1001  \u001b[0m |\n",
      "Test acc: 11.590277777777775 sd: 11.654115331317248\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.1058  \u001b[0m | \u001b[0m 1.55    \u001b[0m | \u001b[0m 1.283   \u001b[0m | \u001b[0m 0.8669  \u001b[0m | \u001b[0m 0.7813  \u001b[0m |\n",
      "Test acc: 11.347222222222221 sd: 11.294800183287798\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.1058  \u001b[0m | \u001b[0m 1.884   \u001b[0m | \u001b[0m 0.8325  \u001b[0m | \u001b[0m 0.5171  \u001b[0m | \u001b[0m 0.9039  \u001b[0m |\n",
      "Test acc: 37.88740327797991 sd: 35.70788802511655\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.3698  \u001b[0m | \u001b[95m 0.1169  \u001b[0m | \u001b[95m 0.1147  \u001b[0m | \u001b[95m 0.1745  \u001b[0m | \u001b[95m 0.5062  \u001b[0m |\n",
      "Test acc: 11.362103174603174 sd: 11.33271219112578\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 1.786   \u001b[0m | \u001b[0m 1.1     \u001b[0m | \u001b[0m 0.9626  \u001b[0m | \u001b[0m 0.7045  \u001b[0m |\n",
      "Test acc: 11.171356421356421 sd: 11.286211338580697\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.1058  \u001b[0m | \u001b[0m 1.738   \u001b[0m | \u001b[0m 1.204   \u001b[0m | \u001b[0m 0.4952  \u001b[0m | \u001b[0m 0.6155  \u001b[0m |\n",
      "Test acc: 17.259920634920636 sd: 16.531959755036656\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.1799  \u001b[0m | \u001b[0m 0.7282  \u001b[0m | \u001b[0m 0.9161  \u001b[0m | \u001b[0m 0.8847  \u001b[0m | \u001b[0m 0.6235  \u001b[0m |\n",
      "Test acc: 36.980513942685 sd: 34.933472069535206\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.3545  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.04998 \u001b[0m |\n",
      "Test acc: 36.980513942685 sd: 34.933472069535206\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.3545  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Test acc: 39.554708266879324 sd: 36.55256982347982\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.3776  \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.6827  \u001b[0m | \u001b[95m 0.0001  \u001b[0m | \u001b[95m 0.7724  \u001b[0m |\n",
      "Test acc: 38.943239752450275 sd: 36.36546111256192\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.3387  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Test acc: 15.936026936026934 sd: 15.38774938063801\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.1368  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Test acc: 34.77654521404522 sd: 34.3038462949238\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.3056  \u001b[0m | \u001b[0m 0.608   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.8001  \u001b[0m |\n",
      "Test acc: 39.27693048910154 sd: 36.7250429390263\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.3747  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.6262  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.207   \u001b[0m |\n",
      "Test acc: 38.943239752450275 sd: 36.36546111256192\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.3387  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "Test acc: 40.81669627886733 sd: 36.68622095523258\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.366   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.325   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Test acc: 40.79330446600184 sd: 36.656071416829995\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.366   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.398   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.4347  \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# evaluate ensemble of fine-tuned and original model\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_gptxlfe = {\n",
    "  \"temperature\": [0.0001, 1.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.0001, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_gpt2xlfe, results_gpt2xlfe = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp(ps, n1=1, min_l=min_l, max_l=max_l, phase=\"val\", uniform=True, mdl=mdl, mdl2=mdl2, return_test_acc=False,\n",
    "                       d=mdl2_d, d_test=mdl2_d_test, inds=mdl2_inds, inds_test=mdl2_inds_test, max_tokens=8)\n",
    "    optimizers_gpt2xlfe.append(BayesianOptimization(f=fun, pbounds=bounds_gptxlfe, verbose=1000))\n",
    "    optimizers_gpt2xlfe[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0})\n",
    "    optimizers_gpt2xlfe[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_gpt2xlfe.append(optimizers_gpt2xlfe[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.3776479076479077,\n",
       " 'params': {'frequency_penalty': 0.0,\n",
       "  'presence_penalty': 0.6826773005263892,\n",
       "  'temperature': 0.0001,\n",
       "  'top_p': 0.7723760255748774}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers_gpt2xlfe[-1].max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 0.1674104367854368,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 0.0,\n",
       "   'temperature': 1.0,\n",
       "   'top_p': 1.0}},\n",
       " {'target': 0.1358333333333333,\n",
       "  'params': {'frequency_penalty': 0.8711056869611193,\n",
       "   'presence_penalty': 0.9175027822849351,\n",
       "   'temperature': 0.28166594880239576,\n",
       "   'top_p': 0.24814697270196176}},\n",
       " {'target': 0.10583333333333332,\n",
       "  'params': {'frequency_penalty': 0.9055600392722987,\n",
       "   'presence_penalty': 1.6292026746717285,\n",
       "   'temperature': 0.4862853433151288,\n",
       "   'top_p': 0.10006268800987392}},\n",
       " {'target': 0.10583333333333332,\n",
       "  'params': {'frequency_penalty': 1.5498253868894298,\n",
       "   'presence_penalty': 1.2832269448593987,\n",
       "   'temperature': 0.8669491149883246,\n",
       "   'top_p': 0.781349642522042}},\n",
       " {'target': 0.10583333333333332,\n",
       "  'params': {'frequency_penalty': 1.8839249053568738,\n",
       "   'presence_penalty': 0.8324946021108477,\n",
       "   'temperature': 0.517134514952664,\n",
       "   'top_p': 0.9039030633298701}},\n",
       " {'target': 0.3697888916638917,\n",
       "  'params': {'frequency_penalty': 0.11685899995653815,\n",
       "   'presence_penalty': 0.11472674569320462,\n",
       "   'temperature': 0.17446698215615375,\n",
       "   'top_p': 0.506239958747463}},\n",
       " {'target': 0.10682539682539684,\n",
       "  'params': {'frequency_penalty': 1.7863719454292961,\n",
       "   'presence_penalty': 1.0998130253729257,\n",
       "   'temperature': 0.9626294632699759,\n",
       "   'top_p': 0.704532514033267}},\n",
       " {'target': 0.10583333333333332,\n",
       "  'params': {'frequency_penalty': 1.7380127471109066,\n",
       "   'presence_penalty': 1.2036106192598868,\n",
       "   'temperature': 0.49522994022680095,\n",
       "   'top_p': 0.6154994602863306}},\n",
       " {'target': 0.1798611111111111,\n",
       "  'params': {'frequency_penalty': 0.7282138092968031,\n",
       "   'presence_penalty': 0.9161331393232395,\n",
       "   'temperature': 0.8846838218985477,\n",
       "   'top_p': 0.6234977422680228}},\n",
       " {'target': 0.35453788901157324,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 0.0,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.049983458947994726}},\n",
       " {'target': 0.35453788901157324,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 0.0,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 1.0}},\n",
       " {'target': 0.3776479076479077,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 0.6826773005263892,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.7723760255748774}},\n",
       " {'target': 0.3386832611832612,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 2.0,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 1.0}},\n",
       " {'target': 0.1367559523809524,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 2.0,\n",
       "   'temperature': 1.0,\n",
       "   'top_p': 1.0}},\n",
       " {'target': 0.3056165131165131,\n",
       "  'params': {'frequency_penalty': 0.6080069631763159,\n",
       "   'presence_penalty': 0.0,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.8001087882574378}},\n",
       " {'target': 0.37465090465090467,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 0.6262183311918568,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.2070101788848195}},\n",
       " {'target': 0.3386832611832612,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 2.0,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.0001}},\n",
       " {'target': 0.365981240981241,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 1.32541339128544,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 1.0}},\n",
       " {'target': 0.365981240981241,\n",
       "  'params': {'frequency_penalty': 0.0,\n",
       "   'presence_penalty': 1.3976158236504674,\n",
       "   'temperature': 0.0001,\n",
       "   'top_p': 0.4347355267648904}}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers_gpt2xlfe[-1].res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
    "# -------------------------------------------------------------------------\n",
    "# [0.14608262108262107, 0.1544311013061013, 0.1774588258963259]\n",
    "# [0.5712862692862692, 0.5167355977355977, 0.5436751026751027]\n",
    "# ('Test acc:', 15.932418276168276, 'sd:', 1.326833930141234)\n",
    "# |  1        |  0.5439   |  0.7545   |  0.8837   |  1.164    |  0.1678   |\n",
    "# [0.006944444444444444, 0.008333333333333333, 0.025000000000000005]\n",
    "# [0.008, 0.0, 0.014666666666666668]\n",
    "# ('Test acc:', 1.3425925925925926, 'sd:', 0.8203724604939516)\n",
    "# |  2        |  0.007556 |  1.563    |  1.115    |  1.345    |  0.4973   |\n",
    "# [0.21354131979131977, 0.173926362988863, 0.13297558922558925, 0.25522775835275835]\n",
    "# [0.5312100122100122, 0.6170219780219779, 0.5921578421578422, 0.5759225219225219]\n",
    "# ('Test acc:', 19.39177575896326, 'sd:', 4.543568017003007)\n",
    "# |  3        |  0.5791   |  1.185    |  1.479    |  0.3418   |  0.9886   |\n",
    "# [0.35648148148148145, 0.3520833333333333, 0.3180147058823529, 0.332175925925926, 0.2954656862745098]\n",
    "# [0.6432820512820513, 0.7113333333333333, 0.7075555555555556, 0.8067179487179486, 0.738952380952381]\n",
    "# ('Test acc:', 33.08442265795207, 'sd:', 2.247834350297864)\n",
    "# |  4        |  0.7216   |  0.5497   |  0.4131   |  0.04958  |  0.5878   |\n",
    "# [0.24212986087986085, 0.20677008177008174, 0.2121680402930403, 0.24574632543382546]\n",
    "# [0.5814134754134754, 0.5753290043290044, 0.6005385725385726, 0.5997070707070707]\n",
    "# ('Test acc:', 22.67035770942021, 'sd:', 1.73869387881864)\n",
    "# |  5        |  0.5892   |  0.989    |  1.323    |  0.6668   |  0.5829   |\n",
    "# [0.006944444444444444, 0.0, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.23148148148148145, 'sd:', 0.32736425054932755)\n",
    "# |  6        |  0.0      |  1.268    |  1.645    |  1.636    |  0.3853   |\n",
    "# [0.029563492063492066, 0.05555555555555556, 0.03511904761904762, 0.024537037037037038, 0.01636904761904762]\n",
    "# [0.07957142857142857, 0.13923809523809524, 0.07619047619047618, 0.15666666666666665, 0.1219047619047619]\n",
    "# ('Test acc:', 3.222883597883598, 'sd:', 1.319310339155671)\n",
    "# |  7        |  0.1147   |  1.617    |  0.524    |  0.9253   |  0.9548   |\n",
    "# [0.0, 0.0, 0.0]\n",
    "# [0.0, 0.008, 0.008]\n",
    "# ('Test acc:', 0.0, 'sd:', 0.0)\n",
    "# |  8        |  0.005333 |  1.573    |  0.1914   |  1.962    |  0.2006   |\n",
    "# [0.29166666666666663, 0.3055555555555555, 0.3819444444444444, 0.24305555555555555, 0.3506944444444444]\n",
    "# [0.6366666666666666, 0.7466666666666666, 0.7399999999999999, 0.7999999999999998, 0.73]\n",
    "# ('Test acc:', 31.458333333333332, 'sd:', 4.809247136994663)\n",
    "# |  9        |  0.7307   |  0.001    |  1.477    |  0.001    |  0.001    |\n",
    "# [0.2643718553548275, 0.2827585030710031, 0.27731273356273356, 0.2543742511573394]\n",
    "# [0.5516450836744954, 0.5830235059058588, 0.544432178932179, 0.5589042819925172]\n",
    "# ('Test acc:', 26.97043357864759, 'sd:', 1.1087671560167434)\n",
    "# |  10       |  0.5595   |  0.001    |  1.146    |  0.5046   |  1.0      |\n",
    "# [0.40625, 0.2916666666666667, 0.34722222222222215]\n",
    "# [0.55, 0.6666666666666665, 0.6066666666666667]\n",
    "# ('Test acc:', 34.83796296296296, 'sd:', 4.678560863751791)\n",
    "# |  11       |  0.6078   |  0.001    |  0.001    |  0.4932   |  0.001    |\n",
    "# [0.32638888888888884, 0.2222222222222222, 0.2916666666666667, 0.2534722222222222, 0.34722222222222215, 0.20138888888888887, 0.21527777777777776, 0.23611111111111108, 0.2847222222222222]\n",
    "# [0.74, 0.6666666666666665, 0.6866666666666665, 0.6133333333333333, 0.7266666666666666, 0.7866666666666666, 0.78, 0.6466666666666666, 0.6933333333333332]\n",
    "# ('Test acc:', 26.427469135802472, 'sd:', 4.8236109901505495)\n",
    "# |  12       |  0.7044   |  1.045    |  1.107    |  0.001    |  0.001    |\n",
    "# [0.2708333333333333, 0.2569444444444444, 0.25, 0.18055555555555555]\n",
    "# [0.62, 0.7666666666666666, 0.6266666666666666, 0.6666666666666665]\n",
    "# ('Test acc:', 23.958333333333332, 'sd:', 3.4895401462225317)\n",
    "# |  13       |  0.67     |  0.7444   |  2.0      |  0.001    |  0.001    |\n",
    "# [0.3333333333333333, 0.3263888888888889, 0.37152777777777773, 0.3020833333333333]\n",
    "# [0.6166666666666667, 0.72, 0.7941025641025641, 0.7266666666666666]\n",
    "# ('Test acc:', 33.33333333333333, 'sd:', 2.4917882108346023)\n",
    "# |  14       |  0.7144   |  0.2284   |  2.0      |  0.001    |  1.0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "[0.25, 0.16025641025641024, 0.3194444444444444, 0.5, 0.0625, 0.3382352941176471, 0.3402777777777778, 0.171875, 0.1875, 0.2976190476190476, 0.375, 0.19642857142857142, 0.375, 0.39583333333333337, 0.4, 0.5625, 0.2708333333333333, 0.15, 0.525, 0.375, 0.25, 0.203125, 0.4583333333333333, 0.3270833333333333, 0.375, 0.484375, 0.3727272727272727, 0.22916666666666666, 0.5208333333333333, 0.25]\n",
      "[0.375, 0.125, 0.3958333333333333, 0.45555555555555555, 0.25, 0.23214285714285715, 0.375, 0.125, 0.375, 0.375, 0.375, 0.4, 0.07738095238095238, 0.4, 0.4, 0.2625, 0.1125, 0.0, 0.35, 0.325, 0.125, 0.6, 0.25, 0.0, 0.125, 0.125, 0.025, 0.125, 0.375, 0.34375]\n",
      "('Test acc:', 32.41315717234835, 'sd:', 12.4103941038018)\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.2627  \u001b[0m | \u001b[0m 0.3582  \u001b[0m | \u001b[0m 0.8393  \u001b[0m | \u001b[0m 0.06305 \u001b[0m | \u001b[0m 0.7254  \u001b[0m |\n",
      "[0.4375, 0.39583333333333337, 0.5576923076923077, 0.5986842105263158, 0.1875, 0.43333333333333335, 0.525, 0.3125, 0.4305555555555556, 0.375, 0.34375, 0.5, 0.4375, 0.44362745098039214, 0.5520833333333333, 0.2919642857142857, 0.20833333333333331, 0.375, 0.4794642857142857, 0.3125, 0.6875]\n",
      "[0.125, 0.3125, 0.125, 0.2519230769230769, 0.375, 0.45833333333333337, 0.3125, 0.25, 0.41666666666666663, 0.275, 0.525, 0.375, 0.5, 0.625, 0.4444444444444444, 0.7517857142857143, 0.125, 0.0625, 0.26666666666666666, 0.2857142857142857, 0.25]\n",
      "('Test acc:', 42.31105442626893, 'sd:', 12.167873544905257)\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.3387  \u001b[0m | \u001b[95m 0.2233  \u001b[0m | \u001b[95m 0.6086  \u001b[0m | \u001b[95m 0.07457 \u001b[0m | \u001b[95m 0.7005  \u001b[0m |\n",
      "[0.0, 0.025, 0.025, 0.125, 0.1]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('Test acc:', 5.500000000000001, 'sd:', 4.847679857416329)\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.181   \u001b[0m | \u001b[0m 0.8761  \u001b[0m | \u001b[0m 0.9505  \u001b[0m | \u001b[0m 0.301   \u001b[0m |\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('Test acc:', 0.0, 'sd:', 0.0)\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.97    \u001b[0m | \u001b[0m 1.772   \u001b[0m | \u001b[0m 0.2702  \u001b[0m | \u001b[0m 0.5597  \u001b[0m |\n",
      "[0.0, 0.025, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('Test acc:', 0.5, 'sd:', 1.0)\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.208   \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 0.7537  \u001b[0m | \u001b[0m 0.3159  \u001b[0m |\n",
      "[0.05, 0.16666666666666666, 0.19999999999999998, 0.15, 0.1, 0.28750000000000003, 0.3770833333333334, 0.3486111111111111, 0.3, 0.15833333333333333, 0.31698717948717947, 0.2, 0.15000000000000002, 0.15714285714285714, 0.12916666666666668, 0.13214285714285715]\n",
      "[0.15, 0.025, 0.15, 0.1, 0.125, 0.175, 0.0, 0.3, 0.1, 0.275, 0.175, 0.3833333333333333, 0.05, 0.1, 0.125, 0.15833333333333333]\n",
      "('Test acc:', 20.14771253052503, 'sd:', 9.238405535174753)\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.1495  \u001b[0m | \u001b[0m 0.7498  \u001b[0m | \u001b[0m 0.5206  \u001b[0m | \u001b[0m 0.891   \u001b[0m | \u001b[0m 0.3153  \u001b[0m |\n",
      "[0.07500000000000001, 0.05625, 0.175, 0.225, 0.1875, 0.05, 0.15, 0.075, 0.175, 0.10833333333333334, 0.05, 0.07500000000000001, 0.1, 0.0, 0.25, 0.15000000000000002]\n",
      "[0.1, 0.0, 0.0, 0.275, 0.025, 0.025, 0.1, 0.05, 0.025, 0.05, 0.0, 0.0, 0.275, 0.125, 0.125, 0.15000000000000002]\n",
      "('Test acc:', 11.888020833333332, 'sd:', 6.855032853544691)\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.08281 \u001b[0m | \u001b[0m 0.9256  \u001b[0m | \u001b[0m 0.4487  \u001b[0m | \u001b[0m 0.7391  \u001b[0m | \u001b[0m 0.3264  \u001b[0m |\n",
      "[0.06666666666666667, 0.025, 0.04583333333333334, 0.025, 0.05, 0.04583333333333334, 0.05, 0.075, 0.0, 0.05, 0.07500000000000001, 0.05]\n",
      "[0.15000000000000002, 0.1, 0.025, 0.1464285714285714, 0.05, 0.05, 0.05, 0.06666666666666667, 0.025, 0.07500000000000001, 0.060714285714285714, 0.025]\n",
      "('Test acc:', 4.652777777777778, 'sd:', 2.0752156663172134)\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.06865 \u001b[0m | \u001b[0m 0.8929  \u001b[0m | \u001b[0m 0.9369  \u001b[0m | \u001b[0m 0.9781  \u001b[0m | \u001b[0m 0.6755  \u001b[0m |\n",
      "[0.4779265873015873, 0.23584054834054835, 0.38057359307359306, 0.3700280112044818, 0.2864583333333333, 0.19480519480519481, 0.34436813186813187, 0.2164835164835165, 0.38055555555555554, 0.40625, 0.36354166666666665, 0.45069444444444445, 0.3317775974025974, 0.47141645119586295, 0.5114583333333333, 0.274156746031746, 0.4168942577030812, 0.4406926406926407, 0.3737745098039216, 0.4179446778711484, 0.45277777777777783, 0.489781746031746, 0.43058155080213906, 0.33904151404151406, 0.4192095588235294]\n",
      "[0.29374999999999996, 0.3654513888888889, 0.31994047619047616, 0.2793154761904762, 0.4344742063492063, 0.35218253968253965, 0.3611111111111111, 0.5271214896214896, 0.42995129870129867, 0.4140512265512265, 0.43849206349206343, 0.5229471916971917, 0.4701388888888889, 0.3743506493506493, 0.36221590909090906, 0.49181547619047616, 0.29673520923520924, 0.5037112193362193, 0.508901515151515, 0.6568108974358974, 0.4351686507936508, 0.5582792207792207, 0.4678571428571428, 0.47291666666666665, 0.41704094516594514]\n",
      "('Test acc:', 37.90813177835236, 'sd:', 8.3970120139775)\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.4302  \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.08144 \u001b[0m | \u001b[95m 0.5063  \u001b[0m | \u001b[95m 0.9403  \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.0, 0.0, 0.18249905925769086, 0.0001)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-afd90453a189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds_gptxl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mresults_gpt2xl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizers_gpt2xl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-afd90453a189>\u001b[0m in \u001b[0;36mfun\u001b[0;34m(temperature, top_p, presence_penalty, frequency_penalty)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"best_of\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds_gptxl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-7ca5afbedeb6>\u001b[0m in \u001b[0;36mtest_sp_conv\u001b[0;34m(params, tol, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_nochange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mnew_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msteps_nochange\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-7ca5afbedeb6>\u001b[0m in \u001b[0;36mtest_sp\u001b[0;34m(params, min_l, max_l, n1, n2, prmt, phase, uniform, max_tokens, mdl, mdl2, d, d_test, inds, inds_test, m2ensemble_frac, return_test_acc)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_sp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#**default_msp,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gpt3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Request predictions from OpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"completions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0msave_modeloutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphaseIx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsps_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdl2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-f4ec06d07fde>\u001b[0m in \u001b[0;36mgen_completions\u001b[0;34m(s, n, max_tokens, best_of, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtc_b_itr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtc_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtc_b_itr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtc_b_itr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgprobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcounts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtc_b_itr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0msu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluate un-fine-tuned model\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_gptxl = {\n",
    "  \"temperature\": [0.0001, 1.1],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.0001, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_gpt2xl, results_gpt2xl = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.005, phase=\"val\", uniform=True, mdl=mdl, max_tokens=8)[0]\n",
    "    optimizers_gpt2xl.append(BayesianOptimization(f=fun, pbounds=bounds_gptxl, verbose=1000))\n",
    "    optimizers_gpt2xl[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_gpt2xl.append(optimizers_gpt2xl[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test accuracy for the top performing (training accuracy ) sampling parameters for gpt2-\n",
    "# \n",
    "# |   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
    "# -------------------------------------------------------------------------\n",
    "# [0.049999999999999996, 0.025000000000000005, 0.061111111111111116]\n",
    "# [0.008, 0.03333333333333333, 0.029333333333333336]\n",
    "# ('Test acc:', 4.537037037037037, 'sd:', 1.5101394842870455)\n",
    "# |  1        |  0.02356  |  0.7232   |  0.9207   |  1.792    |  0.1562   |\n",
    "# [0.2111111111111111, 0.13333333333333333, 0.23576388888888888, 0.3333333333333333]\n",
    "# [0.1965714285714286, 0.11199999999999999, 0.111, 0.12]\n",
    "# ('Test acc:', 22.838541666666668, 'sd:', 7.141744752411932)\n",
    "# |  2        |  0.1349   |  0.6561   |  0.6181   |  0.6707   |  0.1418   |\n",
    "# [0.0, 0.016666666666666666, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.5555555555555556, 'sd:', 0.7856742013183862)\n",
    "# |  3        |  0.0      |  1.035    |  0.6253   |  1.287    |  0.9439   |\n",
    "# [0.5208333333333334, 0.375, 0.3854166666666667, 0.4930555555555555, 0.34027777777777773, 0.40625, 0.3194444444444444]\n",
    "# [0.32, 0.38, 0.21333333333333332, 0.28, 0.16666666666666663, 0.2, 0.2733333333333333]\n",
    "# ('Test acc:', 40.57539682539682, 'sd:', 6.965317270864225)\n",
    "# |  4        |  0.2619   |  0.4573   |  0.1734   |  0.6163   |  0.02537  |\n",
    "# [0.025000000000000005, 0.0, 0.03333333333333333]\n",
    "# [0.008, 0.024000000000000004, 0.008]\n",
    "# ('Test acc:', 1.9444444444444444, 'sd:', 1.4163943093313291)\n",
    "# |  5        |  0.01333  |  1.27     |  1.156    |  1.195    |  0.7833   |\n",
    "# [0.008333333333333333, 0.0, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.2777777777777778, 'sd:', 0.3928371006591931)\n",
    "# |  6        |  0.0      |  1.297    |  1.846    |  1.938    |  0.7382   |\n",
    "# [0.013888888888888888, 0.0, 0.0]\n",
    "# [0.014666666666666668, 0.008, 0.0]\n",
    "# ('Test acc:', 0.4629629629629629, 'sd:', 0.6547285010986551)\n",
    "# |  7        |  0.007556 |  0.2306   |  1.936    |  1.592    |  0.7024   |\n",
    "# [0.2511354386354386, 0.3434765466015466, 0.30643372830872834, 0.3152858715358715]\n",
    "# [0.32786868686868686, 0.3295645530939648, 0.3073928293928294, 0.3104887334887335]\n",
    "# ('Test acc:', 30.408289627039625, 'sd:', 3.349002098569766)\n",
    "# |  8        |  0.3188   |  0.1998   |  0.08897  |  0.9428   |  0.6384   |\n",
    "# [0.4106481481481481, 0.26304563492063493, 0.31493055555555555, 0.3008207070707071, 0.37310600279350276, 0.38941300733580136]\n",
    "# [0.3358236208236208, 0.1989130869130869, 0.21833333333333332, 0.34352380952380945, 0.3320714285714286, 0.3045044955044955]\n",
    "# ('Test acc:', 34.19940093040583, 'sd:', 5.258394155542585)\n",
    "# |  9        |  0.2889   |  0.01     |  0.01     |  0.1864   |  0.669    |\n",
    "# [0.4861111111111111, 0.3020833333333333, 0.2604166666666667, 0.2916666666666667, 0.3055555555555555, 0.34722222222222215, 0.3541666666666667, 0.2708333333333333]\n",
    "# [0.3833333333333333, 0.20666666666666664, 0.3161904761904762, 0.38, 0.3466666666666666, 0.4137777777777778, 0.29333333333333333, 0.35]\n",
    "# ('Test acc:', 32.72569444444444, 'sd:', 6.743512364375678)\n",
    "# |  10       |  0.3362   |  0.01     |  0.01     |  1.212    |  0.01     |\n",
    "# [0.0, 0.0, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.0, 'sd:', 0.0)\n",
    "# |  11       |  0.0      |  0.01     |  0.01     |  2.0      |  1.0      |\n",
    "# [0.5181517556517556, 0.2377946127946128, 0.4213624338624338, 0.3735119047619048]\n",
    "# [0.27763369963369966, 0.32315873015873015, 0.23523076923076924, 0.2697142857142857]\n",
    "# ('Test acc:', 38.77051767676768, 'sd:', 10.102443647288354)\n",
    "# |  12       |  0.2764   |  0.01     |  0.01     |  0.6837   |  0.1847   |\n",
    "# [0.19999999999999998, 0.23750000000000002, 0.2722222222222222, 0.375, 0.20833333333333334, 0.0625, 0.16666666666666666, 0.325]\n",
    "# [0.22, 0.08, 0.10400000000000001, 0.264, 0.12, 0.096, 0.2, 0.16]\n",
    "# ('Test acc:', 23.09027777777778, 'sd:', 9.035987186191242)\n",
    "# |  13       |  0.1555   |  0.8694   |  0.01     |  0.01     |  1.0      |\n",
    "# [0.5590277777777778, 0.3819444444444444, 0.31527777777777777, 0.3541666666666667, 0.37152777777777773, 0.375, 0.518287037037037, 0.34027777777777773, 0.4236111111111111]\n",
    "# [0.2338095238095238, 0.19422222222222224, 0.26, 0.25666666666666665, 0.3053333333333333, 0.31, 0.305, 0.36, 0.256]\n",
    "# ('Test acc:', 40.434670781893004, 'sd:', 7.765741054904079)\n",
    "# |  14       |  0.2757   |  0.01     |  0.8582   |  0.01     |  1.0      |\n",
    "# [0.35763888888888884, 0.3756944444444444, 0.33796296296296297, 0.38055555555555554, 0.2824074074074074, 0.3171296296296296, 0.43402777777777773]\n",
    "# [0.3680952380952381, 0.23466666666666666, 0.2222222222222222, 0.22, 0.32, 0.14, 0.22666666666666666]\n",
    "# ('Test acc:', 35.50595238095238, 'sd:', 4.524186608251292)\n",
    "# |  15       |  0.2474   |  0.01     |  2.0      |  0.01     |  1.0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test accuracy for the top performing (training accuracy 0.2026) sampling parameters for gpt2-small (after the full 18 runs)\n",
    "# np.mean([0.3353320494864612,0.3277777777777778,0.21805555555555556,0.3402514152514152,0.28348214285714285,0.13194444444444445])# = 0.27280723089546616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "\"reinterpretation, harmony, character progression, reading circle\")\n",
    "# \"monolith, elevator effect, time loop, survival, desert resort, town watchman\")\n",
    "# \"monolith, allegro, soundtrack, chord, classical, opera\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.6, temperature=15.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "# \"reinterpretation, harmony, character progression, reading circle\")\n",
    "# # \"monolith, elevator effect, time loop, survival, desert resort, town watchman\")\n",
    "# # \"monolith, allegro, soundtrack, chord, classical, opera\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "# olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.6, temperature=15.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"watermelon juice, cherry juice, blackcurrant mixture, kava, orangeade, lemon juice, cherryade, cranberry juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "# olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_sentence = append_next_token(input_sentence, top_k=10, top_p=0.8, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "# \"\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider, yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider\" + \\\n",
    "# \", yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5pm: Using log_period=1 (max_len=96) reliably finds improvement, need more data and larger gpt2 (medium+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" milk, vodka, beer, ice water, soda, lassi, juice, alcohol, whiskey\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" wine, soda, alcohol, beer, liquor, apple cider, whiskey, milk, bourbon, vodka, cider, lemon juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:6])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=3.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" beer, milk, juice, wine, spirits, alcohol, soda, whiskey, brandy, apple juice, liquor, ice tea, watermelon juice, vodka,\" + \\\n",
    "# \" lemon tea, apple cider, ale, lager, fruit tea, lime cider, cocktail, mocha, red wine, apple soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5am: lr=1e-5, max_len=80, log_period_batches=5 increased accuracy by 8%. Need to add a bunch more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 5 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"soda, milk, juice, wine, vodka, gin, lime juice, beer, hot chocolate, cider, whiskey, fruit juice, cocktail, liquor, \" + \\\n",
    "# \"spirits, watermelon juice, martini, rum, chocolate milk, orangeade\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fine tuning (regular GPT-2):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model on 2nd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, juice, fruit juice, soda, wine, beer, hot chocolate, chocolate milk, alcohol, cider, ice tea, liquor, spirit\")\n",
    "# input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89, olen=olen) # k = 25 also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for too long (in this case ~6:30 hours) overfits\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"beer, juice, soda, liquor, wine, tequila, spirits, alcohol, cocktail, martini, whiskey, rum, vodka\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 15/04/2021 11am: Found learning rate 1e-7, max_listlen 15, min_nw 0.7, max_nw 0.9, lidstone_eps 0.01 works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No fine tuning (testing gpt2) (old append function):\n",
    "# input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake\"\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89)\n",
    "# A list of types of drink: juice, tea, cider, lemonade, milk, beer, hot chocolate,âž¡ ice cold milk. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working (reproducible) examples using various non-fine-tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT3 (via AI Dungeon) (Randomness = 2.0, model = Dragon):\n",
    "# sentence = \"A list of ML algorithms: inverse reinforcement learning, ELMo, decision tree, LDA, \"\n",
    "# expected_completion = \"MLP, MLL, MMM. You can't believe you're actually using these things!\"\n",
    "\n",
    "# sentence = \"A list of animals seen in the wild: wolffish, woodlouse, sheep, zebra, yak, \"\n",
    "# expected_completion = \"goat, fox, dog, rat. You're guessing that a lot of other animals have been seen as well; maybe even all the animals on your list except for wolf and rat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 (via Write with Transformer) (Top-p = 0.67, temperature = 1.89, max time = 1.9):\n",
    "# sentence = \"A list of round fruits: peach, apricot, lime, plum, blackberry, cantaloupe, nectarine, pitaya, persimmon, \"\n",
    "# expected_completion = \"mango, papaya and raspberry, as also many\"\n",
    "\n",
    "# sentence = \"A list of chemical elements: hydrogen, carbon, oxygen, nitrogen, gold, \"\n",
    "# expected_completion = \"silver, aluminum, potassium and phosphorus; atomic number.\"\n",
    "\n",
    "# sentence = \"A list of microbes found on earth: bacteria, virus, prokaryote, amoeba, \"\n",
    "# expected_completion = \"archaea, algae, nematode, euk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This result shows why we need not redistribute the mass when evaluating gpt3 accuracy\n",
    "# response = openai.Completion.create(**{**default_params,\n",
    "#   \"prompt\": \"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\",\n",
    "#   \"temperature\": 1.5,\n",
    "#   \"top_p\": 1.0,\n",
    "#   \"n\": 5,\n",
    "#   \"best_of\": 20,\n",
    "#   \"max_tokens\": 7,\n",
    "#   \"stop\": [\",\", \"\\n\"],\n",
    "# })\n",
    "# for choice in response[\"choices\"]:\n",
    "#     d = {}\n",
    "#     tokens = choice[\"logprobs\"][\"tokens\"]\n",
    "#     t_i = -1\n",
    "#     for t in tokens:\n",
    "#         t_i += 1\n",
    "#         r = [(np.e**v, k) for (k, v) in choice[\"logprobs\"][\"top_logprobs\"][t_i].items()]\n",
    "#         r.sort(reverse=True)\n",
    "#         print(sum([v for (v, k) in r]))\n",
    "#         rd = dict([(k, v) for (v, k) in r])\n",
    "#         r = [k for (v, k) in r]\n",
    "#         d[t] = (rd, r, np.e**choice[\"logprobs\"][\"token_logprobs\"][t_i])\n",
    "#     print('|'.join([' '.join((s.replace(\"\\n\", \"âŽ\"),'%.2f' % (d[s][2] * 100),\n",
    "#                               str(d[s][1].index(s) + 1) if s in d[s][1] else \"<100\")) for s in tokens]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
