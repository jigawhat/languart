{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned language model for pictionary word list completion (topic/category phrase + example words -> list of 30 examples). For example, one may complete the list\n",
    "\n",
    "\"A list of round fruits: peach, apricot, lime, plum,\"\n",
    "\n",
    "with\n",
    "\n",
    "\"mango, cherry, pineapple, strawberry, pumpkin, watermelon, orange, pomegranate, melon, apple, pear, grapefruit, papaya, lemon, kiwi, passionfruit, blueberry, raspberry, blackberry, cantaloupe, nectarine, pitaya, persimmon, durian, guava, jackfruit, avocado, lychee, soursop, guarana, mangosteen, blackcurrant, cranberry\"\n",
    "\n",
    "using this model. These words should be compatible with pictionary/skribbl.io; i.e., \"sketchable\" within a few minutes, and easily recognisable. Scroll to the end for more examples, or see the file `data/examples.txt`. Sketchability parameter estimation examples can also be found in `data/data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, GPT2LMHeadModel, ReformerModelWithLMHead, \\\n",
    "                         get_linear_schedule_with_warmup\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from Learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ###   Options   ###\n",
    "\n",
    "model_name = \"ernst_one\"\n",
    "gpt2_modelkey = \"gpt2-xl\"         # Pretrained model to start from\n",
    "test_set_frac = 0.25                 # Fraction of samples to keep as separate test set (word lists)\n",
    "sample_test_n = 200                  # Number of randomly generated prompts for each sample when validating model\n",
    "log_period_batches = 10              # Batches per iteration\n",
    "learning_rate = 2e-5                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "adam_epsilon = 1e-8                  # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                   # Linear scheduler for optimizer number of warmup steps\n",
    "batch_size = bsz = 64                # Samples per batch\n",
    "N_train_batches = int(1e7 / bsz)     # Total number of batches to show model\n",
    "min_nw, max_nw = 0.7, 0.9            # Minimum and maximum fraction of list to keep when truncating\n",
    "max_listlen = 15                     # Maximum number of words in the list when creating a prompt (at least prior to * max_nw)\n",
    "lidstone_e = 0.01                    # Smoothing for possible words/subwords which are not in the missing list words set\n",
    "max_len = 96                         # Max n. tokens specified in order to match a power of 2, applied prior to *max_nw (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "d = device = pt.device(dev)\n",
    "# world_size = 1\n",
    "# rank = 0\n",
    "# def setup(rank, world_size): \n",
    "#     os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "#     os.environ['MASTER_PORT'] = find_free_port()\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)  # initialize the process group\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "# # mp.spawn(setup, args=(rank, world_size), nprocs=world_size)\n",
    "# setup(rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(gpt2_modelkey.replace(\"-xl\", \"-large\"), padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    tokenizer.encode(\"oranges, pears,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[tokenizer.encode(prompt), \"types of\" in prompt] for prompt in lprompts]\n",
    "cats_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e = [[tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "# lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "# cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "# cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "# phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "lidstone_e = pt.tensor(lidstone_e, device=d)\n",
    "y_zero = (lidstone_e / N_tokens).repeat(N_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk, using nw_draw = 15. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p):  # prmt = prompt tokens, p = list word/phrase tokens\n",
    "    tkzs, sent, tkix = [], [], 0\n",
    "    max_ws = max_len - len(prmt)\n",
    "#     incl_words = pt.randperm(len(p))[:min(max_listlen, len(p))]\n",
    "    incl_words = np.random.choice(len(p), min(max_listlen, len(p)), replace=False)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc = p[phz_i]\n",
    "        tkzs.append((tkix, phz_enc))\n",
    "        tkix += len(phz_enc)\n",
    "        sent.append(phz_enc)\n",
    "        if tkix >= max_ws:\n",
    "            tkix = max_ws\n",
    "            break\n",
    "    sent = pt.hstack(sent)[:max_ws]\n",
    "    missing_w = [p[i] for i in range(len(p)) if i not in incl_words]\n",
    "    trunc_ix = np.random.randint(round(tkix * min_nw), round(tkix * max_nw))\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if len(enc) >= trunc_n and all(enc[:trunc_n] == partial_phr)]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_e)\n",
    "    tunit, y_ = pt.tensor(1 / norm, device=d), y_zero.clone()\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return pt.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def gen_samples_uniform(xcp, xcs, xp, nw, verbose=False):  # Weight testing samples (word lists) uniformly\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        for m in range(nw):\n",
    "            prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "            cat_ix = np.random.randint(len(cp))\n",
    "            x_, y_ = gen_truncated_list(pt.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "            sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0:\n",
    "                sys_print(\"\\rDone: \" + str(j))\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        sqlens.append(sqlen)\n",
    "    if verbose: sys_print(\"\\rDone: \" + str(j) + \", finished!\\n\")\n",
    "    return xs, ys, sqlens\n",
    "def gen_samples(xcp, xcs, xp, n):  # Maximise training batch diversity by randomly sampling the word lists\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets = len(xcp)\n",
    "    for m in range(n):\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "        cat_ix = np.random.randint(len(cp))\n",
    "        x_, y_ = gen_truncated_list(pt.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "        sqlens.append(len(x_))\n",
    "    return xs, ys, sqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "['round fruits', 'wild animals', 'chemical elements', 'microorganisms', 'music', 'outback experiences', 'scientific cycles', 'buildings']\n",
      "Test:\n",
      "['machine learning algorithms', 'dramatic and literature elements']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 400, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test = int(test_set_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "test_idx = np.random.choice(N_wordlists, N_test, replace=False)\n",
    "save_ld(test_idx, \"test.data\")\n",
    "# test_idx = load_ld(\"test.data\")\n",
    "# test_idx = np.array([0, 2])  # Round fruits and chemical elements\n",
    "train_idx = [i for i in range(N_wordlists) if i not in test_idx]\n",
    "print(\"Train:\")\n",
    "print([cats[i][0] for i in train_idx])\n",
    "print(\"Test:\")\n",
    "print([cats[i][0] for i in test_idx])\n",
    "cats_e_test, cats_sing_e_test = [cats_e[i] for i in test_idx], [cats_sing_e[i] for i in test_idx]\n",
    "phrases_e_test = [phrases_e[i] for i in test_idx]\n",
    "cats_e_train, cats_sing_e_train = [cats_e[i] for i in train_idx], [cats_sing_e[i] for i in train_idx]\n",
    "phrases_e_train = [phrases_e[i] for i in train_idx]\n",
    "test_cats = [cats[i][0] for i in test_idx]\n",
    "test_xs, test_ys, test_sqlens = gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, sample_test_n, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "def adapt_form(xs, ys, sqlens):\n",
    "    xs = pt.vstack([F.pad(x, (0, max(0, max_len - len(x))), mode='constant', value=pad_token)[:max_len] for x in xs])\n",
    "    return xs, pt.vstack(ys), pt.tensor(sqlens, device=d)\n",
    "def next_batch(sz):\n",
    "    global cats_e_train, cats_sing_e_train, phrases_e_train\n",
    "    return adapt_form(*gen_samples(cats_e_train, cats_sing_e_train, phrases_e_train, sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "GPT2 device: cuda:0\n",
      "Pretrained parameters loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1271"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "pt.cuda.empty_cache()\n",
    "print(gc.collect())\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2LMHead\")\n",
    "# model_ = GPT2ForSequenceClassification.from_pretrained('gpt2-large',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-xl',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-large',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-medium',\n",
    "model_ = GPT2LMHeadModel.from_pretrained(gpt2_modelkey,\n",
    "    output_hidden_states=False, output_attentions=False, \n",
    "    cache_dir=\"models/pretrained/GPT2LMHead\")\n",
    "# model_.parallelize()\n",
    "device_map = {0: [0, 1, 2],\n",
    "              1: [3, 4, 5, 6, 7, 8],\n",
    "              2: [9, 10, 11, 12, 13, 14],\n",
    "              3: [15, 16, 17, 18, 19, 20],\n",
    "              4: [21, 22, 23, 24, 25, 26, 27],\n",
    "              5: [28, 29, 30, 31, 32, 33, 34],\n",
    "              6: [35, 36, 37, 38, 39, 40, 41],\n",
    "              7: [42, 43, 44, 45, 46, 47],\n",
    "             }\n",
    "model_.parallelize(device_map)\n",
    "# model_ = model_.to(d)\n",
    "print(\"GPT2 device:\", model_.device)\n",
    "model_.resize_token_embeddings(N_tokens)\n",
    "pad_token = model_.config.pad_token_id = model_.config.eos_token_id\n",
    "pad_token = pt.tensor(pad_token, device=d)\n",
    "n_embd = pt.tensor(model_.config.n_embd, device=d)\n",
    "# model = nn.parallel.DistributedDataParallel(model_, device_ids=[d])\n",
    "# model = nn.DataParallel(\n",
    "#     model_, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else model_\n",
    "model = model_\n",
    "print(\"Pretrained parameters loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = None #nn.Linear(n_embd, N_tokens, bias=False).to(d)#.cpu()\n",
    "# nn.init.xavier_uniform_(llayer.weight)\n",
    "# llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else llayer\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()#.to(d)#.cpu()\n",
    "# bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d) if dev != \"cpu\" else bcewl_loss\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1, device=d)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, bsz, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(bsz)\n",
    "\n",
    "#     for x in x_batch.cpu().detach().numpy():\n",
    "#         print(tokenizer.decode(x))\n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)  # Get logits\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens_batch - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     outs = outputs[0][:, -1]\n",
    "#     logits = llayer(outs)\n",
    "    logits = outs\n",
    "    \n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "\n",
    "def inference(x, sqlens):\n",
    "    global model, llayer\n",
    "\n",
    "    x, sqlens = x, sqlens\n",
    "#     for x_ in x.cpu().detach().numpy():\n",
    "#         print(tokenizer.decode(x_))\n",
    "    mask = sequence_mask(sqlens, max_len)\n",
    "    outputs = model(x.long(), attention_mask=mask)  # Get logits\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     outs = outputs[0][:, -1]\n",
    "#     logits = llayer(outs)\n",
    "    logits = outs\n",
    "    return logits\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())#.to(d)#.cpu()\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = 0\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "out_str = ''\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, test_loss, test_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, test_loss, test_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        if batch_i > 1:\n",
    "            gc.collect()\n",
    "            if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "            b_loss, b_accuracy = train_step()\n",
    "            if verbose:\n",
    "                sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                          ' @ batch '+ str(batch_i - 1) + ' (' + str((batch_i - 1) * batch_size) + ' samples) complete.                  ')\n",
    "            iter_loss.append(b_loss)\n",
    "            iter_accuracy.append(b_accuracy)\n",
    "\n",
    "        if (batch_i - 1) % log_period_batches == 0:  # Test on test set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            out_str = '\\n'\n",
    "            for i in range(N_test):\n",
    "                test_X, test_Y, test_Sqlens = adapt_form(test_xs[i], test_ys[i], test_sqlens[i])\n",
    "                feed_batches = [range(len(test_X))[i * bsz:(i + 1) * bsz] for i in range((len(test_X) // bsz) + \\\n",
    "                                                                                        (1 if (len(test_X) % bsz) != 0 else 0))]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(test_X[inds], test_Y[inds], test_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls))\n",
    "                accuracy.append(np.mean(cs))\n",
    "                out_str += test_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]) + '\\n'\n",
    "            \n",
    "            test_l, test_a = np.mean(loss), np.mean(accuracy)\n",
    "            test_loss.append(test_l)\n",
    "            test_accuracy.append(test_a)\n",
    "            if batch_i == 1:\n",
    "                iter_loss, iter_accuracy = [test_l], [test_a]\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l)\n",
    "            train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "            \n",
    "            val_a = 0\n",
    "            if test_a > best_acc:      # Save best accuracy model\n",
    "                best_acc = test_a\n",
    "                best_loss = test_l\n",
    "                best_acc_idx = (batch_i - 1) // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "#                          \"llayer\": llayer.state_dict(),\n",
    "#                          \"softrmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(out_str + \"Batch\", batch_i, ':', train_a, test_a, \"loss:\", train_l, test_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(test_accuracy, label='test acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                g.plot(test_loss, label='test loss')\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, test_accuracy, train_loss, test_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "machine learning algorithms: 0.00011573873, 0.578125\n",
      "dramatic and literature elements: 0.0001001832, 0.80859375\n",
      "Batch 1021 : 0.8890625 0.6933594 loss: 6.332579e-05 0.000107960965 Best: 0.71484375 0.00011023056 idx: 95\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, accuracy: 7.741736e-05, 0.9375 @ batch 1028 (65792 samples) complete.                    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ff61b84ca1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miterate_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-51e9a9ccfdc3>\u001b[0m in \u001b[0;36miterate_training\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mb_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
      "\u001b[0;32m<ipython-input-13-1d36f3133d92>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model (checkpoint)\n",
    "pt.cuda.empty_cache()\n",
    "gc.collect()\n",
    "cpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 2k ts' + \"/\" + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 3k ts' + \"/\" + model_name)  # ~3000 training samples observed has current optimum\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 30k ts' + \"/\" + model_name)\n",
    "model.load_state_dict(cpoint['model'])\n",
    "bcewl_loss.load_state_dict(cpoint['bcewl_loss'])\n",
    "optimizer.load_state_dict(cpoint['optimizer'])\n",
    "scheduler.load_state_dict(cpoint['scheduler'])\n",
    "# llayer.load_state_dict(cpoint['llayer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = int(pad_token.detach().cpu().numpy())\n",
    "def append_next_token(sent, top_k=-1, top_p=0.9, temperature=1.0, olen=None):\n",
    "    print(\"k =\", top_k, \", p =\", top_p, \", temp =\", temperature)\n",
    "    global model\n",
    "    if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    ou = tokens.copy()\n",
    "    while len(tokens) < max_len:\n",
    "        tokens += [padder]\n",
    "    x = pt.tensor([tokens], device=d)\n",
    "    logits = inference(x, pt.tensor([len(ou)], device=d))[0]\n",
    "    logits /= temperature\n",
    "    logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "    probs = F.softmax(logits, dim=0)\n",
    "    token = pt.multinomial(probs, 1).detach().cpu().numpy()[0]\n",
    "    ou += [token]\n",
    "    prev_len = len(sent) if olen is None else olen\n",
    "    sent_new = tokenizer.decode(ou)\n",
    "    print(sent[:prev_len] + '' + sent_new[prev_len:])\n",
    "    return sent_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "\"\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 5 , p = 0.9 , temp = 5.0\n",
      " A list of types of element of drama and writing: fate, diversion, pace, plot twist, silence, monologue, cliffhanger, surprise, attention, fourth wall,,,,\n"
     ]
    }
   ],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "\"milk, soda\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 25 , p = 0.7 , temp = 2.0\n",
      " A list of types of drink: lemonade, water, tea, milk, coffee, coke, milkshake, water, watery of of, soda, milk\n"
     ]
    }
   ],
   "source": [
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)\n",
    "\n",
    "# \n",
    "input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider, yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider\" + \\\n",
    "# \", yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5pm: Using log_period=1 (max_len=96) reliably finds improvement, need more data and larger gpt2 (medium+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" milk, vodka, beer, ice water, soda, lassi, juice, alcohol, whiskey\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" wine, soda, alcohol, beer, liquor, apple cider, whiskey, milk, bourbon, vodka, cider, lemon juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:6])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=3.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" beer, milk, juice, wine, spirits, alcohol, soda, whiskey, brandy, apple juice, liquor, ice tea, watermelon juice, vodka,\" + \\\n",
    "# \" lemon tea, apple cider, ale, lager, fruit tea, lime cider, cocktail, mocha, red wine, apple soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5am: lr=1e-5, max_len=80, log_period_batches=5 increased accuracy by 8%. Need to add a bunch more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 5 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"soda, milk, juice, wine, vodka, gin, lime juice, beer, hot chocolate, cider, whiskey, fruit juice, cocktail, liquor, \" + \\\n",
    "# \"spirits, watermelon juice, martini, rum, chocolate milk, orangeade\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fine tuning (regular GPT-2):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model on 2nd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, juice, fruit juice, soda, wine, beer, hot chocolate, chocolate milk, alcohol, cider, ice tea, liquor, spirit\")\n",
    "# input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89, olen=olen) # k = 25 also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for too long (in this case ~6:30 hours) overfits\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"beer, juice, soda, liquor, wine, tequila, spirits, alcohol, cocktail, martini, whiskey, rum, vodka\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 15/04/2021 11am: Found learning rate 1e-7, max_listlen 15, min_nw 0.7, max_nw 0.9, lidstone_e 0.01 ACTUALLY WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No fine tuning (testing gpt2) (old append function):\n",
    "# input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake\"\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89)\n",
    "# A list of types of drink: juice, tea, cider, lemonade, milk, beer, hot chocolate, ice cold milk. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working (reproducible) examples using various non-fine-tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT3 (via AI Dungeon) (Randomness = 2.0, model = Dragon):\n",
    "# sentence = \"A list of ML algorithms: inverse reinforcement learning, ELMo, decision tree, LDA, \"\n",
    "# expected_completion = \"MLP, MLL, MMM. You can't believe you're actually using these things!\"\n",
    "\n",
    "# sentence = \"A list of animals seen in the wild: wolffish, woodlouse, sheep, zebra, yak, \"\n",
    "# expected_completion = \"goat, fox, dog, rat. You're guessing that a lot of other animals have been seen as well; maybe even all the animals on your list except for wolf and rat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 (via Write with Transformer) (Top-p = 0.67, temperature = 1.89, max time = 1.9):\n",
    "# sentence = \"A list of round fruits: peach, apricot, lime, plum, blackberry, cantaloupe, nectarine, pitaya, persimmon, \"\n",
    "# expected_completion = \"mango, papaya and raspberry, as also many\"\n",
    "\n",
    "# sentence = \"A list of chemical elements: hydrogen, carbon, oxygen, nitrogen, gold, \"\n",
    "# expected_completion = \"silver, aluminum, potassium and phosphorus; atomic number.\"\n",
    "\n",
    "# sentence = \"A list of microbes found on earth: bacteria, virus, prokaryote, amoeba, \"\n",
    "# expected_completion = \"archaea, algae, nematode, euk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
