{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned language model for pictionary word list completion (topic/category phrase + example words -> list of 30 examples). For example, one may complete the list\n",
    "\n",
    "\"A list of round fruits: peach, apricot, lime, plum,\"\n",
    "\n",
    "with\n",
    "\n",
    "\"mango, cherry, pineapple, strawberry, pumpkin, watermelon, orange, pomegranate, melon, apple, pear, grapefruit, papaya, lemon, kiwi, passionfruit, blueberry, raspberry, blackberry, cantaloupe, nectarine, pitaya, persimmon, durian, guava, jackfruit, avocado, lychee, soursop, guarana, mangosteen, blackcurrant, cranberry\"\n",
    "\n",
    "using this model. These words should be compatible with pictionary/skribbl.io; i.e., \"sketchable\" within a few minutes, and easily recognisable. Scroll to the end for more examples, or see the file `data/examples.txt`. Sketchability parameter estimation examples can also be found in `data/data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "with open('../../openai-api-org.txt', 'r') as f: openai.organization = f.read()\n",
    "with open('../../openai-api-key.txt', 'r') as f: openai.api_key      = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1204 14:44:19.681021 24200 modeling_bert.py:226] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I1204 14:44:19.689000 24200 modeling_xlnet.py:339] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alfew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import glob\n",
    "import string\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from bayes_opt import BayesianOptimization\n",
    "from IPython.utils import io\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, GPT2LMHeadModel, GPTNeoForCausalLM, ReformerModelWithLMHead, \\\n",
    "                         get_linear_schedule_with_warmup, GPT2TokenizerFast, AutoTokenizer, XLNetLMHeadModel\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from Learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                  ###   Options   ###\n",
    "model_name = \"ernst_one\"\n",
    "# model_name = \"unfinetuned\"\n",
    "# modelkey = \"xlnet-base-cased\"                   # Pretrained model to start from\n",
    "modelkey = \"gpt2-xl\"\n",
    "# modelclass = \"XLNetLMHeadModel\"\n",
    "modelclass = \"GPT2LMHeadModel\"\n",
    "val_frac, test_frac = 0.25, 0.25    # Fraction of samples to keep as separate validation/test set (word lists)\n",
    "TsN = 200                           # Number of randomly generated prompts for each sample when validating model\n",
    "log_period_batches = 10             # Batches per iteration\n",
    "# learning_rate = 5e-7              # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "learning_rate = 2e-5\n",
    "# learning_rate = 4e-6\n",
    "adam_epsilon = 1e-8                 # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                  # Linear scheduler for optimizer number of warmup steps\n",
    "# batch_size = bsz = 64               # Samples per batch\n",
    "# batch_size = bsz = 32\n",
    "batch_size = bsz = 4\n",
    "# N_train_batches = int(1e7 / bsz)  # Total number of batches to show model\n",
    "N_train_batches = 600\n",
    "n_unfreeze = \"all\"                  # Number of model layers to fine tune, in addition to the last output linear layer\n",
    "# max_len = 1024                    # Max n. tokens applied prior to rng_train (number of phrases range)\n",
    "max_len = 32\n",
    "train_phrase_log_pctile = 0.0       # Phrase generation probability percentile excluded from training dataset\n",
    "lidstone_eps = 0.01                 # Smoothing epsilon for possible words/subwords which are not in the missing list words set\n",
    "lastcomma_repl = ',' # 'EOS', ','   # Token optionally used to replace the final comma that ends the generated phrase\n",
    "use_correct_nouns = True            # Whether to use only correct singular or plural form of category nouns for the given prompt\n",
    "swap_noun = False                   # Whether to swap plural and singular nouns in prompt\n",
    "rng_train_gpt3 = [0, 512]           # Range of prompt list lengths (number of phrases) to generate for training data\n",
    "rng_train = [3, 5]\n",
    "# rng_train = [0, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda\" if pt.cuda.is_available() else \"cpu\"  # Setup torch device(s)\n",
    "d = device = pt.device(dev)\n",
    "# world_size = 1\n",
    "# rank = 0\n",
    "# def setup(rank, world_size): \n",
    "#     os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "#     os.environ['MASTER_PORT'] = find_free_port()\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)  # initialize the process group\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "# # mp.spawn(setup, args=(rank, world_size), nprocs=world_size)\n",
    "# setup(rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([32, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [273, 6231, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [273, 6231, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DerivTokenizer():  # Wrap the tokenizer so that we don't produce the special tokens (NLG case)\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def __len__(self): return self.tokenizer.__len__()\n",
    "    def encode(self, *args, **kwargs): return self.tokenizer.encode(*args, add_special_tokens=False, **kwargs)\n",
    "    def decode(self, *args, **kwargs): return self.tokenizer.decode(*args, **kwargs)\n",
    "gpt3_tokenizer = DerivTokenizer(GPT2TokenizerFast.from_pretrained((\"gpt2-large\")))\n",
    "with io.capture_output() as captured:\n",
    "    tokenizer = DerivTokenizer(AutoTokenizer.from_pretrained(modelkey.replace(\"-xl\", \"-large\")))\n",
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), tokenizer.encode(\"oranges, pears,\"), \\\n",
    "  gpt3_tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    gpt3_tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    gpt3_tokenizer.encode(\"oranges, pears,\") # Note: gpt-3 tokenizes words differently if they are at the start of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_sing = [p for p in lprompts if ((\"types of\" in p) ^ swap_noun)]                 # construct dataset\n",
    "enc_prompts = lambda tknzr, prmts: [pt.tensor(tknzr.encode(p)).to(d) for p in prmts]\n",
    "enc_listset = lambda tknzr, Xs: [[[pt.tensor(tknzr.encode(p + suffix)).to(d) for p in ps] for ps in X] for (X, suffix) in Xs]\n",
    "lprompts_encoded, lprompts_encoded3 = enc_prompts(tokenizer, lprompts), enc_prompts(gpt3_tokenizer, lprompts)\n",
    "lprompts_sing_encoded, lprompts_sing_encoded3 =enc_prompts(tokenizer, lprompts_sing),enc_prompts(gpt3_tokenizer, lprompts_sing)\n",
    "Xs = (cats, ': '), (cats_sing, ': '), (phrases, ', ')\n",
    "(cats_e,cats_sing_e,phrases_e), (cats_e3,cats_sing_e3,phrases_e3) = enc_listset(tokenizer, Xs), enc_listset(gpt3_tokenizer, Xs)\n",
    "comma_token = pt.tensor(tokenizer.encode(\"a,\")[1], device=d)\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)\n",
    "lidstone_eps = pt.tensor(lidstone_eps, device=d) if not isinstance(lidstone_eps, pt.Tensor) else lidstone_eps\n",
    "lidstone_value = lidstone_eps / N_tokens\n",
    "y_zero = (lidstone_value).repeat(N_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phrases = list(set(sum(phrases, [])))\n",
    "vowels = 'aeiuo'\n",
    "# phrase_logs = get_s_avglogs([('An' if p[0].lower() in vowels else 'A') + ' ' + p for p in all_phrases])\n",
    "phrase_logs = ()# todo: function to get log probability of phrase (n-gram) occuring in the pretraining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_max_plog = train_phrase_log_pctile > 0.0\n",
    "if use_max_plog:\n",
    "    max_phrase_log = np.percentile(phrase_logs, 100 * (1.0 - train_phrase_log_pctile))\n",
    "    phrase_incls = [p > max_phrase_log for p in phrase_logs]\n",
    "    phrase_incl = dict(zip(all_phrases, phrase_incls))\n",
    "    all_phrases_enc = sum([[tuple(p_.cpu().detach().numpy().tolist()) for p_ in p] for p in phrases_e], [])\n",
    "    enc_phrase_log_incl = dict(zip(list(set(all_phrases_enc)), phrase_incls))\n",
    "    plt.hist(phrase_logs, bins=250)\n",
    "    plt.axvline(x=max_phrase_log, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p, ra=True, rng=rng_train, mlen=max_len):  # prmt = prompt tokens, p = list phrase/word tokens\n",
    "    tkzs, sent, tkix, wordix = [], [], 0, -1   # rng is the inclusive range of list lengths to generate (number of phrases)\n",
    "    min_nw, max_nw, min_nt, max_nt = rng[0], int(rng[1]), 0, int(mlen) - len(prmt)\n",
    "    incl_words = np.random.choice(len(p), min(len(p), max_nw), replace=False)\n",
    "    if use_max_plog:\n",
    "        p_ra = [i for i in range(len(p)) if enc_phrase_log_incl[tuple(p[i].cpu().detach().numpy().tolist())]]\n",
    "        p_incl = [i for i in range(len(p)) if i not in p_ra]\n",
    "        p_ra_chosen = [i for i in incl_words if i in p_ra]\n",
    "        min_nw -= len(p_ra_chosen)\n",
    "        incl_words = [i for i in incl_words if i in p_incl]\n",
    "    if len(incl_words) == 0:#rare when train_phrase_log_pctile is low enough and min_nw is high enough (temporary optimisation)\n",
    "        return gen_truncated_list(prmt, p, ra=ra, rng=rng, mlen=mlen)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc, wordix = p[phz_i], wordix + 1\n",
    "        tkzs.append((tkix, phz_enc)), sent.append(phz_enc)\n",
    "        tkix += len(phz_enc)\n",
    "        if wordix < min_nw: min_nt = tkix\n",
    "        if tkix >= max_nt:\n",
    "            tkix = max_nt\n",
    "            break\n",
    "    if min_nt - 1 >= tkix:  # rare when max_len is large enough (0.5x max possible total list length) (temporary optimisation)\n",
    "        return gen_truncated_list(prmt, p, ra=ra, rng=rng, mlen=mlen)\n",
    "    sent = pt.hstack(sent)[:max_nt]\n",
    "    # If we don't want to include outliers in target\n",
    "    missing_w = [p[i] for i in range(len(p)) if (i not in incl_words) and (True if (ra or not use_max_plog) else (i in p_incl))]\n",
    "    trunc_ix = np.random.randint(max(min_nt - 1, 0), tkix)\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if len(enc) >= trunc_n and all(enc[:trunc_n] == partial_phr)]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_eps)\n",
    "    tunit, y_ = pt.tensor(1 / norm, device=d), y_zero.clone()\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return pt.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def stac_sample(stac, n):   # Create batches by random permutations (maximise diversity and uniformity) (shuffling done later)\n",
    "    r, mode, total = [], tuple(np.unique(stac)), stac.shape[0]\n",
    "    while n > 0:\n",
    "        if mode == (0,) or mode == (1,) or mode == (-1,):\n",
    "            if n >= total:\n",
    "                new = sum([list(range(total)) for _ in range(n // total)], [])\n",
    "                r += new\n",
    "                n -= len(new)\n",
    "            else:\n",
    "                new = np.random.choice(total, n, replace=False)\n",
    "                stac[new] = (mode[0] + 1) if mode != (1,) else -1\n",
    "                r += new.tolist()\n",
    "                n = 0\n",
    "        else:\n",
    "            old_val, new_val = mode[0] if mode != (-1, 1) else 1, mode[1] if mode != (-1, 1) else -1\n",
    "            old_i = np.nonzero(stac == old_val)[0]\n",
    "            if n >= old_i.shape[0]:\n",
    "                stac[old_i] = new_val\n",
    "                r += old_i.tolist()\n",
    "                n -= old_i.shape[0]\n",
    "            else:\n",
    "                new = np.random.choice(old_i, n, replace=False)\n",
    "                stac[new] = new_val\n",
    "                r += new.tolist()\n",
    "                n = 0\n",
    "        mode = tuple(np.unique(stac))\n",
    "    return r\n",
    "def gen_listname(cp, cp_cs, prompt, prmt, tknzr=tokenizer):\n",
    "    cat_ix = np.random.randint(len(cp_cs))            # First uniformly sample a category title\n",
    "    sing = use_correct_nouns and (cat_ix >= len(cp))  # Singular vs plural prompt prefix\n",
    "    if prompt is None:                                # Uniformly sample a list beginning phrase (\"A list of...\") if not given\n",
    "        lprmpts = ((lprompts_sing_encoded if sing else lprompts_encoded) if tknzr is tokenizer else \\\n",
    "                   (lprompts_sing_encoded3 if sing else lprompts_encoded3)) if tknzr is not None else \\\n",
    "                   (lprompts_sing if sing else lprompts)\n",
    "        prmt = lprmpts[np.random.randint(len(lprmpts))]\n",
    "    return cp_cs[cat_ix], prmt if prompt is None else prompt\n",
    "def gen_listnames_uniform(xcp, xcs, xp, n, prompt=None, tknzr=tokenizer, verbose=False, stac=None):\n",
    "    prmts, cats, ps, j, prmt = [], [], [], 0, None\n",
    "    if prompt is not None and tknzr is not None: prmt = pt.tensor(tknzr.encode(prompt), device=d)\n",
    "    stac_, stac = stac_sample(stac, n) if (stac is not None) else None, stac is not None\n",
    "    if stac: np.random.shuffle(stac_)\n",
    "    for i in (range(len(xcp)) if not stac else stac_):\n",
    "        prmts_, cats_ = [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        for m in range(n if not stac else 1):\n",
    "            cat, prmt = gen_listname(cp, cp_cs, prompt, prmt, tknzr=tknzr)\n",
    "            prmts_.append(prmt), cats_.append(cat)\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0: sys_print(\"\\rGenerating list names, done: \" + str(j))\n",
    "        ps.append(p), prmts.append(prmts_), cats.append(cats_)\n",
    "    if verbose: sys_print(\"\\rGenerating list names, done: \" + str(j) + \", finished!\\n\")\n",
    "    return prmts, cats, ps, stac\n",
    "def gen_samples_uniform(xcp, xcs, xp, n,              # Weight testing samples (word lists) exactly uniformly\n",
    "                        ra=True, rng=rng_train, prompt=None, tknzr=tokenizer, verbose=False, inds=False, stac=None, mlen=1e9):\n",
    "    xs, ys, sqlens, j, prmt = [], [], [], 0, None\n",
    "    prmts, cats, ps, stac = gen_listnames_uniform(xcp, xcs, xp, n, prompt=prompt, tknzr=tknzr, verbose=verbose, stac=stac)\n",
    "    for i in range(len(prmts)):\n",
    "        x, y, sqlen, p = [], [], [], ps[i]\n",
    "        for k in range(len(prmts[i])):\n",
    "            x_, y_ = gen_truncated_list(pt.hstack([prmts[i][k], cats[i][k]]), p, ra=ra, rng=rng, mlen=mlen)\n",
    "            x.append(x_), y.append(y_), sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0: sys_print(\"\\rGenerating list elements, done: \" + str(j))\n",
    "        xs.append(x), ys.append(y), sqlens.append(sqlen)\n",
    "    if inds or stac: xs, ys, sqlens = sum(xs, []), sum(ys, []), sum(sqlens, [])\n",
    "    if verbose: sys_print(\"\\rGenerating list elements, done: \" + str(j) + \", finished!\\n\")\n",
    "    return (xs, ys, sqlens, np.arange(len(xcp)).repeat(n)) if inds else (xs, ys, sqlens)\n",
    "def gen_samples(xcp, xcs, xp, n,\n",
    "                ra=True, rng=rng_train, prompt=None, tknzr=tokenizer, inds=False, mlen=1e9):\n",
    "    xs, ys, sqlens, j, prmt = [], [], [], 0, None   \n",
    "    if prompt is not None and tknzr is not None: prmt = pt.tensor(tknzr.encode(prompt), device=d)\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets, indices = len(xcp), []\n",
    "    for m in range(n):  # Maximise per-batch training diversity by randomly sampling the word lists\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        cat_ix, prmt = gen_listname(cp, cp_cs, prompt, prmt)\n",
    "        x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p, ra=ra, rng=rng, mlen=mlen)\n",
    "        xs.append(x_), ys.append(y_), sqlens.append(len(x_)), indices.append(i)\n",
    "    return (xs, ys, sqlens, np.asarray(indices)) if inds else (xs, ys, sqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  8 21  4  7  5 10 25] [14 11  1 19 24 31 18 32]\n",
      "Train\n",
      " ['round fruits', 'microorganisms', 'outback experiences', 'buildings', 'holed pasta', 'rod shaped pasta', 'sounds of a building', 'biological examples of math in nature', 'non-biological examples of math in nature', 'handcrafts', 'communication media', 'storage media', 'scientific principles behind showers', 'scientific principles behind rain showers', 'spacecraft types', 'real spacecrafts', 'interpersonal tokens of trust'] \n",
      "Validation\n",
      " ['construction sounds', 'hats', 'wild animals', 'woodland ecoregions', 'winds', 'physical tokens that confer trust', 'timbers', 'digital tokens that confer trust'] \n",
      "Test\n",
      " ['chemical elements', 'dramatic and literature elements', 'vehicles referred to as crafts', 'music', 'scientific cycles', 'machine learning algorithms', 'glassware', 'windings']\n",
      "Generating list names, done: 1600, finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating list elements, done: 1600, finished!\n",
      "Generating list names, done: 1600, finished!\n",
      "Generating list elements, done: 1600, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test, N_val = int(test_frac * N_wordlists), int(val_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "# test_idx = np.random.choice(N_train, N_test, replace=False)\n",
    "test_idx = np.asarray([ 2,  8, 21,  4,  7,  5, 10, 25])\n",
    "save_ld(test_idx, \"test_idx\")\n",
    "# test_idx = load_ld(\"test_idx\")\n",
    "trval_idx = np.asarray([i for i in range(N_wordlists) if i not in test_idx])\n",
    "# val_idx = np.random.choice(trval_idx, N_val, replace=False)\n",
    "val_idx = np.asarray([14, 11,  1, 19, 24, 31, 18, 32])\n",
    "save_ld(val_idx, \"val_idx\")\n",
    "# val_idx = load_ld(\"val_idx\")\n",
    "train_idx = np.asarray([i for i in trval_idx if i not in val_idx])\n",
    "print(test_idx, val_idx)\n",
    "print(*sum([[c+'\\n',[cats[i][0] for i in ix]]for(c,ix)in[[\"Train\",train_idx],[\"\\nValidation\",val_idx],[\"\\nTest\",test_idx]]],[]))\n",
    "index_listset, listset_iXs = lambda inds, Xs: [[X[i] for i in inds] for X in Xs],(\"trval_idx\",\"train_idx\",\"val_idx\",\"test_idx\")\n",
    "phase_listsets = {None: {k[:-4]: index_listset(globals()[k], (cats, cats_sing, phrases)) for k in listset_iXs},\n",
    "             \"default\": {k[:-4]: index_listset(globals()[k], (cats_e, cats_sing_e, phrases_e)) for k in listset_iXs},\n",
    "                \"gpt3\": {k[:-4]: index_listset(globals()[k], (cats_e3, cats_sing_e3, phrases_e3)) for k in listset_iXs}}\n",
    "cats_e_test, cats_sing_e_test, phrases_e_test = phase_listsets[\"default\"][\"test\"]\n",
    "cats_e_val, cats_sing_e_val, phrases_e_val = phase_listsets[\"default\"][\"val\"]\n",
    "val_cats = [cats[i][0] for i in val_idx]\n",
    "test_xs,test_ys,test_sqlens= gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, TsN, mlen=max_len, verbose=True)\n",
    "val_xs, val_ys, val_sqlens = gen_samples_uniform(cats_e_val, cats_sing_e_val, phrases_e_val, TsN, mlen=max_len, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function that takes a prompt, existing list and sampling params and returns gpt3's next token probs\n",
    "default_msp = {\n",
    "  \"best_of\": 1,\n",
    "}\n",
    "default_sp = {\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "#   \"top_k\": -1.0,                 # todo: add code to apply this to gpt3 output (top100), max k ~=90, min = 2?\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "}\n",
    "default_params = {\n",
    "  \"engine\": \"davinci\",\n",
    "  \"model\": None,\n",
    "  \"max_tokens\": 1,\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "#   \"top_k\": -1.0,\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "  \"n\": 1,\n",
    "  \"stream\": False,\n",
    "  \"logprobs\": 100,\n",
    "#       \"logit_bias\": {\"50256\": -100},\n",
    "  \"stop\": [\",\", \"\\n\"],\n",
    "}\n",
    "# Define and test the OpenAI API next token probability request (response-token-efficient streaming version)\n",
    "def format_gpt3_probs(choice, tokenize):\n",
    "    res, r = [], sorted([(np.e**v, k) for (k, v) in choice[\"logprobs\"][\"top_logprobs\"][0].items()])[::-1]\n",
    "    for i in range(len(r)):\n",
    "        k = gpt3_tokenizer.encode(r[i][1])\n",
    "        if len(k) == 1: res.append((r[i][0], k if tokenize else r[i][1]))\n",
    "    return res\n",
    "def p_req(s, tokenize=False, **kwargs):\n",
    "    use_stream = \"max_tokens\" in kwargs and kwargs[\"max_tokens\"] != 1\n",
    "    kwargs[\"prompt\"], kwargs[\"stream\"] = s, use_streamtt\n",
    "    with io.capture_output() as captured:\n",
    "        response, result = openai.Completion.create(**{**default_params, **kwargs}), []\n",
    "    return [(np.e**resp[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0], resp[\"choices\"][0][\"logprobs\"][\"tokens\"][0],\n",
    "             format_gpt3_probs(resp[\"choices\"][0], tokenize)) for resp in (response if use_stream else [response])]\n",
    "# todo: version to handle multiple choices for phrase level evaluation (response-token-expensive)\n",
    "def p_req_m(s, tokenize=False, **kwargs):\n",
    "    if \"max_tokens\" not in kwargs: kwargs[\"max_tokens\"] = 8\n",
    "    if \"n\" not in kwargs: kwargs[\"n\"] = 5\n",
    "    if \"best_of\" in kwargs:\n",
    "        kwargs[\"best_of\"] = int(round(kwargs[\"best_of\"]))\n",
    "        if kwargs[\"n\"] != 1: kwargs[\"best_of\"], kwargs[\"n\"] = kwargs[\"n\"], kwargs[\"best_of\"]\n",
    "    kwargs[\"prompt\"] = s\n",
    "    with io.capture_output() as captured:\n",
    "        response, tokens, probs = openai.Completion.create(**{**default_params, **kwargs}), [], []\n",
    "    print(response)\n",
    "    for choice in response[\"choices\"]:\n",
    "        tks = [np.e**v for v in choice[\"logprobs\"][\"token_logprobs\"]]\n",
    "        tks = [(choice[\"logprobs\"][\"tokens\"][i], tks[i]) for i in range(len(tks))]\n",
    "        tokens.append(tks), probs.append(format_gpt3_probs(choice, tokenize))\n",
    "    return tokens, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = p_req(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "b = p_req_m(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "# print(sum([a_[0] for a_ in a[0][2]]))\n",
    "# print(','.join([''.join([b__[0] for b__ in b_]) for b_ in b[0]] + [''.join([a_[1] for a_ in a])]).replace('\\n', '⏎'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[(' rise', 0.00042450978577715574),\n",
       "   (' of', 0.40289209791310315),\n",
       "   (' petroleum', 0.0009587578668471675),\n",
       "   (' price', 0.054738509744018046),\n",
       "   (',', 0.7567268975926714),\n",
       "   (' prices', 0.00031616826560689756),\n",
       "   (' of', 0.32203990903992985),\n",
       "   (' all', 0.01933050037825379)],\n",
       "  [(' coupled', 0.00042894450773589814),\n",
       "   (' air', 0.0014232845713517798),\n",
       "   ('-', 0.27882255585907345),\n",
       "   ('mass', 0.059560302039432404),\n",
       "   (' oscill', 0.3562916293180838),\n",
       "   ('ations', 0.5669678946782227),\n",
       "   (',', 0.7934470269272237),\n",
       "   (' wh', 0.003764413148995526)],\n",
       "  [(' the', 0.022573785038950505),\n",
       "   (' rings', 0.002707167482804267),\n",
       "   (' around', 0.0201571684401751),\n",
       "   (' the', 0.13126393653810087),\n",
       "   (' outer', 0.004503616672517032),\n",
       "   (' planets', 0.8566074214439711),\n",
       "   (',', 0.6361421718365443),\n",
       "   (' the', 0.23771647427808573)],\n",
       "  [(' sand', 0.0028273087260213994),\n",
       "   (' d', 0.36514417623842604),\n",
       "   ('une', 0.6240810507656783),\n",
       "   (',', 0.6381218030420923),\n",
       "   (' sand', 0.033600158324009095),\n",
       "   (' waves', 0.01603063660178203),\n",
       "   (',', 0.8766577356515886),\n",
       "   (' sand', 0.10673122719460017)],\n",
       "  [(' t', 0.0031721965914564823),\n",
       "   ('ors', 0.3402063954868461),\n",
       "   ('ion', 0.481686447727795),\n",
       "   (' pend', 0.21410734019887237),\n",
       "   ('ulum', 0.9908152617734979),\n",
       "   (',', 0.8637602475046349),\n",
       "   (' t', 0.022216389427180343),\n",
       "   ('ors', 0.9262226170941882)]],\n",
       " [[(0.06018702990278039, ' runaway'),\n",
       "   (0.02751229729221121, ' and'),\n",
       "   (0.023309912026698545, ' etc'),\n",
       "   (0.022573785038950505, ' the'),\n",
       "   (0.020258070937917965, ' solar'),\n",
       "   (0.01658434667304955, ' wh'),\n",
       "   (0.01321006156466026, ' super'),\n",
       "   (0.012803172336173035, ' water'),\n",
       "   (0.010169624417868738, ' ice'),\n",
       "   (0.007602371810863707, ' thunder'),\n",
       "   (0.006645528875443971, ' self'),\n",
       "   (0.006188822107332651, ' earthquake'),\n",
       "   (0.006178410754807206, ' ocean'),\n",
       "   (0.006150517834356609, ' climate'),\n",
       "   (0.005985200740100013, ' positive'),\n",
       "   (0.005534297170593313, ' weather'),\n",
       "   (0.0053627589867327055, ' global'),\n",
       "   (0.005060426554132865, ' tornado'),\n",
       "   (0.005053069998038292, ' lightning'),\n",
       "   (0.004887208487259237, ' hurricanes'),\n",
       "   (0.004864404382132857, ' d'),\n",
       "   (0.004791192223955889, ' oscill'),\n",
       "   (0.00464956784621299, ' Brown'),\n",
       "   (0.004574112903180611, ' a'),\n",
       "   (0.0044604987136385365, ' growth'),\n",
       "   (0.004309317672690738, ' cycl'),\n",
       "   (0.004210166851028077, ' planetary'),\n",
       "   (0.003932287348072553, ' ozone'),\n",
       "   (0.0039075390582704265, ' vortex'),\n",
       "   (0.0037442374533828786, ' sun'),\n",
       "   (0.003724306943117574, ' hurricane'),\n",
       "   (0.0036849843510942146, ' whirlwind'),\n",
       "   (0.0036090972758481893, ' ball'),\n",
       "   (0.003596657273553065, ' fire'),\n",
       "   (0.003566865785608486, ' puls'),\n",
       "   (0.0035532297513123623, ' spiral'),\n",
       "   (0.0035154385366780454, ' resonance'),\n",
       "   (0.003461103881151381, ' El'),\n",
       "   (0.0033176021532296033, ' avalanche'),\n",
       "   (0.003316480993188532, ' earthquakes'),\n",
       "   (0.0031721870748809846, ' t'),\n",
       "   (0.0031363182464321003, ' thermal'),\n",
       "   (0.003101594329063176, ' rogue'),\n",
       "   (0.0030676852254727474, ' tidal'),\n",
       "   (0.0028322948354690654, ' boiling'),\n",
       "   (0.0028273087260213994, ' sand'),\n",
       "   (0.002718532680313336, ' snow'),\n",
       "   (0.002714348004793201, ' magnetic'),\n",
       "   (0.0027004820091434817, ' earth'),\n",
       "   (0.0026675442136143805, ' heat'),\n",
       "   (0.002568765103574457, ' explosion'),\n",
       "   (0.0025337293758607854, ' chaos'),\n",
       "   (0.0024750212429208358, ' qu'),\n",
       "   (0.0024528989721007873, ' chain'),\n",
       "   (0.002419633975612112, ' spinning'),\n",
       "   (0.0023950084977607, ' nuclear'),\n",
       "   (0.0023428650926705856, ' wave'),\n",
       "   (0.0023354642157947855, ' torn'),\n",
       "   (0.002255824592320779, ' forest'),\n",
       "   (0.0021781290600622963, ' feedback'),\n",
       "   (0.0021635376415480604, ' ...'),\n",
       "   (0.0021402856019458855, ' ge'),\n",
       "   (0.0021194386777572873, ' freezing'),\n",
       "   (0.0021096133388851675, ' greenhouse'),\n",
       "   (0.002097905107524908, ' conve'),\n",
       "   (0.0020876526044146817, ' jet'),\n",
       "   (0.0020627655428381844, ' formation'),\n",
       "   (0.0019833147854706017, ' atmospheric'),\n",
       "   (0.0019428284573572024, ' pend'),\n",
       "   (0.0019344459969107444, ' aut'),\n",
       "   (0.0019096648949242165, ' wind'),\n",
       "   (0.0019057569504656686, ' electric'),\n",
       "   (0.0018932141231962842, ' lunar'),\n",
       "   (0.001877023502773209, ' explosive'),\n",
       "   (0.0018263199373990803, ' whist'),\n",
       "   (0.0017752163076761279, ' ringing'),\n",
       "   (0.001753292202194887, ' black'),\n",
       "   (0.0017046900050448675, ' sol'),\n",
       "   (0.0016996447845802898, ' period'),\n",
       "   (0.0016857466459501466, ' vacuum'),\n",
       "   (0.0016459630917068724, ' tides'),\n",
       "   (0.0016425267854604513, ' death'),\n",
       "   (0.0016246359809790596, ' flash'),\n",
       "   (0.0016210762475197416, ' waves'),\n",
       "   (0.001604086248657409, ' double'),\n",
       "   (0.0015604282128047465, ' chemical'),\n",
       "   (0.0015390694475958529, ' heart'),\n",
       "   (0.0015200859494983539, ' population'),\n",
       "   (0.0015170919005436563, ' Ross'),\n",
       "   (0.0015036973556496384, ' turbulence'),\n",
       "   (0.001499576566087635, ' Earth'),\n",
       "   (0.0014837152985207381, ' f'),\n",
       "   (0.0014796563708834442, ' planet'),\n",
       "   (0.001458017999697995, ' inflation'),\n",
       "   (0.0014236963871445548, ' gy'),\n",
       "   (0.0014082408185067258, ' ring'),\n",
       "   (0.0013982623385795881, ' M'),\n",
       "   (0.0013928225210760158, ' phase'),\n",
       "   (0.0013897839160544787, ' auto'),\n",
       "   (0.0013863129639340838, ' stock')],\n",
       "  [(0.06018702990278039, ' runaway'),\n",
       "   (0.02751229729221121, ' and'),\n",
       "   (0.023309912026698545, ' etc'),\n",
       "   (0.022573785038950505, ' the'),\n",
       "   (0.020258070937917965, ' solar'),\n",
       "   (0.01658434667304955, ' wh'),\n",
       "   (0.01321006156466026, ' super'),\n",
       "   (0.012803172336173035, ' water'),\n",
       "   (0.010169624417868738, ' ice'),\n",
       "   (0.007602371810863707, ' thunder'),\n",
       "   (0.006645528875443971, ' self'),\n",
       "   (0.006188822107332651, ' earthquake'),\n",
       "   (0.006178410754807206, ' ocean'),\n",
       "   (0.006150517834356609, ' climate'),\n",
       "   (0.005985200740100013, ' positive'),\n",
       "   (0.005534297170593313, ' weather'),\n",
       "   (0.0053627589867327055, ' global'),\n",
       "   (0.005060426554132865, ' tornado'),\n",
       "   (0.005053069998038292, ' lightning'),\n",
       "   (0.004887208487259237, ' hurricanes'),\n",
       "   (0.004864404382132857, ' d'),\n",
       "   (0.004791192223955889, ' oscill'),\n",
       "   (0.00464956784621299, ' Brown'),\n",
       "   (0.004574112903180611, ' a'),\n",
       "   (0.0044604987136385365, ' growth'),\n",
       "   (0.004309317672690738, ' cycl'),\n",
       "   (0.004210166851028077, ' planetary'),\n",
       "   (0.003932287348072553, ' ozone'),\n",
       "   (0.0039075390582704265, ' vortex'),\n",
       "   (0.0037442374533828786, ' sun'),\n",
       "   (0.003724306943117574, ' hurricane'),\n",
       "   (0.0036849843510942146, ' whirlwind'),\n",
       "   (0.0036090972758481893, ' ball'),\n",
       "   (0.003596657273553065, ' fire'),\n",
       "   (0.003566865785608486, ' puls'),\n",
       "   (0.0035532297513123623, ' spiral'),\n",
       "   (0.0035154385366780454, ' resonance'),\n",
       "   (0.003461103881151381, ' El'),\n",
       "   (0.0033176021532296033, ' avalanche'),\n",
       "   (0.003316480993188532, ' earthquakes'),\n",
       "   (0.0031721870748809846, ' t'),\n",
       "   (0.0031363182464321003, ' thermal'),\n",
       "   (0.003101594329063176, ' rogue'),\n",
       "   (0.0030676852254727474, ' tidal'),\n",
       "   (0.0028322948354690654, ' boiling'),\n",
       "   (0.0028273087260213994, ' sand'),\n",
       "   (0.002718532680313336, ' snow'),\n",
       "   (0.002714348004793201, ' magnetic'),\n",
       "   (0.0027004820091434817, ' earth'),\n",
       "   (0.0026675442136143805, ' heat'),\n",
       "   (0.002568765103574457, ' explosion'),\n",
       "   (0.0025337293758607854, ' chaos'),\n",
       "   (0.0024750212429208358, ' qu'),\n",
       "   (0.0024528989721007873, ' chain'),\n",
       "   (0.002419633975612112, ' spinning'),\n",
       "   (0.0023950084977607, ' nuclear'),\n",
       "   (0.0023428650926705856, ' wave'),\n",
       "   (0.0023354642157947855, ' torn'),\n",
       "   (0.002255824592320779, ' forest'),\n",
       "   (0.0021781290600622963, ' feedback'),\n",
       "   (0.0021635376415480604, ' ...'),\n",
       "   (0.0021402856019458855, ' ge'),\n",
       "   (0.0021194386777572873, ' freezing'),\n",
       "   (0.0021096133388851675, ' greenhouse'),\n",
       "   (0.002097905107524908, ' conve'),\n",
       "   (0.0020876526044146817, ' jet'),\n",
       "   (0.0020627655428381844, ' formation'),\n",
       "   (0.0019833147854706017, ' atmospheric'),\n",
       "   (0.0019428284573572024, ' pend'),\n",
       "   (0.0019344459969107444, ' aut'),\n",
       "   (0.0019096648949242165, ' wind'),\n",
       "   (0.0019057569504656686, ' electric'),\n",
       "   (0.0018932141231962842, ' lunar'),\n",
       "   (0.001877023502773209, ' explosive'),\n",
       "   (0.0018263199373990803, ' whist'),\n",
       "   (0.0017752163076761279, ' ringing'),\n",
       "   (0.001753292202194887, ' black'),\n",
       "   (0.0017046900050448675, ' sol'),\n",
       "   (0.0016996447845802898, ' period'),\n",
       "   (0.0016857466459501466, ' vacuum'),\n",
       "   (0.0016459630917068724, ' tides'),\n",
       "   (0.0016425267854604513, ' death'),\n",
       "   (0.0016246359809790596, ' flash'),\n",
       "   (0.0016210762475197416, ' waves'),\n",
       "   (0.001604086248657409, ' double'),\n",
       "   (0.0015604282128047465, ' chemical'),\n",
       "   (0.0015390694475958529, ' heart'),\n",
       "   (0.0015200859494983539, ' population'),\n",
       "   (0.0015170919005436563, ' Ross'),\n",
       "   (0.0015036973556496384, ' turbulence'),\n",
       "   (0.001499576566087635, ' Earth'),\n",
       "   (0.0014837152985207381, ' f'),\n",
       "   (0.0014796563708834442, ' planet'),\n",
       "   (0.001458017999697995, ' inflation'),\n",
       "   (0.0014236963871445548, ' gy'),\n",
       "   (0.0014082408185067258, ' ring'),\n",
       "   (0.0013982623385795881, ' M'),\n",
       "   (0.0013928225210760158, ' phase'),\n",
       "   (0.0013897839160544787, ' auto'),\n",
       "   (0.0013863129639340838, ' stock')],\n",
       "  [(0.06018702990278039, ' runaway'),\n",
       "   (0.02751229729221121, ' and'),\n",
       "   (0.023309912026698545, ' etc'),\n",
       "   (0.022573785038950505, ' the'),\n",
       "   (0.020258070937917965, ' solar'),\n",
       "   (0.01658434667304955, ' wh'),\n",
       "   (0.01321006156466026, ' super'),\n",
       "   (0.012803172336173035, ' water'),\n",
       "   (0.010169624417868738, ' ice'),\n",
       "   (0.007602371810863707, ' thunder'),\n",
       "   (0.006645528875443971, ' self'),\n",
       "   (0.006188822107332651, ' earthquake'),\n",
       "   (0.006178410754807206, ' ocean'),\n",
       "   (0.006150517834356609, ' climate'),\n",
       "   (0.005985200740100013, ' positive'),\n",
       "   (0.005534297170593313, ' weather'),\n",
       "   (0.0053627589867327055, ' global'),\n",
       "   (0.005060426554132865, ' tornado'),\n",
       "   (0.005053069998038292, ' lightning'),\n",
       "   (0.004887208487259237, ' hurricanes'),\n",
       "   (0.004864404382132857, ' d'),\n",
       "   (0.004791192223955889, ' oscill'),\n",
       "   (0.00464956784621299, ' Brown'),\n",
       "   (0.004574112903180611, ' a'),\n",
       "   (0.0044604987136385365, ' growth'),\n",
       "   (0.004309317672690738, ' cycl'),\n",
       "   (0.004210166851028077, ' planetary'),\n",
       "   (0.003932287348072553, ' ozone'),\n",
       "   (0.0039075390582704265, ' vortex'),\n",
       "   (0.0037442374533828786, ' sun'),\n",
       "   (0.003724306943117574, ' hurricane'),\n",
       "   (0.0036849843510942146, ' whirlwind'),\n",
       "   (0.0036090972758481893, ' ball'),\n",
       "   (0.003596657273553065, ' fire'),\n",
       "   (0.003566865785608486, ' puls'),\n",
       "   (0.0035532297513123623, ' spiral'),\n",
       "   (0.0035154385366780454, ' resonance'),\n",
       "   (0.003461103881151381, ' El'),\n",
       "   (0.0033176021532296033, ' avalanche'),\n",
       "   (0.003316480993188532, ' earthquakes'),\n",
       "   (0.0031721870748809846, ' t'),\n",
       "   (0.0031363182464321003, ' thermal'),\n",
       "   (0.003101594329063176, ' rogue'),\n",
       "   (0.0030676852254727474, ' tidal'),\n",
       "   (0.0028322948354690654, ' boiling'),\n",
       "   (0.0028273087260213994, ' sand'),\n",
       "   (0.002718532680313336, ' snow'),\n",
       "   (0.002714348004793201, ' magnetic'),\n",
       "   (0.0027004820091434817, ' earth'),\n",
       "   (0.0026675442136143805, ' heat'),\n",
       "   (0.002568765103574457, ' explosion'),\n",
       "   (0.0025337293758607854, ' chaos'),\n",
       "   (0.0024750212429208358, ' qu'),\n",
       "   (0.0024528989721007873, ' chain'),\n",
       "   (0.002419633975612112, ' spinning'),\n",
       "   (0.0023950084977607, ' nuclear'),\n",
       "   (0.0023428650926705856, ' wave'),\n",
       "   (0.0023354642157947855, ' torn'),\n",
       "   (0.002255824592320779, ' forest'),\n",
       "   (0.0021781290600622963, ' feedback'),\n",
       "   (0.0021635376415480604, ' ...'),\n",
       "   (0.0021402856019458855, ' ge'),\n",
       "   (0.0021194386777572873, ' freezing'),\n",
       "   (0.0021096133388851675, ' greenhouse'),\n",
       "   (0.002097905107524908, ' conve'),\n",
       "   (0.0020876526044146817, ' jet'),\n",
       "   (0.0020627655428381844, ' formation'),\n",
       "   (0.0019833147854706017, ' atmospheric'),\n",
       "   (0.0019428284573572024, ' pend'),\n",
       "   (0.0019344459969107444, ' aut'),\n",
       "   (0.0019096648949242165, ' wind'),\n",
       "   (0.0019057569504656686, ' electric'),\n",
       "   (0.0018932141231962842, ' lunar'),\n",
       "   (0.001877023502773209, ' explosive'),\n",
       "   (0.0018263199373990803, ' whist'),\n",
       "   (0.0017752163076761279, ' ringing'),\n",
       "   (0.001753292202194887, ' black'),\n",
       "   (0.0017046900050448675, ' sol'),\n",
       "   (0.0016996447845802898, ' period'),\n",
       "   (0.0016857466459501466, ' vacuum'),\n",
       "   (0.0016459630917068724, ' tides'),\n",
       "   (0.0016425267854604513, ' death'),\n",
       "   (0.0016246359809790596, ' flash'),\n",
       "   (0.0016210762475197416, ' waves'),\n",
       "   (0.001604086248657409, ' double'),\n",
       "   (0.0015604282128047465, ' chemical'),\n",
       "   (0.0015390694475958529, ' heart'),\n",
       "   (0.0015200859494983539, ' population'),\n",
       "   (0.0015170919005436563, ' Ross'),\n",
       "   (0.0015036973556496384, ' turbulence'),\n",
       "   (0.001499576566087635, ' Earth'),\n",
       "   (0.0014837152985207381, ' f'),\n",
       "   (0.0014796563708834442, ' planet'),\n",
       "   (0.001458017999697995, ' inflation'),\n",
       "   (0.0014236963871445548, ' gy'),\n",
       "   (0.0014082408185067258, ' ring'),\n",
       "   (0.0013982623385795881, ' M'),\n",
       "   (0.0013928225210760158, ' phase'),\n",
       "   (0.0013897839160544787, ' auto'),\n",
       "   (0.0013863129639340838, ' stock')],\n",
       "  [(0.06018702990278039, ' runaway'),\n",
       "   (0.02751229729221121, ' and'),\n",
       "   (0.023309912026698545, ' etc'),\n",
       "   (0.022573785038950505, ' the'),\n",
       "   (0.020258070937917965, ' solar'),\n",
       "   (0.01658434667304955, ' wh'),\n",
       "   (0.01321006156466026, ' super'),\n",
       "   (0.012803172336173035, ' water'),\n",
       "   (0.010169624417868738, ' ice'),\n",
       "   (0.007602371810863707, ' thunder'),\n",
       "   (0.006645528875443971, ' self'),\n",
       "   (0.006188822107332651, ' earthquake'),\n",
       "   (0.006178410754807206, ' ocean'),\n",
       "   (0.006150517834356609, ' climate'),\n",
       "   (0.005985200740100013, ' positive'),\n",
       "   (0.005534297170593313, ' weather'),\n",
       "   (0.0053627589867327055, ' global'),\n",
       "   (0.005060407324548496, ' tornado'),\n",
       "   (0.005053069998038292, ' lightning'),\n",
       "   (0.004887186983589202, ' hurricanes'),\n",
       "   (0.004864404382132857, ' d'),\n",
       "   (0.00479119701515051, ' oscill'),\n",
       "   (0.00464956784621299, ' Brown'),\n",
       "   (0.004574112903180611, ' a'),\n",
       "   (0.0044604987136385365, ' growth'),\n",
       "   (0.004309317672690738, ' cycl'),\n",
       "   (0.004210166851028077, ' planetary'),\n",
       "   (0.0039322940329667285, ' ozone'),\n",
       "   (0.003907548827130286, ' vortex'),\n",
       "   (0.0037442374533828786, ' sun'),\n",
       "   (0.003724306943117574, ' hurricane'),\n",
       "   (0.0036849843510942146, ' whirlwind'),\n",
       "   (0.0036090972758481893, ' ball'),\n",
       "   (0.003596657273553065, ' fire'),\n",
       "   (0.003566865785608486, ' puls'),\n",
       "   (0.0035532297513123623, ' spiral'),\n",
       "   (0.0035154385366780454, ' resonance'),\n",
       "   (0.003461103881151381, ' El'),\n",
       "   (0.0033176021532296033, ' avalanche'),\n",
       "   (0.003316487626157152, ' earthquakes'),\n",
       "   (0.0031721870748809846, ' t'),\n",
       "   (0.0031363182464321003, ' thermal'),\n",
       "   (0.003101594329063176, ' rogue'),\n",
       "   (0.0030676852254727474, ' tidal'),\n",
       "   (0.0028322948354690654, ' boiling'),\n",
       "   (0.0028273087260213994, ' sand'),\n",
       "   (0.002718532680313336, ' snow'),\n",
       "   (0.002714348004793201, ' magnetic'),\n",
       "   (0.0027004820091434817, ' earth'),\n",
       "   (0.0026675442136143805, ' heat'),\n",
       "   (0.002568765103574457, ' explosion'),\n",
       "   (0.0025337293758607854, ' chaos'),\n",
       "   (0.0024750212429208358, ' qu'),\n",
       "   (0.0024528989721007873, ' chain'),\n",
       "   (0.002419633975612112, ' spinning'),\n",
       "   (0.0023950084977607, ' nuclear'),\n",
       "   (0.0023428650926705856, ' wave'),\n",
       "   (0.0023354642157947855, ' torn'),\n",
       "   (0.002255824592320779, ' forest'),\n",
       "   (0.0021781290600622963, ' feedback'),\n",
       "   (0.0021635376415480604, ' ...'),\n",
       "   (0.0021402856019458855, ' ge'),\n",
       "   (0.0021194386777572873, ' freezing'),\n",
       "   (0.0021096133388851675, ' greenhouse'),\n",
       "   (0.002097908673966621, ' conve'),\n",
       "   (0.0020876526044146817, ' jet'),\n",
       "   (0.0020627655428381844, ' formation'),\n",
       "   (0.0019833147854706017, ' atmospheric'),\n",
       "   (0.001942822046033871, ' pend'),\n",
       "   (0.0019344459969107444, ' aut'),\n",
       "   (0.0019096648949242165, ' wind'),\n",
       "   (0.0019057569504656686, ' electric'),\n",
       "   (0.0018932141231962842, ' lunar'),\n",
       "   (0.001877023502773209, ' explosive'),\n",
       "   (0.001826323407410258, ' whist'),\n",
       "   (0.0017752180828933233, ' ringing'),\n",
       "   (0.001753292202194887, ' black'),\n",
       "   (0.0017046900050448675, ' sol'),\n",
       "   (0.0016996447845802898, ' period'),\n",
       "   (0.0016857466459501466, ' vacuum'),\n",
       "   (0.0016459630917068724, ' tides'),\n",
       "   (0.0016425267854604513, ' death'),\n",
       "   (0.0016246359809790596, ' flash'),\n",
       "   (0.0016210762475197416, ' waves'),\n",
       "   (0.001604086248657409, ' double'),\n",
       "   (0.0015604282128047465, ' chemical'),\n",
       "   (0.0015390694475958529, ' heart'),\n",
       "   (0.0015200859494983539, ' population'),\n",
       "   (0.0015170919005436563, ' Ross'),\n",
       "   (0.001503700814157534, ' turbulence'),\n",
       "   (0.001499576566087635, ' Earth'),\n",
       "   (0.0014837152985207381, ' f'),\n",
       "   (0.0014796563708834442, ' planet'),\n",
       "   (0.001458017999697995, ' inflation'),\n",
       "   (0.0014236963871445548, ' gy'),\n",
       "   (0.0014082408185067258, ' ring'),\n",
       "   (0.0013982623385795881, ' M'),\n",
       "   (0.0013928225210760158, ' phase'),\n",
       "   (0.0013897839160544787, ' auto'),\n",
       "   (0.0013863129639340838, ' stock')],\n",
       "  [(0.06018702990278039, ' runaway'),\n",
       "   (0.02751224777012065, ' and'),\n",
       "   (0.02330995631557347, ' etc'),\n",
       "   (0.02257379406846633, ' the'),\n",
       "   (0.02025799598319416, ' solar'),\n",
       "   (0.01658434667304955, ' wh'),\n",
       "   (0.013210041749582777, ' super'),\n",
       "   (0.012803172336173035, ' water'),\n",
       "   (0.010169624417868738, ' ice'),\n",
       "   (0.007602354325428648, ' thunder'),\n",
       "   (0.006645531533656049, ' self'),\n",
       "   (0.006188822107332651, ' earthquake'),\n",
       "   (0.0061783872768909455, ' ocean'),\n",
       "   (0.006150517834356609, ' climate'),\n",
       "   (0.0059852031341807894, ' positive'),\n",
       "   (0.005534289976011667, ' weather'),\n",
       "   (0.0053627589867327055, ' global'),\n",
       "   (0.005060408842670921, ' tornado'),\n",
       "   (0.005053057870684851, ' lightning'),\n",
       "   (0.004887188938464383, ' hurricanes'),\n",
       "   (0.0048644141109513515, ' d'),\n",
       "   (0.00479119701515051, ' oscill'),\n",
       "   (0.0046495692410835525, ' Brown'),\n",
       "   (0.004574106042016403, ' a'),\n",
       "   (0.004460492914993978, ' growth'),\n",
       "   (0.004309320689214165, ' cycl'),\n",
       "   (0.004210166851028077, ' planetary'),\n",
       "   (0.0039322940329667285, ' ozone'),\n",
       "   (0.003907548827130286, ' vortex'),\n",
       "   (0.0037442310881846204, ' sun'),\n",
       "   (0.00372431625389657, ' hurricane'),\n",
       "   (0.0036849880360804088, ' whirlwind'),\n",
       "   (0.0036090972758481893, ' ball'),\n",
       "   (0.0035966608702121374, ' fire'),\n",
       "   (0.003566865785608486, ' puls'),\n",
       "   (0.0035532297513123623, ' spiral'),\n",
       "   (0.003515440645941803, ' resonance'),\n",
       "   (0.003461103881151381, ' El'),\n",
       "   (0.0033176021532296033, ' avalanche'),\n",
       "   (0.003316490942646437, ' earthquakes'),\n",
       "   (0.0031721965914564823, ' t'),\n",
       "   (0.003136325773604926, ' thermal'),\n",
       "   (0.003101596190020334, ' rogue'),\n",
       "   (0.0030676852254727474, ' tidal'),\n",
       "   (0.0028322948354690654, ' boiling'),\n",
       "   (0.00282730165775842, ' sand'),\n",
       "   (0.002718527243253414, ' snow'),\n",
       "   (0.0027143412189316717, ' magnetic'),\n",
       "   (0.002700486599966798, ' earth'),\n",
       "   (0.0026675442136143805, ' heat'),\n",
       "   (0.002568759966049389, ' explosion'),\n",
       "   (0.002533723041545264, ' chaos'),\n",
       "   (0.0024750259454656646, ' qu'),\n",
       "   (0.0024529048590653858, ' chain'),\n",
       "   (0.0024196291363489993, ' spinning'),\n",
       "   (0.0023950192753231896, ' nuclear'),\n",
       "   (0.002342869075544629, ' wave'),\n",
       "   (0.0023354642157947855, ' torn'),\n",
       "   (0.002255828427225846, ' forest'),\n",
       "   (0.0021781329806981322, ' feedback'),\n",
       "   (0.0021635376415480604, ' ...'),\n",
       "   (0.0021402898825213703, ' ge'),\n",
       "   (0.0021194386777572873, ' freezing'),\n",
       "   (0.0021096133388851675, ' greenhouse'),\n",
       "   (0.002097908673966621, ' conve'),\n",
       "   (0.0020876567797240664, ' jet'),\n",
       "   (0.0020627655428381844, ' formation'),\n",
       "   (0.0019833147854706017, ' atmospheric'),\n",
       "   (0.001942822046033871, ' pend'),\n",
       "   (0.0019344440624657145, ' aut'),\n",
       "   (0.0019096648949242165, ' wind'),\n",
       "   (0.0019057540918323874, ' electric'),\n",
       "   (0.0018932141231962842, ' lunar'),\n",
       "   (0.001877023502773209, ' explosive'),\n",
       "   (0.001826325051102064, ' whist'),\n",
       "   (0.0017752193255464166, ' ringing'),\n",
       "   (0.001753297462079384, ' black'),\n",
       "   (0.0017046900050448675, ' sol'),\n",
       "   (0.0016996413852941193, ' period'),\n",
       "   (0.0016857434430345621, ' vacuum'),\n",
       "   (0.0016459647376707875, ' tides'),\n",
       "   (0.0016425267854604513, ' death'),\n",
       "   (0.0016246359809790596, ' flash'),\n",
       "   (0.0016210762475197416, ' waves'),\n",
       "   (0.0016040830404881207, ' double'),\n",
       "   (0.0015604282128047465, ' chemical'),\n",
       "   (0.0015390723718305814, ' heart'),\n",
       "   (0.0015200804771987868, ' population'),\n",
       "   (0.0015170919005436563, ' Ross'),\n",
       "   (0.001503700814157534, ' turbulence'),\n",
       "   (0.001499574316724473, ' Earth'),\n",
       "   (0.001483718265954303, ' f'),\n",
       "   (0.001479659922062995, ' planet'),\n",
       "   (0.0014580207699348262, ' inflation'),\n",
       "   (0.0014236998040199837, ' gy'),\n",
       "   (0.0014082436349911786, ' ring'),\n",
       "   (0.001398263736842626, ' M'),\n",
       "   (0.0013928225210760158, ' phase'),\n",
       "   (0.0013897866956250908, ' auto'),\n",
       "   (0.0013863155979312175, ' stock')]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a completion distribution (top 100) and target next token distribution (multinomial) and computes the\n",
    "# probability that the completion produces a desired output token\n",
    "def prob_corr(pred_p, target_p):\n",
    "    r = 0\n",
    "    if isinstance(pred_p, list):\n",
    "        for (p, token) in pred_p:\n",
    "            if target_p[token] > (lidstone_value + 1e-10): r += p\n",
    "    else:\n",
    "        r = np.sum(target_p[np.nonzero(pred_p > (lidstone_value + 1e-10))[0]])\n",
    "    return r\n",
    "# directly computes the similarity between target and predicted token distributions\n",
    "def score_corr(pred_p, target_p, distance=\"cross-entropy\", redistribute_mass=False, include_negatives=False):  \n",
    "    r = 0\n",
    "    if isinstance(pred_p, list) and not redistribute_mass:\n",
    "        for (p, token) in pred_p:\n",
    "            targ = target_p[token]\n",
    "            if targ > (lidstone_value + 1e-10) or include_negatives:\n",
    "                if   distance == \"unnormalized\":  r -= p * targ\n",
    "                elif distance == \"cross-entropy\": r -= p * np.log(targ)\n",
    "                elif distance == \"kl-divergence\": r += p * np.log(p / targ)\n",
    "                elif distance == \"bhattacharyya\": r += np.sqrt(p * targ)\n",
    "        if distance == \"bhattacharyya\": r = -np.log(r)\n",
    "    else:\n",
    "        p = pred_p\n",
    "        if isinstance(pred_p, list):\n",
    "            p_ = np.asarray([p for (p, _) in pred_p])\n",
    "            ts = np.asarray([t for (_, t) in pred_p])\n",
    "            unaccounted_mass = 1.0 - sum(p_)\n",
    "            n_missing_tokens = N_tokens - len(pred_p)\n",
    "            p = np.repeat(unaccounted_mass / n_missing_tokens, N_tokens)\n",
    "            p[ts] = p_\n",
    "        if not include_negatives:\n",
    "            pos = np.nonzero(target_p > (lidstone_value + 1e-10))[0]\n",
    "            p, target_p = p[pos], target_p[pos]\n",
    "        if   distance == \"unnormalized\":  r = -np.sum(p * targ)\n",
    "        elif distance == \"cross-entropy\": r = -np.sum(p * np.log(target_p))\n",
    "        elif distance == \"kl-divergence\": r =  np.sum(p * np.log(p / target_p))\n",
    "        elif distance == \"bhattacharyya\": r = -np.log(np.sum(np.sqrt(p * target_p)))\n",
    "    return -r\n",
    "# probability that a completion phrase is a desired missing list entry\n",
    "def prob_msp(outs, missing):\n",
    "    correct = 0\n",
    "    missing = set([phrase.lower() for phrase in missing])\n",
    "    for i in range(len(outs)):\n",
    "        out = outs[i].strip().lower()\n",
    "        if out not in missing and (out[:4] == 'the '): out = out[4:]\n",
    "        if out in missing: correct += 1\n",
    "    return correct / len(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   'Fermi-Pasta-Ulam problem,',\n",
      "        array([   37,  7780,    72,    12, 34533,    64,    12,    52,  2543,\n",
      "        1917,    11], dtype=int64),\n",
      "        11),\n",
      "    (   'maccheroncini di campofilone,',\n",
      "        array([20285,  2044,   261,    66,  5362,  2566,  1413,  1659,   346,\n",
      "         505,    11], dtype=int64),\n",
      "        11)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = sum([[len(p[:-1]) for p in p_ if len(p) < 1000] for p_ in phrases_e], [])# Print longest list elements in dataset, get max\n",
    "phrs = sum([[p[:-1] for p in p_ if len(p) < 1000] for p_ in phrases_e], [])\n",
    "m = np.max(lens)\n",
    "inds = [i for i in range(len(phrs)) if lens[i] == m]\n",
    "ree = [(tokenizer.decode(phrs[i].cpu().detach().numpy()), phrs[i].cpu().detach().numpy(), lens[i]) for i in inds]\n",
    "phrl_max = len(ree[0][1]) - 1\n",
    "pr(ree)\n",
    "phrl_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes sampling parameters, then generates n random incomplete list prompts (of length l), obtains completion\n",
    "# distributions (top 100 tokens or full multinomial) and evaluates the average score across the n prompts. n = 20 by default\n",
    "# All samples generated are stored fully for later training of sample-dependent sampling parameter (mixture) distribution\n",
    "sps_ = [\"top_p\", \"temperature\", \"presence_penalty\", \"frequency_penalty\"]  # sampling params                          #top_k\n",
    "msps_= [\"best_of\"] + sps_                                                 # meta sampling params\n",
    "create_folder(data_dir + learning_data_dir)\n",
    "create_folder(data_dir + learning_data_dir + \"sp_samples\")\n",
    "create_folder(data_dir + learning_data_dir + \"sp_samples_test\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_samples_nb\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_samples_nb_test\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_single_samples\")\n",
    "phaseIx = lambda phase: globals()[phase + '_idx']\n",
    "def save_modeloutput(idx, dname, pnames, params, r, min_l, max_l, mdl, xs=None, ys=None, sqlens=None, inds=None, d=None):\n",
    "    engine_str = ','.join([str(params[k]) for k in [\"engine\", \"model\"] if k in params])\n",
    "    for i_raw in range(len(idx)):\n",
    "        i = idx[i_raw]\n",
    "        create_folder(data_dir + learning_data_dir + dname + \"/\" + str(i))\n",
    "        ix, mdl_name = np.nonzero(inds == i_raw)[0], mdl if isinstance(mdl, str) else mdl[\"name\"]\n",
    "        fn = str(time.time()) + '_' + '_'.join([str(v) for v in [params[k] for k in pnames] + [min_l, max_l]]) + '_' + mdl_name\n",
    "        input_data = [d[j] for j in ix] if d else [xs[ix], ys[ix], sqlens[ix]]\n",
    "        save_ld((params, input_data, ix, [r[j] for j in ix], str(mdl)), dname + \"/\" + str(i) + \"/\" + fn, compress=9)\n",
    "def eval_sp(params, min_l=0, max_l=1e9, n=20, prmt=None, phase=\"train\", uniform=True, mdl='gpt3'):\n",
    "    res, max_l = [], int(max_l)\n",
    "    tknzr = gpt3_tokenizer if mdl == \"gpt3\" else tokenizer\n",
    "    xcp, xcs, xp = phase_listsets[\"gpt3\" if mdl == \"gpt3\" else \"default\"][phase]\n",
    "    xs, ys, sqlens, inds = gen_samples_uniform(xcp, xcs, xp, n, prompt=prmt, tknzr=tknzr, inds=True, rng=[min_l, max_l]) \\\n",
    "           if uniform else gen_samples        (xcp, xcs, xp, n, prompt=prmt, tknzr=tknzr, inds=True, rng=[min_l, max_l])\n",
    "    if mdl == 'gpt3': r = [p_req(gpt3_tokenizer.decode(x_.detach().cpu().numpy()), **params) for x_ in xs] \n",
    "    else:             r = mdl[\"probabilities\"](xs, ys, sqlens, **params)\n",
    "    save_modeloutput(phaseIx[phase][np.unique(inds)], \"sp_samples\", sps_, params, r, min_l, max_l, mdl, xs, ys, sqlens, inds)\n",
    "    return np.mean([score_corr(r[i], ys[i]) for i in range(len(r))])\n",
    "def eval_sp_conv(params, tol=0.01, **kwargs):\n",
    "    center, samples = np.inf, []\n",
    "    while True:\n",
    "        samples.append(eval_sp(params, n=2, **kwargs))\n",
    "        new_center = np.mean(samples)\n",
    "        if abs(center - new_center) < tol: return new_center, samples\n",
    "        new_center = center\n",
    "# This metric differs depending on tokenisation, so for the testing of models, a full phrase accuracy function is required\n",
    "def gen_phraselevel_samples_uniform(phase, min_l, max_l, n, prmt, ra=False):\n",
    "    xcp, xcs, xp = phase_listsets[None][phase]\n",
    "    d, (prmts, cats, ps, _) = [], gen_listnames_uniform(xcp, xcs, xp, n, prompt=prmt, tknzr=None)\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen, p = [], [], [], ps[i]\n",
    "        for m in range(n):\n",
    "            prompt, cat = prmts[i][m], cats[i][m]\n",
    "            phr_ix, phr_incl = [], []\n",
    "            while len(phr_ix) < 1:\n",
    "                phr_ix = np.random.choice(len(p), np.random.randint(min_l, min(max_l, len(p) - 1)), replace=False)\n",
    "                if use_max_plog:\n",
    "                    phr_ra = [j for j in range(len(p)) if phrase_log_incl[p[j]]]\n",
    "                    phr_incl = [j for j in range(len(p)) if j not in phr_ra]\n",
    "                    phr_ix = [i for i in phr_ix if i in phr_incl]\n",
    "            missing_ix= [k for k in range(len(p)) if (k not in phr_ix)and(True if (ra or not use_max_plog) else k in phr_incl)]\n",
    "            prompt = (prompt + ' ' + cat + ': ' + ''.join([p[j] + ', ' for j in phr_ix]))[:-1]\n",
    "            d.append([prompt, [p[j] for j in missing_ix]])\n",
    "    return d, np.arange(len(xcp)).repeat(n)\n",
    "strip_the = lambda x: x[4:] if x.lower()[:4] == 'the ' else x\n",
    "strip_tl = lambda x: strip_the(x.strip().lower())\n",
    "strip_comma = lambda x: [x_.strip() for x_ in (x[:-1] if len(x) > 1 else x)]\n",
    "strip_lower = lambda x: [strip_tl(x_) for x_ in (x[:-1] if len(x) > 1 else x)]\n",
    "def ensemble_two_models_results(m2ensemble_frac, r, r2):\n",
    "    bof = len(r[0])\n",
    "    n_replace = int(bof * m2ensemble_frac)\n",
    "    r_new = [[strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_] for r_ in r]\n",
    "    for i in range(len(r)):\n",
    "        cur_pool = set(sum([strip_lower(''.join([r__[0] for r__ in r_]).split(',')) for r_ in r[i][:bof - n_replace]], []))\n",
    "        new_pool = sum([strip_comma(''.join([r__[0] for r__ in r_]).split(',')) for r_ in r2[i]], [])\n",
    "        for j in range(n_replace):\n",
    "            n_phrases = len(r[i][j])\n",
    "            add = []\n",
    "            while len(add) < n_phrases and len(new_pool) > 0:\n",
    "                new_phr = new_pool[0]\n",
    "                stripped_new_phr = strip_tl(new_phr)\n",
    "                if stripped_new_phr not in cur_pool:\n",
    "                    add.append(new_phr), cur_pool.add(stripped_new_phr)\n",
    "                new_pool = new_pool[1:]\n",
    "            if len(add) > 0:\n",
    "                r_new[i][j + bof - n_replace] = add\n",
    "    return [sum(r_, []) for r_ in r_new]\n",
    "def test_sp(params, min_l=0, max_l=1e9, n1=3, n2=10, prmt=None, phase=\"train\", uniform=True, max_tokens=phrl_max,\n",
    "            mdl='gpt3', mdl2=None, d=None, d_test=None, inds=None, inds_test=None, m2ensemble_frac=0.4, return_test_acc=False):\n",
    "    max_l, test_acc, dn = int(max_l), None, \"msp_samples_nb\"\n",
    "    if d is None: d, inds = gen_phraselevel_samples_uniform(phase, min_l, max_l, n1, prmt)\n",
    "    params = {**default_sp, **params, **{'n': n2, 'max_tokens': max_tokens}} #**default_msp,\n",
    "    if mdl == 'gpt3': r = [p_req_m(d_[0], **params)[0] for d_ in d]  # Request predictions from OpenAI\n",
    "    else:             r = mdl[\"completions\"]([d_[0] for d_ in d], **params)\n",
    "    save_modeloutput(phaseIx(phase), dn, msps_, params, r, min_l, max_l, mdl, d=d, inds=inds)\n",
    "    if mdl2 is not None:\n",
    "        if mdl2 == 'gpt3': r2 = [p_req_m(d_[0], **params)[0] for d_ in d]# Ensemble with 2nd model according to m2ensemble_frac\n",
    "        else:              r2 = mdl2[\"completions\"]([d_[0] for d_ in d], **params)# This loads precomputed outputs so no resave\n",
    "        r = ensemble_two_models_results(m2ensemble_frac, r, r2)\n",
    "    else:\n",
    "        r = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_], []) for r_ in r]\n",
    "    #     r = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(','))[:max_l - min_l] for r__ in r_], []) for r_ in r]\n",
    "    acc = np.mean([prob_msp(r[i], d[i][1]) for i in range(len(r))])\n",
    "\n",
    "#     if phase != \"test\":  # if not testing finalised parameters, also output the test set accuracy\n",
    "#         listset_fracs = {\"train\": 1 - (val_frac + test_frac), \"trval\": 1 - test_frac, \"val\": val_frac, \"test\": test_frac}\n",
    "#         n1_ = n1 * int(listset_fracs[phase] / test_frac)  # Use approximately enough samples to converge\n",
    "#         if d_test is None: d_test, inds_test = gen_phraselevel_samples_uniform(\"test\", min_l, max_l, n1_, prmt)\n",
    "#         if mdl == 'gpt3': r_test = [p_req_m(d_[0], **params)[0] for d_ in d_test]\n",
    "#         else:             r_test = mdl[\"completions\"]([d_[0] for d_ in d_test], **params)\n",
    "#         save_modeloutput(phaseIx(\"test\"), dn+\"_test\", msps_, params, r_test, min_l, max_l, mdl, d=d_test, inds=inds_test)\n",
    "#         if mdl2 is not None:\n",
    "#             if mdl2 == 'gpt3': r2_test = [p_req_m(d_[0], **params)[0] for d_ in d_test]\n",
    "#             else:              r2_test = mdl2[\"completions\"]([d_[0] for d_ in d_test], **params)\n",
    "#             r_test = ensemble_two_models_results(m2ensemble_frac, r_test, r2_test)\n",
    "#         else:\n",
    "#             r_test = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_], []) for r_ in r_test]\n",
    "# #r_test =[sum([strip_comma(''.join([r___[0] for r___ in r__]).split(','))[:max_l - min_l] for r__ in r_], []) for r_ in r_test]\n",
    "#         samps = np.asarray([prob_msp(r_test[i], d_test[i][1]) for i in range(len(r_test))])\n",
    "#         test_sd = np.std(100*samps)\n",
    "#         test_acc = np.mean(samps)\n",
    "#         if not return_test_acc:\n",
    "#             print(\"Test acc:\", 100*test_acc, \"sd:\", test_sd)\n",
    "\n",
    "    return (acc, test_acc) if return_test_acc else (acc, None)\n",
    "def test_sp_conv(params, tol=0.01, **kwargs):\n",
    "    center, ys, i, steps_nochange = np.inf, [], 1, 0\n",
    "    while True:\n",
    "        ys.append(test_sp(params, n1=1, **kwargs))\n",
    "        new_center = np.mean([s[0] for s in ys])\n",
    "        if abs(center - new_center) < tol: steps_nochange += 1\n",
    "        else:                              steps_nochange = 0\n",
    "        if steps_nochange >= 3 and i >= 5:\n",
    "            if ys[0][1] is not None: print([s[1] for s in ys])\n",
    "            print([s[0] for s in ys])\n",
    "            j = 1 if ys[0][1] is not None else 0\n",
    "            sys_print(str((\"Test acc:\", 100 * np.mean([s[j] for s in ys]), \"sd:\", np.std([100*s[j] for s in ys])))+\"\\n\", False)\n",
    "            return new_center, ys\n",
    "        center = new_center\n",
    "        i += 1\n",
    "# eval_sp(default_ps)\n",
    "valtest_idx = np.asarray([i for i in range(N_wordlists) if i not in train_idx])\n",
    "phase_listsets[None][\"valtest\"] = index_listset(valtest_idx, (cats, cats_sing, phrases))\n",
    "curr_phase = \"valtest\"\n",
    "curr_sing_ix = np.zeros(len(globals()[curr_phase + \"_idx\"]), dtype=int)\n",
    "# curr_sing_ix[[np.where(valtest_idx == 8)[0][0], np.where(valtest_idx == 11)[0][0], np.where(valtest_idx == 19)[0][0]]] = 1\n",
    "def test_sp_single(params, min_l=0, max_l=1e9, n=10, prmt=None, phase=curr_phase, max_tokens=phrl_max, mdl='gpt3', tol=0.001,\n",
    "                   ra=False):\n",
    "    global single_phase_idx, curr_sing_ix\n",
    "    params = {**default_sp, **params, **{'n': n, 'max_tokens': max_tokens}}\n",
    "    xcp, xcs, xp = phase_listsets[None][phase]\n",
    "    i = stac_sample(curr_sing_ix, 1)[0]\n",
    "#     i = np.random.randint(len(xcp))\n",
    "    orig_i = phaseIx(phase)[i]\n",
    "    \n",
    "    # generate the sample, iterate until steps no change is > 5, saving all results using save_modeloutput\n",
    "    cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "    cp_cs = cp + cs\n",
    "    cat, prompt = gen_listname(cp, cp_cs, prmt, prmt, tknzr=None)\n",
    "    phr_ix, phr_incl = [], []\n",
    "    while len(phr_ix) < 1:\n",
    "        phr_ix = np.random.choice(len(p), np.random.randint(min_l, min(max_l, len(p) - 1)), replace=False)\n",
    "        if use_max_plog:\n",
    "            phr_ra = [j for j in range(len(p)) if phrase_log_incl[p[j]]]\n",
    "            phr_incl = [j for j in range(len(p)) if j not in phr_ra]\n",
    "            phr_ix = [i for i in phr_ix if i in phr_incl]\n",
    "    missing_ix = [k for k in range(len(p)) if (k not in phr_ix) and (True if (ra or not use_max_plog) else k in phr_incl)]\n",
    "    prompt = (prompt + ' ' + cat + ': ' + ''.join([p[j] + ', ' for j in phr_ix]))[:-1]\n",
    "    d = [[prompt, [p[j] for j in missing_ix]]]\n",
    "\n",
    "    center, res, accs, i, steps_nochange = np.inf, [], [], 1, 0\n",
    "    while True:\n",
    "        r_full = p_req_m(prompt, **params)\n",
    "        r = sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_full[0]], [])\n",
    "        acc = prob_msp(r,  [0][1])\n",
    "        res.append(r_full), accs.append(acc)\n",
    "        new_center = np.mean(accs)\n",
    "        if abs(center - new_center) < tol: steps_nochange += 1\n",
    "        else:                              steps_nochange = 0\n",
    "        center = new_center\n",
    "        if steps_nochange >= 5:\n",
    "            print(str(steps_nochange) + \" steps no change, i=\" + str(i) + \" acc = \" + str(center))\n",
    "            if i >= 15:\n",
    "                break\n",
    "        i += 1\n",
    "\n",
    "    n_samples = len(res)\n",
    "    save_modeloutput([orig_i], \"msp_single_samples\", msps_, params,\n",
    "                     res, min_l, max_l, mdl, d=d * n_samples, inds=np.array([0] * n_samples))\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 steps no change, i=6 acc = 0.0\n",
      "6 steps no change, i=7 acc = 0.0\n",
      "7 steps no change, i=8 acc = 0.0\n",
      "8 steps no change, i=9 acc = 0.0\n",
      "9 steps no change, i=10 acc = 0.0\n",
      "10 steps no change, i=11 acc = 0.0\n",
      "11 steps no change, i=12 acc = 0.0\n",
      "12 steps no change, i=13 acc = 0.0\n",
      "13 steps no change, i=14 acc = 0.0\n",
      "14 steps no change, i=15 acc = 0.0\n",
      "0.0 {'temperature': 1.5765058106102432, 'top_p': 0.06691747647547715, 'presence_penalty': 0.5572923965563303, 'frequency_penalty': 0.6475540099947565, 'best_of': 3.2744372132224795}\n",
      "5 steps no change, i=16 acc = 0.11587301587301588\n",
      "0.11587301587301588 {'temperature': 1.491610361391296, 'top_p': 0.6296397305786852, 'presence_penalty': 1.0171489868550327, 'frequency_penalty': 1.490694595989845, 'best_of': 4.636871578714766}\n",
      "5 steps no change, i=8 acc = 0.0492296918767507\n",
      "5 steps no change, i=15 acc = 0.06197012138188608\n",
      "0.06197012138188608 {'temperature': 1.3284938330305758, 'top_p': 0.4489318877690332, 'presence_penalty': 1.9403679245767413, 'frequency_penalty': 0.5572170319786667, 'best_of': 6.6703860146045875}\n",
      "5 steps no change, i=6 acc = 0.0\n",
      "6 steps no change, i=7 acc = 0.0\n",
      "7 steps no change, i=8 acc = 0.0\n",
      "8 steps no change, i=9 acc = 0.0\n",
      "9 steps no change, i=10 acc = 0.0\n",
      "10 steps no change, i=11 acc = 0.0\n",
      "11 steps no change, i=12 acc = 0.0\n",
      "12 steps no change, i=13 acc = 0.0\n",
      "13 steps no change, i=14 acc = 0.0\n",
      "14 steps no change, i=15 acc = 0.0\n",
      "0.0 {'temperature': 0.11366499501264446, 'top_p': 0.6856387851721889, 'presence_penalty': 0.023690554473677183, 'frequency_penalty': 0.7023375984278706, 'best_of': 2.4990235788076993}\n",
      "5 steps no change, i=27 acc = 0.7509158536936317\n",
      "0.7509158536936317 {'temperature': 1.8400338803940575, 'top_p': 0.5188886542785021, 'presence_penalty': 0.8825586952170268, 'frequency_penalty': 0.595336433300244, 'best_of': 4.956604244099436}\n",
      "5 steps no change, i=6 acc = 0.0\n",
      "6 steps no change, i=7 acc = 0.0\n",
      "7 steps no change, i=8 acc = 0.0\n",
      "8 steps no change, i=9 acc = 0.0\n",
      "9 steps no change, i=10 acc = 0.0\n",
      "10 steps no change, i=11 acc = 0.0\n",
      "11 steps no change, i=12 acc = 0.0\n",
      "12 steps no change, i=13 acc = 0.0\n",
      "13 steps no change, i=14 acc = 0.0\n",
      "14 steps no change, i=15 acc = 0.0\n",
      "0.0 {'temperature': 0.042183404443855994, 'top_p': 0.07626055469474419, 'presence_penalty': 0.7024728879061402, 'frequency_penalty': 1.969874382495666, 'best_of': 2.1981152905161796}\n",
      "5 steps no change, i=6 acc = 0.0\n",
      "6 steps no change, i=7 acc = 0.0\n",
      "7 steps no change, i=8 acc = 0.0\n",
      "8 steps no change, i=9 acc = 0.0\n",
      "9 steps no change, i=10 acc = 0.0\n",
      "10 steps no change, i=11 acc = 0.0\n",
      "11 steps no change, i=12 acc = 0.0\n",
      "12 steps no change, i=13 acc = 0.0\n",
      "13 steps no change, i=14 acc = 0.0\n",
      "14 steps no change, i=15 acc = 0.0\n",
      "0.0 {'temperature': 1.9550503931987453, 'top_p': 0.004097319432802777, 'presence_penalty': 0.39391232616665817, 'frequency_penalty': 0.47805395663272576, 'best_of': 6.918422929266105}\n",
      "5 steps no change, i=13 acc = 0.2687839937839938\n",
      "6 steps no change, i=14 acc = 0.265458152958153\n",
      "5 steps no change, i=25 acc = 0.2585050505050505\n",
      "0.2585050505050505 {'temperature': 0.5858933818789516, 'top_p': 0.7431856202201718, 'presence_penalty': 1.715417867147334, 'frequency_penalty': 0.3316929634134773, 'best_of': 3.5425005912882965}\n",
      "5 steps no change, i=25 acc = 0.3480266106442577\n",
      "0.3480266106442577 {'temperature': 1.2413228443995101, 'top_p': 0.6768627286933181, 'presence_penalty': 1.6980508154926672, 'frequency_penalty': 0.7387251198736993, 'best_of': 7.744671272887618}\n",
      "5 steps no change, i=16 acc = 0.21292162698412698\n",
      "0.21292162698412698 {'temperature': 0.3494487546293096, 'top_p': 0.4846522026576065, 'presence_penalty': 1.6721570828245493, 'frequency_penalty': 1.198581792928149, 'best_of': 3.6913964955971665}\n",
      "5 steps no change, i=14 acc = 0.05714285714285715\n",
      "6 steps no change, i=15 acc = 0.05333333333333334\n",
      "0.05333333333333334 {'temperature': 0.5526962778618988, 'top_p': 0.08060974282649273, 'presence_penalty': 1.8741208749571983, 'frequency_penalty': 0.8518603655629979, 'best_of': 2.7604787125885193}\n",
      "5 steps no change, i=16 acc = 0.4270833333333333\n",
      "0.4270833333333333 {'temperature': 0.3526943399672661, 'top_p': 0.2137251062596741, 'presence_penalty': 0.6200337477667799, 'frequency_penalty': 1.5339656407748725, 'best_of': 1.342206168490991}\n",
      "5 steps no change, i=22 acc = 0.2713858111585385\n",
      "0.2713858111585385 {'temperature': 0.8627361774585983, 'top_p': 0.5756724064364385, 'presence_penalty': 1.38570927958998, 'frequency_penalty': 1.3755635361558416, 'best_of': 7.037040188093646}\n",
      "5 steps no change, i=25 acc = 0.41666666666666663\n",
      "0.41666666666666663 {'temperature': 1.2290665472997584, 'top_p': 0.3530389700818603, 'presence_penalty': 0.1192931950914784, 'frequency_penalty': 0.27227165691066024, 'best_of': 1.698525780655471}\n",
      "5 steps no change, i=36 acc = 0.2685185185185185\n",
      "0.2685185185185185 {'temperature': 0.6136761659597534, 'top_p': 0.6043780184456445, 'presence_penalty': 0.4043209194153372, 'frequency_penalty': 1.6889529629776228, 'best_of': 1.3486726821967934}\n",
      "5 steps no change, i=31 acc = 0.26136712749615976\n",
      "0.26136712749615976 {'temperature': 0.5277912690979504, 'top_p': 0.8068406574842886, 'presence_penalty': 0.8540617530054986, 'frequency_penalty': 1.309253727002042, 'best_of': 3.1740765342706636}\n",
      "5 steps no change, i=12 acc = 0.04781140020110608\n",
      "6 steps no change, i=13 acc = 0.05005075994894999\n",
      "7 steps no change, i=14 acc = 0.059868562809739276\n",
      "8 steps no change, i=15 acc = 0.05587732528908999\n",
      "0.05587732528908999 {'temperature': 1.0844211677147533, 'top_p': 0.9702919885711441, 'presence_penalty': 1.6897803128625597, 'frequency_penalty': 0.016104471506370066, 'best_of': 9.348044380596338}\n",
      "5 steps no change, i=19 acc = 0.6243430546062124\n",
      "0.6243430546062124 {'temperature': 0.9696839300779064, 'top_p': 0.3257247597981868, 'presence_penalty': 0.8621295621978051, 'frequency_penalty': 0.9090495137820325, 'best_of': 5.383172731542481}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-b68d89d45c14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sp_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'A list of'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-4d440eacf8a2>\u001b[0m in \u001b[0;36mtest_sp_single\u001b[1;34m(params, min_l, max_l, n, prmt, phase, max_tokens, mdl, tol, ra)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_nochange\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mr_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_req_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrip_comma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr___\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr___\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr__\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_full\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob_msp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-be95bcddc52d>\u001b[0m in \u001b[0;36mp_req_m\u001b[1;34m(s, tokenize, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"prompt\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcaptured\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchoice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"choices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mtks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchoice\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"logprobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_logprobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, idempotency_key, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midempotency_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         response, _, api_key = requestor.request(\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         )\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, stream)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         rbody, rcode, rheaders, stream, my_api_key = self.request_raw(\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         )\n\u001b[0;32m    129\u001b[0m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[1;34m(self, method, url, params, supplied_headers, stream)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         rbody, rcode, rheaders, stream = self._client.request_with_retries(\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabs_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         )\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\http_client.py\u001b[0m in \u001b[0;36mrequest_with_retries\u001b[1;34m(self, method, url, headers, post_data, stream)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                 \u001b[0mconnection_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPIConnectionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\http_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, headers, post_data, stream)\u001b[0m\n\u001b[0;32m    219\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m                     \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m                 )\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mcontent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    751\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \"\"\"\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\";\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1007\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1009\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1010\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    869\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Uniformly sample gpt3 outputs\n",
    "bounds = OrderedDict([\n",
    "  (\"temperature\", [0.0001, 2.0]),  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  (\"top_p\", [0.0001, 1.0]),        # same with this but more obvious\n",
    "#   (\"top_k\", [1, 100]),        # maybe use log of the input value so that lower values are sampled with high resolution\n",
    "  (\"presence_penalty\", [0.0, 2.0]),   # both presence and frequency penalty have optimal values\n",
    "  (\"frequency_penalty\", [0.0, 2.0]),  # this can also go down to -2.0, probably not useful for our case...\n",
    "  (\"best_of\", [0.501, 9.499]),  \n",
    "])\n",
    "while True:\n",
    "    ps = {k: np.random.uniform(*bounds[k]) for k in bounds}\n",
    "    print(test_sp_single(ps, min_l=0, max_l=1e9, n=10, tol=0.01, mdl='gpt3', prmt='A list of'), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sample, generate ~100 samples for a single random prompt, each time choosing a random length of list uniformly as a\n",
    "# percentage of the prompt list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_gpt3_probs(choice, tokenize):\n",
    "    result = []\n",
    "    for logprob_list in choice[\"logprobs\"][\"top_logprobs\"]:\n",
    "        if logprob_list is None:\n",
    "            result.append(None)\n",
    "            continue\n",
    "        res, r = [], sorted([(np.e**v, k) for (k, v) in logprob_list.items()])[::-1]\n",
    "        for i in range(len(r)):\n",
    "            k = gpt3_tokenizer.encode(r[i][1])\n",
    "            if len(k) == 1: res.append((r[i][0], k if tokenize else r[i][1]))\n",
    "        result.append(res)\n",
    "#     pr(result)\n",
    "    return result if len(result) > 1 else result[0]\n",
    "floa = lambda x: float(x) if x is not None else 0\n",
    "response_glob = None\n",
    "def p_req_m(s, tokenize=False, **kwargs):\n",
    "    global response_glob\n",
    "    if \"max_tokens\" not in kwargs: kwargs[\"max_tokens\"] = 8\n",
    "    if \"n\" not in kwargs: kwargs[\"n\"] = 5\n",
    "    if \"best_of\" in kwargs:\n",
    "        kwargs[\"best_of\"] = int(round(kwargs[\"best_of\"]))\n",
    "        if kwargs[\"n\"] != 1: kwargs[\"best_of\"], kwargs[\"n\"] = kwargs[\"n\"], kwargs[\"best_of\"]\n",
    "    kwargs[\"prompt\"] = s\n",
    "#     print({**default_params, **kwargs})\n",
    "    with io.capture_output() as captured:\n",
    "        response, tokens, probs = openai.Completion.create(**{**default_params, **kwargs}), [], []\n",
    "#     print(response)\n",
    "    response_glob = response\n",
    "    for choice in response[\"choices\"]:\n",
    "        tks = [np.e**floa(v) for v in choice[\"logprobs\"][\"token_logprobs\"]]\n",
    "        tks = [(choice[\"logprobs\"][\"tokens\"][i], tks[i]) for i in range(len(tks))]\n",
    "        tokens.append(tks), probs.append(format_gpt3_probs(choice, tokenize))\n",
    "    return tokens, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-4CJQIdgwx3Ho7URppQw1p937HIUnO at 0x22dce56dc50> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": {\n",
       "        \"text_offset\": [\n",
       "          0,\n",
       "          1,\n",
       "          6,\n",
       "          9,\n",
       "          16,\n",
       "          21,\n",
       "          24,\n",
       "          28,\n",
       "          33,\n",
       "          34,\n",
       "          41,\n",
       "          42,\n",
       "          46,\n",
       "          48,\n",
       "          49,\n",
       "          54,\n",
       "          57,\n",
       "          58,\n",
       "          61,\n",
       "          62,\n",
       "          65,\n",
       "          70,\n",
       "          71,\n",
       "          80,\n",
       "          85,\n",
       "          86,\n",
       "          90,\n",
       "          91,\n",
       "          92,\n",
       "          97,\n",
       "          100,\n",
       "          101,\n",
       "          103,\n",
       "          106,\n",
       "          108,\n",
       "          109,\n",
       "          113,\n",
       "          116,\n",
       "          117,\n",
       "          123,\n",
       "          129,\n",
       "          130,\n",
       "          133,\n",
       "          137,\n",
       "          138,\n",
       "          145,\n",
       "          146,\n",
       "          151,\n",
       "          153,\n",
       "          155,\n",
       "          156,\n",
       "          159,\n",
       "          162,\n",
       "          163,\n",
       "          165,\n",
       "          168,\n",
       "          172,\n",
       "          173,\n",
       "          179,\n",
       "          185,\n",
       "          186,\n",
       "          190,\n",
       "          194,\n",
       "          195,\n",
       "          201,\n",
       "          208,\n",
       "          209,\n",
       "          212,\n",
       "          214,\n",
       "          215,\n",
       "          219,\n",
       "          222,\n",
       "          225,\n",
       "          226,\n",
       "          228,\n",
       "          232,\n",
       "          233,\n",
       "          236,\n",
       "          239,\n",
       "          240,\n",
       "          245,\n",
       "          246,\n",
       "          251,\n",
       "          252,\n",
       "          253,\n",
       "          256,\n",
       "          259,\n",
       "          260,\n",
       "          264,\n",
       "          267,\n",
       "          268,\n",
       "          270,\n",
       "          272,\n",
       "          275,\n",
       "          276,\n",
       "          282,\n",
       "          287,\n",
       "          288,\n",
       "          294,\n",
       "          295,\n",
       "          301,\n",
       "          307,\n",
       "          308,\n",
       "          310,\n",
       "          312,\n",
       "          315,\n",
       "          318,\n",
       "          319,\n",
       "          323,\n",
       "          324,\n",
       "          326,\n",
       "          330,\n",
       "          334,\n",
       "          335,\n",
       "          340,\n",
       "          341,\n",
       "          343,\n",
       "          347,\n",
       "          353,\n",
       "          354,\n",
       "          357,\n",
       "          362,\n",
       "          367,\n",
       "          368,\n",
       "          371,\n",
       "          374,\n",
       "          375,\n",
       "          378,\n",
       "          381,\n",
       "          384,\n",
       "          385,\n",
       "          393,\n",
       "          397,\n",
       "          398,\n",
       "          406,\n",
       "          410,\n",
       "          411,\n",
       "          417,\n",
       "          421,\n",
       "          422,\n",
       "          426,\n",
       "          430,\n",
       "          434,\n",
       "          435,\n",
       "          439,\n",
       "          440,\n",
       "          448,\n",
       "          449,\n",
       "          452,\n",
       "          454,\n",
       "          458,\n",
       "          459,\n",
       "          463,\n",
       "          465,\n",
       "          467,\n",
       "          468,\n",
       "          474,\n",
       "          475,\n",
       "          482,\n",
       "          483,\n",
       "          487,\n",
       "          489,\n",
       "          490,\n",
       "          497,\n",
       "          502,\n",
       "          503,\n",
       "          510,\n",
       "          511,\n",
       "          516,\n",
       "          519,\n",
       "          523,\n",
       "          524\n",
       "        ],\n",
       "        \"token_logprobs\": [\n",
       "          null,\n",
       "          -7.287874,\n",
       "          -0.12955146,\n",
       "          -9.262105,\n",
       "          -10.798012,\n",
       "          -0.47781226,\n",
       "          -0.8919495,\n",
       "          -4.594847,\n",
       "          -3.1423085,\n",
       "          -10.437267,\n",
       "          -0.14527082,\n",
       "          -8.385316,\n",
       "          -0.06980557,\n",
       "          -0.07701224,\n",
       "          -6.508633,\n",
       "          -0.02925794,\n",
       "          -0.002120972,\n",
       "          -0.030506138,\n",
       "          -0.06892286,\n",
       "          -7.9681697,\n",
       "          -0.15726355,\n",
       "          -0.24072842,\n",
       "          -2.709908,\n",
       "          -5.288921,\n",
       "          -0.102990575,\n",
       "          -9.08947,\n",
       "          -0.11711888,\n",
       "          -0.09376704,\n",
       "          -6.740299,\n",
       "          -0.0092982855,\n",
       "          -0.08848695,\n",
       "          -5.209296,\n",
       "          -0.010746639,\n",
       "          -0.0027255774,\n",
       "          -0.094745815,\n",
       "          -5.291737,\n",
       "          -0.04134042,\n",
       "          -0.06437976,\n",
       "          -9.246071,\n",
       "          -0.04611839,\n",
       "          -0.08148508,\n",
       "          -6.346433,\n",
       "          -0.11083255,\n",
       "          -0.055938426,\n",
       "          -6.1229353,\n",
       "          -0.2672454,\n",
       "          -6.213791,\n",
       "          -0.00299941,\n",
       "          -0.002460242,\n",
       "          -0.057000753,\n",
       "          -5.7332277,\n",
       "          -0.5192209,\n",
       "          -0.04136502,\n",
       "          -4.215726,\n",
       "          -2.4614356,\n",
       "          -0.022975605,\n",
       "          -0.05752885,\n",
       "          -7.753627,\n",
       "          -0.012994219,\n",
       "          -0.08012336,\n",
       "          -8.916001,\n",
       "          -0.3930756,\n",
       "          -0.05258297,\n",
       "          -7.8786693,\n",
       "          -0.34360716,\n",
       "          -0.068734564,\n",
       "          -7.8113613,\n",
       "          -0.017190533,\n",
       "          -0.051168934,\n",
       "          -8.3245325,\n",
       "          -0.047710672,\n",
       "          -0.014266173,\n",
       "          -0.046954572,\n",
       "          -5.4369054,\n",
       "          -0.512651,\n",
       "          -0.045545187,\n",
       "          -5.4600477,\n",
       "          -0.023852648,\n",
       "          -0.04388041,\n",
       "          -7.0102735,\n",
       "          -0.0581993,\n",
       "          -5.498772,\n",
       "          -1.1990948,\n",
       "          -0.03913914,\n",
       "          -5.3465147,\n",
       "          -0.008199082,\n",
       "          -0.039179925,\n",
       "          -8.494625,\n",
       "          -0.020774353,\n",
       "          -0.033068977,\n",
       "          -5.4556046,\n",
       "          -6.6362543,\n",
       "          -0.0846317,\n",
       "          -0.065830536,\n",
       "          -7.3364077,\n",
       "          -0.014225849,\n",
       "          -0.044318885,\n",
       "          -4.2169166,\n",
       "          -0.13195816,\n",
       "          -9.908352,\n",
       "          -0.0019558237,\n",
       "          -0.033893265,\n",
       "          -5.180127,\n",
       "          -3.579547,\n",
       "          -0.022692049,\n",
       "          -0.0014307739,\n",
       "          -0.16629173,\n",
       "          -5.309614,\n",
       "          -0.043404154,\n",
       "          -4.426824,\n",
       "          -2.7003143,\n",
       "          -0.11477536,\n",
       "          -0.036263555,\n",
       "          -5.841456,\n",
       "          -0.14003736,\n",
       "          -4.287068,\n",
       "          -0.014937819,\n",
       "          -3.5467918,\n",
       "          -0.024931183,\n",
       "          -5.1080093,\n",
       "          -0.44610217,\n",
       "          -0.15503156,\n",
       "          -0.032851096,\n",
       "          -4.7582836,\n",
       "          -0.0026921064,\n",
       "          -0.06500411,\n",
       "          -6.8115854,\n",
       "          -0.004857316,\n",
       "          -0.0008873215,\n",
       "          -0.037688397,\n",
       "          -10.2391405,\n",
       "          -0.41800743,\n",
       "          -0.031991612,\n",
       "          -5.8778067,\n",
       "          -0.03595587,\n",
       "          -0.029274143,\n",
       "          -8.860503,\n",
       "          -1.6254553,\n",
       "          -0.03496258,\n",
       "          -4.484842,\n",
       "          -0.095628284,\n",
       "          -4.4607754,\n",
       "          -0.03359451,\n",
       "          -6.2349453,\n",
       "          -0.030118646,\n",
       "          -5.298784,\n",
       "          -0.035687193,\n",
       "          -6.214629,\n",
       "          -2.7234123,\n",
       "          -0.003167718,\n",
       "          -0.028791364,\n",
       "          -5.5077643,\n",
       "          -0.039995294,\n",
       "          -0.0013789642,\n",
       "          -0.02280485,\n",
       "          -5.634509,\n",
       "          -0.020909889,\n",
       "          -7.146632,\n",
       "          -0.03620997,\n",
       "          -5.398421,\n",
       "          -0.014876471,\n",
       "          -0.023764873,\n",
       "          -5.9448457,\n",
       "          -0.82976675,\n",
       "          -0.013802909,\n",
       "          -9.35307,\n",
       "          -0.027514355,\n",
       "          -9.093751,\n",
       "          -1.298391,\n",
       "          -0.011430941,\n",
       "          -0.029585853,\n",
       "          -5.9024262\n",
       "        ],\n",
       "        \"tokens\": [\n",
       "          \"A\",\n",
       "          \" list\",\n",
       "          \" of\",\n",
       "          \" animal\",\n",
       "          \" seen\",\n",
       "          \" in\",\n",
       "          \" the\",\n",
       "          \" wild\",\n",
       "          \":\",\n",
       "          \" lizard\",\n",
       "          \",\",\n",
       "          \" rob\",\n",
       "          \"in\",\n",
       "          \",\",\n",
       "          \" ratt\",\n",
       "          \"les\",\n",
       "          \"n\",\n",
       "          \"ake\",\n",
       "          \",\",\n",
       "          \" le\",\n",
       "          \"opard\",\n",
       "          \",\",\n",
       "          \" elephant\",\n",
       "          \" seal\",\n",
       "          \",\",\n",
       "          \" new\",\n",
       "          \"t\",\n",
       "          \",\",\n",
       "          \" pant\",\n",
       "          \"her\",\n",
       "          \",\",\n",
       "          \" j\",\n",
       "          \"agu\",\n",
       "          \"ar\",\n",
       "          \",\",\n",
       "          \" tou\",\n",
       "          \"can\",\n",
       "          \",\",\n",
       "          \" sperm\",\n",
       "          \" whale\",\n",
       "          \",\",\n",
       "          \" we\",\n",
       "          \"asel\",\n",
       "          \",\",\n",
       "          \" turkey\",\n",
       "          \",\",\n",
       "          \" plat\",\n",
       "          \"yp\",\n",
       "          \"us\",\n",
       "          \",\",\n",
       "          \" le\",\n",
       "          \"mur\",\n",
       "          \",\",\n",
       "          \" p\",\n",
       "          \"ang\",\n",
       "          \"olin\",\n",
       "          \",\",\n",
       "          \" cater\",\n",
       "          \"pillar\",\n",
       "          \",\",\n",
       "          \" saw\",\n",
       "          \"fish\",\n",
       "          \",\",\n",
       "          \" stick\",\n",
       "          \" insect\",\n",
       "          \",\",\n",
       "          \" ha\",\n",
       "          \"re\",\n",
       "          \",\",\n",
       "          \" bar\",\n",
       "          \"rac\",\n",
       "          \"uda\",\n",
       "          \",\",\n",
       "          \" d\",\n",
       "          \"ingo\",\n",
       "          \",\",\n",
       "          \" ge\",\n",
       "          \"cko\",\n",
       "          \",\",\n",
       "          \" moth\",\n",
       "          \",\",\n",
       "          \" hipp\",\n",
       "          \"o\",\n",
       "          \",\",\n",
       "          \" sl\",\n",
       "          \"oth\",\n",
       "          \",\",\n",
       "          \" ear\",\n",
       "          \"wig\",\n",
       "          \",\",\n",
       "          \" c\",\n",
       "          \"us\",\n",
       "          \"cus\",\n",
       "          \",\",\n",
       "          \" polar\",\n",
       "          \" bear\",\n",
       "          \",\",\n",
       "          \" tiger\",\n",
       "          \",\",\n",
       "          \" nurse\",\n",
       "          \" shark\",\n",
       "          \",\",\n",
       "          \" d\",\n",
       "          \"al\",\n",
       "          \"mat\",\n",
       "          \"ian\",\n",
       "          \",\",\n",
       "          \" fox\",\n",
       "          \",\",\n",
       "          \" m\",\n",
       "          \"anta\",\n",
       "          \" ray\",\n",
       "          \",\",\n",
       "          \" duck\",\n",
       "          \",\",\n",
       "          \" z\",\n",
       "          \"ebra\",\n",
       "          \" shark\",\n",
       "          \",\",\n",
       "          \" le\",\n",
       "          \"opard\",\n",
       "          \" seal\",\n",
       "          \",\",\n",
       "          \" ko\",\n",
       "          \"ala\",\n",
       "          \",\",\n",
       "          \" re\",\n",
       "          \"ind\",\n",
       "          \"eer\",\n",
       "          \",\",\n",
       "          \" fishing\",\n",
       "          \" cat\",\n",
       "          \",\",\n",
       "          \" humming\",\n",
       "          \"bird\",\n",
       "          \",\",\n",
       "          \" feral\",\n",
       "          \" cat\",\n",
       "          \",\",\n",
       "          \" rac\",\n",
       "          \"coon\",\n",
       "          \" dog\",\n",
       "          \",\",\n",
       "          \" owl\",\n",
       "          \",\",\n",
       "          \" dolphin\",\n",
       "          \",\",\n",
       "          \" st\",\n",
       "          \"ur\",\n",
       "          \"geon\",\n",
       "          \",\",\n",
       "          \" war\",\n",
       "          \"th\",\n",
       "          \"og\",\n",
       "          \",\",\n",
       "          \" goose\",\n",
       "          \",\",\n",
       "          \" salmon\",\n",
       "          \",\",\n",
       "          \" cob\",\n",
       "          \"ra\",\n",
       "          \",\",\n",
       "          \" flying\",\n",
       "          \" fish\",\n",
       "          \",\",\n",
       "          \" sponge\",\n",
       "          \",\",\n",
       "          \" pond\",\n",
       "          \" sk\",\n",
       "          \"ater\",\n",
       "          \",\",\n",
       "          \" fox\"\n",
       "        ],\n",
       "        \"top_logprobs\": [\n",
       "          null,\n",
       "          {\n",
       "            \")\": -3.999995,\n",
       "            \",\": -3.9626567,\n",
       "            \"-\": -3.4957035,\n",
       "            \".\": -2.996783,\n",
       "            \":\": -4.2589517\n",
       "          },\n",
       "          {\n",
       "            \" by\": -5.3051896,\n",
       "            \" is\": -4.7752385,\n",
       "            \" of\": -0.12955146,\n",
       "            \" with\": -5.4005494,\n",
       "            \"a\": -4.0487027\n",
       "          },\n",
       "          {\n",
       "            \" all\": -2.3419588,\n",
       "            \" my\": -4.858934,\n",
       "            \" some\": -4.244167,\n",
       "            \" the\": -1.8722247,\n",
       "            \" things\": -4.591436\n",
       "          },\n",
       "          {\n",
       "            \" names\": -3.0447693,\n",
       "            \" rights\": -2.9330578,\n",
       "            \" species\": -1.880354,\n",
       "            \" welfare\": -3.5332756,\n",
       "            \"-\": -2.7834928\n",
       "          },\n",
       "          {\n",
       "            \" at\": -2.9315283,\n",
       "            \" in\": -0.47781226,\n",
       "            \" on\": -2.1177697,\n",
       "            \" or\": -3.8849432,\n",
       "            \" so\": -3.789065\n",
       "          },\n",
       "          {\n",
       "            \" \\\"\": -3.7260861,\n",
       "            \" The\": -3.1909835,\n",
       "            \" Z\": -5.153271,\n",
       "            \" the\": -0.8919495,\n",
       "            \" this\": -3.2782104\n",
       "          },\n",
       "          {\n",
       "            \" episode\": -3.293862,\n",
       "            \" film\": -2.693711,\n",
       "            \" game\": -2.1473854,\n",
       "            \" series\": -2.6839018,\n",
       "            \" show\": -2.8370671\n",
       "          },\n",
       "          {\n",
       "            \" and\": -2.791734,\n",
       "            \" in\": -1.8719648,\n",
       "            \",\": -2.7727368,\n",
       "            \".\": -1.6304716,\n",
       "            \"s\": -2.9581616\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -0.5750583,\n",
       "            \"\\n\\n\": -1.9564669,\n",
       "            \" \": -5.4586873,\n",
       "            \" (\": -5.273421,\n",
       "            \"<|endoftext|>\": -2.9891818\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -4.5801845,\n",
       "            \" (\": -3.3383822,\n",
       "            \" and\": -4.6532016,\n",
       "            \",\": -0.14527082,\n",
       "            \";\": -4.7216372\n",
       "          },\n",
       "          {\n",
       "            \" bird\": -3.5702856,\n",
       "            \" deer\": -3.2003896,\n",
       "            \" snake\": -3.2596507,\n",
       "            \" tort\": -3.666492,\n",
       "            \" turtle\": -3.6383662\n",
       "          },\n",
       "          {\n",
       "            \"bin\": -5.037422,\n",
       "            \"in\": -0.06980557,\n",
       "            \"inia\": -5.9041176,\n",
       "            \"ins\": -3.3110967,\n",
       "            \"inson\": -6.276856\n",
       "          },\n",
       "          {\n",
       "            \" (\": -4.945321,\n",
       "            \" and\": -4.1918383,\n",
       "            \" red\": -4.3524866,\n",
       "            \",\": -0.07701224,\n",
       "            \".\": -5.17365\n",
       "          },\n",
       "          {\n",
       "            \" butterfly\": -3.8969235,\n",
       "            \" crow\": -3.6559033,\n",
       "            \" deer\": -3.84372,\n",
       "            \" rabbit\": -3.7481847,\n",
       "            \" squirrel\": -3.7021298\n",
       "          },\n",
       "          {\n",
       "            \"an\": -6.2005067,\n",
       "            \"ler\": -4.336028,\n",
       "            \"lers\": -6.0164175,\n",
       "            \"les\": -0.02925794,\n",
       "            \"ling\": -6.613066\n",
       "          },\n",
       "          {\n",
       "            \" and\": -9.898314,\n",
       "            \" snake\": -8.3915825,\n",
       "            \",\": -7.4007945,\n",
       "            \"n\": -0.002120972,\n",
       "            \"na\": -8.567093\n",
       "          },\n",
       "          {\n",
       "            \"ack\": -8.258883,\n",
       "            \"ail\": -8.880653,\n",
       "            \"ak\": -7.1509504,\n",
       "            \"ake\": -0.030506138,\n",
       "            \"akes\": -3.5596964\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -4.912585,\n",
       "            \" (\": -4.8037705,\n",
       "            \" and\": -4.342196,\n",
       "            \",\": -0.06892286,\n",
       "            \".\": -3.7009797\n",
       "          },\n",
       "          {\n",
       "            \" coy\": -3.6389327,\n",
       "            \" deer\": -3.408304,\n",
       "            \" rabbit\": -3.205259,\n",
       "            \" scorp\": -3.211252,\n",
       "            \" turtle\": -3.6717505\n",
       "          },\n",
       "          {\n",
       "            \"ach\": -5.9536953,\n",
       "            \"ech\": -3.3309546,\n",
       "            \"m\": -4.048568,\n",
       "            \"mur\": -2.9469478,\n",
       "            \"opard\": -0.15726355\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.7292843,\n",
       "            \" frog\": -3.0944462,\n",
       "            \" ge\": -3.691389,\n",
       "            \",\": -0.24072842,\n",
       "            \".\": -3.7746525\n",
       "          },\n",
       "          {\n",
       "            \" elephant\": -2.709908,\n",
       "            \" lion\": -3.885811,\n",
       "            \" monkey\": -3.631535,\n",
       "            \" tiger\": -3.7430272,\n",
       "            \" z\": -3.8885045\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.1049953,\n",
       "            \" (\": -5.282802,\n",
       "            \" and\": -3.5350833,\n",
       "            \",\": -0.08702043,\n",
       "            \".\": -3.9608946\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -4.7495856,\n",
       "            \" (\": -4.7495394,\n",
       "            \" and\": -3.586164,\n",
       "            \",\": -0.102990575,\n",
       "            \".\": -3.346784\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.599812,\n",
       "            \" deer\": -3.950928,\n",
       "            \" elephant\": -4.034367,\n",
       "            \" sea\": -3.6170962,\n",
       "            \" tiger\": -4.1987004\n",
       "          },\n",
       "          {\n",
       "            \" born\": -4.629734,\n",
       "            \" species\": -5.546711,\n",
       "            \"-\": -5.1559334,\n",
       "            \"t\": -0.11711888,\n",
       "            \"ts\": -3.3311841\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -4.45696,\n",
       "            \" (\": -5.1354957,\n",
       "            \" and\": -3.7509854,\n",
       "            \",\": -0.09376704,\n",
       "            \".\": -3.5318012\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.6910691,\n",
       "            \" deer\": -4.005572,\n",
       "            \" frog\": -4.3525033,\n",
       "            \" tiger\": -4.2964616,\n",
       "            \" turtle\": -4.363959\n",
       "          },\n",
       "          {\n",
       "            \"her\": -0.0092982855,\n",
       "            \"here\": -8.555948,\n",
       "            \"hers\": -5.06344,\n",
       "            \"ing\": -8.48629,\n",
       "            \"y\": -8.082331\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.1802797,\n",
       "            \" (\": -4.764493,\n",
       "            \" and\": -3.8582277,\n",
       "            \",\": -0.08848695,\n",
       "            \".\": -3.6507196\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.6740656,\n",
       "            \" bear\": -4.0062113,\n",
       "            \" deer\": -3.8149655,\n",
       "            \" tiger\": -3.586774,\n",
       "            \" turtle\": -4.0990877\n",
       "          },\n",
       "          {\n",
       "            \"ac\": -5.449883,\n",
       "            \"agu\": -0.010746639,\n",
       "            \"aval\": -7.7822824,\n",
       "            \"ay\": -5.902241,\n",
       "            \"une\": -7.8378987\n",
       "          },\n",
       "          {\n",
       "            \"ar\": -0.0027255774,\n",
       "            \"ard\": -10.892034,\n",
       "            \"aro\": -10.187952,\n",
       "            \"ars\": -6.006609,\n",
       "            \"at\": -10.988478\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.166645,\n",
       "            \" and\": -3.991562,\n",
       "            \",\": -0.094745815,\n",
       "            \".\": -3.7471733,\n",
       "            \"und\": -3.7419662\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.9080663,\n",
       "            \" crocod\": -3.8907323,\n",
       "            \" deer\": -3.8345535,\n",
       "            \" rh\": -4.1128163,\n",
       "            \" tiger\": -3.4461713\n",
       "          },\n",
       "          {\n",
       "            \"c\": -3.253544,\n",
       "            \"ca\": -8.672398,\n",
       "            \"can\": -0.04134042,\n",
       "            \"pee\": -8.597279,\n",
       "            \"ro\": -9.130512\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.2589445,\n",
       "            \" (\": -5.8651648,\n",
       "            \" and\": -3.6224964,\n",
       "            \",\": -0.06437976,\n",
       "            \".\": -4.245303\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.7637851,\n",
       "            \" crocod\": -3.7876651,\n",
       "            \" deer\": -3.831565,\n",
       "            \" par\": -3.8487957,\n",
       "            \" turtle\": -3.912234\n",
       "          },\n",
       "          {\n",
       "            \" whale\": -0.04611839,\n",
       "            \" whales\": -5.7261863,\n",
       "            \",\": -4.74964,\n",
       "            \"-\": -4.911406,\n",
       "            \"ato\": -5.935396\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.146949,\n",
       "            \" (\": -5.116706,\n",
       "            \" and\": -3.6543992,\n",
       "            \",\": -0.08148508,\n",
       "            \".\": -3.6053078\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.6401956,\n",
       "            \" crocod\": -3.9137666,\n",
       "            \" rh\": -3.9390695,\n",
       "            \" sea\": -3.9578876,\n",
       "            \" tiger\": -3.8688602\n",
       "          },\n",
       "          {\n",
       "            \"as\": -4.0689125,\n",
       "            \"asel\": -0.11083255,\n",
       "            \"aver\": -2.9333498,\n",
       "            \"eper\": -6.2688217,\n",
       "            \"evil\": -4.068527\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.312038,\n",
       "            \" (\": -5.6061473,\n",
       "            \" and\": -3.9247394,\n",
       "            \",\": -0.055938426,\n",
       "            \".\": -4.184852\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.9941993,\n",
       "            \" crocod\": -4.1722083,\n",
       "            \" deer\": -4.140363,\n",
       "            \" k\": -4.2164855,\n",
       "            \" tiger\": -3.872377\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.918704,\n",
       "            \" buzz\": -4.012225,\n",
       "            \" v\": -1.8133192,\n",
       "            \",\": -0.2672454,\n",
       "            \".\": -4.373805\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.9851117,\n",
       "            \" deer\": -3.8527417,\n",
       "            \" rabbit\": -4.395783,\n",
       "            \" tiger\": -4.0567555,\n",
       "            \" turtle\": -4.1484036\n",
       "          },\n",
       "          {\n",
       "            \"ap\": -7.932917,\n",
       "            \"ip\": -7.8631907,\n",
       "            \"y\": -6.551102,\n",
       "            \"yp\": -0.00299941,\n",
       "            \"yr\": -8.826975\n",
       "          },\n",
       "          {\n",
       "            \"i\": -7.967078,\n",
       "            \"od\": -8.662227,\n",
       "            \"us\": -0.002460242,\n",
       "            \"uses\": -7.5147657,\n",
       "            \"uss\": -7.215114\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.6058817,\n",
       "            \" (\": -5.2813697,\n",
       "            \" and\": -3.7858746,\n",
       "            \",\": -0.057000753,\n",
       "            \".\": -4.275716\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.7321007,\n",
       "            \" crocod\": -4.2174826,\n",
       "            \" k\": -3.7996817,\n",
       "            \" rh\": -4.129611,\n",
       "            \" turtle\": -4.190818\n",
       "          },\n",
       "          {\n",
       "            \"ech\": -3.0083451,\n",
       "            \"m\": -2.0263314,\n",
       "            \"mur\": -0.5192209,\n",
       "            \"opard\": -1.5742213,\n",
       "            \"uc\": -5.9925637\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.331988,\n",
       "            \" (\": -5.7281246,\n",
       "            \" and\": -4.4284883,\n",
       "            \",\": -0.04136502,\n",
       "            \".\": -4.3404107\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.901082,\n",
       "            \" crocod\": -3.981641,\n",
       "            \" k\": -3.5887995,\n",
       "            \" rh\": -3.788106,\n",
       "            \" tiger\": -3.9758883\n",
       "          },\n",
       "          {\n",
       "            \"anda\": -0.91911143,\n",
       "            \"ang\": -2.4614356,\n",
       "            \"ere\": -2.4512084,\n",
       "            \"he\": -2.33803,\n",
       "            \"uma\": -1.775305\n",
       "          },\n",
       "          {\n",
       "            \"as\": -8.214951,\n",
       "            \"ol\": -3.9764287,\n",
       "            \"olin\": -0.022975605,\n",
       "            \"olina\": -8.27604,\n",
       "            \"oline\": -8.364323\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.1552343,\n",
       "            \" (\": -4.7295985,\n",
       "            \" and\": -4.3889112,\n",
       "            \",\": -0.05752885,\n",
       "            \".\": -4.026683\n",
       "          },\n",
       "          {\n",
       "            \" and\": -4.0266294,\n",
       "            \" ch\": -4.050765,\n",
       "            \" deer\": -4.158035,\n",
       "            \" k\": -3.6816857,\n",
       "            \" rh\": -3.7812226\n",
       "          },\n",
       "          {\n",
       "            \"bird\": -9.2239275,\n",
       "            \"p\": -5.1434565,\n",
       "            \"pie\": -8.302758,\n",
       "            \"pill\": -5.0847483,\n",
       "            \"pillar\": -0.012994219\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -4.742973,\n",
       "            \" (\": -5.095844,\n",
       "            \" and\": -3.8803856,\n",
       "            \",\": -0.08012336,\n",
       "            \".\": -3.6645236\n",
       "          },\n",
       "          {\n",
       "            \" and\": -4.00179,\n",
       "            \" ch\": -3.997842,\n",
       "            \" k\": -4.0111055,\n",
       "            \" rh\": -4.0441947,\n",
       "            \" tiger\": -4.0573325\n",
       "          },\n",
       "          {\n",
       "            \" fish\": -3.4093413,\n",
       "            \",\": -4.234592,\n",
       "            \"-\": -2.229219,\n",
       "            \"fish\": -0.3930756,\n",
       "            \"fly\": -2.8349965\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.0978556,\n",
       "            \" (\": -5.003705,\n",
       "            \" and\": -4.317708,\n",
       "            \",\": -0.05258297,\n",
       "            \".\": -4.2935495\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.9898698,\n",
       "            \" ch\": -4.1105895,\n",
       "            \" crocod\": -4.121347,\n",
       "            \" k\": -4.004644,\n",
       "            \" rh\": -4.087877\n",
       "          },\n",
       "          {\n",
       "            \" bug\": -2.65885,\n",
       "            \" insect\": -0.34360716,\n",
       "            \" insects\": -3.213858,\n",
       "            \"bug\": -4.1098614,\n",
       "            \"le\": -2.011759\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -4.8866324,\n",
       "            \" (\": -5.1675696,\n",
       "            \" and\": -3.739225,\n",
       "            \",\": -0.068734564,\n",
       "            \".\": -4.023908\n",
       "          },\n",
       "          {\n",
       "            \" and\": -3.9686067,\n",
       "            \" ch\": -3.6861782,\n",
       "            \" crocod\": -3.9980295,\n",
       "            \" k\": -4.02363,\n",
       "            \" scorp\": -4.080801\n",
       "          },\n",
       "          {\n",
       "            \"ird\": -6.840371,\n",
       "            \"ke\": -6.313726,\n",
       "            \"re\": -0.017190533,\n",
       "            \"rel\": -6.935392,\n",
       "            \"res\": -5.687616\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.4644604,\n",
       "            \" (\": -5.876173,\n",
       "            \" and\": -3.9771826,\n",
       "            \",\": -0.051168934,\n",
       "            \".\": -4.268637\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.035003,\n",
       "            \" deer\": -3.9364047,\n",
       "            \" k\": -3.9563594,\n",
       "            \" tiger\": -4.1558833,\n",
       "            \" tort\": -3.870601\n",
       "          },\n",
       "          {\n",
       "            \"-\": -5.125992,\n",
       "            \"ac\": -4.9470677,\n",
       "            \"bel\": -5.4004917,\n",
       "            \"rac\": -0.047710672,\n",
       "            \"ram\": -5.03221\n",
       "          },\n",
       "          {\n",
       "            \"oon\": -7.183017,\n",
       "            \"out\": -7.4367704,\n",
       "            \"ud\": -4.6706,\n",
       "            \"uda\": -0.014266173,\n",
       "            \"ude\": -7.540084\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.540519,\n",
       "            \" (\": -6.2256155,\n",
       "            \" and\": -4.127425,\n",
       "            \",\": -0.046954572,\n",
       "            \".\": -4.2530932\n",
       "          },\n",
       "          {\n",
       "            \" and\": -4.0661035,\n",
       "            \" ch\": -4.1545587,\n",
       "            \" crocod\": -4.0325456,\n",
       "            \" k\": -4.0919976,\n",
       "            \" oct\": -4.216723\n",
       "          },\n",
       "          {\n",
       "            \"ach\": -4.355634,\n",
       "            \"andel\": -3.8315785,\n",
       "            \"ingo\": -0.512651,\n",
       "            \"rom\": -2.7928405,\n",
       "            \"ung\": -1.5563217\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.6582346,\n",
       "            \" (\": -5.70979,\n",
       "            \" and\": -3.9596648,\n",
       "            \",\": -0.045545187,\n",
       "            \".\": -4.5635467\n",
       "          },\n",
       "          {\n",
       "            \" bo\": -4.281038,\n",
       "            \" ch\": -4.2341166,\n",
       "            \" crocod\": -3.9058428,\n",
       "            \" k\": -3.6768925,\n",
       "            \" tiger\": -4.275628\n",
       "          },\n",
       "          {\n",
       "            \"ck\": -4.965068,\n",
       "            \"cko\": -0.023852648,\n",
       "            \"ese\": -4.5026426,\n",
       "            \"od\": -6.735423,\n",
       "            \"ys\": -7.0579934\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.041752,\n",
       "            \" (\": -6.5874133,\n",
       "            \" and\": -4.1965904,\n",
       "            \",\": -0.04388041,\n",
       "            \".\": -4.4661026\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -3.7271848,\n",
       "            \" crocod\": -3.799775,\n",
       "            \" k\": -3.7221878,\n",
       "            \" oct\": -4.3923726,\n",
       "            \" tiger\": -4.386845\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -4.925879,\n",
       "            \" (\": -6.1652317,\n",
       "            \" and\": -3.9892638,\n",
       "            \",\": -0.0581993,\n",
       "            \".\": -4.2785897\n",
       "          },\n",
       "          {\n",
       "            \" butterfly\": -3.986512,\n",
       "            \" ch\": -4.036038,\n",
       "            \" k\": -3.9711924,\n",
       "            \" oct\": -3.8885849,\n",
       "            \" scorp\": -3.9822588\n",
       "          },\n",
       "          {\n",
       "            \"o\": -1.1990948,\n",
       "            \"og\": -5.975797,\n",
       "            \"op\": -6.0431647,\n",
       "            \"opot\": -0.37541768,\n",
       "            \"os\": -5.803888\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -6.0089874,\n",
       "            \" (\": -6.5203896,\n",
       "            \" and\": -4.101959,\n",
       "            \",\": -0.03913914,\n",
       "            \".\": -4.8969193\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -3.8492692,\n",
       "            \" crocod\": -3.683196,\n",
       "            \" k\": -3.7217166,\n",
       "            \" rh\": -3.6823187,\n",
       "            \" tiger\": -4.1007795\n",
       "          },\n",
       "          {\n",
       "            \"ings\": -8.393281,\n",
       "            \"ipper\": -6.742097,\n",
       "            \"oth\": -0.008199082,\n",
       "            \"oths\": -5.6128016,\n",
       "            \"ugs\": -7.1439104\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.6417184,\n",
       "            \" (\": -5.9552217,\n",
       "            \" and\": -4.2764044,\n",
       "            \",\": -0.039179925,\n",
       "            \".\": -4.488071\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -3.928374,\n",
       "            \" crocod\": -3.525271,\n",
       "            \" k\": -3.8343375,\n",
       "            \" rh\": -3.850699,\n",
       "            \" tiger\": -4.073458\n",
       "          },\n",
       "          {\n",
       "            \" moth\": -7.3425565,\n",
       "            \",\": -7.492877,\n",
       "            \"less\": -5.554834,\n",
       "            \"w\": -4.4501376,\n",
       "            \"wig\": -0.020774353\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.5390124,\n",
       "            \"\\n\\n\": -6.809783,\n",
       "            \" and\": -4.4933047,\n",
       "            \",\": -0.033068977,\n",
       "            \".\": -4.642459\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -3.6790197,\n",
       "            \" crocod\": -4.035614,\n",
       "            \" k\": -3.752781,\n",
       "            \" oct\": -4.2142677,\n",
       "            \" rh\": -4.222923\n",
       "          },\n",
       "          {\n",
       "            \"actus\": -2.7354329,\n",
       "            \"ic\": -1.1609471,\n",
       "            \"ive\": -2.481805,\n",
       "            \"orm\": -2.2548459,\n",
       "            \"uck\": -1.2948315\n",
       "          },\n",
       "          {\n",
       "            \"co\": -7.0375504,\n",
       "            \"cus\": -0.0846317,\n",
       "            \"cut\": -4.9070783,\n",
       "            \"im\": -6.384135,\n",
       "            \"iman\": -2.7469585\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -4.856674,\n",
       "            \" (\": -4.468216,\n",
       "            \" and\": -3.9751968,\n",
       "            \",\": -0.065830536,\n",
       "            \".\": -4.367996\n",
       "          },\n",
       "          {\n",
       "            \" bo\": -4.171123,\n",
       "            \" ch\": -3.6237214,\n",
       "            \" crocod\": -3.955028,\n",
       "            \" k\": -3.500972,\n",
       "            \" p\": -4.196571\n",
       "          },\n",
       "          {\n",
       "            \" bear\": -0.014225849,\n",
       "            \" bears\": -5.1035886,\n",
       "            \" fox\": -6.331685,\n",
       "            \",\": -6.8095098,\n",
       "            \"bear\": -7.1099477\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.4583926,\n",
       "            \" (\": -5.667506,\n",
       "            \" and\": -4.135036,\n",
       "            \",\": -0.044318885,\n",
       "            \".\": -4.693489\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.0575037,\n",
       "            \" k\": -3.829366,\n",
       "            \" ko\": -4.074746,\n",
       "            \" pengu\": -3.5697606,\n",
       "            \" rh\": -4.166394\n",
       "          },\n",
       "          {\n",
       "            \" and\": -4.419304,\n",
       "            \" beetle\": -5.081089,\n",
       "            \" shark\": -2.7408144,\n",
       "            \",\": -0.13195816,\n",
       "            \".\": -4.921612\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.0380325,\n",
       "            \" k\": -3.877224,\n",
       "            \" ko\": -3.7928505,\n",
       "            \" lion\": -4.136715,\n",
       "            \" rh\": -3.964886\n",
       "          },\n",
       "          {\n",
       "            \" shark\": -0.0019558237,\n",
       "            \" sharks\": -8.954607,\n",
       "            \",\": -7.4247894,\n",
       "            \"hound\": -8.284052,\n",
       "            \"maid\": -8.095522\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.6500845,\n",
       "            \" (\": -6.4164886,\n",
       "            \" and\": -4.4491954,\n",
       "            \",\": -0.033893265,\n",
       "            \".\": -4.739036\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -3.9728327,\n",
       "            \" crocod\": -4.034974,\n",
       "            \" k\": -3.991971,\n",
       "            \" oct\": -4.113759,\n",
       "            \" sea\": -4.0985384\n",
       "          },\n",
       "          {\n",
       "            \"al\": -3.579547,\n",
       "            \"ik\": -3.4253304,\n",
       "            \"ingo\": -2.0974765,\n",
       "            \"rom\": -1.74871,\n",
       "            \"ung\": -0.7513536\n",
       "          },\n",
       "          {\n",
       "            \"ai\": -4.9903107,\n",
       "            \"ek\": -5.6481457,\n",
       "            \"h\": -6.364941,\n",
       "            \"m\": -6.823235,\n",
       "            \"mat\": -0.022692049\n",
       "          },\n",
       "          {\n",
       "            \"ain\": -11.35672,\n",
       "            \"ia\": -9.027267,\n",
       "            \"ian\": -0.0014307739,\n",
       "            \"ians\": -6.757885,\n",
       "            \"ien\": -10.1078415\n",
       "          },\n",
       "          {\n",
       "            \" and\": -4.2357116,\n",
       "            \" dog\": -3.7633605,\n",
       "            \" pel\": -3.6493392,\n",
       "            \" to\": -4.3973727,\n",
       "            \",\": -0.16629173\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.078163,\n",
       "            \" crocod\": -4.183975,\n",
       "            \" k\": -4.061744,\n",
       "            \" p\": -4.1491737,\n",
       "            \" rh\": -4.239113\n",
       "          },\n",
       "          {\n",
       "            \" (\": -5.6126747,\n",
       "            \" and\": -4.5880704,\n",
       "            \" squirrel\": -5.209362,\n",
       "            \",\": -0.043404154,\n",
       "            \".\": -5.131058\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -3.962976,\n",
       "            \" crocod\": -4.1051574,\n",
       "            \" k\": -3.9178443,\n",
       "            \" rh\": -4.138456,\n",
       "            \" wolf\": -3.966905\n",
       "          },\n",
       "          {\n",
       "            \"anta\": -2.7003143,\n",
       "            \"antis\": -1.986554,\n",
       "            \"ink\": -1.876935,\n",
       "            \"ongo\": -0.6368836,\n",
       "            \"ule\": -3.5289812\n",
       "          },\n",
       "          {\n",
       "            \" and\": -6.5722604,\n",
       "            \" ray\": -0.11477536,\n",
       "            \" rays\": -4.4191537,\n",
       "            \",\": -2.5009332,\n",
       "            \"-\": -5.4266305\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.679745,\n",
       "            \" (\": -6.6606297,\n",
       "            \" and\": -4.2791376,\n",
       "            \",\": -0.036263555,\n",
       "            \".\": -4.6071215\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.0751367,\n",
       "            \" crocod\": -3.9974582,\n",
       "            \" k\": -4.119769,\n",
       "            \" oct\": -3.847632,\n",
       "            \" sea\": -3.891417\n",
       "          },\n",
       "          {\n",
       "            \" and\": -4.748264,\n",
       "            \",\": -0.14003736,\n",
       "            \"-\": -3.2303312,\n",
       "            \"bill\": -3.0559576,\n",
       "            \"ling\": -4.830108\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.075276,\n",
       "            \" dolphin\": -4.180439,\n",
       "            \" k\": -3.9142268,\n",
       "            \" oct\": -4.1988297,\n",
       "            \" pengu\": -4.236859\n",
       "          },\n",
       "          {\n",
       "            \"eb\": -5.355209,\n",
       "            \"ebra\": -0.014937819,\n",
       "            \"oop\": -8.266362,\n",
       "            \"or\": -5.2267942,\n",
       "            \"orse\": -6.1317854\n",
       "          },\n",
       "          {\n",
       "            \" and\": -4.3025484,\n",
       "            \" fish\": -4.2293444,\n",
       "            \" shark\": -3.5467918,\n",
       "            \",\": -0.114743136,\n",
       "            \"fish\": -4.2086306\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -6.323572,\n",
       "            \" (\": -6.064705,\n",
       "            \" and\": -4.8397274,\n",
       "            \",\": -0.024931183,\n",
       "            \".\": -5.045122\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.06386,\n",
       "            \" crocod\": -3.951197,\n",
       "            \" gir\": -4.138899,\n",
       "            \" k\": -4.0848064,\n",
       "            \" sea\": -4.2417736\n",
       "          },\n",
       "          {\n",
       "            \"ech\": -2.792793,\n",
       "            \"ek\": -5.41103,\n",
       "            \"m\": -2.7273903,\n",
       "            \"mur\": -1.5783308,\n",
       "            \"opard\": -0.44610217\n",
       "          },\n",
       "          {\n",
       "            \" frog\": -4.485518,\n",
       "            \" ge\": -3.137827,\n",
       "            \" seal\": -0.15503156,\n",
       "            \" shark\": -4.004378,\n",
       "            \",\": -2.970282\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.7418656,\n",
       "            \" (\": -6.6221337,\n",
       "            \" and\": -4.54069,\n",
       "            \",\": -0.032851096,\n",
       "            \".\": -4.5411744\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.022497,\n",
       "            \" elephant\": -3.9985292,\n",
       "            \" k\": -4.0585494,\n",
       "            \" pengu\": -4.0557036,\n",
       "            \" sea\": -4.0840774\n",
       "          },\n",
       "          {\n",
       "            \"al\": -6.1647286,\n",
       "            \"ala\": -0.0026921064,\n",
       "            \"alo\": -10.701521,\n",
       "            \"el\": -7.79497,\n",
       "            \"osh\": -11.195399\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.6148005,\n",
       "            \" and\": -4.050367,\n",
       "            \" bear\": -3.659746,\n",
       "            \",\": -0.06500411,\n",
       "            \".\": -4.8942585\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -3.9807293,\n",
       "            \" crocod\": -4.054483,\n",
       "            \" k\": -3.7665496,\n",
       "            \" pengu\": -4.011785,\n",
       "            \" sea\": -4.260919\n",
       "          },\n",
       "          {\n",
       "            \"eb\": -8.896967,\n",
       "            \"ed\": -5.8820624,\n",
       "            \"eve\": -9.020322,\n",
       "            \"ind\": -0.004857316,\n",
       "            \"x\": -8.135709\n",
       "          },\n",
       "          {\n",
       "            \"e\": -10.760218,\n",
       "            \"ee\": -11.335043,\n",
       "            \"eer\": -0.0008873215,\n",
       "            \"eers\": -7.1621685,\n",
       "            \"oor\": -12.018999\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.216151,\n",
       "            \" (\": -6.198806,\n",
       "            \" and\": -4.3624563,\n",
       "            \",\": -0.037688397,\n",
       "            \".\": -4.9840384\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.2195544,\n",
       "            \" gir\": -4.2676005,\n",
       "            \" k\": -3.9963756,\n",
       "            \" p\": -4.181232,\n",
       "            \" pengu\": -4.0084453\n",
       "          },\n",
       "          {\n",
       "            \" bat\": -3.0606463,\n",
       "            \" bird\": -3.2855878,\n",
       "            \" cat\": -0.41800743,\n",
       "            \" owl\": -2.561047,\n",
       "            \" spider\": -2.5800405\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.3826613,\n",
       "            \" (\": -5.7048965,\n",
       "            \" and\": -4.7034507,\n",
       "            \",\": -0.031991612,\n",
       "            \".\": -4.832174\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.2437005,\n",
       "            \" k\": -4.0423875,\n",
       "            \" p\": -4.2199273,\n",
       "            \" pengu\": -4.133284,\n",
       "            \" rh\": -4.3443666\n",
       "          },\n",
       "          {\n",
       "            \" bird\": -3.4158998,\n",
       "            \" birds\": -8.990213,\n",
       "            \"-\": -7.8478756,\n",
       "            \"bird\": -0.03595587,\n",
       "            \"birds\": -6.846335\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.48547,\n",
       "            \"\\n\\n\": -6.9410133,\n",
       "            \" and\": -4.5174446,\n",
       "            \",\": -0.029274143,\n",
       "            \".\": -5.0717735\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.2401705,\n",
       "            \" gir\": -4.1381655,\n",
       "            \" k\": -4.07533,\n",
       "            \" p\": -4.14631,\n",
       "            \" pengu\": -4.2415056\n",
       "          },\n",
       "          {\n",
       "            \" cat\": -1.6254553,\n",
       "            \" child\": -3.1843693,\n",
       "            \" dog\": -2.2878814,\n",
       "            \" goat\": -3.2200136,\n",
       "            \" pig\": -0.81681573\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.420304,\n",
       "            \" (\": -5.524243,\n",
       "            \" and\": -4.7263727,\n",
       "            \",\": -0.03496258,\n",
       "            \".\": -4.7052317\n",
       "          },\n",
       "          {\n",
       "            \" crocod\": -4.374295,\n",
       "            \" k\": -4.210073,\n",
       "            \" p\": -4.238187,\n",
       "            \" pengu\": -4.4601874,\n",
       "            \" tiger\": -4.1238112\n",
       "          },\n",
       "          {\n",
       "            \"co\": -5.377092,\n",
       "            \"con\": -7.5034113,\n",
       "            \"coon\": -0.095628284,\n",
       "            \"oon\": -2.4652,\n",
       "            \"oons\": -8.543775\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -6.196684,\n",
       "            \" and\": -4.90087,\n",
       "            \" dog\": -4.4607754,\n",
       "            \",\": -0.033689998,\n",
       "            \".\": -5.0204835\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.4714756,\n",
       "            \" (\": -5.367659,\n",
       "            \" and\": -4.839995,\n",
       "            \",\": -0.03359451,\n",
       "            \".\": -4.670351\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.383227,\n",
       "            \" k\": -4.103537,\n",
       "            \" p\": -4.248259,\n",
       "            \" pengu\": -4.390452,\n",
       "            \" rabbit\": -4.550257\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.8424463,\n",
       "            \" and\": -4.6966453,\n",
       "            \" monkey\": -5.8612456,\n",
       "            \",\": -0.030118646,\n",
       "            \".\": -4.938501\n",
       "          },\n",
       "          {\n",
       "            \" bat\": -4.423452,\n",
       "            \" ch\": -4.2880106,\n",
       "            \" k\": -4.1230745,\n",
       "            \" p\": -4.251767,\n",
       "            \" pengu\": -4.16681\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.6816597,\n",
       "            \" (\": -5.67564,\n",
       "            \" and\": -4.375054,\n",
       "            \",\": -0.035687193,\n",
       "            \".\": -4.9856153\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.294043,\n",
       "            \" k\": -4.068133,\n",
       "            \" p\": -4.223754,\n",
       "            \" pengu\": -3.9243343,\n",
       "            \" sea\": -4.3656836\n",
       "          },\n",
       "          {\n",
       "            \"agh\": -6.0402822,\n",
       "            \"eg\": -4.563016,\n",
       "            \"ilt\": -5.265366,\n",
       "            \"ork\": -0.11248856,\n",
       "            \"ur\": -2.7234123\n",
       "          },\n",
       "          {\n",
       "            \"ge\": -9.361103,\n",
       "            \"geon\": -0.003167718,\n",
       "            \"geons\": -6.0724998,\n",
       "            \"kie\": -9.22161,\n",
       "            \"m\": -9.21774\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.7542925,\n",
       "            \" and\": -4.66044,\n",
       "            \" fish\": -6.3393335,\n",
       "            \",\": -0.028791364,\n",
       "            \".\": -5.104112\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.355642,\n",
       "            \" k\": -4.1259627,\n",
       "            \" p\": -4.146375,\n",
       "            \" pengu\": -4.2973533,\n",
       "            \" sea\": -4.0469985\n",
       "          },\n",
       "          {\n",
       "            \"at\": -6.4697666,\n",
       "            \"bler\": -3.5739613,\n",
       "            \"bon\": -6.388265,\n",
       "            \"horse\": -7.5319595,\n",
       "            \"th\": -0.039995294\n",
       "          },\n",
       "          {\n",
       "            \"of\": -11.420256,\n",
       "            \"og\": -0.0013789642,\n",
       "            \"ogg\": -10.9065,\n",
       "            \"ogs\": -6.753698,\n",
       "            \"ox\": -11.110067\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.890095,\n",
       "            \" (\": -7.0214615,\n",
       "            \" and\": -4.786347,\n",
       "            \",\": -0.02280485,\n",
       "            \".\": -5.2188993\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.353088,\n",
       "            \" gir\": -4.4434543,\n",
       "            \" k\": -3.981559,\n",
       "            \" p\": -4.2490573,\n",
       "            \" tiger\": -4.423503\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -6.031941,\n",
       "            \" (\": -6.933351,\n",
       "            \" and\": -4.8511786,\n",
       "            \",\": -0.020909889,\n",
       "            \".\": -5.4477015\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.1446447,\n",
       "            \" k\": -4.0189734,\n",
       "            \" p\": -4.038501,\n",
       "            \" pengu\": -4.2636747,\n",
       "            \" tiger\": -4.009692\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.6357965,\n",
       "            \" and\": -4.5658693,\n",
       "            \" shark\": -5.4118395,\n",
       "            \",\": -0.03620997,\n",
       "            \".\": -5.049294\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.1929154,\n",
       "            \" k\": -4.1133485,\n",
       "            \" p\": -4.1841187,\n",
       "            \" sea\": -4.348536,\n",
       "            \" tiger\": -4.394461\n",
       "          },\n",
       "          {\n",
       "            \",\": -7.1340585,\n",
       "            \"alt\": -7.0563993,\n",
       "            \"ia\": -6.083525,\n",
       "            \"ra\": -0.014876471,\n",
       "            \"ras\": -4.7378416\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -6.663321,\n",
       "            \" and\": -5.202361,\n",
       "            \" snake\": -5.2084074,\n",
       "            \",\": -0.023764873,\n",
       "            \".\": -5.834388\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.322573,\n",
       "            \" crocod\": -4.3192124,\n",
       "            \" elephant\": -4.3000436,\n",
       "            \" k\": -3.9954817,\n",
       "            \" p\": -4.179766\n",
       "          },\n",
       "          {\n",
       "            \" fish\": -0.82976675,\n",
       "            \" fox\": -1.76996,\n",
       "            \" le\": -2.1703162,\n",
       "            \" squirrel\": -1.7563605,\n",
       "            \"fish\": -3.757867\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -6.4985895,\n",
       "            \" (\": -6.84834,\n",
       "            \" and\": -5.4729357,\n",
       "            \",\": -0.013802909,\n",
       "            \".\": -5.970895\n",
       "          },\n",
       "          {\n",
       "            \" k\": -4.0763016,\n",
       "            \" oct\": -4.1825027,\n",
       "            \" p\": -4.186283,\n",
       "            \" pengu\": -4.269161,\n",
       "            \" sea\": -4.1001663\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -6.723988,\n",
       "            \" (\": -6.613833,\n",
       "            \" and\": -4.5705934,\n",
       "            \",\": -0.027514355,\n",
       "            \".\": -5.493293\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.0733886,\n",
       "            \" jelly\": -3.9954467,\n",
       "            \" oct\": -3.4497275,\n",
       "            \" sea\": -3.7922797,\n",
       "            \" squid\": -3.8213553\n",
       "          },\n",
       "          {\n",
       "            \" sk\": -1.298391,\n",
       "            \" snail\": -2.225946,\n",
       "            \" turtle\": -1.1079059,\n",
       "            \",\": -4.2309966,\n",
       "            \"sk\": -1.8357978\n",
       "          },\n",
       "          {\n",
       "            \"ater\": -0.011430941,\n",
       "            \"aters\": -5.7476254,\n",
       "            \"ates\": -7.168073,\n",
       "            \"immer\": -5.3469143,\n",
       "            \"ipper\": -6.617531\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -5.9168763,\n",
       "            \" (\": -6.151278,\n",
       "            \" and\": -4.7019067,\n",
       "            \",\": -0.029585853,\n",
       "            \".\": -5.2191725\n",
       "          },\n",
       "          {\n",
       "            \" ch\": -4.402035,\n",
       "            \" k\": -4.229119,\n",
       "            \" oct\": -4.347409,\n",
       "            \" p\": -4.2219777,\n",
       "            \" sea\": -3.8749623\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"text\": \"A list of animal seen in the wild: lizard, robin, rattlesnake, leopard, elephant seal, newt, panther, jaguar, toucan, sperm whale, weasel, turkey, platypus, lemur, pangolin, caterpillar, sawfish, stick insect, hare, barracuda, dingo, gecko, moth, hippo, sloth, earwig, cuscus, polar bear, tiger, nurse shark, dalmatian, fox, manta ray, duck, zebra shark, leopard seal, koala, reindeer, fishing cat, hummingbird, feral cat, raccoon dog, owl, dolphin, sturgeon, warthog, goose, salmon, cobra, flying fish, sponge, pond skater, fox\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1638839946,\n",
       "  \"id\": \"cmpl-4CJQIdgwx3Ho7URppQw1p937HIUnO\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    /1\\1636268284.341195_4.956604244099436_0.5188886542785021_1.8400338803940575_0.8825586952170268_0.595336433300244_0_1000000000.0_gpt3.data\n",
      "1\n",
      "    /2\\1636268256.266317_6.6703860146045875_0.4489318877690332_1.3284938330305758_1.9403679245767413_0.5572170319786667_0_1000000000.0_gpt3.data\n",
      "2\n",
      "    /3\\1636266407.8010678_1.4783297909920083_0.8855937304270441_1.9876758761468394_1.8518383064064967_0.3587968155192327_0_1000000000.0_gpt3.data\n",
      "    /3\\1636266090.2597322_6.579201777236715_0.8810398693318532_1.784795391339553_1.7760031716489622_1.0819171739326834_0_1000000000.0_gpt3.data\n",
      "    /3\\1636265992.1801705_8.63363609592445_0.7821340984831353_0.10888085733935234_1.4963612487286735_1.8010559835469186_0_1000000000.0_gpt3.data\n",
      "    /3\\1636265953.8956106_4.395114940896341_0.8898429068130744_0.23916636215957687_0.47491010945872425_0.8609274102796161_0_1000000000.0_gpt3.data\n",
      "    /3\\1636265614.752078_4.090586336488145_0.729975393232722_0.24800887703311952_1.4238106668462005_0.05449816410386199_0_1000000000.0_gpt3.data\n",
      "    /3\\1636265314.2292068_5.68129362657311_0.6823829249690215_0.12492172383056012_1.2338630994562552_1.3614514924749073_0_1000000000.0_gpt3.data\n",
      "    /3\\1636265074.118686_9.220260047470072_0.20793838569087875_0.6653873050547702_0.19206351395176746_0.9180735853476016_0_1000000000.0_gpt3.data\n",
      "    /3\\1636264939.895834_2.520189377930881_0.7683892626025761_1.0044926928807012_1.6053129373814141_1.1469630055187283_0_1000000000.0_gpt3.data\n",
      "    /3\\1636264653.237863_8.351315975638158_0.11400166675336848_0.28007269369311205_1.7902093043918783_1.543752743167005_0_1000000000.0_gpt3.data\n",
      "    /3\\1636264301.1768947_2.208968846862086_0.7588940254376444_0.9626431762850698_1.136984302798026_0.3299121135006109_0_1000000000.0_gpt3.data\n",
      "    /3\\1636264141.155075_7.866181881981212_0.21495576292040847_1.2673973615221916_1.3545076504620772_1.931696662711552_0_1000000000.0_gpt3.data\n",
      "    /3\\1636263895.908299_1.8199849544522921_0.9767881314926573_1.6178956748671054_1.8242493534700481_1.6506701755925026_0_1000000000.0_gpt3.data\n",
      "    /3\\1636263844.4469965_9.338470580920408_0.9263252504113209_1.4974739916447186_0.37681256775610406_0.7862492024600707_0_1000000000.0_gpt3.data\n",
      "    /3\\1635818275.1711164_2.1729014488308054_0.798265832818612_0.6356931334018906_1.8387650273499132_0.5459620623456678_0_1000000000.0_gpt3.data\n",
      "    /3\\1635818263.935042_1.9908076088125162_0.12474914887218364_0.4952918743378872_0.17129640276275393_1.0935997862808726_0_1000000000.0_gpt3.data\n",
      "    /3\\1635818219.782608_7.098692007041897_0.45319299528991425_0.12817964117658243_1.4320894756623788_0.1025575928504121_0_1000000000.0_gpt3.data\n",
      "    /3\\1635818105.0657334_7.547472460470845_0.9536295226365858_0.41948655072398844_0.4555341701095439_0.21155837358757812_0_1000000000.0_gpt3.data\n",
      "    /3\\1635817903.9803498_5.796809710899531_0.10647508598087774_1.3888243461790284_0.32236852004487093_0.47286917162872233_0_1000000000.0_gpt3.data\n",
      "    /3\\1635817879.8222516_1.3544751191500737_0.9841144928704664_0.45194836091064317_1.8597293576205651_1.6625772184290335_0_1000000000.0_gpt3.data\n",
      "    /3\\1635817846.3514175_0.7110603736314697_0.27446568717430075_1.027200089324521_0.08965295194171152_1.8713888918764812_0_1000000000.0_gpt3.data\n",
      "    /3\\1635231924.2175694_7.827496177058414_0.2822626683143319_1.9715314863157969_1.4155431053726697_0.18412043942110223_0_1000000000.0_gpt3.data\n",
      "3\n",
      "    /4\\1636268295.260976_2.1981152905161796_0.07626055469474419_0.042183404443855994_0.7024728879061402_1.969874382495666_0_1000000000.0_gpt3.data\n",
      "4\n",
      "    /5\\1636268266.328394_2.4990235788076993_0.6856387851721889_0.11366499501264446_0.023690554473677183_0.7023375984278706_0_1000000000.0_gpt3.data\n",
      "5\n",
      "    /6\\1636266385.7341132_7.825628229431545_0.6247230765113567_1.9403157994364821_1.1963851372608514_0.5913883701972853_0_1000000000.0_gpt3.data\n",
      "    /6\\1636265744.6495037_7.317243883491557_0.14713164713266463_1.9600277947439553_0.7166160153381829_0.046533964382164505_0_1000000000.0_gpt3.data\n",
      "    /6\\1636265734.041887_8.592732369641416_0.25731107988777246_0.8799054482986897_1.5084196305349196_1.0834393763594479_0_1000000000.0_gpt3.data\n",
      "    /6\\1636265655.113082_3.747775442619435_0.9330988394349253_0.6044327235335293_0.26318178340788756_0.4170826001974046_0_1000000000.0_gpt3.data\n",
      "    /6\\1636265541.318569_8.081594911278799_0.3714650651910464_1.7510950280589197_1.3687229457962267_1.7735548816290554_0_1000000000.0_gpt3.data\n",
      "    /6\\1636265183.792225_5.6661787726053605_0.25647368248577274_1.863351705343865_1.6609868458506827_0.15646173937201802_0_1000000000.0_gpt3.data\n",
      "    /6\\1636265011.1242435_3.8185968194910767_0.4393381490714987_0.2278566853569462_0.8007818902871042_0.8611174215559059_0_1000000000.0_gpt3.data\n",
      "    /6\\1636264975.7578754_1.695346162391799_0.7225463531964113_1.1972430809407768_1.7172223675922276_0.1013898269544431_0_1000000000.0_gpt3.data\n",
      "    /6\\1636264849.4717877_1.1560996492579814_0.39925691156895615_1.080470201563279_0.31322365581108724_0.7104486837702813_0_1000000000.0_gpt3.data\n",
      "    /6\\1636264499.16712_8.104312921521617_0.2945254939174189_1.9834511605070393_1.1234918636258013_0.7549520432910943_0_1000000000.0_gpt3.data\n",
      "    /6\\1636264486.7633095_3.966094525866013_0.31108513701841345_1.2248667641121633_1.668191207871406_1.8496832472488152_0_1000000000.0_gpt3.data\n",
      "    /6\\1636264202.601659_8.229110734549522_0.26839276350254637_0.7255516022063373_0.6421956378528384_0.5996213497115823_0_1000000000.0_gpt3.data\n",
      "    /6\\1636264099.096614_7.217666316187997_0.12274405412919596_1.408334156652879_1.8740733376529302_0.7308947198622622_0_1000000000.0_gpt3.data\n",
      "    /6\\1636264071.772726_6.31873919964847_0.41914096608614626_1.8126923333386815_0.15218220800378446_0.2546972064577213_0_1000000000.0_gpt3.data\n",
      "    /6\\1636264046.7008128_8.776354050041396_0.7607605971217422_1.9378188281945272_0.5876649872533473_0.7626963318289615_0_1000000000.0_gpt3.data\n",
      "    /6\\1636263907.0435026_4.626316553971769_0.058880496086629236_0.41019847874043885_1.3834974374310456_1.663964742549707_0_1000000000.0_gpt3.data\n",
      "    /6\\1636263830.1642137_5.228907502974693_0.054382665428371016_1.2201301229546402_1.0006532401077584_1.8900628580263528_0_1000000000.0_gpt3.data\n",
      "    /6\\1635818769.0084877_3.9118584763080104_0.7640157138779065_1.4090663771800114_1.7316949210924941_1.1678504499812512_0_1000000000.0_gpt3.data\n",
      "    /6\\1635818712.6655972_8.933538433844717_0.6808162414515467_0.2043703385964333_1.3910986341630032_1.030706996355106_0_1000000000.0_gpt3.data\n",
      "    /6\\1635818596.0168822_0.5307396546603895_0.6632709071966739_1.7022110129330823_0.9374645825316159_1.8737829234329444_0_1000000000.0_gpt3.data\n",
      "    /6\\1635818475.897873_6.275347509466619_0.11946052998762337_1.4320823098674245_1.5950013546628559_1.114861595862212_0_1000000000.0_gpt3.data\n",
      "    /6\\1635818439.709734_2.1112793350523122_0.43782783382243_0.8915215521565675_0.7015747570131683_0.855977917465579_0_1000000000.0_gpt3.data\n",
      "    /6\\1635818372.9381318_7.159152466183564_0.9045268659097467_0.5753242026557407_1.8093972613369618_0.3031973722791139_0_1000000000.0_gpt3.data\n",
      "    /6\\1635818069.583746_5.1294758229987405_0.7623684216107139_1.4330071001366684_0.5765519861474928_1.134461153983239_0_1000000000.0_gpt3.data\n",
      "    /6\\1635817778.7774217_7.802143116873544_0.17075233519331384_1.2368326018784224_1.0741539149796742_0.26424293377338715_0_1000000000.0_gpt3.data\n",
      "    /6\\1635817740.5218422_0.9583206865399867_0.747393964329377_0.2498154851726669_0.8681345942800094_0.9235380968766786_0_1000000000.0_gpt3.data\n",
      "    /6\\1635817688.7093587_2.8339009467367715_0.41205047465378064_1.659218319008174_0.7332850845911283_0.24431300640816334_0_1000000000.0_gpt3.data\n",
      "    /6\\1635230955.6665323_9.423809939689301_0.8090754059426459_0.20548091199666385_0.5892468905957085_0.43449560898925066_0_1000000000.0_gpt3.data\n",
      "    /6\\1635230824.1477501_6.760933455301577_0.1752940557539363_0.3232842963323021_1.9039001138450595_1.6015965685595708_0_1000000000.0_gpt3.data\n",
      "6\n",
      "    /7\\1636268307.9480286_6.918422929266105_0.004097319432802777_1.9550503931987453_0.39391232616665817_0.47805395663272576_0_1000000000.0_gpt3.data\n",
      "7\n",
      "    /8\\1636268443.823458_3.1740765342706636_0.8068406574842886_0.5277912690979504_0.8540617530054986_1.309253727002042_0_1000000000.0_gpt3.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    /8\\1636267823.9445562_3.843600339853026_0.0014426425008978918_0.11909795791104402_0.2058833895017207_1.173638995980926_0_1000000000.0_gpt3.data\n",
      "8\n",
      "    /9\\1636266257.8463109_7.76243081325919_0.8641623057984978_1.1143809194819314_1.3713417578742721_1.3694050974799052_0_1000000000.0_gpt3.data\n",
      "    /9\\1636265979.702557_5.698525776110642_0.16279415911288156_0.07680458041133424_0.3351396857529587_1.734827633381863_0_1000000000.0_gpt3.data\n",
      "    /9\\1636265861.6424582_1.2818706199657282_0.95831539865926_1.4143406886405743_0.4029647032811794_0.1688444156734381_0_1000000000.0_gpt3.data\n",
      "    /9\\1636265468.3837256_4.917912208706328_0.7164823251084211_1.9002054407093063_1.476157855471318_0.5458838523636238_0_1000000000.0_gpt3.data\n",
      "    /9\\1636264723.101925_9.170957459839762_0.12485319062312907_1.3264360726313325_0.6289916683119106_0.5682513762975179_0_1000000000.0_gpt3.data\n",
      "    /9\\1636264546.8076446_7.648350118936227_0.7946757164647656_1.8758285043805545_1.4310012191582027_0.10979618722704632_0_1000000000.0_gpt3.data\n",
      "    /9\\1636264377.1615775_5.500316047153929_0.5642360588031048_0.2869068324213168_1.7916516308007229_1.1296558120790916_0_1000000000.0_gpt3.data\n",
      "    /9\\1636264111.4485643_3.5422531016216867_0.7473557945805728_1.440627000682956_1.6323861802015875_1.7743924917359486_0_1000000000.0_gpt3.data\n",
      "    /9\\1636263607.0546467_6.8559775939595475_0.3493154695417058_1.8038552734198028_1.4120644523552632_1.2442961486600619_0_1000000000.0_gpt3.data\n",
      "    /9\\1635818780.4814467_2.8258335307164915_0.5608167989502408_0.11882847558937167_1.1628241865597353_1.3641227334329329_0_1000000000.0_gpt3.data\n",
      "    /9\\1635818581.4980476_4.601699731000689_0.9258837439945007_0.5913027606956228_1.0016432962772326_1.0488298032695702_0_1000000000.0_gpt3.data\n",
      "    /9\\1635818521.8180726_2.333628780717009_0.941629456468095_1.552114726811_1.9070492990913404_1.1526173937246842_0_1000000000.0_gpt3.data\n",
      "    /9\\1635817946.3036687_3.2484137496552754_0.7928131395653232_0.9180031719210526_0.059684587780131304_1.7150310042123778_0_1000000000.0_gpt3.data\n",
      "    /9\\1635817925.9433763_4.644913598057439_0.4365899540141402_1.5445977358250758_1.4598285520120116_0.8052563768679222_0_1000000000.0_gpt3.data\n",
      "    /9\\1635230852.8391159_4.666032603599134_0.6474429332740465_1.4715703392216533_0.4598081561416778_0.5654290162762463_0_1000000000.0_gpt3.data\n",
      "9\n",
      "    /10\\1636268422.7458565_1.3486726821967934_0.6043780184456445_0.6136761659597534_0.4043209194153372_1.6889529629776228_0_1000000000.0_gpt3.data\n",
      "    /10\\1636268354.0277307_3.6913964955971665_0.4846522026576065_0.3494487546293096_1.6721570828245493_1.198581792928149_0_1000000000.0_gpt3.data\n",
      "10\n",
      "    /11\\1636267814.1158564_7.25220596942224_0.7421313661475719_0.9193735411017726_1.7544003662784848_1.0471771952603586_0_1000000000.0_gpt3.data\n",
      "11\n",
      "    /12\\1636266221.0976412_6.331779980118173_0.7102914308295531_0.12464878248525842_0.6167739151708105_1.5322465358712196_0_1000000000.0_gpt3.data\n",
      "    /12\\1636266068.3603303_1.42154767078738_0.0645902258389836_1.9610937496148222_1.1747641943600269_0.006836548625832606_0_1000000000.0_gpt3.data\n",
      "    /12\\1636265478.8038437_2.9138974820670076_0.5141168496146297_0.4306479945104924_1.2239676412355973_1.0444963255185928_0_1000000000.0_gpt3.data\n",
      "    /12\\1636265279.216891_5.226284944567439_0.3541942539916424_0.9403349923906852_1.2388369559030326_0.37982257791070073_0_1000000000.0_gpt3.data\n",
      "    /12\\1636265249.4355788_4.1468947685867885_0.45076368950795814_1.170188280053885_0.3684753939141976_0.10744344494441549_0_1000000000.0_gpt3.data\n",
      "    /12\\1636265146.1409721_3.036642004195077_0.07575471876966004_0.8420445588531342_1.4171257878066776_1.9616414335698191_0_1000000000.0_gpt3.data\n",
      "    /12\\1636264949.7644277_2.619975145073772_0.09382181051131784_0.5453720541680147_0.6415033759875786_1.6619540004342945_0_1000000000.0_gpt3.data\n",
      "    /12\\1636264769.0410013_2.0615874197993205_0.7190772560004772_1.9987724665254942_1.7113250595386187_0.37887071933271477_0_1000000000.0_gpt3.data\n",
      "    /12\\1636264559.7151077_3.5229550275861268_0.5812042779456293_0.40131890623565414_1.602567988487565_1.7586300732970144_0_1000000000.0_gpt3.data\n",
      "    /12\\1636264409.137019_7.098986627952954_0.3130671201791779_1.428588076381818_1.599607743373164_1.9494105474177952_0_1000000000.0_gpt3.data\n",
      "    /12\\1636264125.3862686_9.181117544192372_0.17286406591477674_1.2405488795185786_0.05441806538430938_1.9543780624659346_0_1000000000.0_gpt3.data\n",
      "    /12\\1636263757.9917736_3.314730656286208_0.31770951898939614_0.5645595781569911_1.6749678900435068_0.61788381719065_0_1000000000.0_gpt3.data\n",
      "    /12\\1636263656.3726828_5.453002892334651_0.14282538095372443_1.5305947498102435_1.604137130824957_1.8556403640211334_0_1000000000.0_gpt3.data\n",
      "    /12\\1635818634.187726_8.233088761583526_0.8724511667365086_1.4535732322722064_0.6691534162803638_0.8515467074928711_0_1000000000.0_gpt3.data\n",
      "    /12\\1635818553.502659_2.0919950934393268_0.4084446819321401_0.4466776273455287_0.1700405170729249_0.9874675880948163_0_1000000000.0_gpt3.data\n",
      "    /12\\1635818353.1134212_3.3970142415549422_0.35458402711964276_1.849333839870238_0.09754959648057282_0.18490184469770088_0_1000000000.0_gpt3.data\n",
      "    /12\\1635818230.509571_3.1838182970433_0.023712149677752703_1.2043868290926711_1.916058978584071_1.9029081256607512_0_1000000000.0_gpt3.data\n",
      "    /12\\1635817978.2660427_2.007427354442063_0.9856839310370095_0.7689937351186431_1.9097565292913414_0.3405739250210438_0_1000000000.0_gpt3.data\n",
      "    /12\\1635817402.033441_2.93458940820687_0.10519921659349951_1.2180186740917982_0.4091682829420298_1.8240697023675614_0_1000000000.0_gpt3.data\n",
      "    /12\\1635230670.8950417_2.2761643291444975_0.3858665526953844_1.1853843635915642_0.7587657492120943_1.7809127598849803_0_1000000000.0_gpt3.data\n",
      "    /12\\1635230000.0600371_2.634544369350738_0.565604024034079_1.1897705138627501_0.6566332188015571_1.9673233482347772_0_1000000000.0_gpt3.data\n",
      "12\n",
      "    /13\\1636266296.5716906_6.097122047964678_0.3303922568727854_1.25956667464665_0.6677575971827938_1.512296668103562_0_1000000000.0_gpt3.data\n",
      "    /13\\1636265830.0400193_1.7550334546632467_0.4892654520308314_0.21934660375688522_1.2058031147252237_0.33856038059341054_0_1000000000.0_gpt3.data\n",
      "    /13\\1636265797.4093306_7.020827706360384_0.1753526979635601_0.5433445438548853_0.3716217112910378_1.9925117577181448_0_1000000000.0_gpt3.data\n",
      "    /13\\1636265754.7544663_2.590969056978632_0.6521889719886809_0.26511756705694434_0.026887084741857414_0.15553784798013837_0_1000000000.0_gpt3.data\n",
      "    /13\\1636265101.5064027_4.626404244799581_0.9620381750706883_0.48910424359319404_1.504272897507946_0.4185238882621538_0_1000000000.0_gpt3.data\n",
      "    /13\\1636264840.0729377_5.6475238252159405_0.060462719778166855_0.6268028058390761_1.9706422582934755_1.0121618509306147_0_1000000000.0_gpt3.data\n",
      "    /13\\1636264697.4535522_6.078470847404851_0.5302056666047358_0.730036559247733_0.6179909385865225_0.9592857223740137_0_1000000000.0_gpt3.data\n",
      "    /13\\1636264335.2168117_6.334080838372341_0.6107049631507361_1.537075782624854_1.655906625140961_1.0489011559492765_0_1000000000.0_gpt3.data\n",
      "    /13\\1636264316.9875894_9.027177062024501_0.7223952867774149_1.0297007340934208_1.525401073893874_1.2540529208162614_0_1000000000.0_gpt3.data\n",
      "    /13\\1636263415.4323816_1.786454208472846_0.559244919500048_1.3661759747323712_0.829589543257796_0.6297209909708115_0_1000000000.0_gpt3.data\n",
      "    /13\\1636263405.3353994_2.9007673214885856_0.49850054092141843_1.6024458748242767_1.362563682941339_0.1425518696176562_0_1000000000.0_gpt3.data\n",
      "    /13\\1635818867.740466_3.4510167821470668_0.6349320670609276_1.315392849818395_1.188564961849256_1.3218965503675897_0_1000000000.0_gpt3.data\n",
      "    /13\\1635818794.7319994_9.293360842078755_0.35051455865638137_1.3104147031381335_0.25501279966787505_1.5036242787637122_0_1000000000.0_gpt3.data\n",
      "    /13\\1635818197.294039_6.992219340771377_0.28219349999134985_1.6504869647842233_0.8640483522745186_1.0026653561798837_0_1000000000.0_gpt3.data\n",
      "    /13\\1635818122.3421726_4.382981343545119_0.38850583383065995_1.5780442669022878_0.05745757776342053_0.051231572784462553_0_1000000000.0_gpt3.data\n",
      "    /13\\1635818091.8100734_9.428226770153266_0.15486846188791456_0.220626665563323_1.805411748309415_0.8981804090300283_0_1000000000.0_gpt3.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    /13\\1635817590.8554556_2.7836358265256216_0.8908710646890612_1.984027544875337_0.3675683390841493_1.7458746762556965_0_1000000000.0_gpt3.data\n",
      "    /13\\1635231820.938755_7.429972951287356_0.8755140320125568_1.420022850690058_1.6326751318066206_0.7098073862191683_0_1000000000.0_gpt3.data\n",
      "    /13\\1635231130.2095213_7.236813564844454_0.5567695204607009_0.4388521716748669_1.1852826583935745_1.764127383255621_0_1000000000.0_gpt3.data\n",
      "    /13\\1635231078.0933077_5.410704388043913_0.7550089603769894_0.1763013426481533_0.2876958689227296_1.0529286754254727_0_1000000000.0_gpt3.data\n",
      "13\n",
      "    /14\\1636268387.542054_7.037040188093646_0.5756724064364385_0.8627361774585983_1.38570927958998_1.3755635361558416_0_1000000000.0_gpt3.data\n",
      "14\n",
      "    /15\\1636266143.9251368_7.172470459324545_0.2608991816402273_0.7017727436656553_1.1514100068163635_0.21434649902235736_0_1000000000.0_gpt3.data\n",
      "    /15\\1636266075.936059_1.1252113386313614_0.04226874429844503_0.05370766639120018_1.6380603936433968_1.9897119732179471_0_1000000000.0_gpt3.data\n",
      "    /15\\1636266049.5047839_3.24747311588856_0.08357303754066987_1.9500791922838194_1.2147899981046377_0.5382428664192016_0_1000000000.0_gpt3.data\n",
      "    /15\\1636265850.588037_3.690364906680859_0.6036394373613073_1.4863503151457533_1.0492416081937226_1.1315698734764088_0_1000000000.0_gpt3.data\n",
      "    /15\\1636265686.3036232_6.7955775572214625_0.3248959886340736_0.5387971303064562_0.006829243865015711_1.315536724421282_0_1000000000.0_gpt3.data\n",
      "    /15\\1636265510.917914_3.3389409838621296_0.19471999546187047_1.9406043274708513_0.15219185319224127_0.20456929934479495_0_1000000000.0_gpt3.data\n",
      "    /15\\1636265386.008143_8.243367349702892_0.5031853445555973_0.08425555336018202_1.9980535581448886_1.650183472666667_0_1000000000.0_gpt3.data\n",
      "    /15\\1636264731.3698_0.5682995163867282_0.6614042787510531_0.1753960388697377_0.5565464758536289_1.4070831417712348_0_1000000000.0_gpt3.data\n",
      "    /15\\1636264685.4746048_4.271548477633889_0.2603006925957768_0.8172145858465474_0.3971282369882021_0.8809275987115888_0_1000000000.0_gpt3.data\n",
      "    /15\\1636263973.6592543_6.5252673931751595_0.5089706795752854_0.10832272831613136_1.4069674972575128_0.11023694246978666_0_1000000000.0_gpt3.data\n",
      "    /15\\1636263936.0409124_3.9308993205701537_0.7335779971456169_0.8514269389837475_1.85788607198232_1.5795576262023998_0_1000000000.0_gpt3.data\n",
      "    /15\\1636263924.805974_6.4886776328280975_0.5168476722381895_0.6725423159271626_1.7858309454472232_0.6072309005735959_0_1000000000.0_gpt3.data\n",
      "    /15\\1636263866.357369_3.7101484834358702_0.22192069893021688_1.6895653356924092_1.1742771221716337_1.5080555810903524_0_1000000000.0_gpt3.data\n",
      "    /15\\1636263682.069923_3.2463920424933863_0.831078039146103_1.687492043723916_1.7969708211035222_0.2802221035535579_0_1000000000.0_gpt3.data\n",
      "    /15\\1635818503.6564174_7.5783249817339495_0.46755335105033524_1.4892105243288845_0.42557688489347334_1.759032948753845_0_1000000000.0_gpt3.data\n",
      "    /15\\1635817703.5847208_7.5461478098536645_0.47270706313735794_1.3838914002581744_1.0104394741345122_0.2687951841753857_0_1000000000.0_gpt3.data\n",
      "    /15\\1635817652.0993936_5.4209247982511926_0.6135969371169273_0.3564381650629701_1.151100633229228_1.234380035018823_0_1000000000.0_gpt3.data\n",
      "    /15\\1635817414.3551478_8.754363554920289_0.8258634846394155_1.1934159219055605_1.4469776805522845_1.505194958693852_0_1000000000.0_gpt3.data\n",
      "    /15\\1635231144.295638_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data\n",
      "    /15\\1635230194.9128883_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data\n",
      "15\n",
      "    /16\\1636266396.4793613_3.323094232150394_0.7425785585864733_0.1938560151873175_0.2126642135278911_0.049489840647752414_0_1000000000.0_gpt3.data\n",
      "    /16\\1636266242.964132_6.36018298238452_0.07844237708554352_1.0392389522410508_1.3355848607829552_0.3248175514587448_0_1000000000.0_gpt3.data\n",
      "    /16\\1636265721.1613524_7.714187945715146_0.08779494155239448_0.3081594053048162_1.0661001863924522_0.6435345182306049_0_1000000000.0_gpt3.data\n",
      "    /16\\1636264753.0368242_6.528588218906993_0.19384860381735744_0.2138493326724303_0.7695116125488899_0.06443208856751381_0_1000000000.0_gpt3.data\n",
      "    /16\\1636264673.8836203_8.071727629073107_0.9858918991569493_0.45239137639709615_0.36268553392997305_1.4589274013464735_0_1000000000.0_gpt3.data\n",
      "    /16\\1636264584.1736631_5.216922413292656_0.2861449413359102_0.3568109651784652_0.11078313800247686_1.0277840138455625_0_1000000000.0_gpt3.data\n",
      "    /16\\1636264535.085012_8.209882215926996_0.40956794917915174_0.7415307023944093_1.7629631348580599_1.4576513911536806_0_1000000000.0_gpt3.data\n",
      "    /16\\1636264457.8397021_3.1337540286410412_0.4346847104355359_1.0644141082236611_1.3233565597659447_1.3436184279574133_0_1000000000.0_gpt3.data\n",
      "    /16\\1636264237.3087907_3.709809456238657_0.03272383309600265_0.8384733695782128_1.5864089797526557_0.559625080778515_0_1000000000.0_gpt3.data\n",
      "    /16\\1636264056.590351_3.2624792117205472_0.21606754472830592_1.959173472586357_1.5705535160049044_1.3656632746398245_0_1000000000.0_gpt3.data\n",
      "    /16\\1636263994.3788145_3.9103817774047225_0.7489557438697154_0.19284730659928948_0.29875765201316495_0.9145552384206208_0_1000000000.0_gpt3.data\n",
      "    /16\\1636263959.253802_7.045746350297894_0.2455792947365808_0.36429263211485635_0.0656144197346149_0.0697111481970909_0_1000000000.0_gpt3.data\n",
      "    /16\\1636263509.179537_4.818316012299142_0.940321681803856_1.2091605895689883_0.6462672578649844_0.9947500626844792_0_1000000000.0_gpt3.data\n",
      "    /16\\1635818886.6301444_7.893746116376257_0.6632811353680618_0.8720805355172391_0.551755865843818_0.943869585554854_0_1000000000.0_gpt3.data\n",
      "    /16\\1635818875.676339_1.421863879917494_0.529741719376561_1.6288752217490174_1.3823262499416777_0.510799040903938_0_1000000000.0_gpt3.data\n",
      "    /16\\1635818827.0982478_3.0918296171589947_0.6287490924723018_0.1403538746156081_0.047915741575158544_0.5295930687938066_0_1000000000.0_gpt3.data\n",
      "    /16\\1635818341.7741313_2.1323252324772692_0.7665174286395003_0.5501493224314716_1.2325190534397288_1.4406183046396706_0_1000000000.0_gpt3.data\n",
      "    /16\\1635817824.6148038_1.9466510867525675_0.685508859741014_0.46412200791785363_0.3486974323060392_0.5863677055765895_0_1000000000.0_gpt3.data\n",
      "    /16\\1635817793.779443_2.0926672399097823_0.30803167831895706_1.4632633853709658_1.6661566581988059_1.2091432520467122_0_1000000000.0_gpt3.data\n",
      "    /16\\1635817755.9323032_3.521899470875294_0.6336537166629185_0.47642666804300915_0.3047442514704506_1.9776896846231413_0_1000000000.0_gpt3.data\n",
      "    /16\\1635817665.7889385_2.9721515667640035_0.5223047644774825_1.2771449062069635_0.901741838709498_0.7753336922118506_0_1000000000.0_gpt3.data\n",
      "    /16\\1635817557.2794306_0.8472057048587394_0.2581909820778891_1.9694836208303825_1.8704526776502985_1.9785903155840339_0_1000000000.0_gpt3.data\n",
      "    /16\\1635230430.3166234_6.641664941364905_0.46426735663489765_1.1984616925804619_1.5514014748777676_1.8791199501468938_0_1000000000.0_gpt3.data\n",
      "16\n",
      "    /17\\1636266373.5646756_8.441893566207598_0.6257671738330294_0.5509122218904401_0.8134796176893011_1.950547265554013_0_1000000000.0_gpt3.data\n",
      "    /17\\1636266316.9312131_5.163576700765505_0.5005768457591224_0.3678634652184979_1.5735727798549979_0.13321236724515373_0_1000000000.0_gpt3.data\n",
      "    /17\\1636265941.5087547_6.859248982395177_0.3692483600584426_1.591418536556698_1.4789329942178457_1.0795386045067246_0_1000000000.0_gpt3.data\n",
      "    /17\\1636265767.288926_0.5846839749072217_0.36338759244024016_0.49841890228732283_1.9599360182608914_0.217588704043018_0_1000000000.0_gpt3.data\n",
      "    /17\\1636265293.0219517_7.714177991763544_0.5715414718764289_1.6026515303651612_1.038884846540058_1.292286254911929_0_1000000000.0_gpt3.data\n",
      "    /17\\1636265265.6192753_1.8636702463558774_0.5251283367840279_1.0828938869086022_1.2621998979311786_0.6923732107044966_0_1000000000.0_gpt3.data\n",
      "    /17\\1636265126.0766582_5.04266342724862_0.3943681225624617_1.813443059756642_1.5963838477893086_0.8199441189388263_0_1000000000.0_gpt3.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    /17\\1636265062.2624097_3.339297714322278_0.3045473894686623_1.1586839696469795_1.2970251503325512_1.7900309080049432_0_1000000000.0_gpt3.data\n",
      "    /17\\1636264711.792185_4.931715269084913_0.5717347506869458_0.757929635532331_1.6692738362880033_1.8782934101168793_0_1000000000.0_gpt3.data\n",
      "    /17\\1636264607.77551_4.753477888002891_0.31741062692429056_0.46174976802006423_1.178575437776471_0.13447260445263587_0_1000000000.0_gpt3.data\n",
      "    /17\\1636264086.165215_9.34039287679395_0.5337375752189903_1.7376509784926628_0.40073251537378574_1.9043959757184845_0_1000000000.0_gpt3.data\n",
      "    /17\\1636263720.4133253_3.543721191695376_0.2576694305040388_1.1961269816669098_0.4609078373266682_0.6403984672562446_0_1000000000.0_gpt3.data\n",
      "    /17\\1636263595.3828769_5.329849188095466_0.36288989526831145_0.7901186396837344_0.7815078095613506_0.604932890513366_0_1000000000.0_gpt3.data\n",
      "    /17\\1636263392.7131734_4.129274292215535_0.5690977819004593_1.561492458752256_1.957220922346987_0.09999109053672117_0_1000000000.0_gpt3.data\n",
      "    /17\\1635818948.9790268_4.854983641063494_0.7198220263874834_1.8992496041766733_1.418510733745435_1.521971144064962_0_1000000000.0_gpt3.data\n",
      "    /17\\1635818694.6351383_3.0287644604013693_0.4028420399947185_1.1022355157309747_1.4974311021864792_1.6271937677760049_0_1000000000.0_gpt3.data\n",
      "    /17\\1635818665.0958743_0.8390042738498107_0.5196605824642824_0.42242607225141315_1.9120913994665194_0.42259329215136154_0_1000000000.0_gpt3.data\n",
      "    /17\\1635818300.841716_7.038964682298078_0.8350173490599869_1.1914174039002121_0.47022387632021845_0.9958808404372976_0_1000000000.0_gpt3.data\n",
      "    /17\\1635818035.2232635_6.087237269810093_0.056677403191568755_1.605854172935696_1.61076542982727_1.9767852295772843_0_1000000000.0_gpt3.data\n",
      "    /17\\1635817999.365315_7.513491924902917_0.7129907598696411_1.8465495220406511_1.0151153966273343_1.1871089032918498_0_1000000000.0_gpt3.data\n",
      "    /17\\1635817892.2810276_5.087367702667709_0.4960915663772823_0.16944968516801448_0.24723741418359868_0.24810959484639872_0_1000000000.0_gpt3.data\n",
      "    /17\\1635817715.3478806_5.84707138483426_0.37263327889254705_0.6961447390058901_0.003032396487855804_1.6378499926851835_0_1000000000.0_gpt3.data\n",
      "    /17\\1635817630.4475477_4.16517359417365_0.5910738905884133_1.9651668061210203_0.31621154420559416_0.41707512880022035_0_1000000000.0_gpt3.data\n",
      "17\n",
      "    /18\\1636268468.5333405_5.383172731542481_0.3257247597981868_0.9696839300779064_0.8621295621978051_0.9090495137820325_0_1000000000.0_gpt3.data\n",
      "    /18\\1636268342.8386695_7.744671272887618_0.6768627286933181_1.2413228443995101_1.6980508154926672_0.7387251198736993_0_1000000000.0_gpt3.data\n",
      "18\n",
      "    /19\\1636268455.9789336_9.348044380596338_0.9702919885711441_1.0844211677147533_1.6897803128625597_0.016104471506370066_0_1000000000.0_gpt3.data\n",
      "    /19\\1636267840.3945403_6.671664539080371_0.2667659010824706_1.9641347982087323_1.5520068613725624_0.7724046548846462_0_1000000000.0_gpt3.data\n",
      "19\n",
      "    /20\\1636266350.8085663_6.021476270407486_0.73120334998878_1.5306478210779284_1.5168079318221817_0.6355240203692871_0_1000000000.0_gpt3.data\n",
      "    /20\\1636266306.7115586_4.67465826706198_0.014274985320947993_1.4843680344475163_1.7932367820597372_1.986005578045132_0_1000000000.0_gpt3.data\n",
      "    /20\\1636266276.225133_9.481901424346509_0.3450301587531133_1.5514387720774492_1.2009052305277366_0.10285240197477763_0_1000000000.0_gpt3.data\n",
      "    /20\\1636265665.0853987_1.5303654351072833_0.09785213783295875_1.2726608215918656_1.1260352814556622_1.1272686401080232_0_1000000000.0_gpt3.data\n",
      "    /20\\1636265638.9982014_5.561671792071387_0.18242316145932527_0.7564120465879949_0.09037579616148284_0.6848897264504779_0_1000000000.0_gpt3.data\n",
      "    /20\\1636265364.1207087_6.648519561577383_0.3411741904221239_0.7300532154665871_1.27088854772148_1.6829868439372453_0_1000000000.0_gpt3.data\n",
      "    /20\\1636264227.5698502_7.42561947228057_0.11989307870256766_0.03903850610356022_0.1422884677577998_1.5703547454239208_0_1000000000.0_gpt3.data\n",
      "    /20\\1636264165.9876294_8.561467787794097_0.30463411996389883_1.1395075550357872_1.8713089455328615_1.70878177105832_0_1000000000.0_gpt3.data\n",
      "    /20\\1636263948.0019073_9.330571147965442_0.4914374452662473_1.2044313848197103_0.5520558828443278_0.5887406238807249_0_1000000000.0_gpt3.data\n",
      "    /20\\1636263732.1070368_1.5800855735671226_0.30349091266908035_1.29816771230281_1.2537971505630985_0.41015887582939703_0_1000000000.0_gpt3.data\n",
      "    /20\\1636263698.3334062_8.222982674577146_0.4943998362317888_0.22637636227989621_0.16832183913926468_0.221586691836698_0_1000000000.0_gpt3.data\n",
      "    /20\\1636263617.5296173_2.196020139899783_0.07100577667888151_0.07179990959754949_1.1067568769198057_0.357582110678367_0_1000000000.0_gpt3.data\n",
      "    /20\\1636263431.9232564_1.9210174297808629_0.8230782524057552_1.9573891390180755_1.346754495145666_1.4035256312103128_0_1000000000.0_gpt3.data\n",
      "    /20\\1635818285.3240292_4.181820753734673_0.8010452893404826_0.03152597879516133_1.4197434107203217_0.5358553714171477_0_1000000000.0_gpt3.data\n",
      "    /20\\1635818081.1883535_4.5987441105032385_0.7078246945289776_0.19049392923034314_0.9086124966215787_1.5946136296028148_0_1000000000.0_gpt3.data\n",
      "    /20\\1635817603.2689295_7.888925145747876_0.8252997851476106_1.7712270515921356_1.4200924906419323_0.45507247872423084_0_1000000000.0_gpt3.data\n",
      "20\n",
      "    /21\\1636268324.2853143_3.5425005912882965_0.7431856202201718_0.5858933818789516_1.715417867147334_0.3316929634134773_0_1000000000.0_gpt3.data\n",
      "21\n",
      "    /22\\1636266199.26506_1.017684160380182_0.8986235639580199_1.504162849145476_1.8146617588202079_0.614375442330084_0_1000000000.0_gpt3.data\n",
      "    /22\\1636266131.9062967_6.209309364471558_0.46764428034473454_0.766384994754936_1.8129651596521494_1.706539940629797_0_1000000000.0_gpt3.data\n",
      "    /22\\1636265967.9879026_7.073002843781147_0.7748123480877976_1.5678212194600814_1.4140778848939022_1.1501291438693528_0_1000000000.0_gpt3.data\n",
      "    /22\\1636265928.6312127_3.4760284414024083_0.1316545795602036_1.7741784475871571_0.9475149208094311_1.4739091882843796_0_1000000000.0_gpt3.data\n",
      "    /22\\1636265625.5661438_8.275132654228772_0.4963878540046968_1.7984067242753243_0.3715099911753996_1.8992792591997585_0_1000000000.0_gpt3.data\n",
      "    /22\\1636265593.8320563_8.022596685036236_0.05689461014567843_1.5916348335723134_1.2937848014829854_0.9148504280296723_0_1000000000.0_gpt3.data\n",
      "    /22\\1636265530.7398758_1.6806581347253151_0.9116228744511498_0.06992167384648756_1.637582508384899_1.5653648845429966_0_1000000000.0_gpt3.data\n",
      "    /22\\1636265019.9097357_1.846243532429535_0.3169371696725868_0.10540141384403286_1.6072936281503907_1.4083951389315965_0_1000000000.0_gpt3.data\n",
      "    /22\\1636264662.366437_1.6087585485648153_0.4938767922375958_0.6728049426529512_0.1268962453156821_1.4021714995617347_0_1000000000.0_gpt3.data\n",
      "    /22\\1636264430.7172754_0.7817170214714885_0.5970987660709518_0.002699435714281513_0.5228199629343915_1.8332202790610947_0_1000000000.0_gpt3.data\n",
      "    /22\\1636264215.6078575_3.0958028321179234_0.8914175132338076_0.2533266740111037_0.9680193976655_1.391017555856196_0_1000000000.0_gpt3.data\n",
      "    /22\\1636263637.3645437_5.223423046299605_0.2992678160719047_0.2141092913852099_0.19198811583687792_0.6571862207717238_0_1000000000.0_gpt3.data\n",
      "    /22\\1636263627.3623073_3.9338657952092206_0.3641008528561064_0.19144600799362305_1.7259631643225093_0.13206331140891825_0_1000000000.0_gpt3.data\n",
      "    /22\\1636263555.0857027_0.8658647613227852_0.802779135349522_0.962913301558142_0.38067338274656803_1.6113913403429592_0_1000000000.0_gpt3.data\n",
      "    /22\\1635818677.4165373_7.7655656096070995_0.289896390002939_0.48239242378280656_1.5185158393969194_0.4706363779699969_0_1000000000.0_gpt3.data\n",
      "    /22\\1635818411.5542407_7.9890026591129635_0.11461010564452602_1.5506602115792947_0.7658246064038079_1.2480989870114856_0_1000000000.0_gpt3.data\n",
      "    /22\\1635818388.4996867_1.557101782359005_0.6996337555645786_1.7854056819240458_1.376780432075194_0.03351637399796914_0_1000000000.0_gpt3.data\n",
      "    /22\\1635817915.2468817_8.61363154019723_0.5339312590397984_0.009202865452617004_1.2001640051098337_1.5544745299041953_0_1000000000.0_gpt3.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    /22\\1635817535.381256_2.981895229231018_0.7434749781381845_1.3026987099335117_0.8125694322005208_0.4223860378415132_0_1000000000.0_gpt3.data\n",
      "    /22\\1635231210.0901039_9.1631326129662_0.6027150797547363_1.5650822581165449_1.2758399713238846_0.8453946674024875_0_1000000000.0_gpt3.data\n",
      "22\n",
      "    /23\\1636266338.170382_4.478814160411088_0.45610740006148587_0.10494172583056938_1.035736326884519_0.38830557290148393_0_1000000000.0_gpt3.data\n",
      "    /23\\1636266232.0024624_6.003941157908025_0.054391648690582176_0.4549241382313859_1.8062073569083956_0.2158961444144185_0_1000000000.0_gpt3.data\n",
      "    /23\\1636266025.1629162_1.6911025798746664_0.04183159955591708_0.5999338070874076_0.47300519497881566_1.3500650964838055_0_1000000000.0_gpt3.data\n",
      "    /23\\1636266014.4086928_4.599284464459264_0.9078682059712897_1.9718085319064325_0.3687861567702604_0.6023620359549311_0_1000000000.0_gpt3.data\n",
      "    /23\\1636265884.5102694_8.421689951299111_0.3410603576492451_0.6885309129538615_0.6276125574475657_1.1697095040092493_0_1000000000.0_gpt3.data\n",
      "    /23\\1636265699.5661364_5.3495574552832155_0.6724395242211506_1.485732379002937_1.4844677557064856_0.9681087562188748_0_1000000000.0_gpt3.data\n",
      "    /23\\1636265550.2506688_2.7740314947547637_0.09894010350754062_1.7264754784067144_1.7467618337006205_0.569871203281358_0_1000000000.0_gpt3.data\n",
      "    /23\\1636265429.442923_8.095531023202588_0.4397026361286594_1.9244005056302862_0.6647173613673898_0.5624733718859347_0_1000000000.0_gpt3.data\n",
      "    /23\\1636265325.5758455_8.712057108944544_0.016294461414536877_1.1054003915048822_0.47295332310978555_1.385690487858407_0_1000000000.0_gpt3.data\n",
      "    /23\\1636265113.362678_8.47244435601221_0.3093248912799006_1.2803131455526178_0.2389753878260763_1.258239807191958_0_1000000000.0_gpt3.data\n",
      "    /23\\1636264891.0964103_3.319751831212251_0.1948925347485687_0.46349392736564304_0.881981389911308_0.23201991674038758_0_1000000000.0_gpt3.data\n",
      "    /23\\1636264807.7324717_7.196660342218253_0.36025866814841306_0.6472467511808319_1.2806143302537605_0.09479199892126111_0_1000000000.0_gpt3.data\n",
      "    /23\\1636264346.629275_8.996232377367779_0.46277808055098746_1.5507570646408375_1.0804980321698323_0.47669878648739106_0_1000000000.0_gpt3.data\n",
      "    /23\\1635818924.0908453_6.325868779043428_0.7136434278638238_1.6078156305117273_0.22778463119323877_0.2770764676668709_0_1000000000.0_gpt3.data\n",
      "    /23\\1635818911.1323905_4.306609992621554_0.27292865727929116_1.0120673430700577_0.8842673898698654_0.38031351104023803_0_1000000000.0_gpt3.data\n",
      "    /23\\1635818605.2203865_2.87629441975502_0.758233253666205_0.5488315045523398_1.2830236885861455_0.6495910288073152_0_1000000000.0_gpt3.data\n",
      "    /23\\1635818024.5591986_6.651437782815235_0.6854525037677323_1.825648667119271_0.7070950890377274_1.0470135856562202_0_1000000000.0_gpt3.data\n",
      "    /23\\1635817391.9129114_1.6394261990261771_0.23328156587882054_0.050537565763611625_0.8836587952340564_0.4627066303846692_0_1000000000.0_gpt3.data\n",
      "    /23\\1635231984.718771_4.466620755026855_0.3580973095107925_0.1604914270747234_0.3393342978183971_1.3620055209609807_0_1000000000.0_gpt3.data\n",
      "    /23\\1635231748.1828172_6.329800596816317_0.7144788968122141_0.1818172164855412_0.043031919043166056_0.1516569533484311_0_1000000000.0_gpt3.data\n",
      "    /23\\1635230923.4872236_2.833382060075634_0.015349378260612159_1.7700009089226063_0.4985990425750466_0.7530684740185298_0_1000000000.0_gpt3.data\n",
      "    /23\\1635230443.9419708_2.6084578082998253_0.8895132171734407_0.7790222516118874_0.9920519251189963_1.6610683680545366_0_1000000000.0_gpt3.data\n",
      "    /23\\1635230096.6468573_8.206165935004579_0.4835066101608081_0.2512553097394036_1.0641334721954665_0.5899295206831441_0_1000000000.0_gpt3.data\n",
      "23\n",
      "    /24\\1636268403.9461608_1.698525780655471_0.3530389700818603_1.2290665472997584_0.1192931950914784_0.27227165691066024_0_1000000000.0_gpt3.data\n",
      "    /24\\1636268246.0546415_4.636871578714766_0.6296397305786852_1.491610361391296_1.0171489868550327_1.490694595989845_0_1000000000.0_gpt3.data\n",
      "24\n",
      "    /25\\1636268363.5811682_2.7604787125885193_0.08060974282649273_0.5526962778618988_1.8741208749571983_0.8518603655629979_0_1000000000.0_gpt3.data\n",
      "25\n",
      "    /26\\1636266361.728347_9.181390144338774_0.31660639445503075_0.4771482547340526_0.8224706498663026_1.7998215168561635_0_1000000000.0_gpt3.data\n",
      "    /26\\1636266175.416873_4.047315265797579_0.20387070069055974_0.6904893762993634_1.4518540930549986_1.0672679037144674_0_1000000000.0_gpt3.data\n",
      "    /26\\1636265904.5396757_0.6483333000293624_0.9262349007389917_0.6763613503389145_1.4399144338183107_0.73609455232754_0_1000000000.0_gpt3.data\n",
      "    /26\\1636265709.642175_6.849636239661067_0.30410435589830453_1.6139031352166175_1.3515600415112465_0.8210988059879585_0_1000000000.0_gpt3.data\n",
      "    /26\\1636265414.9128013_3.112202741242494_0.7617272430595489_0.26280057281594515_0.1251960158303278_0.7891559871554334_0_1000000000.0_gpt3.data\n",
      "    /26\\1636265303.1448658_6.25152029392305_0.5875644435003531_1.5627420707263633_1.9681125920635378_1.0218874056167941_0_1000000000.0_gpt3.data\n",
      "    /26\\1636265136.6952462_7.582448484602494_0.8641746568709577_0.742047882966326_0.28169144354599984_0.5885053915566081_0_1000000000.0_gpt3.data\n",
      "    /26\\1636264915.2757115_4.895566497141097_0.040353097681905835_1.3409458254686464_1.515979452637909_1.374929371342682_0_1000000000.0_gpt3.data\n",
      "    /26\\1636264865.9496963_4.839987860502098_0.6301518978411764_1.9887688500765213_0.46465049983398043_1.8847004451508982_0_1000000000.0_gpt3.data\n",
      "    /26\\1636263855.8724241_6.526685157629823_0.08664560574058018_0.7788770892549414_0.06949569862658289_1.373170538974986_0_1000000000.0_gpt3.data\n",
      "    /26\\1636263805.4524584_8.217585921232404_0.686101641089821_0.12469339416024847_0.5023199187199938_1.5186574029546303_0_1000000000.0_gpt3.data\n",
      "    /26\\1635818850.3133962_7.800763345131317_0.7362312445090331_0.1691808503353108_1.867357262155666_0.2082824644723149_0_1000000000.0_gpt3.data\n",
      "    /26\\1635818617.505187_7.571726473167604_0.9168501595568956_0.9085094641890119_0.6926906840985256_1.480962551658346_0_1000000000.0_gpt3.data\n",
      "    /26\\1635818208.5994372_7.618225218130903_0.7410354000590581_1.506093037183143_0.8955417997617672_0.6642835092387891_0_1000000000.0_gpt3.data\n",
      "    /26\\1635818058.5381505_4.0843400467759094_0.4783282031294172_0.4175573693586726_0.36345715104119014_0.17090695997152672_0_1000000000.0_gpt3.data\n",
      "    /26\\1635817956.1928096_3.050767477764442_0.37623062847622823_1.8253433548039921_0.9701912553416128_1.6572049416764707_0_1000000000.0_gpt3.data\n",
      "    /26\\1635817639.256084_0.6177788195406704_0.5589629902077832_0.131804390792802_1.4730322911636178_0.4820862982608032_0_1000000000.0_gpt3.data\n",
      "26\n",
      "    /27\\1636266328.4753242_5.547198511779058_0.9464056358491268_1.686234484689862_0.24165855520843715_0.12739091647358425_0_1000000000.0_gpt3.data\n",
      "    /27\\1636266165.322882_9.346661699859427_0.09896713827363021_1.2524672032390194_1.7206046882865624_1.326376471179737_0_1000000000.0_gpt3.data\n",
      "    /27\\1636266003.291439_9.470134691356003_0.7711960775149796_0.08017333823697026_0.8925039639742343_1.659576036647472_0_1000000000.0_gpt3.data\n",
      "    /27\\1636265873.538627_7.39117986809465_0.92393536574761_1.9284983818108867_1.540785509045114_0.9031821659168444_0_1000000000.0_gpt3.data\n",
      "    /27\\1636265235.5906248_4.375173088749868_0.10190713759550635_1.5656379094266413_1.817482131120671_1.3169177888957875_0_1000000000.0_gpt3.data\n",
      "    /27\\1636265044.1947553_5.180298361966314_0.21290749148092805_1.9827598111736782_1.2264826538245897_1.254115348221236_0_1000000000.0_gpt3.data\n",
      "    /27\\1636265000.3061903_1.001865104093015_0.022584341946527437_0.10201598065735733_1.0010987236961795_1.7534469481055501_0_1000000000.0_gpt3.data\n",
      "    /27\\1636264905.0480783_5.959604911966014_0.14529926775875115_1.9190942930532964_0.22240037890010633_1.9548897717763598_0_1000000000.0_gpt3.data\n",
      "    /27\\1636264642.297138_5.734720640412129_0.8521825447791781_0.9733888459303657_0.9624960776326517_1.220512573241553_0_1000000000.0_gpt3.data\n",
      "    /27\\1636264191.9262242_7.3584113329557805_0.5162322998284107_0.9210080823372585_1.8967778674969062_1.7917676491441283_0_1000000000.0_gpt3.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    /27\\1636264175.7175944_4.334321599645667_0.9732387803305715_0.4181060691774109_1.008841479257601_0.6529093077640746_0_1000000000.0_gpt3.data\n",
      "    /27\\1636264155.2204392_3.5557704597801125_0.39204589862332445_0.9145698691161555_1.1964912680501003_0.45248053797559207_0_1000000000.0_gpt3.data\n",
      "    /27\\1636263672.0656922_6.901278542884458_0.9915200865031326_1.091828212238108_1.600689511328584_1.244058610853321_0_1000000000.0_gpt3.data\n",
      "    /27\\1635818459.8940294_6.081274619868682_0.3305496595225973_0.4422386622709817_1.621513839800853_1.061791295637942_0_1000000000.0_gpt3.data\n",
      "    /27\\1635818167.3812141_4.158843330593089_0.05264974662427038_0.10006402724159139_1.4315055381755128_0.8734932170239196_0_1000000000.0_gpt3.data\n",
      "    /27\\1635818140.1387608_8.274747620116536_0.5216423045699963_1.3687571498058209_1.7600980351743145_1.9860853533100178_0_1000000000.0_gpt3.data\n",
      "    /27\\1635817462.066056_3.343912097281028_0.7133360617732859_1.5015696106191758_0.34530861733294027_1.4251711463845798_0_1000000000.0_gpt3.data\n",
      "27\n",
      "    /28\\1636266154.0041673_5.588536113439086_0.22433509651749697_0.2800098669400113_1.1141652909425452_0.896529313362352_0_1000000000.0_gpt3.data\n",
      "    /28\\1636266099.2247448_2.327292779011543_0.6154278264773265_0.7973249267716914_0.5541340191933093_1.1521464171189713_0_1000000000.0_gpt3.data\n",
      "    /28\\1636266060.6359982_1.6167331870406128_0.40135119074022746_0.2426123234790542_0.9724466056805094_1.1758198293305657_0_1000000000.0_gpt3.data\n",
      "    /28\\1636265211.8282077_0.6936226696505182_0.6602378875300886_0.44351101315800684_0.7299618194652886_0.0025705220860381406_0_1000000000.0_gpt3.data\n",
      "    /28\\1636265083.0338304_1.831024721234717_0.9477654698066882_0.6902889556255836_1.5478005838719162_0.5582796033898481_0_1000000000.0_gpt3.data\n",
      "    /28\\1636264619.0852473_2.453562601936083_0.42411900241604394_1.7934509082476495_1.1664033314069597_0.5269602736453207_0_1000000000.0_gpt3.data\n",
      "    /28\\1636264421.9507325_3.6394370804816227_0.3555110231322902_1.2650746281651484_1.2603865540898833_0.7342297560234283_0_1000000000.0_gpt3.data\n",
      "    /28\\1636264395.4905338_6.5876615831590515_0.2525451816137233_1.7703446902199942_1.7712604926243303_0.9750193591657594_0_1000000000.0_gpt3.data\n",
      "    /28\\1636263709.3997946_9.23736670721834_0.15941828421947776_1.4502273427227936_0.07278912735286358_0.23005571581781936_0_1000000000.0_gpt3.data\n",
      "    /28\\1636263572.6886022_4.6997017429268695_0.4098403058870165_1.5109005604625947_0.573635949925053_0.5539113642123177_0_1000000000.0_gpt3.data\n",
      "    /28\\1636263495.5669627_0.8267572098833801_0.8565946635319063_1.7698116652457345_1.9729622580956123_0.34700622109165513_0_1000000000.0_gpt3.data\n",
      "    /28\\1635818450.1015775_5.16794421775601_0.8722477180461752_0.26099260914468214_1.1745463634584248_0.7799939291209759_0_1000000000.0_gpt3.data\n",
      "    /28\\1635818177.5436306_4.150271134968663_0.7404743291189314_0.1099397215835765_1.2704495083806233_0.6506170656495158_0_1000000000.0_gpt3.data\n",
      "    /28\\1635818048.6335464_7.889897329427498_0.351939492786713_0.8609410352552174_0.9589309426491794_0.031340448960222256_0_1000000000.0_gpt3.data\n",
      "    /28\\1635818010.2952151_8.794433105497125_0.15673025695206588_0.7923931275501486_1.2839796221688238_0.9291302559716248_0_1000000000.0_gpt3.data\n",
      "28\n",
      "    /29\\1636266286.099712_2.0448555408937876_0.38799358474774215_0.15713911110553747_0.019346983614460633_1.3935617229768182_0_1000000000.0_gpt3.data\n",
      "    /29\\1636266191.280425_4.525618021915326_0.8160739845385688_1.6278985915263569_0.06927222491097385_1.832694674959651_0_1000000000.0_gpt3.data\n",
      "    /29\\1636265895.0779927_5.1877097751162795_0.9074393218448322_0.8993575267023786_0.5232411125863383_1.1218116251150876_0_1000000000.0_gpt3.data\n",
      "    /29\\1636265839.726101_3.800826996990867_0.6839100002183438_1.452651255661768_1.0267406072033505_0.5100807272527681_0_1000000000.0_gpt3.data\n",
      "    /29\\1636265785.5151567_6.786914328500702_0.39624489139121055_1.755256555760752_1.156690553807666_1.130452911121981_0_1000000000.0_gpt3.data\n",
      "    /29\\1636265582.0326278_3.457551812552783_0.30005983825600774_1.5185163775784865_0.5883725524584453_1.6312636943437966_0_1000000000.0_gpt3.data\n",
      "    /29\\1636265521.6212745_5.6867299944519365_0.2271556914482103_1.6032721992935537_0.48250096908555595_0.8595313436747662_0_1000000000.0_gpt3.data\n",
      "    /29\\1636265439.6885073_4.61606499107992_0.033969248842956115_1.806825788961404_1.4554059768436285_0.3369861413996247_0_1000000000.0_gpt3.data\n",
      "    /29\\1636264876.6829765_8.025416715366225_0.7882827848959413_0.27536774935269115_1.9109823827993495_0.3660342381223527_0_1000000000.0_gpt3.data\n",
      "    /29\\1636264818.7469997_4.145421570380119_0.31735251383224156_0.2531719675068492_0.43751449175613555_0.011492856393457984_0_1000000000.0_gpt3.data\n",
      "    /29\\1636264629.6410024_5.070650417454855_0.9336446998511685_0.8321362176630077_1.5942355056959636_0.6634577266331014_0_1000000000.0_gpt3.data\n",
      "    /29\\1636264595.6878533_9.136661750299087_0.09758533588562898_0.06965153163740001_1.5467025833658774_0.26080165746418804_0_1000000000.0_gpt3.data\n",
      "    /29\\1636264365.2135477_3.1477080334122607_0.7316977899085453_1.3344715554774906_1.2997007776657208_1.6118744904502653_0_1000000000.0_gpt3.data\n",
      "    /29\\1636264007.374042_1.9915119010929465_0.9167522058169393_0.430853744903987_0.8428013354944399_1.7594121756907493_0_1000000000.0_gpt3.data\n",
      "    /29\\1636263984.2070312_5.237884722663626_0.02938804948448241_0.609805970813281_0.3506217869353079_1.141507612834468_0_1000000000.0_gpt3.data\n",
      "    /29\\1636263794.1729636_0.5130034999967872_0.9280517780324599_1.290829604234763_1.7026269752697312_1.5139583932679828_0_1000000000.0_gpt3.data\n",
      "    /29\\1636263470.6675858_6.908312459862111_0.9322586521667592_1.5374790406580765_0.17471736509543323_0.9366467943645149_0_1000000000.0_gpt3.data\n",
      "    /29\\1635818837.3269918_5.931806472582023_0.884778006641912_1.9589189447791195_1.9730880447582502_0.7528471950384972_0_1000000000.0_gpt3.data\n",
      "    /29\\1635818561.5552053_0.6577057883373731_0.23931028419482078_0.6846118622478891_1.6098658878764904_1.8712791397235018_0_1000000000.0_gpt3.data\n",
      "    /29\\1635818532.426294_8.650972789719338_0.31892302911303744_0.22534501305513815_1.3597018777538752_1.940988510103765_0_1000000000.0_gpt3.data\n",
      "    /29\\1635818484.6211572_0.8998835034548778_0.7034710629551217_0.7176567876779153_1.205155963891393_1.0076131735279736_0_1000000000.0_gpt3.data\n",
      "    /29\\1635818156.9889128_5.036228071632721_0.5794188945330283_1.2608687266490777_0.27947503486639547_0.5431345126717328_0_1000000000.0_gpt3.data\n",
      "    /29\\1635817986.9249825_1.260599523319888_0.7586932205670225_1.2133347696151482_0.11194057785877254_1.8047698064601703_0_1000000000.0_gpt3.data\n",
      "    /29\\1635817810.0810356_6.51528395536925_0.20646473012664063_1.3575064007544777_0.263383884296466_0.35495445520569313_0_1000000000.0_gpt3.data\n",
      "    /29\\1635817766.983859_7.075356835716574_0.7954142742618686_0.10442209486698328_1.2285611957180793_0.5917568533120565_0_1000000000.0_gpt3.data\n",
      "    /29\\1635817616.9225774_2.6120052523843347_0.914228085758027_1.9720745835724394_1.7385779072169008_0.021659535493653292_0_1000000000.0_gpt3.data\n",
      "    /29\\1635817505.848934_6.471093110251012_0.5743307396181819_1.3309850625450002_0.17381031185506712_1.6029610950725457_0_1000000000.0_gpt3.data\n",
      "    /29\\1635817438.1277924_1.9118715532507204_0.946795805091026_1.918299900572878_0.7429078732468484_0.4233230178172993_0_1000000000.0_gpt3.data\n",
      "    /29\\1635231009.9640863_6.029032306989462_0.8001647090983064_1.4193479661819417_0.991109160346936_0.33327957729304813_0_1000000000.0_gpt3.data\n",
      "    /29\\1635230807.0630784_0.7763456892438009_0.7319002652463885_1.8642427776906223_1.0464897025737334_0.39053165329840756_0_1000000000.0_gpt3.data\n",
      "29\n",
      "    /30\\1636265156.3536444_2.4285239023215617_0.9051705749882393_1.4500252125240898_1.6644267053871302_0.7397514415181727_0_1000000000.0_gpt3.data\n",
      "    /30\\1636264829.378552_6.402274620790726_0.44448617082701747_0.09642966465854856_1.1091713718744334_0.5448245978437649_0_1000000000.0_gpt3.data\n",
      "    /30\\1636264573.7774804_9.39017820508316_0.6784262120836919_1.6889477726047737_1.3170796191969414_0.6345779958649314_0_1000000000.0_gpt3.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    /30\\1636264521.7656512_4.634605923116705_0.8661296757366485_0.8351153515039353_0.23852668207055183_1.6814440350190356_0_1000000000.0_gpt3.data\n",
      "    /30\\1636264509.4525983_6.779054736800901_0.8087159024478852_0.5146560919745364_0.616971709323374_1.9430083658393096_0_1000000000.0_gpt3.data\n",
      "    /30\\1636264255.844194_7.941629768677764_0.323268506068973_0.3840295285942603_0.5233397391117915_1.8276545434747138_0_1000000000.0_gpt3.data\n",
      "    /30\\1636263765.589445_0.6801726722603829_0.005476638971376789_0.37294149927993286_0.918907380995126_0.7298856546024859_0_1000000000.0_gpt3.data\n",
      "    /30\\1635818936.0828831_7.848991873373151_0.5350198326922376_0.6367591532613471_1.0954036403940894_0.7744972563995178_0_1000000000.0_gpt3.data\n",
      "    /30\\1635818749.770244_6.415744085067136_0.43783111906357264_1.5366282801451034_0.11717976591928925_0.5806277400084898_0_1000000000.0_gpt3.data\n",
      "    /30\\1635818739.0183675_6.550844670290125_0.11059755075138637_0.26706135046865864_1.3958098469578497_0.2445605459160778_0_1000000000.0_gpt3.data\n",
      "    /30\\1635818724.3664267_8.048097919659726_0.03619691166387068_1.506676035733237_0.9005743663455474_0.43554969712161995_0_1000000000.0_gpt3.data\n",
      "    /30\\1635818422.3609607_5.2368970699304835_0.0019220024840446881_0.6308230256706682_1.0822625772960446_1.839435396707943_0_1000000000.0_gpt3.data\n",
      "    /30\\1635818311.5117714_7.90085492860157_0.5352494806010109_1.3906370480624166_0.229995850367805_1.7244194621280549_0_1000000000.0_gpt3.data\n",
      "30\n",
      "    /31\\1636268371.9088852_1.342206168490991_0.2137251062596741_0.3526943399672661_0.6200337477667799_1.5339656407748725_0_1000000000.0_gpt3.data\n",
      "31\n",
      "    /32\\1636268235.256534_3.2744372132224795_0.06691747647547715_1.5765058106102432_0.5572923965563303_0.6475540099947565_0_1000000000.0_gpt3.data\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# Just extract the features for the last entry (token); accumulating averages up to that token shuld account for most info\n",
    "# at least without many more datapoints. Draw learning curve for x = n. unique wordlists and x = n. samples per wordlist...\n",
    "# and then the objective y using the optimal (peak) n. samples per wordlist for each x = n. unique wordlists\n",
    "sp_data = OrderedDict()\n",
    "for i in range(1, N_wordlists):\n",
    "    fs = glob.glob(data_dir + learning_data_dir + \"/msp_single_samples/\" + str(i) + '/*')[::-1]  # Sort by most recent first\n",
    "    entries = []\n",
    "    for file in fs:\n",
    "        d_ = load_ld(file, pad=False)\n",
    "        params, input_data, ix, r_, mdl_string = d_\n",
    "        sent, missing = input_data[0]\n",
    "        params_granulated = {k: round(params[k], 5) for k in params}\n",
    "        sample_hash = mdl_string + ':' + str(i) + ':' + str(params_granulated) + sent\n",
    "#         print(sample_hash)\n",
    "#         break\n",
    "        if sample_hash in sp_data:  # Only use the most recent re-evaluation\n",
    "            continue\n",
    "        prompt_r = p_req_m(sent, echo=True, max_tokens=1, n=1)  # Temporary fix since we forgot this in original request\n",
    "#         print(prompt_r)\n",
    "        sp_data[sample_hash] = {\n",
    "            \"sent\": sent,\n",
    "            \"params\": params,\n",
    "            \"i\": i,\n",
    "            \"ix\": ix,\n",
    "            \"missing\": missing,\n",
    "            \"mdl_string\": mdl_string,\n",
    "            \"r\": r_,\n",
    "            \"prompt_r\": prompt_r,\n",
    "        }\n",
    "#         print(sample_hash)\n",
    "        print('   ', file.split(\"msp_single_samples\")[1])\n",
    "    print(i)\n",
    "        # Get top100 distribution features, with without softmax, min, max, various percentiles\n",
    "        # All the P(phrase) features\n",
    "#         break\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 172\n"
     ]
    }
   ],
   "source": [
    "for hsh in sp_data:\n",
    "    d_ = sp_data[hsh]\n",
    "    sent = d_[\"sent\"]\n",
    "    prompt_r = d_[\"prompt_r\"]\n",
    "    pr(prompt_r)\n",
    "    print(len(gpt3_tokenizer.encode(sent)), len(prompt_r[1][0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/learning_data//msp_single_samples/15\\\\1635230194.0755582_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.0825396_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.090518_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.097499_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.106476_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.113457_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.120438_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.1294138_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.1388946_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.1468737_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.1548526_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.1628315_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.1698127_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.1777909_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.1847725_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.1917536_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.1987345_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.2057164_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.2126973_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.2196789_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.22666_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.234639_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.2416205_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.249599_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.25658_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.2635617_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.270543_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.2785218_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.2845054_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.291487_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.2974708_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.3044522_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.3124309_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.3194122_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.3263938_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.333375_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.3403566_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.3473372_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.357311_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.3672845_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.3782551_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.3862336_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.3932147_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.400196_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4071774_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4151561_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4211402_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4291186_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4361_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4430811_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4500628_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.457044_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4690125_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4787524_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4884717_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.4954526_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5044289_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5124078_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5208929_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5298696_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5388458_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5498164_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5587919_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5677674_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5767436_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5847218_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.5927012_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.599683_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6066644_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6136456_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.621624_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6315975_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6405733_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6505466_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6585252_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6655066_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6744833_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6849928_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6909723_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.6989508_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7059324_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7129138_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7188976_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7258792_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7338576_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7418363_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7488177_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7548015_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7627802_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7697616_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7777398_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7847211_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.7917027_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.798684_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.8066626_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.8136442_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.8206263_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.8276067_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.835586_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.843075_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.8510532_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.8570373_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.8640187_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.8719974_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.8789785_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.8889515_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.895933_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.9059067_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635230194.9128883_5.278562262277534_0.14084506704914782_1.9033350325658105_0.20076085702877866_0.8158879199025932_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.1719673_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.1799467_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.1869287_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.194906_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.2048798_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.210863_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.2178445_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.2248256_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.2338026_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.2437758_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.253749_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.2627249_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.2736955_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.2846665_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635231144.295638_4.804870558352345_0.4761466191548659_0.07783831189946334_0.6962026284013796_1.2218717009176252_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635817414.3551478_8.754363554920289_0.8258634846394155_1.1934159219055605_1.4469776805522845_1.505194958693852_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635817652.0993936_5.4209247982511926_0.6135969371169273_0.3564381650629701_1.151100633229228_1.234380035018823_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635817703.5847208_7.5461478098536645_0.47270706313735794_1.3838914002581744_1.0104394741345122_0.2687951841753857_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1635818503.6564174_7.5783249817339495_0.46755335105033524_1.4892105243288845_0.42557688489347334_1.759032948753845_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636263682.069923_3.2463920424933863_0.831078039146103_1.687492043723916_1.7969708211035222_0.2802221035535579_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636263866.357369_3.7101484834358702_0.22192069893021688_1.6895653356924092_1.1742771221716337_1.5080555810903524_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636263924.805974_6.4886776328280975_0.5168476722381895_0.6725423159271626_1.7858309454472232_0.6072309005735959_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636263936.0409124_3.9308993205701537_0.7335779971456169_0.8514269389837475_1.85788607198232_1.5795576262023998_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636263973.6592543_6.5252673931751595_0.5089706795752854_0.10832272831613136_1.4069674972575128_0.11023694246978666_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636264685.4746048_4.271548477633889_0.2603006925957768_0.8172145858465474_0.3971282369882021_0.8809275987115888_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636264731.3698_0.5682995163867282_0.6614042787510531_0.1753960388697377_0.5565464758536289_1.4070831417712348_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636265386.008143_8.243367349702892_0.5031853445555973_0.08425555336018202_1.9980535581448886_1.650183472666667_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636265510.917914_3.3389409838621296_0.19471999546187047_1.9406043274708513_0.15219185319224127_0.20456929934479495_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636265686.3036232_6.7955775572214625_0.3248959886340736_0.5387971303064562_0.006829243865015711_1.315536724421282_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636265850.588037_3.690364906680859_0.6036394373613073_1.4863503151457533_1.0492416081937226_1.1315698734764088_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636266049.5047839_3.24747311588856_0.08357303754066987_1.9500791922838194_1.2147899981046377_0.5382428664192016_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636266075.936059_1.1252113386313614_0.04226874429844503_0.05370766639120018_1.6380603936433968_1.9897119732179471_0_1000000000.0_gpt3.data',\n",
       " 'data/learning_data//msp_single_samples/15\\\\1636266143.9251368_7.172470459324545_0.2608991816402273_0.7017727436656553_1.1514100068163635_0.21434649902235736_0_1000000000.0_gpt3.data']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(data_dir + learning_data_dir + \"/msp_single_samples/\" + str(15) + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': 1.3284938330305758,\n",
       " 'top_p': 0.4489318877690332,\n",
       " 'presence_penalty': 1.9403679245767413,\n",
       " 'frequency_penalty': 0.5572170319786667,\n",
       " 'best_of': 6.6703860146045875,\n",
       " 'n': 10,\n",
       " 'max_tokens': 11}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = load_ld(glob.glob(data_dir + learning_data_dir + \"/msp_single_samples/2/*\")[0], pad=False)\n",
    "params, input_data, ix, r_, mdl_string = d_\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 steps no change, i=6 acc = 0.5\n",
      "6 steps no change, i=7 acc = 0.5\n",
      "7 steps no change, i=8 acc = 0.5\n",
      "8 steps no change, i=9 acc = 0.5\n",
      "9 steps no change, i=10 acc = 0.5\n",
      "10 steps no change, i=11 acc = 0.5\n",
      "11 steps no change, i=12 acc = 0.5\n",
      "12 steps no change, i=13 acc = 0.5\n",
      "13 steps no change, i=14 acc = 0.5\n",
      "14 steps no change, i=15 acc = 0.5\n",
      "0.5 {'temperature': 0.1818172164855412, 'top_p': 0.7144788968122141, 'presence_penalty': 0.043031919043166056, 'frequency_penalty': 0.1516569533484311, 'best_of': 6.329800596816317}\n",
      "5 steps no change, i=68 acc = 0.05748875307698838\n",
      "0.05748875307698838 {'temperature': 1.420022850690058, 'top_p': 0.8755140320125568, 'presence_penalty': 1.6326751318066206, 'frequency_penalty': 0.7098073862191683, 'best_of': 7.429972951287356}\n",
      "5 steps no change, i=93 acc = 0.16245791245791244\n",
      "0.16245791245791244 {'temperature': 1.9715314863157969, 'top_p': 0.2822626683143319, 'presence_penalty': 1.4155431053726697, 'frequency_penalty': 0.18412043942110223, 'best_of': 7.827496177058414}\n",
      "5 steps no change, i=69 acc = 0.4492753623188406\n",
      "0.4492753623188406 {'temperature': 0.1604914270747234, 'top_p': 0.3580973095107925, 'presence_penalty': 0.3393342978183971, 'frequency_penalty': 1.3620055209609807, 'best_of': 4.466620755026855}\n",
      "5 steps no change, i=6 acc = 0.0\n",
      "6 steps no change, i=7 acc = 0.0\n",
      "7 steps no change, i=8 acc = 0.0\n",
      "8 steps no change, i=9 acc = 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-5b74ae2cff81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sp_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'A list of'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-104-1c3a0214e0c6>\u001b[0m in \u001b[0;36mtest_sp_single\u001b[1;34m(params, min_l, max_l, n, prmt, phase, max_tokens, mdl, tol, ra)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_nochange\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mr_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_req_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrip_comma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr___\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr___\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr__\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_full\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob_msp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-be95bcddc52d>\u001b[0m in \u001b[0;36mp_req_m\u001b[1;34m(s, tokenize, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"prompt\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcaptured\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchoice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"choices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mtks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchoice\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"logprobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_logprobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, idempotency_key, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midempotency_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         response, _, api_key = requestor.request(\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         )\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, stream)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         rbody, rcode, rheaders, stream, my_api_key = self.request_raw(\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         )\n\u001b[0;32m    129\u001b[0m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[1;34m(self, method, url, params, supplied_headers, stream)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         rbody, rcode, rheaders, stream = self._client.request_with_retries(\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabs_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         )\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\http_client.py\u001b[0m in \u001b[0;36mrequest_with_retries\u001b[1;34m(self, method, url, headers, post_data, stream)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                 \u001b[0mconnection_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPIConnectionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\http_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, headers, post_data, stream)\u001b[0m\n\u001b[0;32m    219\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m                     \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m                 )\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mcontent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    751\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \"\"\"\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\";\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1007\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1009\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1010\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    869\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Uniformly sample gpt3 outputs\n",
    "bounds = OrderedDict([\n",
    "  (\"temperature\", [0.0001, 2.0]),  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  (\"top_p\", [0.0001, 1.0]),        # same with this but more obvious\n",
    "#   (\"top_k\", [1, 100]),        # maybe use log of the input value so that lower values are sampled with high resolution\n",
    "  (\"presence_penalty\", [0.0, 2.0]),   # both presence and frequency penalty have optimal values\n",
    "  (\"frequency_penalty\", [0.0, 2.0]),  # this can also go down to -2.0, probably not useful for our case...\n",
    "  (\"best_of\", [0.501, 9.499]),  \n",
    "])\n",
    "while True:\n",
    "    ps = {k: np.random.uniform(*bounds[k]) for k in bounds}\n",
    "    print(test_sp_single(ps, min_l=0, max_l=1e9, n=10, tol=0.01, phase=\"train\", mdl='gpt3', prmt='A list of'), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Model device: cuda:0\n",
      "Pretrained parameters loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in locals():  # Load pretrained weights\n",
    "    del model\n",
    "print(gc.collect()), pt.cuda.empty_cache()\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/\" + modelkey)\n",
    "model_ = locals()[modelclass].from_pretrained(modelkey, output_hidden_states=False, output_attentions=False, \n",
    "    cache_dir=\"models/pretrained/\" + modelkey)\n",
    "if pt.cuda.device_count() > 1 and \"gpt\" in modelkey:\n",
    "    device_map = {0: [0, 1, 2],\n",
    "                  1: [3, 4, 5, 6, 7, 8],\n",
    "                  2: [9, 10, 11, 12, 13, 14],\n",
    "                  3: [15, 16, 17, 18, 19, 20],\n",
    "                  4: [21, 22, 23, 24, 25, 26, 27],\n",
    "                  5: [28, 29, 30, 31, 32, 33, 34],\n",
    "                  6: [35, 36, 37, 38, 39, 40, 41],\n",
    "                  7: [42, 43, 44, 45, 46, 47],\n",
    "                 }\n",
    "    model_.parallelize(device_map)\n",
    "else:\n",
    "    model_ = model_.to(d)\n",
    "print(\"Model device:\", model_.device)\n",
    "if \"gpt2\" in modelkey:\n",
    "    model_.resize_token_embeddings(N_tokens)\n",
    "    pad_token = model_.config.pad_token_id = model_.config.eos_token_id\n",
    "    pad_token = pt.tensor(pad_token, device=d)\n",
    "    repl_token = pt.tensor(tokenizer.encode(lastcomma_repl)[0], device=d) if lastcomma_repl != 'EOS' else pad_token\n",
    "    n_embd = pt.tensor(model_.config.n_embd, device=d)\n",
    "else:\n",
    "    pad_token = model_.config.pad_token_id\n",
    "    pad_token = pt.tensor(pad_token, device=d)\n",
    "    mask_token = pt.tensor(tokenizer.encode(\"<mask>\")).to(d)\n",
    "# model = nn.parallel.DistributedDataParallel(model_, device_ids=[d])\n",
    "# model = nn.DataParallel model_, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else model_\n",
    "model = model_\n",
    "mname_fn = modelkey\n",
    "multimask_arch = \"xlnet\" in modelkey\n",
    "print(\"Pretrained parameters loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning the last 12 of 12 model layers plus the output linear layer\n"
     ]
    }
   ],
   "source": [
    "max_layer = max([int(name.split('transformer.layer.')[1].split('.')[0]) for (name, _) in model.named_parameters() \\\n",
    "                 if \"transformer.layer.\" in name])\n",
    "if n_unfreeze == \"all\": n_unfreeze = max_layer + 1\n",
    "if n_unfreeze < 0: n_unfreeze = max_layer + n_unfreeze\n",
    "print(\"Fine tuning the last \" + str(n_unfreeze) + \" of \" + str(max_layer + 1) + \" model layers plus the output linear layer\")\n",
    "for (name, v) in model.named_parameters():\n",
    "    if name == \"transformer.mask_emb\":              continue      # torch.Size([1, 1, 768])\n",
    "    if name == \"transformer.word_embedding.weight\": continue      # torch.Size([32000, 768])\n",
    "    if name == \"lm_loss.bias\":                      continue      # torch.Size([32000])\n",
    "    else:\n",
    "        layer_n = int(name.split('transformer.layer.')[1].split('.')[0])\n",
    "        if layer_n < n_unfreeze: v.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "curr_ri = np.zeros(len(train_idx), dtype=int)\n",
    "def next_batch(sz):\n",
    "    global phase_listsets, curr_ri\n",
    "    cats_, cats_sing_, phrases_ = phase_listsets[\"default\"][\"train\"]\n",
    "    return adapt_form(*gen_samples_uniform(cats_, cats_sing_, phrases_, sz, ra=False, stac=curr_ri, mlen=max_len))\n",
    "#     return adapt_form(*gen_samples(cats_, cats_sing_, phrases_, sz, ra=False, mlen=max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also create a gpt3 prompt-completion-based regression model to predict values/densities of sampling parameters (might work if\n",
    "# it's possible to find a humanlike transliteration of the problem statement that gpt3 can bootstrap on to find the params, or\n",
    "# to find some (possibly entirely textual) representation of a params-correlating multidimensional metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entirely textual representation attempts:\n",
    "# for example: Some round fruits: apple, orange, pear. As a percentage of all round fruits, this list represents <blank>\n",
    "# with: Some round fruits: apple, orange, pear. Does this list use a relatively strict definition of round fruits? <blank>\n",
    "# and Some round fruits: apple, orange, pear. To what degree is this a representative list? <blank>  davinci-instruct priming\n",
    "# etc... in some sense it reformulates it as a multi sentiment classification that's able to predict optimal PLM sampling params\n",
    "# From early experiments this may be possible however the noise is difficult to deal without some heavy improvements on priming\n",
    "# Alternatively, we could use the top-p numerical token instead of <blank> and find a priming prompt that outputs these best\n",
    "# This way we can \"fine-tune\" GPT3-davinci (which is much better than curie but has no fine tuning API) by \"priming recursion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = None #nn.Linear(n_embd, N_tokens, bias=False).to(d)#.cpu()                  # Model definition\n",
    "# nn.init.xavier_uniform_(llayer.weight)\n",
    "# llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else llayer\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()#.to(d)#.cpu()\n",
    "# bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d) if dev != \"cpu\" else bcewl_loss\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1, device=d)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def multimask_model(model, x=None, sqlens=None, past=None, seq_maxlen=None, add=None, many_inp=None, return_states=None, **kw):\n",
    "    x = pt.cat([x, pad_token.repeat((x.shape[0], 1))], axis=1)\n",
    "    if add == 0: \n",
    "        x[pt.arange(x.shape[0]).to(d), sqlens] = mask_token\n",
    "    else:\n",
    "        x[:, -1] = mask_token\n",
    "    perm_mask = pt.ones(x.shape[0], x.shape[1], x.shape[1], dtype=pt.float).to(d)  # causal mask\n",
    "    perm_mask = pt.triu(perm_mask, diagonal=0)\n",
    "#     perm_mask = pt.zeros((x.shape[0], (seq_maxlen if add == 0 else 0) + add + 1, seq_maxlen + add + 1), dtype=pt.float).to(d)\n",
    "    for i in range(sqlens.shape[0]):\n",
    "        l = sqlens[i] + add\n",
    "        perm_mask[i, :, -(x.shape[1] - l):seq_maxlen + 2] = 1.0  # Previous tokens don't see last token or padding tokens\n",
    "        if add > 0:\n",
    "            perm_mask[i, :, seq_maxlen + 1] = 0.0\n",
    "            perm_mask[i, :, -1] = 1.0\n",
    "#     if add > 0:\n",
    "#         perm_mask = pt.zeros((x.shape[0], 2, 2), dtype=pt.float).to(d)\n",
    "#         perm_mask[:, :, -1] = 1.0\n",
    "#         perm_mask = pt.ones((x.shape[0], 1, 1), dtype=pt.float).to(d)\n",
    "    attn_mask = None\n",
    "#     if (past is not None) and add > 0:\n",
    "# #         attn_mask = sequence_mask(sqlens, seq_maxlen)  # The equivalent attention_mask (debug)\n",
    "# #         attn_mask = pt.cat([attn_mask, pt.ones(attn_mask.shape[0], add).to(d)], dim=1)\n",
    "# #         attn_mask = pt.cat([attn_mask, pt.zeros(attn_mask.shape[0], 1).to(d)], dim=1)\n",
    "#         past_ = []\n",
    "#         for i in range(len(past)):\n",
    "#             past_.append(past[i][:-1])  # Don't use the hidden states of the mask token from last iteration\n",
    "#         past = tuple(past_)\n",
    "    target_mapping = pt.zeros((x.shape[0], 1, seq_maxlen + add + 1), dtype=pt.float).to(d)\n",
    "    if add == 0:\n",
    "        target_mapping[pt.arange(x.shape[0]).to(d), 0, sqlens] = 1.0\n",
    "    else:\n",
    "        target_mapping[:, 0, -1] = 1.0\n",
    "        target_mapping = target_mapping[:, :, -2:]\n",
    "#     print(x.shape, perm_mask.shape, attn_mask.shape if attn_mask is not None else None, \\\n",
    "#           target_mapping.shape, (len(past), past[0].shape) if past is not None else None)\n",
    "#     print(tokenizer.decode(x[0].cpu().detach().numpy()))\n",
    "#     print(perm_mask, target_mapping)\n",
    "    res = model(x, perm_mask=perm_mask if attn_mask is None else None, target_mapping=target_mapping,\n",
    "                   mems=past, attention_mask=attn_mask, use_mems=None if (past is None and not return_states) else True)\n",
    "#     print(res[0].shape)\n",
    "    return res\n",
    "# next_token_logits = outputs[0]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]\n",
    "def singlemask_model(model, x=None, sqlens=None, past=None, return_states=None, seq_maxlen=None, add=None, many_inp=None, **kw):\n",
    "    mask = sequence_mask(sqlens, seq_maxlen) if (many_inp or add != 0) else None\n",
    "    if add > 0: mask = pt.cat([mask, pt.ones(mask.shape[0], add).to(d)], dim=1)  # Append mask entry for new stream token\n",
    "    return model(x.long(), attention_mask=mask, use_cache=None if not return_states else True, past_key_values=past)\n",
    "def inference(x, sqlens, past=None, return_states=False, seq_maxlen=max_len, add=0, return_fulloutput=False):\n",
    "    global model\n",
    "    many_inp = x.shape[1] > 1\n",
    "    outputs = multimask_model(model, **locals()) if multimask_arch else singlemask_model(model, **locals())\n",
    "    if return_fulloutput: return outputs\n",
    "    logits = outputs[0].squeeze(1) if multimask_arch else \\\n",
    "            (outputs[0][[pt.arange(x.shape[0]), sqlens - 1]] if many_inp else outputs[0].squeeze(1))\n",
    "#     logits = outputs[0][[pt.arange(x.shape[0]), sqlens - 1]] if many_inp else outputs[0].squeeze(1)\n",
    "\n",
    "    return (logits, outputs[1]) if return_states else logits  # Optionally return the past states needed to restore the stream\n",
    "def adapt_form(xs, ys, sqlens, mlen=max_len, repl_finalcomma=True):\n",
    "    xs = pt.vstack([F.pad(x, (0, max(0, mlen - len(x))), mode='constant', value=pad_token)[:mlen] for x in xs])\n",
    "    _ys = pt.vstack(ys) if ys is not None else None\n",
    "    if repl_finalcomma and (lastcomma_repl != ',') and ys is not None:\n",
    "        _ys[:, repl_token] += _ys[:, comma_token] - lidstone_value\n",
    "        _ys[:, comma_token] = lidstone_value\n",
    "    return xs, _ys, pt.tensor(sqlens, device=d)\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, bsz, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(bsz)\n",
    "\n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)  # Get logits\n",
    "    logits = outputs[0][[pt.arange(x_batch.shape[0]), sqlens_batch - 1]]\n",
    "\n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lidstone_value + 1e-10)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lidstone_value + 1e-10)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = -1  # Batch 0 is the first iteration, where validation occurs without any training\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "out_str = ''\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, val_loss, val_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):  # Training loop function\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, val_loss, val_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        if batch_i > 0:\n",
    "            gc.collect()\n",
    "            if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "            b_loss, b_accuracy = train_step()\n",
    "            mname_fn = model_name\n",
    "            if verbose:\n",
    "                sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                          ' @ batch '+ str(batch_i) + ' (' + str(batch_i * batch_size) + ' samples) complete.                  ')\n",
    "            iter_loss.append(b_loss), iter_accuracy.append(b_accuracy)\n",
    "\n",
    "        if batch_i % log_period_batches == 0:  # Test on val set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            out_str = '\\n'\n",
    "            for i in range(N_val):\n",
    "                val_X, val_Y, val_Sqlens = adapt_form(val_xs[i], val_ys[i], val_sqlens[i], repl_finalcomma=batch_i > 0)\n",
    "                feed_batches = [range(len(val_X))[i * bsz:(i + 1) * bsz] for i in range((len(val_X) // bsz) + \\\n",
    "                                                                                        (1 if (len(val_X) % bsz) != 0 else 0))]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(val_X[inds], val_Y[inds], val_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls)), accuracy.append(np.mean(cs))\n",
    "                out_str += val_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]) + '\\n'\n",
    "            \n",
    "            val_l, val_a = np.mean(loss), np.mean(accuracy)\n",
    "            val_loss.append(val_l), val_accuracy.append(val_a)\n",
    "            if batch_i == 0: iter_loss, iter_accuracy = [val_l], [val_a]\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l), train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "\n",
    "#             if ((val_a > best_acc and val_a >= train_a) or \\\n",
    "            if ((val_a > best_acc) or \\\n",
    "              (batch_i // log_period_batches) == 1) and batch_i > 0:      # Save best accuracy model\n",
    "                best_acc = val_a\n",
    "                best_loss = val_l\n",
    "                best_acc_idx = batch_i // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "#                          \"llayer\": llayer.state_dict(),\n",
    "#                          \"softmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(out_str + \"Batch\", batch_i, ':', train_a, val_a, \"loss:\", train_l, val_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(val_accuracy, label='val acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                plt.yscale(\"log\")\n",
    "                g.plot(val_loss, label='val loss')\n",
    "                plt.yscale(\"log\")\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, val_accuracy, train_loss, val_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "construction sounds: 1.5462981, 0.703125\n",
      "hats: 5.6392183, 0.59765625\n",
      "wild animals: 3.69217, 0.71875\n",
      "woodland ecoregions: 1.7893951, 0.6484375\n",
      "winds: 1.4743235, 0.55859375\n",
      "physical tokens that confer trust: 4.3564568, 0.56640625\n",
      "timbers: 2.9912105, 0.5859375\n",
      "digital tokens that confer trust: 3.4626179, 0.63671875\n",
      "Batch 600 : 0.165625 0.6269531 loss: 0.16254742 3.1189613 Best: 0.65185547 4.4667377 idx: 14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.65185547, 4.4667377)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gc.collect())  # Train ernst model (enumeration representation neural subtext transfer)\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pt.cuda.empty_cache(), gc.collect()  # Load best model (checkpoint)\n",
    "cpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "model.load_state_dict(cpoint['model'])\n",
    "bcewl_loss.load_state_dict(cpoint['bcewl_loss'])\n",
    "optimizer.load_state_dict(cpoint['optimizer'])\n",
    "scheduler.load_state_dict(cpoint['scheduler'])\n",
    "# llayer.load_state_dict(cpoint['llayer'])\n",
    "mname_fn = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_filtering(logits, tcounts=None, filter_value=-float('Inf'),  # Function to tune the output token distribution\n",
    "                  top_k=0, top_p=0.0, temperature=1.0, frequency_penalty=0.0, presence_penalty=0.0):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if tcounts is not None: logits -= (tcounts * frequency_penalty) + ((tcounts > 0) * presence_penalty)\n",
    "    logits /= temperature\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gprobs(s, past=None, return_sts=False, tcounts=None, add=0, **kwargs):  # Inference and sampling for tokens\n",
    "    global model\n",
    "    xs, mlen = None, None\n",
    "    if isinstance(s, tuple):    # s either list of token tensors or tuple of preformatted 2d tensors\n",
    "        xs, _, sqlen = s\n",
    "        mlen = max(sqlen)\n",
    "    else:\n",
    "        sqlen = [len(s_) for s_ in s]\n",
    "        mlen = max(sqlen)\n",
    "        xs, _, sqlen = adapt_form([pt.tensor(s_).to(d) for s_ in s], None, sqlen, mlen=mlen)\n",
    "    gc.collect(), pt.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    y_hat = inference(xs, sqlen, seq_maxlen=mlen, add=add, past=past, return_states=return_sts)\n",
    "    if return_sts: y_hat, states = y_hat\n",
    "    y_hat = pt.vstack([F.softmax(top_filtering(y_hat[i], tcounts[i] if tcounts is not None else None,\n",
    "                                               **kwargs), dim=0) for i in range(len(xs))])\n",
    "    return (y_hat, states) if return_sts else y_hat\n",
    "def append_next_token(sent, olen=None, top_k=-1, top_p=0.9, temperature=1.0):  # Interface for field testing\n",
    "    print(\"k =\", top_k, \", p =\", top_p, \", temp =\", temperature)\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    ou = tokens.copy()\n",
    "    tcounts = pt.zeros(N_tokens, dtype=int).to(d)\n",
    "    for token in tokens: tcounts[token] += 1\n",
    "    probs = gprobs([tokens], top_k=top_k, top_p=top_p, temperature=temperature, tcounts=[tcounts])[0]\n",
    "    token = pt.multinomial(probs, 1).detach().cpu().numpy()[0]\n",
    "    ou += [token]\n",
    "    prev_len = len(sent) if olen is None else olen\n",
    "    sent_new = tokenizer.decode(ou)\n",
    "    print(sent[:prev_len] + '➡' + sent_new[prev_len:])\n",
    "    return sent_new\n",
    "def gen_probs(s, **kwargs):  # Adapter for strings\n",
    "    inp = [tokenizer.encode(s_) for s_ in s]\n",
    "    return gprobs(inp, **kwargs)\n",
    "def gen_completions(s, n=1, max_tokens=phrl_max, best_of=1, **kwargs):  # Completion generator equivalent to OpenAI's for GPT3\n",
    "    gpu_multiplier = 1/(bsz if \"xlnet\" in modelkey else 4)\n",
    "    n_bats, best_of, outputs = int(np.ceil(len(s) / int(bsz * gpu_multiplier))), int(round(best_of)), []\n",
    "    if n == 1 and best_of != 1: n, best_of = best_of, n\n",
    "    if best_of == 1 and n != 1: best_of = n\n",
    "    gc.collect()\n",
    "    for i in range(n_bats):\n",
    "        s_batch, tc_b = s[i * int(bsz * gpu_multiplier):(i + 1) * int(bsz * gpu_multiplier)], []\n",
    "        print(s_batch)\n",
    "        for s_ in s_batch:\n",
    "            tc = pt.zeros(N_tokens, dtype=int).to(d)\n",
    "            for t in tokenizer.encode(s_): tc[t] += 1\n",
    "            tc_b.append(tc)\n",
    "        p, sts = gen_probs(s_batch, return_sts=True, tcounts=tc_b, **kwargs)\n",
    "        sql_b = [len(tokenizer.encode(s_)) for s_ in s_batch]\n",
    "        mlen = max(sql_b)\n",
    "        sql_b = pt.tensor(sql_b).to(d)\n",
    "        # First use the (as yet undiverged) token distribution (multinomial) to generate n tokens for each sample\n",
    "        tokens = pt.multinomial(p, n, replacement=True) \n",
    "        outs, avg_logprobs = [], []\n",
    "        for j in range(n):\n",
    "            tks, tc_b_itr = tokens[:, j], [tc_.clone() for tc_ in tc_b]\n",
    "            for j in range(len(tc_b_itr)): tc_b_itr[j][tks[j]] += 1\n",
    "            gc.collect(), pt.cuda.empty_cache()\n",
    "            if multimask_arch:\n",
    "                s_b = [tokenizer.decode(np.hstack([tokenizer.encode(s_batch[i]),\n",
    "                                                   tks[[i]].cpu().detach().numpy()])) for i in range(len(s_batch))]\n",
    "                print(s_b)\n",
    "                p = gen_probs(s_b, tcounts=tc_b_itr, **kwargs)\n",
    "            else:\n",
    "                p, st = gprobs((pt.unsqueeze(tks,-1),None,sql_b), past=sts, return_sts=True, tcounts=tc_b_itr, add=1, **kwargs)\n",
    "            su, ls, out = pt.log(p[pt.arange(p.shape[0]), tks]), pt.ones(p.shape[0]).to(d), [tks.cpu().detach()]\n",
    "            for token_i in range(max_tokens - 1):\n",
    "                t = pt.multinomial(p, 1).to(d)[:, 0]\n",
    "                out.append(t.cpu().detach())\n",
    "                for j in range(len(tc_b_itr)): tc_b_itr[j][t[j]] += 1\n",
    "                cont = t != pad_token\n",
    "                ls += cont.int()\n",
    "                su += cont * pt.log(p[pt.arange(p.shape[0]), t])\n",
    "                if token_i == max_tokens - 1: break\n",
    "                if multimask_arch:\n",
    "                    s_b = [tokenizer.decode(np.hstack([tokenizer.encode(s_b[i]),\n",
    "                                                       t[[i]].cpu().detach().numpy()])) for i in range(len(s_b))]\n",
    "                    print(s_b)\n",
    "                    p = gen_probs(s_b, tcounts=tc_b_itr, **kwargs)\n",
    "                else:\n",
    "                    p,st=gprobs((pt.unsqueeze(t,-1),None,sql_b),past=st,return_sts=True,tcounts=tc_b_itr,add=token_i+2,**kwargs)\n",
    "            outs.append(pt.vstack(out).T), avg_logprobs.append(su / ls)\n",
    "#             return None\n",
    "        gc.collect(), pt.cuda.empty_cache()\n",
    "        outs = pt.stack(outs, 1)\n",
    "        avg_logprobs = pt.vstack(avg_logprobs).T\n",
    "        s1 = outs.shape[0]\n",
    "        idx = pt.argsort(avg_logprobs, axis=1)[:, :best_of].repeat_interleave(max_tokens, 1).reshape(s1, best_of, max_tokens)\n",
    "        outs = pt.gather(outs, 1, idx)\n",
    "        outputs += [[[(tokenizer.decode([x_]),) for x_ in x] for x in o] for o in outs.numpy()]\n",
    "#         outputs += [[x for x in o] for o in outs.cpu().detach().numpy()]\n",
    "    pr([[' '.join([x_[0] for x_ in x]) for x in o] for o in outputs])\n",
    "#     pr([[tokenizer.decode(x) for x in o] for o in outputs])\n",
    "    return outputs\n",
    "mdl = {\"completions\": gen_completions, \"probabilities\": gprobs, \"name\": mname_fn + ',' + modelkey, \"mstr\": str(model)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gprobs(s, past=None, return_sts=False, tcounts=None, add=0, **kwargs):  # Inference and sampling for tokens\n",
    "    global model\n",
    "    xs, mlen = None, None\n",
    "    if isinstance(s, tuple):    # s either list of token tensors or tuple of preformatted 2d tensors\n",
    "        xs, _, sqlen = s\n",
    "        mlen = max(sqlen)\n",
    "    else:\n",
    "        sqlen = [len(s_) for s_ in s]\n",
    "        mlen = max(sqlen)\n",
    "        xs, _, sqlen = adapt_form([pt.tensor(s_).to(d) for s_ in s], None, sqlen, mlen=mlen)\n",
    "    gc.collect(), pt.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    y_hat = inference(xs, sqlen, seq_maxlen=mlen, add=add, past=past, return_states=return_sts)\n",
    "    if return_sts: y_hat, states = y_hat\n",
    "    y_hat = pt.vstack([F.softmax(top_filtering(y_hat[i], tcounts[i] if tcounts is not None else None,\n",
    "                                               **kwargs), dim=0) for i in range(len(xs))])\n",
    "    return (y_hat, states) if return_sts else y_hat\n",
    "def append_next_token(sent, olen=None, top_k=-1, top_p=0.9, temperature=1.0):  # Interface for field testing\n",
    "    print(\"k =\", top_k, \", p =\", top_p, \", temp =\", temperature)\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    ou = tokens.copy()\n",
    "    tcounts = pt.zeros(N_tokens, dtype=int).to(d)\n",
    "    for token in tokens: tcounts[token] += 1\n",
    "    probs = gprobs([tokens], top_k=top_k, top_p=top_p, temperature=temperature, tcounts=[tcounts])[0]\n",
    "    token = pt.multinomial(probs, 1).detach().cpu().numpy()[0]\n",
    "    ou += [token]\n",
    "    prev_len = len(sent) if olen is None else olen\n",
    "    sent_new = tokenizer.decode(ou)\n",
    "    print(sent[:prev_len] + '➡' + sent_new[prev_len:])\n",
    "    return sent_new\n",
    "def gen_probs(s, **kwargs):  # Adapter for strings\n",
    "    inp = [tokenizer.encode(s_) for s_ in s]\n",
    "    return gprobs(inp, **kwargs)\n",
    "def gen_completions(s, n=1, max_tokens=phrl_max, best_of=1, **kwargs):  # Completion generator equivalent to OpenAI's for GPT3\n",
    "    gpu_multiplier = 1/(bsz if \"xlnet\" in modelkey else 4)\n",
    "    n_bats, best_of, outputs = int(np.ceil(len(s) / int(bsz * gpu_multiplier))), int(round(best_of)), []\n",
    "    if n == 1 and best_of != 1: n, best_of = best_of, n\n",
    "    if best_of == 1 and n != 1: best_of = n\n",
    "    gc.collect()\n",
    "    for i in range(n_bats):\n",
    "        s_batch, tc_b = s[i * int(bsz * gpu_multiplier):(i + 1) * int(bsz * gpu_multiplier)], []\n",
    "        print(s_batch)\n",
    "        for s_ in s_batch:\n",
    "            tc = pt.zeros(N_tokens, dtype=int).to(d)\n",
    "            for t in tokenizer.encode(s_): tc[t] += 1\n",
    "            tc_b.append(tc)\n",
    "        p, sts = gen_probs(s_batch, return_sts=True, tcounts=tc_b, **kwargs)\n",
    "        sql_b = [len(tokenizer.encode(s_)) for s_ in s_batch]\n",
    "        mlen = max(sql_b)\n",
    "        sql_b = pt.tensor(sql_b).to(d)\n",
    "        # First use the (as yet undiverged) token distribution (multinomial) to generate n tokens for each sample\n",
    "        tokens = pt.multinomial(p, n, replacement=True) \n",
    "        outs, avg_logprobs = [], []\n",
    "        for j in range(n):\n",
    "            tks, tc_b_itr = tokens[:, j], [tc_.clone() for tc_ in tc_b]\n",
    "            for j in range(len(tc_b_itr)): tc_b_itr[j][tks[j]] += 1\n",
    "            gc.collect(), pt.cuda.empty_cache()\n",
    "            if multimask_arch:\n",
    "                s_b = [tokenizer.decode(np.hstack([tokenizer.encode(s_batch[i]),\n",
    "                                                   tks[[i]].cpu().detach().numpy()])) for i in range(len(s_batch))]\n",
    "                print(s_b)\n",
    "                p = gen_probs(s_b, tcounts=tc_b_itr, **kwargs)\n",
    "            else:\n",
    "                p, st = gprobs((pt.unsqueeze(tks,-1),None,sql_b), past=sts, return_sts=True, tcounts=tc_b_itr, add=1, **kwargs)\n",
    "            su, ls, out = pt.log(p[pt.arange(p.shape[0]), tks]), pt.ones(p.shape[0]).to(d), [tks]\n",
    "            for token_i in range(max_tokens - 1):\n",
    "                t = pt.multinomial(p, 1).to(d)[:, 0]\n",
    "                out.append(t)\n",
    "                for j in range(len(tc_b_itr)): tc_b_itr[j][t[j]] += 1\n",
    "                cont = t != pad_token\n",
    "                ls += cont.int()\n",
    "                su += cont * pt.log(p[pt.arange(p.shape[0]), t])\n",
    "                if token_i == max_tokens - 1: break\n",
    "                if multimask_arch:\n",
    "                    s_b = [tokenizer.decode(np.hstack([tokenizer.encode(s_b[i]),\n",
    "                                                       t[[i]].cpu().detach().numpy()])) for i in range(len(s_b))]\n",
    "                    print(s_b)\n",
    "                    p = gen_probs(s_b, tcounts=tc_b_itr, **kwargs)\n",
    "                else:\n",
    "                    p,st=gprobs((pt.unsqueeze(t,-1),None,sql_b),past=st,return_sts=True,tcounts=tc_b_itr,add=token_i+2,**kwargs)\n",
    "            outs.append(pt.vstack(out).T), avg_logprobs.append(su / ls)\n",
    "#             return None\n",
    "        gc.collect(), pt.cuda.empty_cache()\n",
    "        outs = pt.stack(outs, 1)\n",
    "        avg_logprobs = pt.vstack(avg_logprobs).T\n",
    "        s1 = outs.shape[0]\n",
    "        idx = pt.argsort(avg_logprobs, axis=1)[:, :best_of].repeat_interleave(max_tokens, 1).reshape(s1, best_of, max_tokens)\n",
    "        outs = pt.gather(outs, 1, idx)\n",
    "        outputs += [[[(tokenizer.decode([x_]),) for x_ in x] for x in o] for o in outs.cpu().detach().numpy()]\n",
    "#         outputs += [[x for x in o] for o in outs.cpu().detach().numpy()]\n",
    "    pr([[' '.join([x_[0] for x_ in x]) for x in o] for o in outputs])\n",
    "#     pr([[tokenizer.decode(x) for x in o] for o in outputs])\n",
    "    return outputs\n",
    "mdl = {\"completions\": gen_completions, \"probabilities\": gprobs, \"name\": mname_fn + ',' + modelkey, \"mstr\": str(model)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "{   'best_of': 1.0,\n",
      "    'frequency_penalty': 0.04738827217229063,\n",
      "    'presence_penalty': 0.0744755794115483,\n",
      "    'temperature': 1.3101102471365533,\n",
      "    'top_p': 0.9903237363946299}\n",
      "['A list of construction sound:']\n",
      "['A list of construction sound::']\n",
      "['A list of construction sound:::']\n",
      "['A list of construction sound::::']\n",
      "['A list of construction sound:::::']\n",
      "['A list of construction sound::::::']\n",
      "['A list of construction sound::']\n",
      "['A list of construction sound:::']\n",
      "['A list of construction sound::::']\n",
      "['A list of construction sound:::::']\n",
      "['A list of construction sound::::: and']\n",
      "['A list of construction sound::']\n",
      "['A list of construction sound:::']\n",
      "['A list of construction sound::::']\n",
      "['A list of construction sound:::::']\n",
      "['A list of construction sound::::::']\n",
      "['A list of construction sound::']\n",
      "['A list of construction sound:::']\n",
      "['A list of construction sound::::']\n",
      "['A list of construction sound:::::']\n",
      "['A list of construction sound::::::']\n",
      "['A list of construction sound::']\n",
      "['A list of construction sound:: The']\n",
      "['A list of construction sound:: The<eop>']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 1.87 GiB already allocated; 0 bytes free; 2.02 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.04738827217229063, 0.0744755794115483, 1.3101102471365533, 0.9903237363946299)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d10e99096fc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0moptimizers_modelf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds_modelf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#     optimizers_modelf[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0moptimizers_modelf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mresults_modelf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers_modelf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-d10e99096fc8>\u001b[0m in \u001b[0;36mfun\u001b[1;34m(temperature, top_p, presence_penalty, frequency_penalty)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"best_of\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mpr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"A list of\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0moptimizers_modelf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds_modelf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#     optimizers_modelf[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-2887af08840a>\u001b[0m in \u001b[0;36mtest_sp_conv\u001b[1;34m(params, tol, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_nochange\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[0mnew_center\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msteps_nochange\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-2887af08840a>\u001b[0m in \u001b[0;36mtest_sp\u001b[1;34m(params, min_l, max_l, n1, n2, prmt, phase, uniform, max_tokens, mdl, mdl2, d, d_test, inds, inds_test, m2ensemble_frac, return_test_acc)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_sp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_tokens'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m#**default_msp,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmdl\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Request predictions from OpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"completions\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[0msave_modeloutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphaseIx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsps_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmdl2\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-8c5d9e992a5f>\u001b[0m in \u001b[0;36mgen_completions\u001b[1;34m(s, n, max_tokens, best_of, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m                                                        t[[i]].cpu().detach().numpy()])) for i in range(len(s_b))]\n\u001b[0;32m     77\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtcounts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtc_b_itr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgprobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msql_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_sts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtcounts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtc_b_itr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_i\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-8c5d9e992a5f>\u001b[0m in \u001b[0;36mgen_probs\u001b[1;34m(s, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgen_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Adapter for strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgprobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgen_completions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mphrl_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_of\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Completion generator equivalent to OpenAI's for GPT3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mgpu_multiplier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"xlnet\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodelkey\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-8c5d9e992a5f>\u001b[0m in \u001b[0;36mgprobs\u001b[1;34m(s, past, return_sts, tcounts, add, **kwargs)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_maxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_sts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_sts\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     y_hat = pt.vstack([F.softmax(top_filtering(y_hat[i], tcounts[i] if tcounts is not None else None,\n",
      "\u001b[1;32m<ipython-input-21-4f956b10a533>\u001b[0m in \u001b[0;36minference\u001b[1;34m(x, sqlens, past, return_states, seq_maxlen, add, return_fulloutput)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mmany_inp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultimask_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmultimask_arch\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msinglemask_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_fulloutput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmultimask_arch\u001b[0m \u001b[1;32melse\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqlens\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmany_inp\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-4f956b10a533>\u001b[0m in \u001b[0;36mmultimask_model\u001b[1;34m(model, x, sqlens, past, seq_maxlen, add, many_inp, return_states, **kw)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m#     print(perm_mask, target_mapping)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     res = model(x, perm_mask=perm_mask if attn_mask is None else None, target_mapping=target_mapping,\n\u001b[1;32m---> 61\u001b[1;33m                    mems=past, attention_mask=attn_mask, use_mems=None if (past is None and not return_states) else True)\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;31m#     print(res[0].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, labels, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1444\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1446\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1447\u001b[0m         )\n\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1256\u001b[0m                 \u001b[0mtarget_mapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m                 \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m             )\n\u001b[0;32m   1260\u001b[0m             \u001b[0moutput_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mtarget_mapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m         )\n\u001b[0;32m    527\u001b[0m         \u001b[0moutput_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;31m# post processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[0moutput_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_vec_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# g-stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py\u001b[0m in \u001b[0;36mpost_attention\u001b[1;34m(self, h, attn_vec, residual)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;34m\"\"\"Post-attention processing.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# post-attention projection (back to `d_model`)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mattn_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ibnd,hnd->ibh\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mattn_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(equation, *operands)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 1.87 GiB already allocated; 0 bytes free; 2.02 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# optimise fine-tuned model sampling params\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_modelf = {\n",
    "  \"temperature\": [0.99, 2.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.99, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 0.1],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 0.1],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_modelf, results_modelf = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 1.0\n",
    "        pr(ps)\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.005, phase=\"val\", uniform=True, mdl=mdl, n2=20, max_tokens=5, prmt=\"A list of\")[0]\n",
    "    optimizers_modelf.append(BayesianOptimization(f=fun, pbounds=bounds_modelf, verbose=1000))\n",
    "#     optimizers_modelf[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0})\n",
    "    optimizers_modelf[-1].maximize(init_points=5, n_iter=10)\n",
    "    results_modelf.append(optimizers_modelf[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer\n",
    "tokenizerr = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
    "# modell = XLNetLMHeadModel.from_pretrained('xlnet-large-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 1.89 GiB already allocated; 0 bytes free; 2.04 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-fbaad2744a8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtarget_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m  \u001b[1;31m# Our first (and only) prediction will be the last token of the sequence (the masked token)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mperm_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_mapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mnext_token_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, labels, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1444\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1446\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1447\u001b[0m         )\n\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1256\u001b[0m                 \u001b[0mtarget_mapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m                 \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m             )\n\u001b[0;32m   1260\u001b[0m             \u001b[0moutput_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mtarget_mapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m         )\n\u001b[0;32m    527\u001b[0m         \u001b[0moutput_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;31m# post processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[0moutput_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_vec_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# g-stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py\u001b[0m in \u001b[0;36mpost_attention\u001b[1;34m(self, h, attn_vec, residual)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;34m\"\"\"Post-attention processing.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# post-attention projection (back to `d_model`)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mattn_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ibnd,hnd->ibh\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mattn_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(equation, *operands)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 1.89 GiB already allocated; 0 bytes free; 2.04 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# We show how to setup inputs to predict a next token using a bi-directional context.\n",
    "# input_ids = pt.tensor(tokenizerr.encode(\"Hello, my dog is very<mask>\", add_special_tokens=False)).unsqueeze(0).to(d)\n",
    "# input_ids = pt.tensor(tokenizerr.encode(\"A list of common types of wild animal:<mask>\", add_special_tokens=False)).unsqueeze(0).to(d)\n",
    "# input_ids = pt.tensor(tokenizerr.encode(\"The road was long, but not the<mask>\", add_special_tokens=False)).unsqueeze(0).to(d)\n",
    "input_ids = pt.tensor(tokenizerr.encode(\"A list of construction sounds:<mask>\", add_special_tokens=False)).unsqueeze(0).to(d)\n",
    "perm_mask = pt.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=pt.float).to(d)\n",
    "perm_mask[:, :, -1] = 1.0  # Previous tokens don't see last token\n",
    "target_mapping = pt.zeros((1, 1, input_ids.shape[1]), dtype=pt.float).to(d) # Shape [1, 1, seq_length] => let's predict one token\n",
    "target_mapping[0, 0, -1] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)\n",
    "\n",
    "outputs = model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping)\n",
    "next_token_logits = outputs[0]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 1.89 GiB already allocated; 0 bytes free; 2.04 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-80cba40c378b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenizerr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_token_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 1.89 GiB already allocated; 0 bytes free; 2.04 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "tokenizerr.decode(pt.argsort(next_token_logits[0, 0])[-50:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-16.193918,\n",
       " -16.183165,\n",
       " -16.122074,\n",
       " -16.08592,\n",
       " -16.043228,\n",
       " -16.03282,\n",
       " -16.0242,\n",
       " -16.00353,\n",
       " -15.979343,\n",
       " -15.977925,\n",
       " -15.936374,\n",
       " -15.922286,\n",
       " -15.9158,\n",
       " -15.909621,\n",
       " -15.875632,\n",
       " -15.871074,\n",
       " -15.861634,\n",
       " -15.825805,\n",
       " -15.774126,\n",
       " -15.554242,\n",
       " -15.54916,\n",
       " -15.542339,\n",
       " -15.379066,\n",
       " -15.3337,\n",
       " -15.333503,\n",
       " -15.292143,\n",
       " -15.264986,\n",
       " -15.20713,\n",
       " -15.105776,\n",
       " -15.044917,\n",
       " -14.981879,\n",
       " -14.973442,\n",
       " -14.910143,\n",
       " -14.671865,\n",
       " -14.574007,\n",
       " -14.510053,\n",
       " -14.498207,\n",
       " -14.486406,\n",
       " -14.438374,\n",
       " -14.284411,\n",
       " -14.193142,\n",
       " -14.12361,\n",
       " -14.119947,\n",
       " -13.70911,\n",
       " -13.136736,\n",
       " -13.095249,\n",
       " -12.753677,\n",
       " -12.56003,\n",
       " -11.044312,\n",
       " -10.502604]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pt.sort(next_token_logits[0, 0])[0][-50:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "['An exhaustive list of some types of construction sound:']\n",
      "['A list of common types of hats:']\n",
      "['A list of some animals seen in the wild:']\n",
      "['A list of types of  wood:']\n",
      "['A list of some types of winds:']\n",
      "['An exhaustive list of different types of physical tokens of trust:']\n",
      "['A list of different types of timber:']\n",
      "['An exhaustive list of well-known digital tokens that confer trust:']\n",
      "[   [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [':  Hip ly  \" \" \" \" \" \"', ':  Hip ly  \" \" \" \" \" \"'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    ['. . . . . . . . . . .', '. . . . . . . . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [': : : . . . . . . . .', ': : : . . . . . . . .'],\n",
      "    ['. . . . . . . . . . .', '. . . . . . . . . . .'],\n",
      "    ['<eop> Any Ale Ale , , , , , , ,', '<eop> Any Ale Ale , , , , , , ,']]\n",
      "['A list of different types of chemical element:']\n",
      "['A list of types of  essential element to successful drama and storytelling:']\n",
      "['A list of some types of vehicles referred to as crafts:']\n",
      "['A list of common types of music genre:']\n",
      "['A list of different types of cyclic system:']\n",
      "['A list of some types of AI algorithm:']\n",
      "['A list of common types of thing made of glass:']\n",
      "['A long list of some types of coil winding:']\n",
      "[   [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    ['a  lice ly ly ly . . . . .', 'a  lice ly ly ly . . . . .'],\n",
      "    ['here . . . . . . . . . .', 'here . . . . . . . . . .'],\n",
      "    [   ' ken ken ea ita ita ita ita Against Against Against',\n",
      "        ' ken ken ea ita ita ita ita Against Against Against'],\n",
      "    [': : : , 3 . . . . . .', ': : : , 3 . . . . . .'],\n",
      "    [   ': : leans leans An An An An An An An',\n",
      "        ': : leans leans An An An An An An An'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [': . . . . . . . . . .', ': . . . . . . . . . .']]\n",
      "['An exhaustive list of some types of noise of building:']\n",
      "['A long list of hats:']\n",
      "['A long list of some types of wild animals:']\n",
      "['An exhaustive list of different types of woods:']\n",
      "['An exhaustive list of some types of wind:']\n",
      "['A list of some types of physical objects of trust:']\n",
      "['An exhaustive list of some types of lumber:']\n",
      "['A list of well-known types of digital token that can confer trust:']\n",
      "[   [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    ['a a a a an  . . . . .', 'a a a a an  . . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [': . . . . . . . . . .', ': . . . . . . . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [': ly  . . . . . . . .', ': ly  . . . . . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .']]\n",
      "['A long list of common types of periodic element:']\n",
      "['An exhaustive list of different types of element of drama and writing:']\n",
      "['An exhaustive list of common types of craft:']\n",
      "['A list of some types of classification of music:']\n",
      "['A list of well-known types of cyclic phenomena:']\n",
      "['A long list of ML algorithms:']\n",
      "['A long list of different types of glass things:']\n",
      "['A long list of some types of winding:']\n",
      "[   [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [   'once every an an an an an an . . .',\n",
      "        'once every an an an an an an . . .'],\n",
      "    [': : : , . . . . . . .', ': : : , . . . . . . .'],\n",
      "    [':  Piece  . . . . . . .', ':  Piece  . . . . . . .'],\n",
      "    ['<eop> A . . . . . . . . .', '<eop> A . . . . . . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [' <unk> n n . . . . . . .', ' <unk> n n . . . . . . .']]\n",
      "['An exhaustive list of common types of construction noise:']\n",
      "['A list of types of  hat:']\n",
      "['Well-known animals seen in the wild:']\n",
      "['A list of well-known woods:']\n",
      "['A list of different winds:']\n",
      "['A list of different types of object that confer trust:']\n",
      "['A list of common types of timbers:']\n",
      "['An exhaustive list of well-known types of digital token of trust:']\n",
      "[   [' . . . . <eop> \" \" \" \" \"', ' . . . . <eop> \" \" \" \" \"'],\n",
      "    ['a an an an an an an An  . .', 'a an an an an an an An  . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    ['a a a a a a a a a a A', 'a a a a a a a a a a A'],\n",
      "    ['a a a a  ged ge ge e e E', 'a a a a  ged ge ge e e E'],\n",
      "    [   '. <eop> Not ed ed ed ed ed ed zed ,',\n",
      "        '. <eop> Not ed ed ed ed ed ed zed ,'],\n",
      "    ['- - \" \" \" \" \" \" \" \" \"', '- - \" \" \" \" \" \" \" \" \"'],\n",
      "    [': : . . . . . . . . .', ': : . . . . . . . . .']]\n",
      "['An exhaustive list of well-known types of periodic table element:']\n",
      "['A long list of different dramatic and literature elements:']\n",
      "['A list of different types of crafts:']\n",
      "['An exhaustive list of common types of music genre:']\n",
      "['A list of common types of scientific cycles:']\n",
      "['An exhaustive list of common ML models:']\n",
      "['A list of some types of glass object:']\n",
      "['A long list of different types of electromagnetic coil winding:']\n",
      "[   [': : , 4 5 6 7 8  . .', ': : , 4 5 6 7 8  . .'],\n",
      "    [':  . . . . . . . . .', ':  . . . . . . . . .'],\n",
      "    [':  . . . . . . . . .', ':  . . . . . . . . .'],\n",
      "    [' - - - - . . . . . .', ' - - - - . . . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [', , I I I I I I I I I', ', , I I I I I I I I I'],\n",
      "    [':  ( )  . . . . . .', ':  ( )  . . . . . .'],\n",
      "    [': : . . . . . . . . .', ': : . . . . . . . . .']]\n",
      "['An exhaustive list of well-known types of construction noise:']\n",
      "['An exhaustive list of well-known types of hat:']\n",
      "['A long list of common types of wild animal:']\n",
      "['An exhaustive list of common types of woodland ecoregion:']\n",
      "['A long list of common winds:']\n",
      "['A long list of physical objects of trust:']\n",
      "['A long list of well-known types of wood:']\n",
      "['An exhaustive list of common digital tokens that can confer trust:']\n",
      "[   [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [   ': :  <unk> <unk> <unk> <unk> ′ ′ ′ ′',\n",
      "        ': :  <unk> <unk> <unk> <unk> ′ ′ ′ ′'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [   ': : Base Four Three Fifty Two One Face Face ,',\n",
      "        ': : Base Four Three Fifty Two One Face Face ,'],\n",
      "    ['<eop> Any An And And And  . . . .', '<eop> Any An And And And  . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    ['like like like . . . . . . . .', 'like like like . . . . . . . .'],\n",
      "    ['. . . . . . . . . . .', '. . . . . . . . . . .']]\n",
      "['A list of different types of element of the periodic table:']\n",
      "['A long list of well-known types of element of drama and storywriting:']\n",
      "['A long list of some crafts:']\n",
      "['A long list of different types of music type:']\n",
      "['Well-known cyclic effects:']\n",
      "['A list of well-known types of artificial intelligence algorithms:']\n",
      "['A list of well-known things made of glass:']\n",
      "['An exhaustive list of different types of wind:']\n",
      "[   [':  . . . . . . . . .', ':  . . . . . . . . .'],\n",
      "    [   'each a short very short very very very very very very',\n",
      "        'each a short very short very very very very very very'],\n",
      "    ['. . . . . . . . . . .', '. . . . . . . . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [   'best most most top most most most best best best best',\n",
      "        'best most most top most most most best best best best'],\n",
      "    [': :  strand ly ly ly . . . .', ': :  strand ly ly ly . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .'],\n",
      "    [' . . . . . . . . . .', ' . . . . . . . . . .']]\n",
      "['A list of common noises of building:']\n",
      "['A list of types of  hat:']\n",
      "['A list of some types of animals found in the wild:']\n",
      "['A list of different types of wood:']\n",
      "['A list of some types of winds:']\n",
      "['An exhaustive list of different types of physical object that can confer trust:']\n",
      "['An exhaustive list of common types of lumber:']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.20541783713361572, 1.5689387028580402, 0.2661199454778089, 0.2665727715909656)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-6c259ec353a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moptimizers_modelf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds_modelf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#     optimizers_modelf[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0moptimizers_modelf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mresults_modelf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizers_modelf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-6c259ec353a2>\u001b[0m in \u001b[0;36mfun\u001b[0;34m(temperature, top_p, presence_penalty, frequency_penalty)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"best_of\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0moptimizers_modelf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds_modelf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#     optimizers_modelf[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-19d4fbcb881f>\u001b[0m in \u001b[0;36mtest_sp_conv\u001b[0;34m(params, tol, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_nochange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mnew_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msteps_nochange\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-19d4fbcb881f>\u001b[0m in \u001b[0;36mtest_sp\u001b[0;34m(params, min_l, max_l, n1, n2, prmt, phase, uniform, max_tokens, mdl, mdl2, d, d_test, inds, inds_test, m2ensemble_frac, return_test_acc)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_sp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#**default_msp,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gpt3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Request predictions from OpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"completions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0msave_modeloutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphaseIx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsps_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdl2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-d5332a5be5f9>\u001b[0m in \u001b[0;36mgen_completions\u001b[0;34m(s, n, max_tokens, best_of, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0msu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcont\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtoken_i\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_tokens\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgprobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msql_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtcounts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtc_b_itr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_logprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msu\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-d5332a5be5f9>\u001b[0m in \u001b[0;36mgprobs\u001b[0;34m(s, past, return_sts, tcounts, add, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapt_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_maxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_sts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_sts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimise fine-tuned model sampling params\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_modelf = {\n",
    "  \"temperature\": [0.0001, 1.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.0001, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_modelf, results_modelf = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 1.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.005, phase=\"val\", uniform=True, mdl=mdl, n2=2)[0]\n",
    "    optimizers_modelf.append(BayesianOptimization(f=fun, pbounds=bounds_modelf, verbose=1000))\n",
    "#     optimizers_modelf[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0})\n",
    "    optimizers_modelf[-1].maximize(init_points=5, n_iter=10)\n",
    "    results_modelf.append(optimizers_modelf[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers_modelf[-1].max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # optimise fine-tuned model params with refined bounds\n",
    "# lgroups_ft = [[4, 5]]\n",
    "# bounds_gptxlf_rf = {\n",
    "#   \"temperature\": [0.0001, 0.003],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "#   \"top_p\": [0.001, 1.0],        # same with this but more obvious\n",
    "# #   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "#   \"presence_penalty\": [0.1, 1.0],   # both presence and frequency penalty have optimal values\n",
    "# #   \"frequency_penalty\": [0.0, 1.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "# #   \"best_of\": [0.51, 5.49], # to do\n",
    "# }\n",
    "# optimizers_gpt2xlf_rf, results_gpt2xlf_rf = [], []\n",
    "# for lgroup in lgroups_ft:\n",
    "#     min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "#     def fun(temperature, top_p, presence_penalty):\n",
    "#         global min_l, max_l\n",
    "#         ps = locals()\n",
    "#         ps[\"best_of\"] = 5.0\n",
    "#         return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.002, phase=\"val\", uniform=True, mdl=mdl)[0]\n",
    "#     optimizers_gpt2xlf_rf.append(BayesianOptimization(f=fun, pbounds=bounds_gptxlf_rf, verbose=1000))\n",
    "#     optimizers_gpt2xlf_rf[-1].probe(params={\"temperature\": 0.001, \"top_p\": 0.001, \"presence_penalty\": 0.4052})\n",
    "#     optimizers_gpt2xlf_rf[-1].maximize(init_points=2, n_iter=8)\n",
    "#     results_gpt2xlf_rf.append(optimizers_gpt2xlf_rf[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers_gpt2xlf_rf[-1].probe(params={\"temperature\": 0.001, \"top_p\": 0.001, \"presence_penalty\": 0.4052})\n",
    "# optimizers_gpt2xlf_rf[-1].maximize(n_iter=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers_gpt2xlf[-1].max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fix result formatting\n",
    "# for i in range(N_wordlists):\n",
    "#     fs = glob.glob(data_dir + learning_data_dir + \"/msp_single_samples/\" + str(i) + '/*')\n",
    "#     entries = []\n",
    "#     for file in fs:\n",
    "#         d_ = load_ld(file, pad=False)\n",
    "#         params, input_data, ix, r_, mdl_string = d_\n",
    "#         d_ = params, [x[0] for x in input_data], ix, r_, mdl_string\n",
    "#         save_ld(d_, file, pad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load predictions from the top performing fine-tuned model, and create the ensemble mdl object\n",
    "# optimal_params = {\"temperature\": ?, \"top_p\": ?, \"presence_penalty\": ?, \"frequency_penalty\": ?}\n",
    "# optimal_params = optimizers_gpt2xlf[-1].max[\"params\"]\n",
    "optimal_params = {**default_sp, **{'frequency_penalty': 0.0727219392109375,\n",
    "                                   'presence_penalty': 0.3910543467725913,\n",
    "                                   'temperature': 0.057551002098534226,\n",
    "                                   'top_p': 0.25933633649499327}}\n",
    "def get_sp_samples(params, test=False):  # Get all datapoints which match these parameters (todo: for each length group)\n",
    "    dn = 'msp_samples_nb' + (\"_test\" if test else '') + '/'\n",
    "    dname = 'data/learning_data/' + dn\n",
    "    D, R, inds = [], [], []  # Gathered input data and model results\n",
    "    for i in range(len(cats)):\n",
    "        idx_set = train_idx if i in train_idx else (val_idx if i in val_idx else test_idx)\n",
    "        D_ = []\n",
    "        fns = glob.glob(dname + str(i) + '/*')\n",
    "        if len(fns) == 0: continue\n",
    "        fns = [fn.split('/')[-1].split('\\\\')[-1] for fn in fns][::-1]  # Most recent first\n",
    "        load_fns = []\n",
    "        for fn in fns:\n",
    "            fn_split = fn.split('_')\n",
    "            params = {sps_[i]: float(fn_split[i + 1]) for i in range(len(sps_))}\n",
    "            if (\"ernst_one\" in fn) and all([approx_eq(params[k], optimal_params[k]) for k in sps_]): load_fns.append(fn)\n",
    "        for fn in load_fns[:15]:\n",
    "            params, d, _, r, mdl_str = load_ld(dn + str(i) + '/' + fn.split('.data')[0])\n",
    "            D_ += d\n",
    "            R += r\n",
    "        D += D_\n",
    "        i_in_set = idx_set.tolist().index(i)\n",
    "        inds += [i_in_set for _ in range(len(D_))]\n",
    "    return D, R, np.asarray(inds)\n",
    "mdl2_d, mdl2_r, mdl2_inds = get_sp_samples(optimal_params)\n",
    "mdl2_d_test, mdl2_r_test, mdl2_inds_test = get_sp_samples(optimal_params, test=True)\n",
    "mdl2_d_x, mdl2_d_test_x = [d_[0] for d_ in mdl2_d], [d_[0] for d_ in mdl2_d_test]\n",
    "def precomputed_completions(d_x, **kwargs):\n",
    "    return mdl2_r if (d_x == mdl2_d_x) else (mdl2_r_test if d_x == mdl2_d_test_x else None)\n",
    "mdl2 = {\"completions\": precomputed_completions, \"name\": \"precomputed_one\", \"mstr\": \"precomputed_one_mstr\"}\n",
    "len(mdl2_d), len(mdl2_d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate ensemble of fine-tuned and original model\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_gptxlfe = {\n",
    "  \"temperature\": [0.0001, 1.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.0001, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_gpt2xlfe, results_gpt2xlfe = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp(ps, n1=1, min_l=min_l, max_l=max_l, phase=\"val\", uniform=True, mdl=mdl, mdl2=mdl2, return_test_acc=False,\n",
    "                       d=mdl2_d, d_test=mdl2_d_test, inds=mdl2_inds, inds_test=mdl2_inds_test)\n",
    "    optimizers_gpt2xlfe.append(BayesianOptimization(f=fun, pbounds=bounds_gptxlfe, verbose=1000))\n",
    "    optimizers_gpt2xlfe[-1].probe(params={\"temperature\": 1.0, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0})\n",
    "    optimizers_gpt2xlfe[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_gpt2xlfe.append(optimizers_gpt2xlfe[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers_gpt2xlfe[-1].max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizers_gpt2xlfe[-1].res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
    "# -------------------------------------------------------------------------\n",
    "# [0.14608262108262107, 0.1544311013061013, 0.1774588258963259]\n",
    "# [0.5712862692862692, 0.5167355977355977, 0.5436751026751027]\n",
    "# ('Test acc:', 15.932418276168276, 'sd:', 1.326833930141234)\n",
    "# |  1        |  0.5439   |  0.7545   |  0.8837   |  1.164    |  0.1678   |\n",
    "# [0.006944444444444444, 0.008333333333333333, 0.025000000000000005]\n",
    "# [0.008, 0.0, 0.014666666666666668]\n",
    "# ('Test acc:', 1.3425925925925926, 'sd:', 0.8203724604939516)\n",
    "# |  2        |  0.007556 |  1.563    |  1.115    |  1.345    |  0.4973   |\n",
    "# [0.21354131979131977, 0.173926362988863, 0.13297558922558925, 0.25522775835275835]\n",
    "# [0.5312100122100122, 0.6170219780219779, 0.5921578421578422, 0.5759225219225219]\n",
    "# ('Test acc:', 19.39177575896326, 'sd:', 4.543568017003007)\n",
    "# |  3        |  0.5791   |  1.185    |  1.479    |  0.3418   |  0.9886   |\n",
    "# [0.35648148148148145, 0.3520833333333333, 0.3180147058823529, 0.332175925925926, 0.2954656862745098]\n",
    "# [0.6432820512820513, 0.7113333333333333, 0.7075555555555556, 0.8067179487179486, 0.738952380952381]\n",
    "# ('Test acc:', 33.08442265795207, 'sd:', 2.247834350297864)\n",
    "# |  4        |  0.7216   |  0.5497   |  0.4131   |  0.04958  |  0.5878   |\n",
    "# [0.24212986087986085, 0.20677008177008174, 0.2121680402930403, 0.24574632543382546]\n",
    "# [0.5814134754134754, 0.5753290043290044, 0.6005385725385726, 0.5997070707070707]\n",
    "# ('Test acc:', 22.67035770942021, 'sd:', 1.73869387881864)\n",
    "# |  5        |  0.5892   |  0.989    |  1.323    |  0.6668   |  0.5829   |\n",
    "# [0.006944444444444444, 0.0, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.23148148148148145, 'sd:', 0.32736425054932755)\n",
    "# |  6        |  0.0      |  1.268    |  1.645    |  1.636    |  0.3853   |\n",
    "# [0.029563492063492066, 0.05555555555555556, 0.03511904761904762, 0.024537037037037038, 0.01636904761904762]\n",
    "# [0.07957142857142857, 0.13923809523809524, 0.07619047619047618, 0.15666666666666665, 0.1219047619047619]\n",
    "# ('Test acc:', 3.222883597883598, 'sd:', 1.319310339155671)\n",
    "# |  7        |  0.1147   |  1.617    |  0.524    |  0.9253   |  0.9548   |\n",
    "# [0.0, 0.0, 0.0]\n",
    "# [0.0, 0.008, 0.008]\n",
    "# ('Test acc:', 0.0, 'sd:', 0.0)\n",
    "# |  8        |  0.005333 |  1.573    |  0.1914   |  1.962    |  0.2006   |\n",
    "# [0.29166666666666663, 0.3055555555555555, 0.3819444444444444, 0.24305555555555555, 0.3506944444444444]\n",
    "# [0.6366666666666666, 0.7466666666666666, 0.7399999999999999, 0.7999999999999998, 0.73]\n",
    "# ('Test acc:', 31.458333333333332, 'sd:', 4.809247136994663)\n",
    "# |  9        |  0.7307   |  0.001    |  1.477    |  0.001    |  0.001    |\n",
    "# [0.2643718553548275, 0.2827585030710031, 0.27731273356273356, 0.2543742511573394]\n",
    "# [0.5516450836744954, 0.5830235059058588, 0.544432178932179, 0.5589042819925172]\n",
    "# ('Test acc:', 26.97043357864759, 'sd:', 1.1087671560167434)\n",
    "# |  10       |  0.5595   |  0.001    |  1.146    |  0.5046   |  1.0      |\n",
    "# [0.40625, 0.2916666666666667, 0.34722222222222215]\n",
    "# [0.55, 0.6666666666666665, 0.6066666666666667]\n",
    "# ('Test acc:', 34.83796296296296, 'sd:', 4.678560863751791)\n",
    "# |  11       |  0.6078   |  0.001    |  0.001    |  0.4932   |  0.001    |\n",
    "# [0.32638888888888884, 0.2222222222222222, 0.2916666666666667, 0.2534722222222222, 0.34722222222222215, 0.20138888888888887, 0.21527777777777776, 0.23611111111111108, 0.2847222222222222]\n",
    "# [0.74, 0.6666666666666665, 0.6866666666666665, 0.6133333333333333, 0.7266666666666666, 0.7866666666666666, 0.78, 0.6466666666666666, 0.6933333333333332]\n",
    "# ('Test acc:', 26.427469135802472, 'sd:', 4.8236109901505495)\n",
    "# |  12       |  0.7044   |  1.045    |  1.107    |  0.001    |  0.001    |\n",
    "# [0.2708333333333333, 0.2569444444444444, 0.25, 0.18055555555555555]\n",
    "# [0.62, 0.7666666666666666, 0.6266666666666666, 0.6666666666666665]\n",
    "# ('Test acc:', 23.958333333333332, 'sd:', 3.4895401462225317)\n",
    "# |  13       |  0.67     |  0.7444   |  2.0      |  0.001    |  0.001    |\n",
    "# [0.3333333333333333, 0.3263888888888889, 0.37152777777777773, 0.3020833333333333]\n",
    "# [0.6166666666666667, 0.72, 0.7941025641025641, 0.7266666666666666]\n",
    "# ('Test acc:', 33.33333333333333, 'sd:', 2.4917882108346023)\n",
    "# |  14       |  0.7144   |  0.2284   |  2.0      |  0.001    |  1.0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate un-fine-tuned model\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_gptxl = {\n",
    "  \"temperature\": [0.0001, 1.1],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.0001, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_gpt2xl, results_gpt2xl = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.005, phase=\"val\", uniform=True, mdl=mdl)[0]\n",
    "    optimizers_gpt2xl.append(BayesianOptimization(f=fun, pbounds=bounds_gptxl, verbose=1000))\n",
    "    optimizers_gpt2xl[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_gpt2xl.append(optimizers_gpt2xl[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test accuracy for the top performing (training accuracy ) sampling parameters for gpt2-\n",
    "# \n",
    "# |   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
    "# -------------------------------------------------------------------------\n",
    "# [0.049999999999999996, 0.025000000000000005, 0.061111111111111116]\n",
    "# [0.008, 0.03333333333333333, 0.029333333333333336]\n",
    "# ('Test acc:', 4.537037037037037, 'sd:', 1.5101394842870455)\n",
    "# |  1        |  0.02356  |  0.7232   |  0.9207   |  1.792    |  0.1562   |\n",
    "# [0.2111111111111111, 0.13333333333333333, 0.23576388888888888, 0.3333333333333333]\n",
    "# [0.1965714285714286, 0.11199999999999999, 0.111, 0.12]\n",
    "# ('Test acc:', 22.838541666666668, 'sd:', 7.141744752411932)\n",
    "# |  2        |  0.1349   |  0.6561   |  0.6181   |  0.6707   |  0.1418   |\n",
    "# [0.0, 0.016666666666666666, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.5555555555555556, 'sd:', 0.7856742013183862)\n",
    "# |  3        |  0.0      |  1.035    |  0.6253   |  1.287    |  0.9439   |\n",
    "# [0.5208333333333334, 0.375, 0.3854166666666667, 0.4930555555555555, 0.34027777777777773, 0.40625, 0.3194444444444444]\n",
    "# [0.32, 0.38, 0.21333333333333332, 0.28, 0.16666666666666663, 0.2, 0.2733333333333333]\n",
    "# ('Test acc:', 40.57539682539682, 'sd:', 6.965317270864225)\n",
    "# |  4        |  0.2619   |  0.4573   |  0.1734   |  0.6163   |  0.02537  |\n",
    "# [0.025000000000000005, 0.0, 0.03333333333333333]\n",
    "# [0.008, 0.024000000000000004, 0.008]\n",
    "# ('Test acc:', 1.9444444444444444, 'sd:', 1.4163943093313291)\n",
    "# |  5        |  0.01333  |  1.27     |  1.156    |  1.195    |  0.7833   |\n",
    "# [0.008333333333333333, 0.0, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.2777777777777778, 'sd:', 0.3928371006591931)\n",
    "# |  6        |  0.0      |  1.297    |  1.846    |  1.938    |  0.7382   |\n",
    "# [0.013888888888888888, 0.0, 0.0]\n",
    "# [0.014666666666666668, 0.008, 0.0]\n",
    "# ('Test acc:', 0.4629629629629629, 'sd:', 0.6547285010986551)\n",
    "# |  7        |  0.007556 |  0.2306   |  1.936    |  1.592    |  0.7024   |\n",
    "# [0.2511354386354386, 0.3434765466015466, 0.30643372830872834, 0.3152858715358715]\n",
    "# [0.32786868686868686, 0.3295645530939648, 0.3073928293928294, 0.3104887334887335]\n",
    "# ('Test acc:', 30.408289627039625, 'sd:', 3.349002098569766)\n",
    "# |  8        |  0.3188   |  0.1998   |  0.08897  |  0.9428   |  0.6384   |\n",
    "# [0.4106481481481481, 0.26304563492063493, 0.31493055555555555, 0.3008207070707071, 0.37310600279350276, 0.38941300733580136]\n",
    "# [0.3358236208236208, 0.1989130869130869, 0.21833333333333332, 0.34352380952380945, 0.3320714285714286, 0.3045044955044955]\n",
    "# ('Test acc:', 34.19940093040583, 'sd:', 5.258394155542585)\n",
    "# |  9        |  0.2889   |  0.01     |  0.01     |  0.1864   |  0.669    |\n",
    "# [0.4861111111111111, 0.3020833333333333, 0.2604166666666667, 0.2916666666666667, 0.3055555555555555, 0.34722222222222215, 0.3541666666666667, 0.2708333333333333]\n",
    "# [0.3833333333333333, 0.20666666666666664, 0.3161904761904762, 0.38, 0.3466666666666666, 0.4137777777777778, 0.29333333333333333, 0.35]\n",
    "# ('Test acc:', 32.72569444444444, 'sd:', 6.743512364375678)\n",
    "# |  10       |  0.3362   |  0.01     |  0.01     |  1.212    |  0.01     |\n",
    "# [0.0, 0.0, 0.0]\n",
    "# [0.0, 0.0, 0.0]\n",
    "# ('Test acc:', 0.0, 'sd:', 0.0)\n",
    "# |  11       |  0.0      |  0.01     |  0.01     |  2.0      |  1.0      |\n",
    "# [0.5181517556517556, 0.2377946127946128, 0.4213624338624338, 0.3735119047619048]\n",
    "# [0.27763369963369966, 0.32315873015873015, 0.23523076923076924, 0.2697142857142857]\n",
    "# ('Test acc:', 38.77051767676768, 'sd:', 10.102443647288354)\n",
    "# |  12       |  0.2764   |  0.01     |  0.01     |  0.6837   |  0.1847   |\n",
    "# [0.19999999999999998, 0.23750000000000002, 0.2722222222222222, 0.375, 0.20833333333333334, 0.0625, 0.16666666666666666, 0.325]\n",
    "# [0.22, 0.08, 0.10400000000000001, 0.264, 0.12, 0.096, 0.2, 0.16]\n",
    "# ('Test acc:', 23.09027777777778, 'sd:', 9.035987186191242)\n",
    "# |  13       |  0.1555   |  0.8694   |  0.01     |  0.01     |  1.0      |\n",
    "# [0.5590277777777778, 0.3819444444444444, 0.31527777777777777, 0.3541666666666667, 0.37152777777777773, 0.375, 0.518287037037037, 0.34027777777777773, 0.4236111111111111]\n",
    "# [0.2338095238095238, 0.19422222222222224, 0.26, 0.25666666666666665, 0.3053333333333333, 0.31, 0.305, 0.36, 0.256]\n",
    "# ('Test acc:', 40.434670781893004, 'sd:', 7.765741054904079)\n",
    "# |  14       |  0.2757   |  0.01     |  0.8582   |  0.01     |  1.0      |\n",
    "# [0.35763888888888884, 0.3756944444444444, 0.33796296296296297, 0.38055555555555554, 0.2824074074074074, 0.3171296296296296, 0.43402777777777773]\n",
    "# [0.3680952380952381, 0.23466666666666666, 0.2222222222222222, 0.22, 0.32, 0.14, 0.22666666666666666]\n",
    "# ('Test acc:', 35.50595238095238, 'sd:', 4.524186608251292)\n",
    "# |  15       |  0.2474   |  0.01     |  2.0      |  0.01     |  1.0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test accuracy for the top performing (training accuracy 0.2026) sampling parameters for gpt2-small (after the full 18 runs)\n",
    "# np.mean([0.3353320494864612,0.3277777777777778,0.21805555555555556,0.3402514152514152,0.28348214285714285,0.13194444444444445])# = 0.27280723089546616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "\"reinterpretation, harmony, character progression, reading circle\")\n",
    "# \"monolith, elevator effect, time loop, survival, desert resort, town watchman\")\n",
    "# \"monolith, allegro, soundtrack, chord, classical, opera\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.6, temperature=15.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "# \"reinterpretation, harmony, character progression, reading circle\")\n",
    "# # \"monolith, elevator effect, time loop, survival, desert resort, town watchman\")\n",
    "# # \"monolith, allegro, soundtrack, chord, classical, opera\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "# olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.6, temperature=15.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"watermelon juice, cherry juice, blackcurrant mixture, kava, orangeade, lemon juice, cherryade, cranberry juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "# olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_sentence = append_next_token(input_sentence, top_k=10, top_p=0.8, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "# \"\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider, yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider\" + \\\n",
    "# \", yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5pm: Using log_period=1 (max_len=96) reliably finds improvement, need more data and larger gpt2 (medium+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" milk, vodka, beer, ice water, soda, lassi, juice, alcohol, whiskey\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" wine, soda, alcohol, beer, liquor, apple cider, whiskey, milk, bourbon, vodka, cider, lemon juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:6])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=3.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" beer, milk, juice, wine, spirits, alcohol, soda, whiskey, brandy, apple juice, liquor, ice tea, watermelon juice, vodka,\" + \\\n",
    "# \" lemon tea, apple cider, ale, lager, fruit tea, lime cider, cocktail, mocha, red wine, apple soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5am: lr=1e-5, max_len=80, log_period_batches=5 increased accuracy by 8%. Need to add a bunch more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 5 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"soda, milk, juice, wine, vodka, gin, lime juice, beer, hot chocolate, cider, whiskey, fruit juice, cocktail, liquor, \" + \\\n",
    "# \"spirits, watermelon juice, martini, rum, chocolate milk, orangeade\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fine tuning (regular GPT-2):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model on 2nd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, juice, fruit juice, soda, wine, beer, hot chocolate, chocolate milk, alcohol, cider, ice tea, liquor, spirit\")\n",
    "# input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89, olen=olen) # k = 25 also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for too long (in this case ~6:30 hours) overfits\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"beer, juice, soda, liquor, wine, tequila, spirits, alcohol, cocktail, martini, whiskey, rum, vodka\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 15/04/2021 11am: Found learning rate 1e-7, max_listlen 15, min_nw 0.7, max_nw 0.9, lidstone_eps 0.01 works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No fine tuning (testing gpt2) (old append function):\n",
    "# input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake\"\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89)\n",
    "# A list of types of drink: juice, tea, cider, lemonade, milk, beer, hot chocolate,➡ ice cold milk. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working (reproducible) examples using various non-fine-tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT3 (via AI Dungeon) (Randomness = 2.0, model = Dragon):\n",
    "# sentence = \"A list of ML algorithms: inverse reinforcement learning, ELMo, decision tree, LDA, \"\n",
    "# expected_completion = \"MLP, MLL, MMM. You can't believe you're actually using these things!\"\n",
    "\n",
    "# sentence = \"A list of animals seen in the wild: wolffish, woodlouse, sheep, zebra, yak, \"\n",
    "# expected_completion = \"goat, fox, dog, rat. You're guessing that a lot of other animals have been seen as well; maybe even all the animals on your list except for wolf and rat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 (via Write with Transformer) (Top-p = 0.67, temperature = 1.89, max time = 1.9):\n",
    "# sentence = \"A list of round fruits: peach, apricot, lime, plum, blackberry, cantaloupe, nectarine, pitaya, persimmon, \"\n",
    "# expected_completion = \"mango, papaya and raspberry, as also many\"\n",
    "\n",
    "# sentence = \"A list of chemical elements: hydrogen, carbon, oxygen, nitrogen, gold, \"\n",
    "# expected_completion = \"silver, aluminum, potassium and phosphorus; atomic number.\"\n",
    "\n",
    "# sentence = \"A list of microbes found on earth: bacteria, virus, prokaryote, amoeba, \"\n",
    "# expected_completion = \"archaea, algae, nematode, euk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_s_avglogs(X, use_log_probs=True):\n",
    "#     tokens = [pt.tensor(tokenizer.encode(x)).to(d) for x in X]\n",
    "#     sqlens = [len(x) for x in tokens]\n",
    "#     n_bats = (len(sqlens) // batch_size) + 1\n",
    "#     res = []\n",
    "#     for i in range(n_bats):\n",
    "#         tokens_b, sqlens_b = tokens[i * bsz:(i + 1) * bsz], sqlens[i * bsz:(i + 1) * bsz]\n",
    "#         xs, _, sqlen = adapt_form(tokens_b, None, sqlens_b, mlen=max(sqlens_b))\n",
    "#         logits = inference(xs, sqlen, seq_maxlen=max(sqlens_b), return_fulloutput=True)[0]\n",
    "#         pt.cuda.empty_cache()\n",
    "# #         logits = pt.stack(logits, 0)\n",
    "#         for i in range(len(sqlens_b)):\n",
    "#             x_logits = [logits[i][j] for j in range(sqlens_b[i])]\n",
    "#             x_logs = ([pt.log(F.softmax(logits[i][j]))[tokens_b[i][j]].cpu().detach().numpy() for j in range(sqlens_b[i])] if \\\n",
    "#                       use_log_probs else \\\n",
    "#                       [logits[i][j][tokens_b[i][j]].cpu().detach().numpy() for j in range(sqlens_b[i])])\n",
    "#             res.append(np.mean(x_logs[1:]))  # ignore initial prefix token 'A'/'An'\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = openai.Completion.create(**{**default_params,\n",
    "#   \"prompt\": \"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\",\n",
    "#   \"temperature\": 1.5,\n",
    "#   \"top_p\": 1.0,\n",
    "#   \"n\": 5,\n",
    "#   \"best_of\": 20,\n",
    "#   \"max_tokens\": 7,\n",
    "#   \"stop\": [\",\", \"\\n\"],\n",
    "# })\n",
    "# for choice in response[\"choices\"]:\n",
    "#     d = {}\n",
    "#     tokens = choice[\"logprobs\"][\"tokens\"]\n",
    "#     t_i = -1\n",
    "#     for t in tokens:\n",
    "#         t_i += 1\n",
    "#         r = [(np.e**v, k) for (k, v) in choice[\"logprobs\"][\"top_logprobs\"][t_i].items()]\n",
    "#         r.sort(reverse=True)\n",
    "#         print(sum([v for (v, k) in r]))\n",
    "#         rd = dict([(k, v) for (v, k) in r])\n",
    "#         r = [k for (v, k) in r]\n",
    "#         d[t] = (rd, r, np.e**choice[\"logprobs\"][\"token_logprobs\"][t_i])\n",
    "#     print('|'.join([' '.join((s.replace(\"\\n\", \"⏎\"),'%.2f' % (d[s][2] * 100),\n",
    "#                               str(d[s][1].index(s) + 1) if s in d[s][1] else \"<100\")) for s in tokens]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
