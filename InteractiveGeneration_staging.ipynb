{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned language model for pictionary word list completion (topic/category phrase + example words -> list of 30 examples). For example, one may complete the list\n",
    "\n",
    "\"A list of round fruits: peach, apricot, lime, plum,\"\n",
    "\n",
    "with\n",
    "\n",
    "\"mango, cherry, pineapple, strawberry, pumpkin, watermelon, orange, pomegranate, melon, apple, pear, grapefruit, papaya, lemon, kiwi, passionfruit, blueberry, raspberry, blackberry, cantaloupe, nectarine, pitaya, persimmon, durian, guava, jackfruit, avocado, lychee, soursop, guarana, mangosteen, blackcurrant, cranberry\"\n",
    "\n",
    "using this model. These words should be compatible with pictionary/skribbl.io; i.e., \"sketchable\" within a few minutes, and easily recognisable. Scroll to the end for more examples, or see the file `data/examples.txt`. Sketchability parameter estimation examples can also be found in `data/data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function that takes a prompt, existing list and sampling params and returns gpt3's next token probs\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../../openai-api-org.txt', 'r') as f:\n",
    "    openai.organization = f.read()\n",
    "with open('../../openai-api-key.txt', 'r') as f:\n",
    "    openai.api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0827 21:59:32.685862 25060 util.py:54] message='Request to OpenAI API' method=post path=https://api.openai.com/v1/engines/davinci/completions\n",
      "I0827 21:59:32.914251 25060 util.py:54] message='OpenAI API response' path=https://api.openai.com/v1/engines/davinci/completions processing_ms=55 response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9513645441314544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.537477946279368, 11),\n",
       " (0.13583560651902138, 612),\n",
       " (0.05047786275986347, 287),\n",
       " (0.02716520099399863, 314),\n",
       " (0.016418246026493798, 553),\n",
       " (0.013505279444806811, 257),\n",
       " (0.012723189571842179, 1399),\n",
       " (0.011949824343516208, 262),\n",
       " (0.0115568724690796, 986),\n",
       " (0.010122162015954343, 13),\n",
       " (0.009089103504717132, 198),\n",
       " (0.007662558064498022, 1),\n",
       " (0.006628610993341391, 357),\n",
       " (0.005430918535227721, 526),\n",
       " (0.0047060592426866965, 9313),\n",
       " (0.004347117053138358, 340),\n",
       " (0.004293079377186419, 356),\n",
       " (0.004252868000456822, 764),\n",
       " (0.004121455093250252, 345),\n",
       " (0.0033353778756207027, 618),\n",
       " (0.0029040237606820884, 428),\n",
       " (0.0028391550178658736, 9962),\n",
       " (0.0026527617814475148, 407),\n",
       " (0.0024139482354796227, 339),\n",
       " (0.002384587799445274, 3926),\n",
       " (0.002275762768310696, 25),\n",
       " (0.002266336789734363, 2644),\n",
       " (0.0021313706682531794, 960),\n",
       " (0.002084003866013265, 484),\n",
       " (0.002070437171586569, 319),\n",
       " (0.0019997252157227126, 673),\n",
       " (0.0018983465661886302, 281),\n",
       " (0.001887598297597058, 4032),\n",
       " (0.0017899430057491366, 784),\n",
       " (0.001591598375632174, 1106),\n",
       " (0.0015172111486534286, 734),\n",
       " (0.0013828072596040145, 616),\n",
       " (0.0013646231077629432, 6),\n",
       " (0.0013643002761281348, 851),\n",
       " (0.0013507044605557447, 1600),\n",
       " (0.001252267964564927, 532),\n",
       " (0.0012114871796207057, 379),\n",
       " (0.0011182220616010985, 8),\n",
       " (0.001032268986553324, 290),\n",
       " (0.0010232808438718755, 11580),\n",
       " (0.0009504067567558594, 373),\n",
       " (0.0009250723567478127, 2084),\n",
       " (0.0008920699581859775, 492),\n",
       " (0.0008704554304581425, 837),\n",
       " (0.0008452281221501898, 628),\n",
       " (0.0007949022554407016, 661),\n",
       " (0.0007715909545342924, 890),\n",
       " (0.0007626060326022832, 685),\n",
       " (0.0007597284432864854, 30),\n",
       " (0.0007359973792819189, 878),\n",
       " (0.0006788662708161118, 326),\n",
       " (0.0006629316931560503, 477),\n",
       " (0.0006586402996642122, 318),\n",
       " (0.0005683887240456192, 7398),\n",
       " (0.0005474989577107981, 1377),\n",
       " (0.0005388843360347305, 0),\n",
       " (0.0005227184893996735, 777),\n",
       " (0.0005010994367632128, 617),\n",
       " (0.00048368988019992557, 828),\n",
       " (0.0004834447599306329, 438),\n",
       " (0.00046782231637656466, 1911),\n",
       " (0.00046630156404276786, 1115),\n",
       " (0.00045536876260537994, 2130),\n",
       " (0.0004452173357857092, 674),\n",
       " (0.00039993816912183136, 26),\n",
       " (0.0003806112671074767, 867),\n",
       " (0.0003788548529430763, 12359),\n",
       " (0.0003755917784426733, 1701),\n",
       " (0.00036837025422097107, 530),\n",
       " (0.0003661754382238201, 46385),\n",
       " (0.0003594397459487495, 611),\n",
       " (0.0003377139238514609, 35713),\n",
       " (0.00033585555038739644, 2637),\n",
       " (0.0003220656987006443, 534),\n",
       " (0.000320932736630073, 737),\n",
       " (0.0003182698341256709, 1312),\n",
       " (0.0003177657760101643, 3256),\n",
       " (0.00030242749354020054, 12),\n",
       " (0.0003002338160616909, 5615),\n",
       " (0.0002962952898703403, 366),\n",
       " (0.0002902247311763669, 511),\n",
       " (0.00029015290944370666, 1141),\n",
       " (0.00028779503938121983, 60),\n",
       " (0.0002546529296718143, 2474),\n",
       " (0.00025198449503113047, 15327),\n",
       " (0.0002443443639485261, 355),\n",
       " (0.00024244758870440152, 23029),\n",
       " (0.00023603345606471645, 393),\n",
       " (0.00023545399827507865, 19056),\n",
       " (0.00022908029103226363, 736),\n",
       " (0.00021004852132648784, 16317),\n",
       " (0.00020901239532144267, 546),\n",
       " (0.00020773049822390234, 2253)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def p_req(s, temperature=1.0, top_p=1.0, presence_penalty=0.0, frequency_penalty=0.0):\n",
    "    response = openai.Completion.create(**{\n",
    "      \"engine\": \"davinci\",\n",
    "      \"prompt\": s,\n",
    "      \"max_tokens\": 1,\n",
    "      \"temperature\": temperature,\n",
    "      \"top_p\": top_p,\n",
    "      \"presence_penalty\": presence_penalty,\n",
    "      \"frequency_penalty\": frequency_penalty,\n",
    "      \"n\": 1,\n",
    "      \"stream\": False,\n",
    "      \"logprobs\": 100,\n",
    "#       \"logit_bias\": {\"50256\": -100},\n",
    "      \"stop\": \"\\n\"\n",
    "    })\n",
    "#     print(res[\"choices\"][0][\"logprobs\"][\"top_logprobs\"])\n",
    "    r = [(np.e**v, k) for (k, v) in response[\"choices\"][0][\"logprobs\"][\"top_logprobs\"][0].items()]\n",
    "    r.sort(reverse=True)\n",
    "    res = []\n",
    "    for i in range(len(r)):\n",
    "        k = gpt3_tokenizer.encode(r[i][1])\n",
    "        if len(k) == 1:\n",
    "            res.append((r[i][0], k[0]))\n",
    "    return res\n",
    "a = p_req(\"Once upon a time\")\n",
    "print(sum([a_[0] for a_ in a]))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006916793387894473 bytes:\\xe2\\x80 [33661, 7479, 27705, 17, 59, 87, 1795] [33661, 7479, 27705, 17, 59, 87, 1795]\n",
      "0.00021436615507941935 bytes: \\xe2\\x80 [33661, 25, 3467, 27705, 17, 59, 87, 1795] [33661, 25, 3467, 27705, 17, 59, 87, 1795]\n"
     ]
    }
   ],
   "source": [
    "for a_ in a:\n",
    "    txt = a_[1]\n",
    "#     if txt[:6] == \"bytes:\":\n",
    "#         txt = txt[6:].strip()\n",
    "    r = gpt3_tokenizer.encode(txt)\n",
    "    if len(r) > 1:\n",
    "        print(a_[0], a_[1], gpt3_tokenizer.encode(txt), r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0827 21:29:48.538520 25060 filelock.py:274] Lock 2837494709440 acquired on C:\\Users\\alfew/.cache\\huggingface\\transformers\\f1179e28982928f50ca02b0188fcd80fb4fa871ba1719df5bf81ac308d0d10af.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0655e3a96c49a4a1cbb212d8c0fe08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1355256, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0827 21:29:50.982174 25060 filelock.py:318] Lock 2837494709440 released on C:\\Users\\alfew/.cache\\huggingface\\transformers\\f1179e28982928f50ca02b0188fcd80fb4fa871ba1719df5bf81ac308d0d10af.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0.lock\n"
     ]
    }
   ],
   "source": [
    "gpt3_tokenizer = GPT2TokenizerFast.from_pretrained(gpt2_modelkey.replace(\"-xl\", \"-large\"), padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a completion distribution (top 100) and target next token distribution (multinomial) and computes the\n",
    "# probability that the completion produces a desired output token\n",
    "def prob_corr(top100, target_p):\n",
    "    r = 0\n",
    "    for (p, token) in top100:\n",
    "        if target_p[token] > (lid_val + 1e-10):\n",
    "            r += p\n",
    "    return r\n",
    "def score_corr(top100, target_p):  # The same but we weight the outputs by their target magnitude (analogous to expectation)\n",
    "    r = 0                          # Don't know which should work best, try, should also probably redistribute unaccounted mass\n",
    "    for (p, token) in top100:\n",
    "        targ = target_p[token]\n",
    "        if targ > (lid_val + 1e-10):\n",
    "            r += p * (targ - lid_val)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes some sampling parameters, then generates n random incomplete list prompts (of length l), obtains completion\n",
    "# distributions (top 100 tokens) and evaluates the average score across the n prompts. n = 20 by default\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that uses bayesian optimisation or similar method to quickly find the maxima of the above function (find best params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that uses the l argument to do the bayesian optimisation once for each \"length group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 'global evaluator' function that compares the previous two methods using the same code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a gaussian process model of length features (+cond.prob. features) vs sampling params (mt), mu sigma, mixture dist., eps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include gpt2/gpt-neo embeddings (next step gpt3 embeddings (?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if fine-tuning a secondary post-completion filter stage improves accuracy (aim for as few false negatives as possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with typical one-hot fine-tuning of gpt2, gpt-neo & gpt3 (optimise sampling params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with multinomial fine-tuning of gpt2, gpt-neo (next step gpt3 multinomial) (optimise sampling params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as originally thought, use an ensemble of the most successful of the above methods to create candidate outputs, then train a\n",
    "# joint filter to distinguish between correct and erroneous list completions (gpt2/gpt-neo/gpt3-prompt) (next step gpt3) 0FNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using the joint filter trained with the ensemble outputs to filter the responses of the best single model from the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, GPT2LMHeadModel, ReformerModelWithLMHead, \\\n",
    "                         get_linear_schedule_with_warmup\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from transformers import GPT2TokenizerFast\n",
    "from Learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ###   Options   ###\n",
    "\n",
    "model_name = \"ernst_one\"\n",
    "# gpt2_modelkey = \"gpt2\"               # Pretrained model to start from\n",
    "gpt2_modelkey = \"gpt2-xl\"            # Pretrained model to start from\n",
    "test_set_frac = 0.25                 # Fraction of samples to keep as separate test set (word lists)\n",
    "sample_test_n = 200                  # Number of randomly generated prompts for each sample when validating model\n",
    "log_period_batches = 10               # Batches per iteration\n",
    "# learning_rate = 5e-7                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "learning_rate = 7e-5                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "# learning_rate = 4e-6                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "adam_epsilon = 1e-8                  # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                   # Linear scheduler for optimizer number of warmup steps\n",
    "# batch_size = bsz = 8                 # Samples per batch\n",
    "batch_size = bsz = 64                # Samples per batch\n",
    "# batch_size = bsz = 128                # Samples per batch\n",
    "N_train_batches = int(1e7 / bsz)     # Total number of batches to show model\n",
    "min_nw, max_nw = 0.7, 0.9            # Minimum and maximum fraction of list to keep when truncating\n",
    "max_listlen = 15                     # Maximum number of words in the list when creating a prompt (at least prior to * max_nw)\n",
    "lidstone_e = 0.01                    # Smoothing for possible words/subwords which are not in the missing list words set\n",
    "max_len = 96                         # Max n. tokens specified in order to match a power of 2, applied prior to *max_nw (tokens)\n",
    "lastcomma_repl = ',' # 'EOS', ','    # Token optionally used to replace the final comma that ends the generated phrase\n",
    "use_correct_nouns = True             # Whether to use only correct singular or plural form of category nouns for the given prompt\n",
    "swap_noun = False                    # Whether to swap plural and singular nouns in prompt (diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "d = device = pt.device(dev)\n",
    "# world_size = 1\n",
    "# rank = 0\n",
    "# def setup(rank, world_size): \n",
    "#     os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "#     os.environ['MASTER_PORT'] = find_free_port()\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)  # initialize the process group\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "# # mp.spawn(setup, args=(rank, world_size), nprocs=world_size)\n",
    "# setup(rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0827 20:49:03.546845 25060 tokenization_utils.py:384] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-large-vocab.json from cache at C:\\Users\\alfew\\.cache\\torch\\pytorch_transformers\\69f8d734111f39eaa51a85907bfdc81a7ef42242d638ffab6f77df305402b2b2.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "I0827 20:49:03.547841 25060 tokenization_utils.py:384] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-large-merges.txt from cache at C:\\Users\\alfew\\.cache\\torch\\pytorch_transformers\\38d28acc17953e356348dca948e152c653c0ccf5058a552eea30168e27f02046.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(gpt2_modelkey.replace(\"-xl\", \"-large\"), padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    tokenizer.encode(\"oranges, pears,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[tokenizer.encode(prompt), \"types of\" in prompt] for prompt in lprompts]\n",
    "cats_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e = [[tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "comma_token = pt.tensor(tokenizer.encode(\",\")[0], device=d)\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "lprompts_sing = [(prmpt, typesof) for (prmpt, typesof) in lprompts_encoded if typesof ^ swap_noun]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "# lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "# cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "# cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "# phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "lidstone_e = pt.tensor(lidstone_e, device=d)\n",
    "lid_val = lidstone_e / N_tokens\n",
    "y_zero = (lid_val).repeat(N_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk, using nw_draw = 15. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p):  # prmt = prompt tokens, p = list word/phrase tokens\n",
    "    tkzs, sent, tkix = [], [], 0\n",
    "    max_ws = max_len - len(prmt)\n",
    "#     incl_words = pt.randperm(len(p))[:min(max_listlen, len(p))]\n",
    "    incl_words = np.random.choice(len(p), min(max_listlen, len(p)), replace=False)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc = p[phz_i]\n",
    "        tkzs.append((tkix, phz_enc))\n",
    "        tkix += len(phz_enc)\n",
    "        sent.append(phz_enc)\n",
    "        if tkix >= max_ws:\n",
    "            tkix = max_ws\n",
    "            break\n",
    "    sent = pt.hstack(sent)[:max_ws]\n",
    "    missing_w = [p[i] for i in range(len(p)) if i not in incl_words]\n",
    "    trunc_ix = np.random.randint(round(tkix * min_nw), round(tkix * max_nw))\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if len(enc) >= trunc_n and all(enc[:trunc_n] == partial_phr)]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_e)\n",
    "    tunit, y_ = pt.tensor(1 / norm, device=d), y_zero.clone()\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return pt.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def gen_samples_uniform(xcp, xcs, xp, nw, verbose=False):  # Weight testing samples (word lists) uniformly\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        for m in range(nw):\n",
    "#             prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "#             cat_ix = np.random.randint(len(cp))\n",
    "#             x_, y_ = gen_truncated_list(pt.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "            cat_ix = np.random.randint(len(cp_cs))  # First uniformly sample a category title\n",
    "            sing = cat_ix >= len(cp)\n",
    "            lprmpts = lprompts_sing if sing else lprompts_encoded\n",
    "            prmt, _ = lprmpts[np.random.randint(len(lprmpts))]\n",
    "            x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p)\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "            sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0:\n",
    "                sys_print(\"\\rDone: \" + str(j))\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        sqlens.append(sqlen)\n",
    "    if verbose: sys_print(\"\\rDone: \" + str(j) + \", finished!\\n\")\n",
    "    return xs, ys, sqlens\n",
    "def gen_samples(xcp, xcs, xp, n):  # Maximise training batch diversity by randomly sampling the word lists\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets = len(xcp)\n",
    "    for m in range(n):\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        cat_ix = np.random.randint(len(cp_cs))  # First uniformly sample a category title\n",
    "        sing = cat_ix >= len(cp)\n",
    "        lprmpts = lprompts_sing if sing else lprompts_encoded\n",
    "        prmt, _ = lprmpts[np.random.randint(len(lprmpts))]\n",
    "        x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "        sqlens.append(len(x_))\n",
    "    return xs, ys, sqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "['round fruits', 'wild animals', 'microorganisms', 'music', 'machine learning algorithms', 'outback experiences', 'scientific cycles', 'buildings', 'glassware']\n",
      "Test:\n",
      "['hats', 'chemical elements', 'dramatic and literature elements']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 600, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test = int(test_set_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "test_idx = np.random.choice(N_wordlists, N_test, replace=False)\n",
    "save_ld(test_idx, \"test.data\")\n",
    "# test_idx = load_ld(\"test.data\")\n",
    "# test_idx = np.array([0, 2])  # Round fruits and chemical elements\n",
    "train_idx = [i for i in range(N_wordlists) if i not in test_idx]\n",
    "print(\"Train:\")\n",
    "print([cats[i][0] for i in train_idx])\n",
    "print(\"Test:\")\n",
    "print([cats[i][0] for i in test_idx])\n",
    "cats_e_test, cats_sing_e_test = [cats_e[i] for i in test_idx], [cats_sing_e[i] for i in test_idx]\n",
    "phrases_e_test = [phrases_e[i] for i in test_idx]\n",
    "cats_e_train, cats_sing_e_train = [cats_e[i] for i in train_idx], [cats_sing_e[i] for i in train_idx]\n",
    "phrases_e_train = [phrases_e[i] for i in train_idx]\n",
    "test_cats = [cats[i][0] for i in test_idx]\n",
    "test_xs, test_ys, test_sqlens = gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, sample_test_n, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "def adapt_form(xs, ys, sqlens, repl_finalcomma=True):\n",
    "    xs = pt.vstack([F.pad(x, (0, max(0, max_len - len(x))), mode='constant', value=pad_token)[:max_len] for x in xs])\n",
    "    _ys = pt.vstack(ys)\n",
    "    if repl_finalcomma and (lastcomma_repl != ','):\n",
    "        _ys[:, repl_token] += _ys[:, comma_token] - lid_val\n",
    "        _ys[:, comma_token] = lid_val\n",
    "    return xs, _ys, pt.tensor(sqlens, device=d)\n",
    "def next_batch(sz):\n",
    "    global cats_e_train, cats_sing_e_train, phrases_e_train\n",
    "    return adapt_form(*gen_samples(cats_e_train, cats_sing_e_train, phrases_e_train, sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "GPT2 device: cuda:0\n",
      "Pretrained parameters loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1271"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "pt.cuda.empty_cache()\n",
    "print(gc.collect())\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2LMHead\")\n",
    "# model_ = GPT2ForSequenceClassification.from_pretrained('gpt2-large',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-xl',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-large',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-medium',\n",
    "model_ = GPT2LMHeadModel.from_pretrained(gpt2_modelkey,\n",
    "    output_hidden_states=False, output_attentions=False, \n",
    "    cache_dir=\"models/pretrained/GPT2LMHead\")\n",
    "if pt.cuda.device_count() > 1:\n",
    "    # model_.parallelize()\n",
    "    device_map = {0: [0, 1, 2],\n",
    "                  1: [3, 4, 5, 6, 7, 8],\n",
    "                  2: [9, 10, 11, 12, 13, 14],\n",
    "                  3: [15, 16, 17, 18, 19, 20],\n",
    "                  4: [21, 22, 23, 24, 25, 26, 27],\n",
    "                  5: [28, 29, 30, 31, 32, 33, 34],\n",
    "                  6: [35, 36, 37, 38, 39, 40, 41],\n",
    "                  7: [42, 43, 44, 45, 46, 47],\n",
    "                 }\n",
    "    # device_map = {0: [0, 1, 2],\n",
    "    #               1: [3, 4, 5, 6, 7, 8],\n",
    "    #               2: [9, 10, 11, 12, 13, 14],\n",
    "    #               3: [15, 16, 17, 18, 19, 20],\n",
    "    #               4: [21, 22, 23, 24, 25, 26, 27],\n",
    "    #               5: [28, 29, 30, 31, 32, 33, 34],\n",
    "    #               6: [35, 36, 37, 38, 39, 40, 41],\n",
    "    #               7: [42, 43, 44, 45, 46, 47],\n",
    "    #              }\n",
    "    model_.parallelize(device_map)\n",
    "else:\n",
    "    model_ = model_.to(d)\n",
    "print(\"GPT2 device:\", model_.device)\n",
    "model_.resize_token_embeddings(N_tokens)\n",
    "pad_token = model_.config.pad_token_id = model_.config.eos_token_id\n",
    "pad_token = pt.tensor(pad_token, device=d)\n",
    "repl_token = pt.tensor(tokenizer.encode(lastcomma_repl)[0], device=d) if lastcomma_repl != 'EOS' else pad_token\n",
    "n_embd = pt.tensor(model_.config.n_embd, device=d)\n",
    "# model = nn.parallel.DistributedDataParallel(model_, device_ids=[d])\n",
    "# model = nn.DataParallel(\n",
    "#     model_, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else model_\n",
    "model = model_\n",
    "print(\"Pretrained parameters loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = None #nn.Linear(n_embd, N_tokens, bias=False).to(d)#.cpu()\n",
    "# nn.init.xavier_uniform_(llayer.weight)\n",
    "# llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else llayer\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()#.to(d)#.cpu()\n",
    "# bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d) if dev != \"cpu\" else bcewl_loss\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1, device=d)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, bsz, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(bsz)\n",
    "\n",
    "#     for x in x_batch.cpu().detach().numpy():\n",
    "#         print(tokenizer.decode(x))\n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)  # Get logits\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens_batch - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     outs = outputs[0][:, -1]\n",
    "#     logits = llayer(outs)\n",
    "    logits = outs\n",
    "    \n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lid_val + 1e-10)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "\n",
    "def inference(x, sqlens):\n",
    "    global model, llayer\n",
    "\n",
    "    x, sqlens = x, sqlens\n",
    "#     for x_ in x.cpu().detach().numpy():\n",
    "#         print(tokenizer.decode(x_))\n",
    "    mask = sequence_mask(sqlens, max_len)\n",
    "    outputs = model(x.long(), attention_mask=mask)  # Get logits\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     outs = outputs[0][:, -1]\n",
    "#     logits = llayer(outs)\n",
    "    logits = outs\n",
    "    return logits\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())#.to(d)#.cpu()\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lid_val + 1e-10)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = -1  # Batch 0 is the first iteration, where testing occurs without any training\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "out_str = ''\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, test_loss, test_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, test_loss, test_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        if batch_i > 0:\n",
    "            gc.collect()\n",
    "            if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "            b_loss, b_accuracy = train_step()\n",
    "            if verbose:\n",
    "                sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                          ' @ batch '+ str(batch_i) + ' (' + str(batch_i * batch_size) + ' samples) complete.                  ')\n",
    "            iter_loss.append(b_loss)\n",
    "            iter_accuracy.append(b_accuracy)\n",
    "\n",
    "        if batch_i % log_period_batches == 0:  # Test on test set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            out_str = '\\n'\n",
    "            for i in range(N_test):\n",
    "                test_X, test_Y, test_Sqlens = adapt_form(test_xs[i], test_ys[i], test_sqlens[i], repl_finalcomma=batch_i > 0)\n",
    "                feed_batches = [range(len(test_X))[i * bsz:(i + 1) * bsz] for i in range((len(test_X) // bsz) + \\\n",
    "                                                                                        (1 if (len(test_X) % bsz) != 0 else 0))]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(test_X[inds], test_Y[inds], test_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls))\n",
    "                accuracy.append(np.mean(cs))\n",
    "                out_str += test_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]) + '\\n'\n",
    "            \n",
    "            test_l, test_a = np.mean(loss), np.mean(accuracy)\n",
    "            test_loss.append(test_l)\n",
    "            test_accuracy.append(test_a)\n",
    "            if batch_i == 0:\n",
    "                iter_loss, iter_accuracy = [test_l], [test_a]\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l)\n",
    "            train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "            \n",
    "            val_a = 0\n",
    "            if test_a > best_acc:      # Save best accuracy model\n",
    "                best_acc = test_a\n",
    "                best_loss = test_l\n",
    "                best_acc_idx = batch_i // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "#                          \"llayer\": llayer.state_dict(),\n",
    "#                          \"softrmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(out_str + \"Batch\", batch_i, ':', train_a, test_a, \"loss:\", train_l, test_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(test_accuracy, label='test acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                g.plot(test_loss, label='test loss')\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, test_accuracy, train_loss, test_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hats: 0.00010320337, 0.671875\n",
      "chemical elements: 8.422259e-05, 0.46875\n",
      "dramatic and literature elements: 0.0001090692, 0.84375\n",
      "Batch 650 : 0.9140625 0.6614583 loss: 5.7221092e-05 9.883172e-05 Best: 0.7135417 9.9054414e-05 idx: 37\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAEvCAYAAABfSXyoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABw40lEQVR4nO3deXxU1f3/8deZyUwWEgIkEJawyyL7DgpqcEFwA61116qt1J/V2s2K/Vbbalut2tbauhSXqnXfi4qKWwQUEFB2UHYI+xbInszM+f1xh5BlAgMkmeTm/Xw8YjL3nnvv55MEbz5zzj3HWGsRERERERERqS+eWAcgIiIiIiIiTYsKUREREREREalXKkRFRERERESkXqkQFRERERERkXqlQlRERERERETqlQpRERERERERqVdxsbpwenq67dKlS62cq6CggGbNmtXKuRoit+cHytEt3J6j2/ODxp3jwoULd1trW8c6jsZM9+bouT0/UI5u4fYc3Z4fNO4cD3dvjlkh2qVLFxYsWFAr58rOziYrK6tWztUQuT0/UI5u4fYc3Z4fNO4cjTEbYx1DY6d7c/Tcnh8oR7dwe45uzw8ad46HuzdraK6IiIiIiIjUKxWiIiIiIiIiUq9UiIqIiIiIiEi9itkzoiIiIiIiIrFWVlZGTk4OxcXFsQ4lotTUVFauXBnrMA4rISGBzMxMfD5f1MeoEBURERERkSYrJyeHlJQUunTpgjEm1uFUk5eXR0pKSqzDqJG1lj179pCTk0PXrl2jPk5Dc0VEREREpMkqLi4mLS2tQRahjYExhrS0tKPuUVYhKiIiIiIiTZqK0ONzLN8/FaIiIiIiIiIxkpuby6OPPnpMx55zzjnk5uZG3f73v/89Dz744DFdq7apEBUREREREYmRwxWiwWDwsMdOnz6dFi1a1EFUdU+FqIiIHLX9RWW8s3gr89btIbewNNbhSAOSt38vX73+N/J3b451KCIijcKUKVNYu3YtgwYN4rbbbiM7O5uxY8dyxRVX0L9/fwAmTZrE0KFD6du3L1OnTi0/tkuXLuzevZsNGzZw4okncsMNN9C3b1/GjRtHUVHRYa+7aNEiRo0axYABA7jwwgvZt28fAA8//DB9+vRhwIABXHbZZQB8/vnnDBo0iEGDBjF48GDy8vKOO2/Nmisi0gCFQpYbnluAP87DdaO7MrxLywbx/Mq6Xfk8++UGXluYQ2HpoXdpM5rH06ttc3plJNOtdTKtk+NJS/aTnhxPenI8iX5vDKOW+pSfu4sRy/7A/9rcFOtQREQahfvuu49ly5axaNEiALKzs/nqq69YtmwZXbt2JS8vj6effppWrVpRVFTE8OHD+d73vkdaWlql86xevZqXXnqJJ554gksuuYQ33niDq666qsbrXnPNNfzzn//ktNNO46677uIPf/gDDz30EPfddx/r168nPj6+fNjvgw8+yCOPPMLo0aPJz88nISHhuPNWISoi0gB99u1OPlm1k/g4D+8v206/Ds257uSunDewHfFx9VvUWWuZtXo3//liPZ99uwu/18P5A9tz2YiOFJQE+HZ7Ht/uyOPb7Xk8u24PpYFQtXMk+b2c3D2dX47ryYntmtdr/FK/fH7njxMTCsQ4EhGRo/eHd5azYuuBWj1nn/bN+d35fY/qmBEjRlRaCuXhhx/mrbfeAmDz5s2sXr26WiHatWtXBg0aBMDQoUPZsGFDjeffv38/ubm5nHbaaQD84Ac/4Pvf/z4AAwYM4Morr2TSpElMmjQJgNGjR/OLX/yCK6+8kosuuojMzMyjyicSFaIiIg3QU7PX0y41gQ9/firvLN7Kf77YwC9fW8y976/impM6c+Np3fHH1e3TFUWlQd78JodnvtjA6p35pCf7+dmZPbhyZGdap8SXt8vq1ab862DIsv1AMXvyS9idX8Lu/FL25JeybX8Rb3+zhXMensX5A9rz87N60jW9WZ3GL7Hh8/kBFaIiIsejWbND98hZs2bx8ccfM2fOHJKSksjKyoq4VEp8/KF7s9frPeLQ3Jq89957zJw5k2nTpnHPPfewfPlypkyZwrnnnsv06dMZNWoUH3/8Mb179z6m8x+kQlREpIFZsfUAX67dw+3je9M8wceVIztzxYhO5b2Sf/voOwpKAtxxzol1cv2tuUU8N2cjL8/fRG5hGX3bN+fB7w/k/Ch6Y70eQ4cWiXRokVht3y/P6sXUWWt5evYG3lu6jUuGZXLL6T1oH6GtNF6+8B9CKkRFpDE62p7L2pCSknLYZy4PHDhAy5YtSUpKYtWqVcydO/e4r5mamkrLli2ZNWsWp5xyCv/973857bTTCIVCbN68mbFjxzJmzBhefPFF8vPz2bNnD/3796d///7MmTOHVatWqRAVEXGbp79YT6LPyxUjOpVvM8Zwas/WnNqzNf/31lL+PXMdp/RozZge6bVyzWDIMnfdHh5dVMzCGZ9hrWVcn7ZcP6b2nk9NTfJx29m9ufbkrjzy2RpenLeJN77ewsOXDWJ8v3a1kIU0BP7w0FxUiIqIRCUtLY3Ro0fTr18/JkyYwLnnnltp/5lnnsmzzz7LgAED6NWrF6NGjaqV6z777LPceOONFBYW0q1bN/7zn/8QDAa56qqr2L9/P9Zafv7zn9OiRQvuvPNOPvvsM7xeL3369GHChAnHff2oClFjzHjgH4AXeNJae1+V/S2Bp4HuQDFwvbV22XFHJyLSxOzMK2baoq1cOrwjqUm+iG1+e24f5q3fyy9eXcT7t55CWnJ8xHZHYq1l0eZcpi3eyrtLtrErr4TEOPjhmG5cPaozHVslHU8qNWqdEs/vL+jLDad241+frmFIp5Z1ch03iOL+2xv4DzAE+D9r7YPh7R2B54C2QAiYaq39R33EHOcL94haFaIiItF68cUXK73Oysoq/zo+Pp73338/4nEHnwNNT09n2bJD5devfvWriO1///vfl389aNCgiL2rs2fPrrbtn//8Z02hH7MjFqLGGC/wCHAWkAPMN8ZMs9auqNDsN8Aia+2F4ZviI8AZtR6tiIjLPT93E6XBENeN7lJjm0S/l39cNogLH/mS299YwhPXDDtsj2VhaYA9+aXsyi9hT34pe/JLWL+ngPeXbmfT3kL8Xg9je7fmgoEdiNu1irPPqJshv1V1aJHIvRf1r5drNUZR3n/3Aj8FJlU5PAD80lr7tTEmBVhojPmoyrF1w+MlYD14VIiKiMhhRNMjOgJYY61dB2CMeRmYCFS8mfUB7gWw1q4yxnQxxmRYa3fUdsAiIm5VXBbkhbkbOfPENnRrnXzYtn3bp3L7hN7c8+4Knp+3iatHda7W5pOVO7jn3RVs2FNYbZ/HwOgT0rn59BM4u29bUhOd3tfs7G9rJxmpDUe8/1prdwI7jTGVxnFZa7cB28Jf5xljVgIdqHzvrjNlJk7PiIqIyGFFU4h2ACquSp0DjKzSZjFwETDbGDMC6AxkAipERUSi9L9FW9hTUMr1Y7oeuTFw3cld+Py7Xfzx3RWM7NqKnhkpAOTsK+Tud1YwY8UOTmiTzO3je5MeXtMzLdlPWnI8ac38JPi0tmcDF83994iMMV2AwcC82gnryALEqUdUREQOK5pCNNJ4L1vl9X3AP4wxi4ClwDc4w4Iqn8iYycBkgIyMDLKzs48m1hrl5+fX2rkaIrfnB8rRLdyeY13mZ63l4S+K6JjioWTTUrI3Rzc50EUdQnyzIcT1T8zi/0Yl8ummMv63tgyAS3r6GNclRBybIR/Id8Zx7gVW13A+t/8MG5lo7r+HP4ExycAbwM+stREXxquLe/MA4iBQ6urfpabwb0U5uoPbc6yN/FJTUw87a22sBYPBBh3fQcXFxUf1s4imEM0BOlZ4nQlsrdggfHO7DsA4DyqtD39Qpd1UYCrAsGHDbMWHcI9HdnY2tXWuhsjt+YFydAu35xgpv/97aymrd+bzyuRRR5xZtrA0wMtfbWZs7zbV1tCctXoXW/K/4sHvD2Ds0KNbJDq1806ue2Y+v55VSl5JgLP7ZnDX+X0jLqFyJG7/GTYyR7z/Ho4xxodThL5grX2zpnZ1cW/e+bmPOBN09e9SU/i3ohzdwe051kZ+K1euJCUlpXYCqgN5eXkNOr6DEhISGDx4cNTto1kNfT7QwxjT1RjjBy4DplVsYIxpEd4H8CNgZk3vvIqIuMXM73bxwrxNfLV+Lws27jti+2e+3MDd767g9L9mc/0z85m1ehfWOh1cT85aT3pyPOcPPPplTMb2bsNNWd1p0zyep34wjH9fPeyYilBpcI54/61J+E3hp4CV1tq/1WGMEQXx4tXQXBEROYwjFqLW2gBwM/AhsBJ41Vq73BhzozHmxnCzE4HlxphVwATg1roKWESkLq3dlc/jn69l9Y7DD4EpLA3wf28vpVt6M1IS4nh+7sbDtg8EQzw/ZyPDu7Tkp6f3YElOLlc/9RVnPzSTf326ms+/28U1J3UmPu7Yntv89fjefPLLLM44MeOYjpeGJ5r7rzGmrTEmB/gF8FtjTI4xpjkwGrgaON0Ysyj8cU59xR40Pj0jKiISpdzcXB599NFjPv6hhx6isLD6xITgLAOzYMGCYz53XYpqHVFr7XRgepVtj1f4eg7Qo3ZDExGpH1tzi3hn8VamLd7K8q3OYI6nZ6/nzZtOJrNl5LU0H/p4NZv3FvHK5FG8v2w7L87bxF3nldS4pufHK3ewdX8xv7+gL+P6tuWmsd15Z/E2np69ngdnfIc/zsOVIzvVWY7SOEVx/92OM2S3qtlEfsa0XgRNHB4bjNXlRUQalYOF6E033XRMxz/00ENcddVVJCXVzfrfdSWaobkiIq4RClk27y3koxU7+Nenq7nk8TmcfN+n3Pv+KuI8ht+eeyIv/mgkRWVBrv3PfPYXllU7x7It+3ly1jouH9GJkd3SuHJkJ0qDIV5dkFPjdZ/5cgMdWiSW91jGx3m5eGgm7/10DK/++CSevW5EjUWsSGMTND4NzRURidKUKVNYu3YtgwYN4rbbbgPggQceYPjw4QwYMIA//elPABQUFHDuuecycOBA+vXrxyuvvMLDDz/M1q1bGTt2LGPHjj3sdV566SX69+9Pv379uP322wFnIqRrr72Wfv360b9/f/7+978D8PDDD9OnTx8GDBjAZZddVid5R9UjKiLSmK3dlc+Ts9azctsBVu/Io6D0UE9Nz4xkfnlWT84f2J4uFSYQmnr1MH7w9Ffc8NwCnvvhiPKlTgLBELe/sYT05HimTOgNQI+MFEZ2bcWLX23kx6d2w+Op3BG1avsB5q7by5QJvfFW2WeMYUTXVnWVukhMBD0+vEEVoiIi0bjvvvtYtmwZixYtAmDGjBmsXr2ar776Cmst55xzDjNnzmTXrl20b9+e9957D4D9+/eTmprK3/72Nz777DPS09NrvMbWrVu5/fbbWbhwIS1btmTcuHG8/fbbdOzYkS1btrBs2TLA6Z09GNP69euJj48v31bbVIiKiGtZa3l+7kb+NH0lXmMYkNmC7w/rSK+2KfRqm0LPjBSS4yP/b/Ck7mk8eMlAfvrSN/zy1cX883JnFrinZq9n+dYDPHblEFITfeXtrxrVmVte+obPV+9ibK82lc713JyNxMd5uHRYR0SagpDxEVd9FTcRkYbv/SmwfWntnrNtf5hwX9TNZ8yYwYwZM8pnoD1w4ACrV6/mlFNO4Ve/+hW333475513HqecckrU55w/fz5ZWVm0bt0agCuvvJKZM2dy5513sm7dOm655RbOPfdcxo0bB8CAAQO48sormTRpEpMmTYo+16OgQlREGozisiDxcZ4jLoMSjZ0Hirnt9SV8/t0uTuvZmgcuHkCb5glHdY4LBrZnx/5i/jR9Je1SE+jpCfH3Od8xrk8G4/u1rdT27L5tSU+O54W5GysVovsLy3jr6y1MGtSBls38VS8h4kohjw+vLY51GCIijZK1ljvuuIMf//jHQOXlWxYuXMj06dO54447GDduHHfddVfU54ykZcuWLF68mA8//JBHHnmEV199laeffpr33nuPmTNnMm3aNO655x6WL19OXFztlo4qREWkQdh5oJgz/vY5qYk+zh/YngsGtqd325RjKkrfX7qNO95aSnFZkHsm9uWqUZ2Pubj90Sld2ZJbxJOz19MqweDzeLl7Yr9q5/PHebh0eCaPZa9lS25R+fIpry3cTFFZkB+c3OWYri/SGIU86hEVkUbqKHoua0tKSgp5eYdm6z/77LO58847ufLKK0lOTmbr1q20bNmSQCBAq1atuOqqq0hOTuaZZ56pdPzhhuaOHDmSW2+9ld27d9OyZUteeuklbrnlFnbv3o3f7+d73/se3bt359prryUUCrF582bGjh3LmDFjePHFF8nPz6dFixa1mrcKURFpEB77fC2FpUEGdWzB1JnreCx7LT3aJHPBwPZMGtyBjq2OPBNcKGS5482lvLJgMwMyU/n7pYPo3jr5uOIyxnDneX3Yvr+YD5Zv555JvWmbGrln9fIRnXg0ey0vzdvEr87uRTBkeW7ORkZ0aUWf9s2PKw6RxiTk8RGvQlREJCppaWmMHj2afv36MWHCBB544AFWrlzJSSedBEBiYiIvvfQSa9as4bbbbsPj8eDz+XjssccAmDx5MhMmTKBdu3Z89tlnEa/Rrl077r33XsaOHVv+3OnEiRNZvHgx1113HaFQCIB7772XYDDIVVddxf79+7HW8vOf/7zWi1BQISoiDcDOA8W8OG8TFw3uwAPfH8ie/BKmL93GtMVb+etH3/Hwp6t55ccnMaRTy8Oe55UFm3llwWZ+fGo3fnV2L3ze2pkY3Osx/OPyQTz1v2yuHFHzEiuZLZM4vVcbXp6/mZ+e0YNZq3exaW8hvx7fq1biEGk0PHHEadZcEZGovfjii5Ve33rrrdx6663AoaG53bt35+yzz6527C233MItt9wS8bzZ2dnlX19xxRVcccUVlfYPHDiQr7/+utpxs2fPPtoUjpqWbxGRmHv883UEQpabTz8BgLTkeK4+qQuv3Xgys349ltbJ8fzqtcUUl9W8LuHOA8X8efpKTuqWxpQJvWutCD0oPs5LnzRvtRlxq7pqVGd255cwY8V2nvlyA22bJ3B237aHPUbEbayG5oqIyBGoEBWRmNp5oJgX5m3kosEd6JzWrNr+jq2SuP/igazbVcADH35b43l+N205JYEQf76of61MdnSsTu3ZmsyWifz9o++YtXo3V47sVOtFsUhDZ71+4qj5jSMRERH9dSQiMVW1NzSSMT3SuWpUJ57+Yj1frd9bbf+Hy7fz/rLt/OzMHnRNr17M1ievx3DFyE6s3VWA3+vh8pE1D+UVcSvr9eFTj6iIiByGClERiZmDvaEX1tAbWtEdE06kY8skfvXaYgpKDv2Be6C4jLv+t4wT2zXnhlO61XXIUblkWEf8cR7OG9iO9OT4WIcjUv88fnwECIYiLxcgItLQ1LS8iUTnWL5/KkRFJGb+PTPcGzq25t7Qg5rFx/HAxQPYvK+Q+95fVb79/g9WsSuvhPsu6t9ghsCmJ8cz7ebR/P6CvrEORSQ2vE4hWhoIxToSEZEjSkhIYM+ePSpGj5G1lj179pCQcHTrtWvWXBGJiZ15xTw/1+kN7RLlcNqR3dK47uSuPP3Fesb3a0t8nIfn527ih2O6MrBji7oN+Cj1bqvlWqQJi3OG5hYFQiT6vbGORkTksDIzM8nJyWHXrl2xDiWi4uLioy7y6ltCQgKZmZlHdYwKURGJiX9/Hn1vaEW/Ht+L7G938uvXl5Dg89ChRSK/OKtnHUUpIsfCeP34TZDcQADwxTocEZHD8vl8dO3aNdZh1Cg7O5vBgwfHOoxa1zDGsYlIzJQEgvx+2nK+3rTviG2ttTzzxXpuf30Jb32Tw44Dxcd0zWPpDT0oweflwUsGsm1/EWt3FfCnC/vRLF7vqYk0JCbOD0BZWWmMIxERkYZKf72JNHHvLt7GM19u4I2FObxww0gGZLaose3Dn6zh7x9/R6LPyysLNgNwQptkRndP46Tu6QTLDv9sRShkmbd+L499vvaYekMPGtKpJXdP7Me+glKyerU5pnOISN3xeJ1e0LKSkhhHIiIiDZUKUZEmzFrLs3M20CUtiUDIcs3TX/Hy5FERn298YuY6/v7xd1w8NJP7LurPqu15fLl2N1+s2cOrC3J4ds5GDPDvb2dzcvd0Rp+QxvAurYiP87B0y37+t2gr7y7Zyo4DJST5vfzirJ5H3Rta0VWjOh9H5iJSl0ycM1t0WemxjZoQERH3UyEq4kKhkGX7gWLat0g8bLtvNueyJGc/90zsy2k923DJv+dw1ZNf8eqPR9GtdXJ5u//O3cifpq/k3AHt+Mv3BuD1GPp1SKVfh1Qmn9qd0kCIRZtzeeHjBWwNenhy1joe/3wtfq+H9GQ/W/cX4/MaTuvZht+e254zTmxDkl//+xFxK094aG5AQ3NFRKQG+ktQxIX+8uEqnpy1nnduHkOf9jXP3vrslxtIiY/joiGZNIuP4/kfjeTSf8/hyifn8eqPT6JjqyReX5jDnW8v48wT2/DQpYPweky18/jjPIzo2orCHn6ysk6moCTAVxv28uWa3WzeW8StZ7ZmfN92pCZp0hKRpqD8GdFSDc0VEZHIVIiKuMyuvBKe/XIDwZDl7neX89INozCmevG4M6+Y6Uu3cdWozuWT/ZzQJpnnfzSSy6bO5con5/HDMV35wzvLOaVHOv+6YkjU63Q2i49jbK82jNXzmyJNktd3sEdUhaiIiESmWXNFXGbqzLWUBkL8cExX5q7by4fLt0ds9+K8TZQFLdec1KXS9hPbNee560ewt6CU301bztDOLfn31UNJ8GktQBGJjjf8jGhQhaiIiNRAhaiIi+zKK+G/czcyaXAH7pjQm14ZKfxp+kqKy4KV2pUGQrwwbxNZvVrTNcKEQQM7tuDZ60dw9ajOPH3tcD3PKSJHxRPuEVUhKiIiNVEhKuIiT8xaR2kgxC2n9yDO6+HO8/qweW8RT3+xvlK795dtY1deCT84uUuN5xrauSX3TOpHSoKe6xSRo+P1HewR1WRFIiISWVSFqDFmvDHmW2PMGmPMlAj7U40x7xhjFhtjlhtjrqv9UEXkcHbnl/DcnA1MGtShvJdzTI90zjwxg0c+XcPOA4eWUXhuzka6pCVxWo/WsQpXRFwszqehuSIicnhHLESNMV7gEWAC0Ae43BjTp0qznwArrLUDgSzgr8YYfy3HKiKHMXWm0xt68+knVNr+f+eeSGkwxAMffgvAsi37WbhxH1ef1AVPhBlwRUSOV1z50Fz1iIqISGTR9IiOANZYa9dZa0uBl4GJVdpYIMU4U3MmA3uBQK1GKiI1qtgbWnH9T4Cu6c24bnRXXv86h6U5+3nmyw0k+b18f1hmjKIVEbc7ODQ3FFQhKiIikUVTiHYANld4nRPeVtG/gBOBrcBS4FZrbahWIhSRI6qpN/Sgm08/gVZJfn7z1lKmLd7KRUM60FzPfopIHfEdLETVIyoiIjWIZirMSGP3bJXXZwOLgNOB7sBHxphZ1toDlU5kzGRgMkBGRgbZ2dlHG29E+fn5tXauhsjt+YFyPBJrLWtyQ5SF4IQWHvzeQ/8sD5RYnpldyMh2XjYtX8CmGs5xfhd4Zvl+AE6M21Un32+3/xzdnh80jRyl7sXFH+wR1TOiIiISWTSFaA7QscLrTJyez4quA+6z1lpgjTFmPdAb+KpiI2vtVGAqwLBhw2xWVtYxhl1ZdnY2tXWuhsjt+YFyrElxWZBpi7by9BfrWbW9EAB/nIdhnVsy+oR0Tu6exqwl2wjY9fzx8jF0rzIst6JTQpZvHv2CVs38XHneiONJpUZu/zm6PT9oGjlK3TvYI2rVIyoiIjWIphCdD/QwxnQFtgCXAVdUabMJOAOYZYzJAHoB62ozUJGmZMeBYp6fu5EX5m1ib0EpvdumcP/3BpCe4ueLNXv4Ys3u8smHAC4c3OGwRSiA12N49caT8BhNUCQidevgM6JWz4iKiEgNjliIWmsDxpibgQ8BL/C0tXa5MebG8P7HgXuAZ4wxS3GG8t5urd1dh3GLuNa0xVv5xSuLCFrLGb0zuH5MF07qloYJF5Cn984AnAmK5qzdw9It+7ludJeozh0f562rsEVEyhmvM2uuDagQFRGRyKLpEcVaOx2YXmXb4xW+3gqMq93QRJqegpIA97y7gj7tm/PPywfTOa1ZjW3Tk+M5f2B7zh/Yvh4jFJH6ZIwZD/wD543gJ62191XZ3xv4DzAE+D9r7YPRHlunDhai6hEVEZEaRDNrrojUkydnrWdXXgm/O7/vYYtQEXG/KNfx3gv8FHjwGI6tO97wrNzBsnq7pIiINC4qREUaiF15JUyduZYJ/doytHPLWIcjIrF3xHW8rbU7rbXzgaoVXzRrgNed8kJUPaIiIhKZClGRBuLhT1ZTEghx29m9Yh2KiDQM0azjXRfHHr/yobnqERURkciiekZUROrW2l35vPjVJq4c2YluR5j9VkSajGjW8T7uY+tkjW9ryQIK83Jduy5tU1hzVzm6g9tzdHt+4N4cVYiKNAAPfPAtCXEefnpGj1iHIiINRzTreB/3sXW1xnfp53EkJ/hcuy5tU1hzVzm6g9tzdHt+4N4cNTRXJMYWbtzLB8u3c+Np3UlPjo91OCLScJSv422M8eOs4z2tHo6tFQHiNFmRiIjUSD2iIjFkreXP01fRJiWeH57SNdbhiEgDEs063saYtsACoDkQMsb8DOhjrT0Q6dj6jD9AHJ6QClEREYlMhahIDH24fAcLN+7jvov6k+TXP0cRqSyKdby34wy7jerY+hQwKkRFRKRmGporEiO5haXc/8EqerRJ5uKhEf+OFBFptALEYawKURERiUyFqEgtWrcrn6dmr2d3fkmNbUIhy2sLNnP6Xz9n495CfnteH+K8+qcoIu4SNHF41SMqIiI10FhAkVpSWBrgR88uYN3uAv7y/iouGNSe60Z3oW/71PI2q7Yf4M63lzF/wz6Gdm7JHyf148R2zWMYtYhI3Qji1dBcERGpkQpRkVpy9zsrWL+ngAe/P5AlObm8tiCH1xfmMKJrK649uQvTVpXw0YzZNE+I4/6LB3DxkEw8nkhL/YmINH5BE4fHBmIdhoiINFAqREVqwftLt/Hy/M38v6zuXDw0k4uHZvLLs3rxyoJNPPvlRm564WsALh/RiV+f3YuWzfwxjlhEpG5paK6IiByOClGR47Q1t4gpby5lYGYqvzirZ/n21CQfk0/tzvWjuzJrzW42rlrKtRP7xzBSEZH6EzRxeNUjKiIiNdAMKSLHIRiy/PyVRZQFQ/zjssH4Ikw6FOf1MLZXG7qkemMQoYhIbARNHHGaNVdERGqgHlGRI3jz6xxyC8s4b0A72jRPqLTv8c/XMm/9Xh78/kC6pDeLUYQiIg1PyMThtTXPIC4iIk2bClGRw9iTX8LtbyyhLGi5570VnNQtjQsGtmdCv3as31PA3z/6jvMGtON7QzrEOlQRkQYlZOLwESAYsng1MZuIiFShQlTkMN74OoeyoGXq1UNZtvUA7yzeypQ3l3Ln/5aR5I8jo3kCf7qwP8bojywRkYpCJo54ApQGQiT69WiCiIhUpkJUpAbWWl7+ajPDOrdkXN+2jOvblp+f2YNlWw4wbfEWvly7h7sn9iU10RfrUEVEGpyQx4ePAKXBEImoEBURkcpUiIrUYN76vazbXcBNY08o32aMoX9mKv0zU2MYmYhIw2eNF79xekRFRESq0qy5IjV4+atNpCTEcW7/drEORUSk0bGeOOIIUhpUISoiItWpEBWJILewlOnLtnPh4A7uf7bJWvj6v1CwJ9aRiIiLWBMemqseURERiUCFqEgEb369hdJAiMuGd4p1KHVv0xyYdjN8dGesIxERF7EeZ9bcMvWIiohIBFEVosaY8caYb40xa4wxUyLsv80Ysyj8scwYEzTGtKr9cEXqnrWWl+dvYmBmKn3aN491OHVvyavO58Uvwe41sY1FRFzDeuLwq0dURERqcMRC1BjjBR4BJgB9gMuNMX0qtrHWPmCtHWStHQTcAXxurd1bB/GK1LmvN+Xy3Y58Lh/RBHpDA6Ww4m3oNhbiEuDzv8Q6IhFxCRteR7REhaiIiEQQTY/oCGCNtXadtbYUeBmYeJj2lwMv1UZwIrHw0lebaOb3cv7A9rEOpe6t/QSK9sHIG2HEZFj6GuxcFeuoRMQNPHF4jaWsrCzWkYiISAMUTSHaAdhc4XVOeFs1xpgkYDzwxvGHJlL/DhSX8e6SrVwwqD3N4pvA6kZLX4PEVnDCGXDyT8HfDD6/L9ZRiYgbeJ3/hwZKS2IciIiINETR/KVtImyzNbQ9H/iipmG5xpjJwGSAjIwMsrOzo4nxiPLz82vtXA2R2/ODhpPjp5vKKC4L0dO7q9bjaSg5HuQNFHHyinfY3vZ0Vs/6AoAu7c6hy/JXmZ+YRUFyl6M+Z0PLsba5PT9oGjlK/bAeHwBlKkRFRCSCaArRHKBjhdeZwNYa2l7GYYblWmunAlMBhg0bZrOysqKL8giys7OprXM1RG7PDxpGjtZa7n94Nn3aJXDtBWMwJtJ7MMeuIeRYyeJXIFRKh7N/RofOJznbRg6Ehz5keP5HcN4LR33KBpdjLXN7ftA0cpT6YTzOnxjBgApRERGpLppCdD7QwxjTFdiCU2xeUbWRMSYVOA24qlYjFKlFxWVBpi3eyntLthEf5yE9JZ70Zn7SkuMJhiwrth3gnol9a70IbZCWvgapHaHjyEPbElvCST+B7D/D1m+g/eDYxScijVp5IVpWGuNIRESkITpiIWqtDRhjbgY+BLzA09ba5caYG8P7Hw83vRCYYa0tqLNoRY7RzgPFPD93Iy/M28SeglK6pCURH+fl60372FNQig0PNm/m9zJxcMRHoN0lfxes/RRG/xQ8VR4VH/X/YO6j8Nm9cOWrsYlPRBo9Gy5Ey8rUIyoiItVFNRuLtXY6ML3KtservH4GeKa2AhOpDau2H+Dfn6/j3SVbCYQsZ/Ruw/Wju3JS97TyXs9gyLKvsJQ9+aU0i/fSPMEX46jrwYq3wQah//er70to7hSon9wNm+dDx+H1Hp4rBUrguw8hZ77zfW83INYRidQpj/dgj6gKURERqa4JTAsqTdWG3QV879EvAbhyZGeuPbkLXdKbVWvn9RjSk+NJT46v7xBjZ+lr0KYvZPSNvH/Ej2HOI/DRXXDWH6BVd0hqBY1tyHJZMWz8AlbPgL3rYMwv4ODzsNEcW7QPivY6nwv30nbbV/D15upt45OhVTfnIz7l0HZrYdNcWPIyLH8Livc72798GE68ALLugIw+1c8n4gImPFmRhuaKiEgkKkTFlcqCIW59+Ru8HsP7PzuVDi0SYx1Sw7FvA2yeB2f8ruY28clOkTT9V/DUWc62hFSnIE3rDu0GQY9xkN4j+uK0eD/sWesUhHvWgg0552rVHdK6Oc+n1oYDW+G7D+C7GbD+cygrhLgEp0D8zwQYcYOTe3xy9WPLiuHrZ+GLf8CBLdV29wb49gjXT85wcmrRCTbNgdyNEJcIJ54HAy6DDkNg3r+d4c8r34G+F0LWFGjdqzayF2kwTLhH1GqyIhERiUCFqLjS3z/6jsU5+3n0yiEqQqta+rrzuf/Fh2834gbofjrsXg1714aLyLVOD9/S12DG/0HLLk5B2mMcdBmDN1AE25ZUaB8uOvesgcLdVS5gqLQSVGIrpzBNznCK0qRWzufEVpCaCd3GVn+etSJrYd7jTi9usBRSO8GgK6DH2dBljFP4fnI3fDUVvv0ALviHkx84w2a/+S/M/CvkbYXOo2HY9ZVjSGzJ3EUrGXXSydWvXZx76PuzZ53zef3nTnGZdYdThFbsKR17B4wM9zrPe9zpLe00Crz+6udObnPoDYCjLdoDpbBlgRN/616Nr0dbGjXj1WRFIiJSMxWi4jpfrt3NY5+v5bLhHTmnf7tYh9OwWOsUkZ1OcnrsjiQtXABVlbsJVn/kfHzzvFPceXycEiqD2RXaJbd1ju99TuViqlVXwDi9sxWL3L3rnI/Cvc6Q2GCFP2DbD4EJ90d+ZrVgN7x9E6z+EHqOhzP/ELnwOud+6HcR/O9m+O+FMOgqp4dy9t9h/2ZnBuELH4eup0Ys2oq/3QstOlbbDh2hbf8jfz8rSmoFZ9wJo26COf+EjXOcgrgS6/ReL32dSkV7Urozo3HmcMgcBh2GQmILZ9+BbbDmI2c48tpsKM1ztqd2gp4H3zQ4BfxJRxevyNEKT1YUUo+oiIhEoEJUXGVfQSm/eGUxXdOacdf5evaumh3LYNcqOPdvx3eeFp1g+A+dj7Ji2Dgb1s9k3dY9dBt2ZrjY7BZ5+GtFbXo7H5FY6wyrLdwL62fCJ3+Ap850hree+XtoHn6TYV02vDkZinJhwgNOT+7hev46jYIbZ8Pn98EXD8Oi56HDMDg/3ENa372GzdKcfA6nrLhy0b77W9jyNWR/THmBmt4TvPGwY6nzunkHp9f7hDOhYJfzpsGil2D+k85Q5a6nwdjfQPtBdZebNG3hZ0RtUD2iIiJSnQpRcQ1rLXe8uZQ9BSU8cc1okvz69S5nLexbD1/+0+ml6DOp9s7tS3CKnRPOZFN2Nt36ZtXOeY0BfzPnY/CV0OcCmPVXZzjrynfg1F9CSR7Mfsgpwq56E9r2iz7mM38PAy51Ct3OJzfsYau+hMhFe/EB2Pq1MxNvzkIozXeef+15NrTpUzmnYdc5Pa4bv3Cen132BjxxujND8mlTnGvEQu7mGnqZpbELebzO50BZjCMREZGGSH+pi2u8PH8zHyzfzm/O6U3/zNRYh3PsggHI3+48F3msQiHYMNNZfiVnvvOcYOEeZ9/Ay51euMYmPsUpHodcAx/+1nneE2DotXD2vcc21LTNibUZYf1LaA7dspyPaMTFO72+3U+HrNud7+Psv8PKd2Hiv5ze4vq09HV4+//BRVOdSZvEVawJ94gG1CMqIiLVqRCVRq8sGGLeur3c/c4KxpyQzo/GdIt1SMfni7/Dp390njkccJmz5mRKxtGd45M/wBcPOV+37g29JjjDTzOHN/7iq1U3uPxFZ7huoBR6nBnriBqnxJYw6RHnmdl3fgZPj4eRPyYubjTsXHlokqm9a2HveudZ2lN+6cyefLyshdl/c95M6DzaGSYsERljxgP/ALzAk9ba+6rsN+H95wCFwLXW2q/D+34O/Ahn/PZS4DprbXF9xR7yHJw1V4WoiIhUp0JUGp1QyLJqex5frt3Nl2v3MG/dHgpKg6Qnx/PXSwbi8TTgIZbRWPq684ylJ86ZmfajO50ZYwdeBieeD74jzAK8Z60zfLX/9+GcBw9NYuM2XU+NdQTucMIZcNMc582LeY8zhsfhiwr7k9IhtUP4edoXnaG/g648/AzGhxMMwHu/cJbJ6f99mPiI01Mr1RhjvMAjwFlADjDfGDPNWruiQrMJQI/wx0jgMWCkMaYD8FOgj7W2yBjzKnAZ8Ex9xW9N+E8MPSMqIiIRqBCVRmXNznyufmoe2/Y7b+p3S2/GhUM6cHL3dEafkE5qoi/GER6nnaucyYTOedCZdGfXd7DkZVjyKrx5A2SOgOumg/cwec74rfOH/bg/ubcIldoVnwznPAD9LmbdZ8/SbcjpTs9zq26Hfoe2fA0fTIFpNzsTHk24HzqNPLrrlOTBa9fCmo+d3tWxvz32grZpGAGssdauAzDGvAxMBCoWohOB56y1FphrjGlhjDk4XXgckGiMKQOSgK31F3qFHlEVoiIiEoEKUWlU7p2+kvziAA9+fyCjT0ijXWoM1wgNBsBby/+EVk4DDPQ+z3nduieccZfzB/uiF5wiIPteZ1skaz+Db6c7vVZHO5xXpNNINnUuolv/rOr7OgyB6z90euw/ugueHuc819k6wqzHHu+h9VcPrsVqvPD2jbBjhTND8dBr6zobN+gAbK7wOgen1/NIbTpYaxcYYx4ENgFFwAxr7Yy6DLaqQz2imqxIRESqUyEqjcbcdXv4ZNVObh/fm4uHHsdEPrVhXTa8cg1c+Bj0Prf2zrvif86EMc2rrH/q8cCQq501JWf9zXmmrluV5+qCAfjgDmjR2VmbUqS2GQMDvu88czz7784Q8OVvRX+8PxmueFXP9UYv0nMGNpo2xpiWOL2lXYFc4DVjzFXW2uerXcSYycBkgIyMDLKzs48n5nIlRc76oYV5ubV2zoYkPz/flXlVpBzdwe05uj0/cG+OjboQtaEQZWWlBDU1vOtZa7l3+krapSZw3egusQ3mwFZ4/YdQsh8+/I2zdEltPOO2e42zzuf4+2puM+EvsGkuvPVjuPGLyrPfLvwP7FoJl/w3dktxSNMQnwxn3Amn/zby/kAJFOc6S+MU7YOi8OdOJ0P6CfUaaiOXA1Rc2yaT6sNra2pzJrDeWrsLwBjzJnAyUK0QtdZOBaYCDBs2zGZlZdVK8LM+ng5AswQftXXOhiQ7O9uVeVWkHN3B7Tm6PT9wb46N+uGcHVvW4b83g4LvPol1KFLH3lu6jcU5+/nluF4k+LyxCyRYBq9dB2VFzpIh+zbA/Kdq59wr/+d8PvH8mtv4m8HFTztLsfzvJ87so+D8kf/Zn6HLKYc/XqQ2GRP5w5cAKW0how90Ge38Tg65RkXo0ZsP9DDGdDXG+HEmG5pWpc004BrjGAXst9ZuwxmSO8oYkxSeWfcMYGV9Bh/yOM+yGz0jKiIiETTqQjQ+oRmgm5zblQZC3P/Bt/Rum8KFgzvENpiPfw+b58IFD8Oo/+es3zjzfijKPfxxO1cSX7z78G1W/M9ZXuVI64e2GwBn3Q3fvQ9fPeFsy/6L0wM1/l6nEBCRRs9aGwBuBj7EKSJftdYuN8bcaIy5MdxsOrAOWAM8AdwUPnYe8DrwNc7SLR7CvZ71Fr8Jv2kYCtTnZUVEpJFo1ENzExKdQtQTLIlxJFKXXpi3kU17C3n2+hF4Y7k0y4ppMOdfMPwG6H+xs+2se+Dfp8Ksv8K4eyIft3k+PHseA32t4MzzIw/j3bseti2GcX+MLpaRNzoTE834LSS3hvlPOD1ObfsfW24i0iBZa6fjFJsVtz1e4WsL/KSGY38H/K5OAzwc4yGIB09Ij8+IiEh1jbtHtLwQVY+oWx0oLuPhT1Yz+oQ0Tu2RHrtA9qx1hsK2HwJn/+nQ9nYDnPU95/0bcjdVP27venjpMvAnk1S01ZncJZKV4dF2J14QXTzGwKRHnaU1XrsWfEnOzLoiIg1I0PhUiIqISESNuhD1eL2UWB+ekHpE3erx7LXsKyzjjgknYmI15LSsCF79ARgPXPJs9R7N03/rFIafVOkRLdoHL17iDEu7/gN2p42EmQ/A/pzq11jxP2g/GFp2jj6uZulw4b+dZTHG/sbpGRURaUBUiIqISE0adSEKUGL8eFWIutK2/UU8NXs9kwa1p1+H1NgEESiB/90MO5bCRU9Ai07V26RmOs+LLn0Vtn4TPq4UXrna6RG97EVI78GaE34INgQf/l/l43M3wZaF0Gfi0cfXfSz8eq1zfRGRBiZo4jAqREVEJILGX4gSjzekoblu9LcZ32Et/HJcr9gEsOs7eOIMWPY6nH4n9BxXc9sxP4ekNJhxpzOT7Ts/hQ2zYOIjzqyhQHFiBpzyS1jxtvN850Er33E+Rzsst6rElsd2nIhIHQt5fHitClEREamu0ReipcZPnApR19lfVMbbi7Zw+YiOdGyVVL8Xtxa+fg6mngZ5W+HyV+DUXx3+mIRUOO12p/h86TJY/BJk/QYGXlq53ck/hZZdYfptTq8pOMNy2/aHtO51k4+ISIwEPT686hEVEZEIXFCIxuOzGprrNp+t2klZ0HLBoHperqUoF16/Dqbd4iylcuMX0Gt8dMcOvQ5adYPvPoCBl8Npv67expcAE+6HPath7qNwYCtsnndsw3JFRBq4kPHhtVq+RUREqotq+RZjzHjgH4AXeNJae1+ENlnAQ4AP2G2tPa3WojyMMk88cVY9om7z4fLttEmJZ3DHFvV30Z0r4YVL4MAWOON3MPpn4DmK92ri/M7kQSv+5xxf0+RKPcdBr3Ph8/uhaK+zrc+k441eRKTBsR4fcQQIhmxsl98SEZEG54iFqDHGCzwCnAXkAPONMdOstSsqtGkBPAqMt9ZuMsa0qaN4qwl4EvCVqRB1k+KyINnf7uLioZl46vMPl5kPQsl+uP5D6Dj82M7RcYTzcSTj74VHRsAX/4A2fSC9x7FdT0SkAbOeOOIIUBYM4fV4Yx2OiIg0INF094wA1lhr11lrS4GXgarjCK8A3rTWbgKw1u6s3TBrFvTG40eFqJvM/G4XRWVBxvdrW38XDYVg3WfQc/yxF6FHo2VnZ+Ii0LBcEXGtkMeHnwAlgVCsQxERkQYmmqG5HYDNFV7nACOrtOkJ+Iwx2UAK8A9r7XO1EuERBLwJJGporqt8sHw7qYk+RnRtVX8X3b4YCvdA9zPq75on/9SZGGnY9fV3TRGR+uT146OIUhWiIiJSRTSFaKSxkTbCeYYCZwCJwBxjzFxr7XeVTmTMZGAyQEZGBtnZ2UcdcFW+UkuaLa2VczVU+fn5rsmvNGjxe6v/Sh3MMRCyfLCkkMFt4vhi1sx6i6vTxtfpBnyxI56yOvpeR/45joQFy+vkerHgpt/VSNyeHzSNHKX+WK8Pn8mjLKhCVEREKoumEM0BOlZ4nQlsjdBmt7W2ACgwxswEBgKVClFr7VRgKsCwYcNsVlbWMYZ9yIIlT5JQUkJtnKuhys7OdkV+X63fy+Qn5/Hs9SM4qXtapX0Hc5y9ejeFgXlce+Ygsvpk1F9w/3kA2vZn9LhJdXYJt/wcD8ftObo9P2gaOUo98vjxEVCPqIiIVBPNM6LzgR7GmK7GGD9wGTCtSpv/AacYY+KMMUk4Q3dX1m6okYXiEonXM6KNwtOz11MaDPGn6SsIhap2qjs+WL6NJL+XU3qk119gJXnOEirdT6+/a4qINAVe5xnRUvWIiohIFUcsRK21AeBm4EOc4vJVa+1yY8yNxpgbw21WAh8AS4CvcJZ4WVZ3YVfgSyCBMqyNXNhIw7B9fzEfrdxBr4wUlm05wDtLqnaqQyhkmbF8B1m9WpPgq8fZFTfMhlBZ/T4fKiLSFHjVIyoiIpFFtUiitXa6tbantba7tfZP4W2PW2sfr9DmAWttH2ttP2vtQ3UUb3W+ROJNGSWlZfV2STl6L8/fRDBkefzqofRp15z7P/iWkkCwUptvNueyM6+Es/vW42y5AGs/BV8SdBpVv9cVEXG7uHAhqh5RERGpIqpCtEGLSwSguKggxoFITQLBEC9/tZlTe7ama3ozfnPOiWzJLeK/czZWavfh8u34vIaxvettGVrHmk+gyxiIi6/f64qIuJzx+vEZ9YiKiEh1jb4Q9fjDhWixCtGG6uOVO9l+oJirRnYCYEyPdE7t2Zp/frqG/YVOT7a1lg+WbWf0Cek0T/DVX3D7NsDetXo+VESkDhivDx9BFaIiIlJNoy9Evf4kAErVI9pgvTBvI+1SEzi9Qk/nlPG9OVBcxqPZawDIybds2lvI+FgMywU9HyoiUgc84aG5Wr5FRESqavSFqKe8EC2McSQSyfrdBcxavZvLR3Qiznvo161P++ZcNDiT/3y5gS25RSzYHsBj4Mz6XLIFnEK0eSak96jf64qINAHGp8mKREQkskZfiHrjnaG5pRqa2yC9OG8jcR7DZcM7Vtv3y3E9AfjrjG9ZuCPAsC6tSE+ux+c0gwFYNxNOOB2Mqb/riog0ER6vJisSEZHIGn0hGhfuEQ2UqBBtaIrLgry2MIdxfTNo0zyh2v72LRK5fnRX3vx6Czn5tv6H5W5ZCCX79XyoiEgd8cTF4zdBSsqCR24sIiJNSuMvRBObARAo0dDchua9JdvILSzjqpGda2zz/7K60yLJmZxoXN9aHpYbKIEZv4Ulr0bev/YTMB7oelrtXldERADw+vwABAOlMY5EREQamrhYB3C8fPEHe0RViDY0z8/bSLfWzTipe1qNbVITffxxUj/e+WIpmS2Tau/ihXvhlatg4xfO60AJDLm6cpu1n0L7IZDUqvauKyIi5TzhZbECpSUxjkRERBqaRt8j6k9wekSDKkQblOVb9/PNplyuHNkZc4TnL88b0J7LT6zFZ0P3bYCnz4ac+TDxUWdG3Gm3wKIXD7Up2ucMzT1Bs+WKiNSV8h7RMhWiIiJSWaPvEfWHh+aGSotiHIlU9PzcTST4PFw8JLN+L7xlIbx4KQTL4Oq3octo6HcRvHQZvH0TGC8MvBTWfQ42pOdDRUTqUJzfeZNRhaiIiFTV6AvRhHAhastUiDYUBSUBpi3awvkD2pMafv6zXqyaDq9fD8mt4drp0NqZlRdfIlz2Erx4Cbx9I3i8sP5ziG8OHYbVX3wiIk2Mx+vcA4KBshhHIiIiDU2jL0TjE5znCm2phuY2FB8u305BaZBLIizZUiushbxtsGct7F3rfN6zBr77ANoNgitegeQ2lY/xJznbX7gE3pwM/mbQ9VTwNvp/AiIiDZYJPyMaDKhHVEREKmv0f4XHJSQDYAPFMY5EDnrj6xw6tUpiWOeWtX/yjXPg5SugaO+hbV4/tOwKQ6+FcX90isxI/M3CxejFsGmOng8VEalr4R7RUJlmzRURkcoafSGK10fAekBDcxuErblFfLl2D7ee0eOIkxQdtdzNzky4iS1g7G8grTu06g6pmc5w22jEJ8OVr8Hil2Hg5bUbn4iIVOZ1JiuyQfWIiohIZY2/EAVK8OMJqBBtCN76ZgvWwveOZpKivetJ2z0P7GlQU/FaWgivXAnBUrj8lUPPfx6L+BQYccOxHy8iItEJF6LqERURkapcUYgWGz9GQ3NjzlrLGwtzGNG1FR1bHcWaoG/dSP/NcyFuI5z7N/AlVD0xvPNT2LYELn/5+IpQERGpP+GhuTagQlRERCpr9OuIApTixwRViMbaN5tzWbe74OiWbMlZCJvnkpvaBxa9AP8ZD/tzKrf58mFY+hqc/n/Qa3ztBi0i0oAZY8YbY741xqwxxkyJsN8YYx4O719ijBlSYV8LY8zrxphVxpiVxpiT6jd6KgzNVSEqIiKVuaMQNX7iVIjG3Jtf55Dg8zChf9voD5r7CMQ3Z2n/O50lVnavgX+fBhtmO/tXfwwf/x76TIJTflUXYYuINEjGGC/wCDAB6ANcbozpU6XZBKBH+GMy8FiFff8APrDW9gYGAivrPOiqDhaiWr5FRESqcEchSjxeTYQQUyWBIO8s3sbZfduSkhDl2qG5m2H52zDkGoJxSdD7HLjhU0hqBc9eAJ/+Cd64Htr0gUmP1vz8qIiIO40A1lhr11lrS4GXgYlV2kwEnrOOuUALY0w7Y0xz4FTgKQBrbam1NrceY3ccHJobUiEqIiKVueIZ0TLjxxtSj2gsfbJyJ/uLyo5ukqKv/u18HvljWLTO+bp1T/jRJ/DWj2Hm/ZDYCi57oeYlWURE3KsDsLnC6xxgZBRtOgABYBfwH2PMQGAhcKu1tqDqRYwxk3F6U8nIyCA7O7tWgs/Pz2f+1xsYDhTs31dr520o8vPzXZdTVcrRHdyeo9vzA/fm6I5C1OPHF1KPaCy9sTCHts0TGH1CenQHlOTBwmehz0Ro0QlYd2hfQnO49AVY9Dy0HQAtu9RFyCIiDV2kYSA2yjZxwBDgFmvtPGPMP4ApwJ3VGls7FZgKMGzYMJuVlXU8MZfLzs5meN+esACSEnzU1nkbiuzsbNflVJVydAe35+j2/MC9ObpiaG6ZiVchGkO78krI/m4XkwZ3wOuJcvjsNy9AyQE46ebI+z0eGHINtB9Ua3GKiDQyOUDHCq8zga1RtskBcqy188LbX8cpTOtXeGiu0dBcERGpwhWFaND48VsVorHyv0VbCIYsFw/tEN0BoSDMfRQ6joTMoXUbnIhI4zUf6GGM6WqM8QOXAdOqtJkGXBOePXcUsN9au81aux3YbIzpFW53BrCi3iI/KDxZkdGsuSIiUkVUhWgU08dnGWP2G2MWhT/uqv1Qaxbw+IlXIRozb369hYGZqZzQJiW6A1a9B7kb4aSf1G1gIiKNmLU2ANwMfIgz4+2r1trlxpgbjTE3hptNx3m2YQ3wBHBThVPcArxgjFkCDAL+XF+xlztYiKpHVEREqjjiM6IVpo8/C2eoz3xjzDRrbdV3VmdZa8+rgxiPKOiJJx692xoLK7cdYMW2A/zhgr7RHzTnEWjRGXrH5NdFRKTRsNZOxyk2K257vMLXFoj4rp61dhEwrC7jO6KDQ3ODKkRFRKSyaHpEo5k+PqaCXj/xlFIWDMU6lCbnlfmb8XkNFwxsH90BOQth81wYeSN4vHUbnIiIxJZ6REVEpAbRFKI1TQ1f1UnGmMXGmPeNMUfRPXb8Qh4/iZRSVBqoz8s2ebvySnh5/ibOH9iels380R009xGIbw6Dr6rb4EREJPbChahHhaiIiFQRzfIt0Uwf/zXQ2Vqbb4w5B3gb6FHtRHW0Vlmp9eIxluzPPqN5UnytnLMhaahrB728qoSSshAjmu09YnwmVEabnV/Qe9Vb5GRewNq5X1fa31BzrE3KsfFze37QNHKUeuTxYjHqERURkWqiKUSPOH28tfZAha+nG2MeNcakW2t3V2lXJ2uVzVj2FgCDBw2gY/t2tXLOhqQhrh20O7+E7E8+5cLBHbjs3EE1NyzYDQv/AwuehPztkN6LjpfcR8fmlX9ODTHH2qYcGz+35wdNI0epR8YQNHF4rQpRERGpLJpCtHz6eGALzvTxV1RsYIxpC+yw1lpjzAicIb97ajvYGnmdXtCSovx6u2RTN3XmOkoDIW4+/YTIDXaugjn/giWvQrAEup8OF/wTTjjTWSNURESahJDHh9cGCIUsnmjXmhYREdc7YiFqrQ0YYw5OH+8Fnj44fXx4/+PAxcD/M8YEgCLgsvBMfvUiFH4GpbS4sL4u2aTtzi/huTkbmDSoA91aJ1dvsPFL+O+FgIFBVzgTE7XpXe9xiohI7IWMDx8BSoMhEjRJnYiIhEXTIxrN9PH/Av5Vu6FFz8Q5PaKlRQWxCqFJOWxv6Pal8OKlkNoRrn0PUjLqP0AREWkwQh4f/oOFqE+FqIiIOFwxRtKEe0QDpSpE69rB3tCJkXpD966D/14E8Slw9VsqQkVEhJAn3CMa0BJrIiJySFQ9og2eLwGAoIbm1rknauoNzdvuDMcNBeDad6FFx8gnEBGRJsV6fPiMClEREanMFYWop7xHVIVoXXJ6QzcycVAHulfsDS3Khee/B/m74AfvQOteMYtRREQaFutVj6iIiFTnikLUxDmFaLCkKMaRuNsTM9dREghW7g0tK4KXLodd38KVr0Lm0NgFKCIiDY71+PETpCyoQlRERA5xRSHqCQ/NDalHtM7sCfeGXjCw/aHe0GAAXrsONs2Bi592lmgRERGpyOsjjgAl6hEVEZEKXDFZkdfn9IiGytQjWlfeXbKNorIg/y8r3BsaCsG0W+C79+HcB6HfRbENUEREGiTrObR8i4iIyEGuKEQPzpprS1WI1pWPV+6gW3ozerVNAWvhozth8YuQ9RsY/qNYhyciIg2U8frwmaCeERURkUpcUYharzM0F/WI1om84jLmrtvDmX3Cy7HM/jvM+ReMmAyn/Tq2wYmISMPm9eMnoGdERUSkElcUoiGP0yNKQIVoXZi1ejdlQcsZvdvAwmfhkz9Av4th/F/AmFiHJyIiDVmcX7PmiohINa4oRDGGEvwYFaJ14uOVO0hN9DGscDa8+zM44UyY9Bh43PHrIyIidcd4VYiKiEh1rqkkSkw8nkBJrMNwnWDI8tmqnVzXeRfet34EHYbBJc9BeMkcERGRwzEHe0Q1NFdERCpwTSFaavx4gsWxDsN1vt60j0Dhfibv/BOktIUrXgF/s1iHJSIijYQnzo/fqEdUREQqc8U6ogBlJh5vUENza9vHy7dzr/8pEou2w+UfQlKrWIckIiKNiHpERUQkEtf0iJZ5EvAGNTS3tnmXvsR5njmYsb+BjsNjHY6IiDQynjg/cWj5FhERqcw1hWjAE09cSIVobdq8egk/Kfo321oOgzE/j3U4IiLSCHnDPaJavkVERCpyTSEa9MbjC+kZ0VoTKCFx2g2U4sNeOBU83lhHJCIijZAnzllHVD2iIiJSkWsK0YAnAZ9Vj2it+eRu0vNW8Y9mt9K+U/dYRyMiIo2UR+uIiohIBK4pRG1cAn5bGusw3GH1xzDnXzwXHEezgRfEOhoREWnETFw8XmMpDZTFOhQREWlAXFOIhrwJxKtH9Phtng9v3sCB5j34U9kVnHFiRqwjEhGRxszrAyBUpjeLRUTkENcUotaXSDylBEM21qE0XivfgWfPg4RU/p72O1KSkxmU2SLWUYmISGPm9QMQDOjNYhEROcQ1hShxCSRQSnFZMNaRNE5zHoVXroa2/Sm7bgavr/dzeu82eDwm1pGJiEhjFi5E1SMqIiIVuacQ9SWSQIkK0aMVCsL7t8OHd8CJ58MP3mH+Tg95xQENyxURkeN3cGiunhEVEZEK4mIdQG0xviT8JkhRSSkkx8c6nMahtADeuAG+fQ9OuhnOugc8Hj5euR5/nIdTeqTHOkIREWnsDvaIBtQjKiIih0TVI2qMGW+M+dYYs8YYM+Uw7YYbY4LGmItrL8ToGH8iACXFBfV96cbrgzvgu/dhwgNw9p/A4yGvuIwPl29ndPc0kvyueZ9CRKRROtL91zgeDu9fYowZUmW/1xjzjTHm3fqLugrPwR5RPSMqIiKHHLEQNcZ4gUeACUAf4HJjTJ8a2v0F+LC2g4yGxxcuRAtViEYlFIJV70K/78HIyQDkFpZy1ZPz2HGgmOtGd41xgCIiTVuU998JQI/wx2TgsSr7bwVW1nGoh1c+NFc9oiIickg0PaIjgDXW2nXW2lLgZWBihHa3AG8AO2sxvqh545sBUFaiQjQqW7+Bwj3Q42wAdueXcNnUuazclsfjVw3l1J6tYxygiEiTF839dyLwnHXMBVoYY9oBGGMygXOBJ+sz6GrCQ3NRISoiIhVEM/ayA7C5wuscYGTFBsaYDsCFwOnA8JpOZIyZjPOOLRkZGWRnZx9luJHl5+ezeecOegJLF3/Nvt17a+W8DUV+fn7U36ut+SHSEw1+7+Fnu+284WW6YPhyezw7t37KX+YXs7fI8tMhCcTtXEn2zvp9A/1ocmyslGPj5/b8oGnk2Igc8f5bQ5sOwDbgIeDXQErdhRiFcCFqgypERUTkkGgK0UgVTdXFOh8CbrfWBo2puQCy1k4FpgIMGzbMZmVlRRflEWRnZ9OtVR/YBN06d+TkMbVz3oYiOzubaL5X32zax/WPfckZJ2Yw9eqhHO5nwRN3Q+YwOg07kzuenEd+wMvzNwxnRNdWtRf4UYg2x8ZMOTZ+bs8PmkaOjUg099+IbYwx5wE7rbULjTFZh71IHb5JnJ2dTYt9KxgEFObtd9WbHE3hTRvl6A5uz9Ht+YF7c4ymEM0BOlZ4nQlsrdJmGPByuPBJB84xxgSstW/XRpDRiEtwhuYGSwrr65INSnFZkF++thivx/DRih18sGw7E/q3i9y4YDds+Zp9I37JJf+eQ0FJgOd/NJJBHVvUa8wiInJY0dx/a2pzMXCBMeYcIAFobox53lp7VdWL1OWbxFlZWbAxHhZDUnycq97kaApv2ihHd3B7jm7PD9ybYzTPiM4Hehhjuhpj/MBlwLSKDay1Xa21Xay1XYDXgZvqswgF8McnARAsbZqF6IMffsu6XQU8cc0w+rZvzl3TlrO/sIY129Z8AlhuW5xBSSDES5NHqQgVEWl4jnj/Db++Jjx77ihgv7V2m7X2DmttZvi+fBnwaaQitF6Eh+YaDc0VEZEKjliIWmsDwM04s+GuBF611i43xtxojLmxrgOMlv9gj2hx0ytEv1q/l6e+WM+VIzuR1asNf/neAPYWlHLfB5Gf8wytnsF+TwtmFXTgqR8Mo2/71HqOWEREjiTK++90YB2wBngCuCkmwR7OwVlzgzW8OSoiIk1SVAtFWmun49zsKm57vIa21x5/WEfPnxguRMuKYnH5mCksDXDb64vJbJnIb845EYB+HVL54ZiuTJ25jomDOjCqW9qhA0JBilfO4OOygfz5woEM7tQyRpGLiMiRHOn+a621wE+OcI5sILsOwovOwR7RkApRERE5JJqhuY2CP8EZmmtLm1Yhet/7q9i4p5AHLh5Is/hD7yv8/MyedGyVyG/eXEpxWbB8+wcz3iMpeABvz3F8b2hmLEIWEZGmJNwj6lEhKiIiFbimEPX4nUKUsqYzNPfLNbt5bs5Grj25S+VeTyDR7+XPF/Zn3e4C/vXpGgDmrdvD6i/eIoSH8y+KzaNCIiLSxIQLUT0jKiIiFUU1NLdR8CUCYMuKYxxI/cgrLuO215fQNb0Zt4/vHbHNKT1ac9GQDjz++VoGdWzBr99Ywou+JYTaDSOuWWyWaRERkSZGQ3NFRCQC1/SIEucUogSaxtDcBz/8lm37i3jw+wNI9HtrbHfnuX1ITfTxo+cW0Dy4l96hNcT1HFePkYqISJMWLkS9NkAoVHUZVBERaarcU4h64wjgxRNwf4/o9v3FvPTVZi4d3pGhnQ/fs9mymZ+7J/YjJT6Ox0ftdzb2OKseohQREaF8aK6PAKXBUIyDERGRhsI9Q3OBEuIxTaAQfXLWOoLW8v9OOyGq9ucOaMfZfTOIe/OH0KwNtB1QxxGKiIiEhXtE/eFCNMFX8ygeERFpOtzTIwqUeuLxBN1diO4tKOWFeZu4YGB7OqUlRX1cHCFY+6nTG+px1Y9dREQaMk+FHtGAekRFRMThqoqkzPiJq+NCdNmW/Xy1fm+dXuNwnvliPUVlQf5fVvejO3DLAijOhRPOrJO4REREIvJ4CJk44kyQMg3NFRGRMFcNzS3zJOCtw0L0QHEZP3j6K/YUlHLL6SfwszN74vWYOrteVXnFZTzz5QbO7ptBz4yUozt49UdgvNB9bN0EJyIiUoOQx6ceURERqcRVPaJBTzzeUEmdnf9fn65hT0EpZ/XJ4J+fruG6Z+azr6D+1kV7fu4mDhQH+MnY6J4NrWT1DOg4AhJb1n5gIiIih2E9cc4zoipERUQkzFWFaMCbgD9UNz2i63cX8J8v1nPx0EyeuGYY917Un7lr93D+v2azbMv+OrlmRcVlQZ6avY5TeqQzILPF0R18YBtsX6LZckVEJCYO9oiWqBAVEZEwVxWiQW8CPnt0PZTb9heR9cBnPDV7/WHb/em9lfi9Hn59di8ALh/RiVdvPIlQyHLRY1/y6oLNxxx3NF6Zv5nd+aVH1xtqLSx7E546C4wHep1TdwGKiIjUwIYLUT0jKiIiB7mqEA15E/DZoxua+8f3VrJhTyH3vLuCaYu3Rmwze/VuPl65g5vGnkCb5gnl2wd1bME7t4xheJeW/Pr1JUx85Auemr2enQdqt1c2ELL8+/O1DOvckpFdD79uaLltS+CZc+H16yAhFX7wDrQ5sVbjEhERiYrXj89oaK6IiBziqsmKbFwC8bYEay3GHHkSodmrd/Pekm38ZGx3FmzYx69eXUzr5HhO6p5W3iYQDHH3u8vp2CqRH47pWu0cacnxPHvdCJ6bs5E3vs7hnndX8Mf3VnBStzQuGNieCf3akZrkiyr+UMhiDNVin7M1wNb9pfzpwv5HzqtgN3z6R/j6WUhoAef9HYb8ADxat01ERGLDenzl64iKiIiA6wrRRBJMKSWBIy+YXRIIctf/ltE5LYlbTu9BSVmIix//ksn/XcDrN55Mr7bOrLQvfbWJ73bk89iVQ2o8Z5zXw/VjunL9mK6s2ZnPtMVbeWfxVqa8uZQ/T1/J+z87lQ4tEg8bT15xGWf89XMCIUuvjBR6tXU+emak8N66Mvq0a05Wr9aRD963wZkVd/UMWD8TgmUw4seQdbsmJxIRkdjz+vERVI+oiIiUc1Uhii+BBEopLgsesRB9ctZ61u0u4JnrhpPg85Lg8/LM9SO48JEvuPY/X/HWTaNJ9Hn520ffMbJrK8b3axtVCCe0SeYXZ/Xk52f2YOHGfVw6dS7PfrmB35xz+GGxr8zfzM68EiYOas/GPYW8umAzhaXB8v13TjrhUG9o4V7YshDWZTsF6O5vne0tuzq9n8Ouhza9o4pXRESkznn1jKiIiFTmrkI0LpFESsktC9LiMM1y9hXyz09XM75vW7J6tSnf3qFFIv+5bjiX/nsu1/7nKwZmtiC3qIy7zu8T1VDfiowxDOvSign92vLSV5u49YweNIuP/O0OhizPfLmBEV1a8Y/LBgPOMN2c3ftZvzmHtYtmMaFoK7y1EHLmw541zoFeP3QeDUOvhZ5nQ1r3o4pRRESkPpg4Pz5KyVePqIiIhLmqEDX+RBJNKdtKApEbLHgalr1J/vY8nvGUMbikBTxTeb6mvsDstmWs3HYAuwcmt0qg+4zHjjmme0sCLA3u58DjD9AsNSFim9yCUu7Pz6NXcjI8XgxFuXiK9tKpNJ9OwGkAm4FmbSBzOAy60vncYQj4mx1zbCIiIvXC68dHkYbmiohIOXcVor4kAEqKi4CU6g0WPE3p3hz2F2fQqWUi8R4LoWC1Zi3iPfRonciOA8V0aumP2CZaKT5DaoJh5/4C2qbEYajes7ojt4BmPmiV6IX4dpDR13m2M7EVJLZg2cZd9DvrKkjtCEfZMysiIhJrxuvDZwKUBW2sQxERkQbCVYWo1+9MCFRSXBBxv83bzgfBYfwj9Wbev+VUiKt59Zr08Edt2LBkGz958WumjhzKuL6VnzVdtDmXSY98wV3n9WFghFl5AXYXZkOLTrUUjYiISP3yxPnxEaA0cOxv7IqIiLu4ah1Rb7zTI1oWqRANlmEKdrGuJIV7JvbDf5gitLad3TeDDi0SeWr2+mr7npq9npT4OC4Z3rHe4hEREalPJs6v5VtERKQSVxWicX6nEC0tKqy+M38nAM3SMjn5hNrq64xOnNfDtSd3Yd76vSzbsr98+9bcIqYv3calwzuSXMNERiIiIo2diYsP94iqEBUREUdUhagxZrwx5ltjzBpjzJQI+ycaY5YYYxYZYxYYY8bUfqhHFhfvDM0NlEboEc3bDkB8qw71GVK5S0d0pJnfy9MVekWfnbMBay0/OLlLTGISERGpD544Z/mWUj0jKiIiYUcsRI0xXuARYALQB7jcGNOnSrNPgIHW2kHA9cCTtRxnVOISnBlkA8XVe0SL9+UAkBijQrR5go/vD+vIO0u2suNAMQUlAV6at4nx/drSsVVSTGISERGpD8brx2/UIyoiIodE0yM6AlhjrV1nrS0FXgYmVmxgrc231h58m7MZEJO3PP3hQjRYWr0Q3b9zMwAprWP3LOZ1o7sQCFmem7OBN77O4UBxgB/WMEGRiIiIa3j9+AmqEBURkXLRPJjYAWcVy4NygJFVGxljLgTuBdoA59ZKdEfJn+D0LAZLqheiRXu2ELSG1hmx6REF6JzWjLNOzOCFeZtITfQxsGMLhnRqGbN4RERE6oXXT5wJUhrUrLkiIuKIphCNtHBltR5Pa+1bwFvGmFOBe4Azq53ImMnAZICMjAyys7OPKtia5Ofnk52dTWLeekYC23M2Vjt3yuZVJNCCTd8uJW9j7OZoGpocZEZhGbmFZUzIDPL5558f8ZiD+bmZcnQHt+fo9vygaeQoMeB1nhEtC+gZURERcURTiOYAFcezZgJba2psrZ1pjOlujEm31u6usm8qMBVg2LBhNisr6+gjjiA7O5usrCzY0xEWQnrLFKqee+0397HTtmTiuLF4PJFq6/pxmrW8t/UL9uSX8stLsvB5j1wUl+fnYsrRHdyeo9vzg6aRo8SA5+BkRRqaKyIijmgK0flAD2NMV2ALcBlwRcUGxpgTgLXWWmuMGQL4gT21HewR+ZxZcymrPjQ3oXgn231pMS1CAYwxPHnNMEoCoaiKUBERkUbP63cK0TINzRUREccRC1FrbcAYczPwIeAFnrbWLjfG3Bje/zjwPeAaY0wZUARcWmHyovpzsBANFFfblVy6m6LEXvUcUGRtmifEOgQREZH64/UBEAyWxjgQERFpKKLpEcVaOx2YXmXb4xW+/gvwl9oN7RjEHewRLaq8PVBKqt1PsFnb+o9JRESkqfP6AQiVqRAVERGHu8aGxsUTwmAClQvR0v3bAPA0bxeLqERERI6JMWa8MeZbY8waY8yUCPuNMebh8P4l4cdjMMZ0NMZ8ZoxZaYxZboy5tf6jr+BgIRooiWkYIiLScLirEDWGUvx4qtzo9m7fBEBCq/axiEpEROSoGWO8wCPABKAPcLkxpk+VZhOAHuGPycBj4e0B4JfW2hOBUcBPIhxbf8JDc21APaIiIuJwVyEKlHri8QQrPyOau9MpRJu37hjpEBERkYZoBLDGWrvOWlsKvAxMrNJmIvCcdcwFWhhj2llrt1lrvwaw1uYBK3HWBY+NcI+oDZbFLAQREWlYXFeIBkw8cVUK0cI9WwBo1a5zLEISERE5Fh2AzRVe51C9mDxiG2NMF2AwMK/2Q4zSwUJUPaIiIhIW1WRFjUmZJx5vlUI0kLuVgPWQ0TYzRlGJiIgctUjrjVWdkf6wbYwxycAbwM+stQciXsSYyTjDesnIyCA7O/uYgq0qPz+//Fytd66mL1CUf6DWzh9rFfNzK+XoDm7P0e35gXtzdF0hGvAk4C2r/Iyoyd/OXtOCNj7XpSsiIu6VA1R8piQT2BptG2OMD6cIfcFa+2ZNF7HWTgWmAgwbNsxmZWUdd+AA2dnZlJ9rZR6sgAS/h9o6f6xVys+llKM7uD1Ht+cH7s3RdUNzg954/LZyIeov2sn+uPQYRSQiInJM5gM9jDFdjTF+4DJgWpU203DW8TbGmFHAfmvtNmOMAZ4CVlpr/1a/YUdQPjRXz4iKiIjDdV2EQW8CvlBBpW3JpbvJT9KwXBERaTystQFjzM3Ah4AXeNpau9wYc2N4/+M4a3yfA6wBCoHrwoePBq4GlhpjFoW3/Sa8Lnj9C8+aa0J6RlRERByuK0RD3gT8du+h1yFLq9Be9jcbGsOoREREjl64cJxeZdvjFb62wE8iHDebyM+Pxka4R5SgClEREXG4bmiujUsggVLKgiEAduUeoKXJw9O8bYwjExERaaLChagJaWiuiIg4XFuIFpUFAdi5zVlDNL5l7JZPExERadLCQ3M9oTJCoaoT/4qISFPkukIUXxIJppTiUqcQzd3hFKIprTse7igRERGpK+Ee0TiClIZHLImISNPmwkK0co9o4Z4tALRq2zmWUYmIiDRd4ULUT4D9RRqeKyIiLixEjS+RBEopLnPecS3NdZZcS2qlobkiIiIxER6a6yPAym0HYhyMiIg0BK4rRD3+JHwmSFFJMQAmbxsBvJCUFuPIREREmihPuBA1QVZuy4txMCIi0hC4shAFKC101hL1F+1kvzcNPK5LVUREpHEID81tnWjUIyoiIoALC1GvPxGA0pJCrLU0K91NUXzrGEclIiLShIWH5mY296oQFRERwIWFaFy80yMaKC5gf1EZaXYfgWZtYhyViIhIExbuEW2f4mXd7gKKwxMKiohI0xUX6wBq28FCtKykgJx9RXQw+ziQ0i7GUYmIVFZWVkZOTg7FxcWxDqWS1NRUVq5cGeswDishIYHMzEx8Pl+sQ5FohQvRjGZegiHL6h359M9MjXFQIiISS64rRH0J4R7RkiK27cmln8mnpGX7GEclIlJZTk4OKSkpdOnSBWNMrMMpl5eXR0pKSqzDqJG1lj179pCTk0PXrl1jHY5Ey+MFDG2aOb/rK7cdUCEqItLEuW5ori8xGYBgaRH7dmwGIDm9YyxDEhGppri4mLS0tAZVhDYGxhjS0tIaXE+yHIEx4PXTwm9I8ntZoedERUSaPNf1iPrDQ3NDJQUU5OcA0Cxda4iKSMOjIvTY6PvWSHn9mFAZvdumqBAVERH39YjGxTuz5gZLiyjL3QqA0TOiIiKV5Obm8uijjx7Tseeccw65ubm1G5C4n9cHwVJObNecldsOYK2NdUQiIhJDURWixpjxxphvjTFrjDFTIuy/0hizJPzxpTFmYO2HGh3jawaALSuCvO3ORhWiIiKVHK4QDQYPP6Pp9OnTadGiRR1EJa5WoRDNKw6wJbco1hGJiEgMHbEQNcZ4gUeACUAf4HJjTJ8qzdYDp1lrBwD3AFNrO9Co+RKcz6WF+At3EDBxkNQqZuGIiDREU6ZMYe3atQwaNIjbbruN7Oxsxo4dy/XXX0///v0BmDRpEkOHDqVv375MnXrof+tdunRh9+7dbNiwgRNPPJEbbriBvn37Mm7cOIqKqhcX77zzDiNHjmTw4MGceeaZ7NixA4D8/Hyuu+46+vfvz4ABA3jjjTcA+OCDDxgyZAgDBw7kjDPOqIfvhtQLrx+CZZzYrjkAK7flxTggERGJpWieER0BrLHWrgMwxrwMTARWHGxgrf2yQvu5QGZtBnlU4pyhuaUlhaQE9lCYlE5zPU8kIg3YH95ZzoqttfvMXJ/2zfnd+X1r3H/fffexbNkyFi1aBEB2djZfffUVc+fOLS9En376aVq1akVRURHDhw/ne9/7HmlpaZXOs3r1al566SWeeOIJLrnkEt544w2uuuqqSm3GjBnD3LlzMcbw5JNPcv/99/PXv/6Ve+65h9TUVJYuXQrAvn372LVrFzfccAMzZ86ka9eu7N27txa/KxJT4R7R3m1TMMaZOfesPhmxjkpERGIkmkK0A7C5wuscYORh2v8QeP94gjouPqcQzcvLozf7CCTpJiciEo0RI0bQpUuX8tcPP/wwb731FgCbN29m9erV1QrRrl27MmjQIACGDh3Khg0bqp03JyeHSy+9lG3btlFaWlq+7MrHH3/Myy+/XN6uZcuWvPPOO5x66qnlbVq10ogW1/D6IVhKs/g4OrdKYqUmLBIRadKiKUQjdSdGnGHAGDMWpxAdU8P+ycBkgIyMDLKzs6OL8gjy8/MPncsGyQIK8vPI8OwjN9iRJbV0nViplJ9LKUd3cHuOtZlfamoqeXnO0MRfZHWqlXNWdfD8keTn5xMKhcrbFBYWEh8fTzAYJC8vj1mzZvHhhx8yY8YMkpKSOOecc9i7dy95eXlYa8nPzyc/Px+fz1d+jkAgQEFBQbXr3nTTTdx8882cc845zJo1i3vvvZe8vDyCwWC19oWFhQQCgcPGDs7yN27+XXMlrw+CZQDlExaJiEjTFU0hmgNUXIgzE9hatZExZgDwJDDBWrsn0omstVMJPz86bNgwm5WVdbTxRpSdnU3FcwU+j8NPKRlmH96uZ9Otlq4TK1XzcyPl6A5uz7E281u5ciUpKSm1cq5j0a5dOwoKCspjSEpKIi4uDq/XS0pKCmVlZaSnp5ORkcGqVauYP38+SUlJpKSkYIwhOdlZs9nj8ZSfIz4+nrKysmp55efnc8IJJ5CSksJrr71Wfo3x48fzzDPP8NBDDwHO0NzTTz+dX/3qV+zevbt8aG6kXtGEhAQGDx5ch98hqXXhHlFwCtEPlm+noCRAs3jXrSQnIiJRiGbW3PlAD2NMV2OMH7gMmFaxgTGmE/AmcLW19rvaD/PolJh4Uikg1RSS2Kp9rMMREWlw0tLSGD16NP369eO2226rtn/8+PEEAgEGDBjAnXfeyahRo475Wr///e/5/ve/zymnnEJ6enr59t/+9rfs27ePfv36MXDgQD777DNat27N1KlTueiiixg4cCCXXnrpMV9XGpjwZEXgFKLWwqrtmrBIRKSpOuLbkNbagDHmZuBDwAs8ba1dboy5Mbz/ceAuIA14NLzQeMBaO6zuwj68gCeeTsaZldHbXIWoiEgkL774YqXXWVlZ5UNi4+Pjef/9yI/7H3wOND09nWXLlpVv/9WvfhWx/cSJE5k4cWK17cnJyTz77LPVtk+YMIEJEyZElYM0IpWG5jq95iu3HWBo55axjEpERGIkqvEw1trpwPQq2x6v8PWPgB/VbmjHrswTT5dwIUpK29gGIyIiIk6PaGkhAB1aJNI8IU7PiYqINGHRDM1tdAKeBNqb3c6LlHaxDUZERETA4yt/RtQYQ29NWCQi0qS5shANeuPxmvDEvuoRFRERib0KQ3MB+rRrzqrteYRCESfiFxERl3NlIRryJgAQ9PggUc+eiIiIxFyFWXPBeU60sDTIxr2FMQxKRERixZ2FaFwiAGWJGWAiLYMqIiIi9arCrLngzJwLaHiuiEgT5c5CNNwjqmG5IiIiDYTXV6lHtGdGCh6jQlREpKlyZSHaorkzLby/hZZuERGJJDc3l0cfffSYj3/ooYcoLNSQSjkKXj+EDvWIJvi8dGudrEJURKSJcmUh2jI1FQBPc82YKyISiQpRqXdVhuaCMzx35ba8GAUkIiKx5MpCFJ/zjKiG5oqIRDZlyhTWrl3LoEGDuO222wB44IEHOO200xgwYAC/+93vACgoKODcc89l4MCB9OvXj1deeYWHH36YrVu3MnbsWMaOHVvt3HfffTfDhw+nX79+TJ48GWudWVHXrFnDmWeeycCBAxkyZAhr164F4P7776d///4MHDiQKVOm1NN3QOpdlaG54MycuyW3iP2FZTUcJCIibhUX6wDqRNzBZ0TVIyoijcD7U2D70to9Z9v+MOG+Gnffd999LFu2jEWLFgEwY8YMVq9eTXZ2NsnJyVxwwQXMnDmTXbt20b59e9577z0A9u/fT2pqKn/729/47LPPSE9Pr3bum2++mbvuuguAq6++mnfffZfzzz+fK6+8kilTpnDhhRdSXFxMKBTi/fff5+2332bevHkkJSWxd+/e2v0+NHLGmPHAPwAv8KS19r4q+014/zlAIXCttfbraI6td1VmzQVn5lyAldsPMKpbWiyiEhGRGHFpj2iS8zklI7ZxiIg0EjNmzGDGjBmMGTOGIUOGsGrVKlavXk3//v35+OOPuf3225k1axap4UcfDuezzz5j5MiR9O/fn08//ZTly5eTl5fHli1buPDCCwFISEggKSmJjz/+mOuuu46kJOf/261atarTPBsTY4wXeASYAPQBLjfG9KnSbALQI/wxGXjsKI6tX14f2BCEguWb+mjmXBGRJsudPaI+9YiKSCNymJ7L+mKt5Y477uCKK64gJSWl0r6FCxcyffp07rjjDsaNG1fe2xlJcXExN910EwsWLKBjx478/ve/p7i4uHx4bqTrGi2zVZMRwBpr7ToAY8zLwERgRYU2E4HnrPMNnmuMaWGMaQd0ieLY+uX1OZ/fvx08cWAMrTHck7iJpFk+5ixNDC+5Fv4o/xpstd8Rg8GEdxvKvyTC71KlYw99XX5OC7ZKe1P+2VQ9DBt+UbB3L3M2fVLpiocu5TkUW3mIptLxVQ8yEV5Hyjtybqb6pkjty/OquNdEbAZQuGMHX+9ZQJXvUMWrARVzOvK/5QghVz6qxv8f1HzuQ/97qfr/GXP4UwKF27azaP/imhtEHUX1q9d0jIn4c6m5vQ3/x9Z4hfBxJnL/UtHWLSw5cGjUjan2xbExR4jneFX7t1KDkq1bWJpXIb+Dh1UK73hjrfpbX93RXuFo2pds3cKy/MOPnCqPy0b+na94G678/7zI58kYPJ70Dj2OIsqj585CtHkm+JOheYdYRyIi0iClpKSQl3dokpizzz6bO++8kwsuuICUlBS2bNmCz+cjEAjQqlUrrrrqKpKTk3nmmWcqHV91aG5xcTEA6enp5Ofn8/rrr3PxxRfTvHlzMjMzefvtt5k0aRIlJSUEg0HGjRvH3XffzRVXXFE+NFe9ouU6AJsrvM4BRkbRpkOUx9avtv0hsRUseSX8F5HFWMulJkiwKIQpsuESNLwvfNjBP3YPfT7EY+r2D+Ej2h/by9eLXbEOoG4NAtgR4yDq2ACA7bGOou70B9gW6yjqVixyXBSfpkL0mPT7HpxwBiQ0j3UkIiINUlpaGqNHj6Zfv35MmDCBBx54gJUrV3LmmWfi8XhITk7m+eefZ82aNdx22214PB58Ph+PPfYYAJMnT2bChAm0a9eOzz77rPy8LVq04IYbbqB///506dKF4cOHl+/773//y49//GPuuusufD4fr732GuPHj2fRokUMGzYMv9/POeecw5///Od6/340UJHeeI/c5VO9TTTHOicwZjLOsF4yMjLIzs4+ihBrlp+fX+VccTDyP7Vy7kgi9bpX3mYrbT/YY2AqH4Ct0PNkqdyLULEHKD+/gGbNkspPXeHsla5tD22qcHzlNlUjrPQDtJWPqfKp0leVv4z04674PTi0pYYBCxQVFpIYHjYf4RIAmKrxRaHGnploDqhwXPmbFRF6E6seESlHi6WoqIjExMRooogcGtF1LNbYaVtTuyqO1It5uPdkioqKSAjneKTvd+RRKpGzrI0RLUdzjppG1hQVFZOY6IyGjNTi0O/J4XrVa47D2sr/mmwNPY6Hc7zjfoqKikkI53gkNf17hqOLOzmYSm4t3Q9q4s5C1OOBJL2jLiJyOC+++GKl17feeivXX399paG53bt35+yzz6527C233MItt9wS8bx//OMf+eMf/1hte48ePfj000+rbZ8yZYpmy40sB+hY4XUmsDXKNv4ojgXAWjsVmAowbNgwm5WVdVxBH5SdnU1tnashcnt+oBzdwu05uj0/cG+O7pysSEREpPGbD/QwxnQ1xviBy4BpVdpMA64xjlHAfmvttiiPFRERiRl39oiKiIg0ctbagDHmZuBDnCVYnrbWLjfG3Bje/zgwHWfpljU4y7dcd7hjY5CGiIhIRCpERUREGihr7XScYrPitscrfG2Bn0R7rIiISEOhobkiIjFS08QLcnj6vomIiDR+KkRFRGIgISGBPXv2qKg6StZa9uzZQ0JCdLMHioiISMOkobkiIjGQmZlJTk4Ou3Y1rEX6iouLG3yRl5CQQGZmZqzDEBERkeOgQlREJAZ8Ph9du3aNdRjVZGdnM3jw4FiHISIiIi6nobkiIiIiIiJSr1SIioiIiIiISL1SISoiIiIiIiL1ysRqxkZjzC5gYy2dLh3YXUvnaojcnh8oR7dwe45uzw8ad46drbWtYx1EY6Z781Fxe36gHN3C7Tm6PT9o3DnWeG+OWSFam4wxC6y1w2IdR11xe36gHN3C7Tm6PT9oGjlK/XD775Lb8wPl6BZuz9Ht+YF7c9TQXBEREREREalXKkRFRERERESkXrmlEJ0a6wDqmNvzA+XoFm7P0e35QdPIUeqH23+X3J4fKEe3cHuObs8PXJqjK54RFRERERERkcbDLT2iIiIiIiIi0kg06kLUGDPeGPOtMWaNMWZKrOOpDcaYp40xO40xyypsa2WM+cgYszr8uWUsYzxexpiOxpjPjDErjTHLjTG3hre7Ik9jTIIx5itjzOJwfn8Ib3dFfhUZY7zGmG+MMe+GX7sqR2PMBmPMUmPMImPMgvA2t+XYwhjzujFmVfjf5Eluy1Hql+7NjZPuzY07v4p0b3ZFjk3i3txoC1FjjBd4BJgA9AEuN8b0iW1UteIZYHyVbVOAT6y1PYBPwq8bswDwS2vticAo4Cfhn51b8iwBTrfWDgQGAeONMaNwT34V3QqsrPDajTmOtdYOqjBtutty/AfwgbW2NzAQ5+fpthylnuje3Kjp3ty486tI9+bGn2PTuDdbaxvlB3AS8GGF13cAd8Q6rlrKrQuwrMLrb4F24a/bAd/GOsZazvd/wFluzBNIAr4GRrotPyAT53+EpwPvhre5LccNQHqVba7JEWgOrCc8X4Abc9RH/X7o3hz7OGsxX92bG+GH7s2NP8emdG9utD2iQAdgc4XXOeFtbpRhrd0GEP7cJsbx1BpjTBdgMDAPF+UZHhazCNgJfGStdVV+YQ8BvwZCFba5LUcLzDDGLDTGTA5vc1OO3YBdwH/Cw7ieNMY0w105Sv3SvdkFdG9u1B5C9+bGnmOTuTc35kLURNimKYAbEWNMMvAG8DNr7YFYx1ObrLVBa+0gnHcmRxhj+sU4pFpljDkP2GmtXRjrWOrYaGvtEJxhhj8xxpwa64BqWRwwBHjMWjsYKMANQ30klnRvbuR0b268dG92jSZzb27MhWgO0LHC60xga4xiqWs7jDHtAMKfd8Y4nuNmjPHh3OhesNa+Gd7sujyttblANs6zRW7KbzRwgTFmA/AycLox5nnclSPW2q3hzzuBt4ARuCvHHCAn3CsA8DrOzc9NOUr90r25EdO9udHnp3szrsixydybG3MhOh/oYYzpaozxA5cB02IcU12ZBvwg/PUPcJ7baLSMMQZ4Clhprf1bhV2uyNMY09oY0yL8dSJwJrAKl+QHYK29w1qbaa3tgvNv71Nr7VW4KEdjTDNjTMrBr4FxwDJclKO1djuw2RjTK7zpDGAFLspR6p3uzY2U7s1AI84PdG/GJTk2pXuzCT/w2igZY87BGQvvBZ621v4pthEdP2PMS0AWkA7sAH4HvA28CnQCNgHft9bujVGIx80YMwaYBSzl0DMMv8F5FqXR52mMGQA8i/N76QFetdbebYxJwwX5VWWMyQJ+Za09z005GmO64bzTCs4wmRettX9yU44AxphBwJOAH1gHXEf49xaX5Cj1S/fmxkn35sadX1W6NzfeHKHp3JsbdSEqIiIiIiIijU9jHporIiIiIiIijZAKUREREREREalXKkRFRERERESkXqkQFRERERERkXqlQlRERERERETqlQpRERERERERqVcqREVERERERKReqRAVERERERGRevX/AQUTiNG70aH8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, accuracy: 5.4148517e-05, 0.9375 @ batch 652 (41728 samples) complete.                  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ff61b84ca1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miterate_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-b95603c8b01a>\u001b[0m in \u001b[0;36miterate_training\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mb_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
      "\u001b[0;32m<ipython-input-13-1d36f3133d92>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlens_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mout_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlens_batch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    919\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    758\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m                 )\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add cross attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model (checkpoint)\n",
    "pt.cuda.empty_cache()\n",
    "gc.collect()\n",
    "cpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 2k ts' + \"/\" + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 3k ts' + \"/\" + model_name)  # ~3000 training samples observed has current optimum\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 30k ts' + \"/\" + model_name)\n",
    "model.load_state_dict(cpoint['model'])\n",
    "bcewl_loss.load_state_dict(cpoint['bcewl_loss'])\n",
    "optimizer.load_state_dict(cpoint['optimizer'])\n",
    "scheduler.load_state_dict(cpoint['scheduler'])\n",
    "# llayer.load_state_dict(cpoint['llayer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = int(pad_token.detach().cpu().numpy())\n",
    "def append_next_token(sent, top_k=-1, top_p=0.9, temperature=1.0, olen=None):\n",
    "    print(\"k =\", top_k, \", p =\", top_p, \", temp =\", temperature)\n",
    "    global model\n",
    "    if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    ou = tokens.copy()\n",
    "    while len(tokens) < max_len:\n",
    "        tokens += [padder]\n",
    "    x = pt.tensor([tokens], device=d)\n",
    "    logits = inference(x, pt.tensor([len(ou)], device=d))[0]\n",
    "    logits /= temperature\n",
    "    logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "    probs = F.softmax(logits, dim=0)\n",
    "    token = pt.multinomial(probs, 1).detach().cpu().numpy()[0]\n",
    "    ou += [token]\n",
    "    prev_len = len(sent) if olen is None else olen\n",
    "    sent_new = tokenizer.decode(ou)\n",
    "    print(sent[:prev_len] + 'âž¡' + sent_new[prev_len:])\n",
    "    return sent_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "\"reinterpretation, harmony, character progression, reading circle\")\n",
    "# \"monolith, elevator effect, time loop, survival, desert resort, town watchman\")\n",
    "# \"monolith, allegro, soundtrack, chord, classical, opera\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 25 , p = 0.6 , temp = 15.0\n",
      " A list of types of element of drama and writing: attention, surprise, fourth wall, diversion, fate, silence, pace, cliffhanger, character progression, monologuereinterpretation,âž¡, reading circle, cliffhaft-style character progression\n"
     ]
    }
   ],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.6, temperature=15.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "\"watermelon juice, cherry juice, blackcurrant mixture, kava, orangeade, lemon juice, cherryade, cranberry juice\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 , p = 0.8 , temp = 5.0\n",
      "A list of types of element of drama and writing: kava, lemonade, coffee, milkshakewatermelon juice, coke, orangeade, blackcurrant mixture, water, cherry juice, lemon juice, âž¡ black\n"
     ]
    }
   ],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=10, top_p=0.8, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "# \"\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider, yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider\" + \\\n",
    "# \", yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5pm: Using log_period=1 (max_len=96) reliably finds improvement, need more data and larger gpt2 (medium+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" milk, vodka, beer, ice water, soda, lassi, juice, alcohol, whiskey\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" wine, soda, alcohol, beer, liquor, apple cider, whiskey, milk, bourbon, vodka, cider, lemon juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:6])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=3.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" beer, milk, juice, wine, spirits, alcohol, soda, whiskey, brandy, apple juice, liquor, ice tea, watermelon juice, vodka,\" + \\\n",
    "# \" lemon tea, apple cider, ale, lager, fruit tea, lime cider, cocktail, mocha, red wine, apple soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5am: lr=1e-5, max_len=80, log_period_batches=5 increased accuracy by 8%. Need to add a bunch more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 5 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"soda, milk, juice, wine, vodka, gin, lime juice, beer, hot chocolate, cider, whiskey, fruit juice, cocktail, liquor, \" + \\\n",
    "# \"spirits, watermelon juice, martini, rum, chocolate milk, orangeade\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fine tuning (regular GPT-2):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model on 2nd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, juice, fruit juice, soda, wine, beer, hot chocolate, chocolate milk, alcohol, cider, ice tea, liquor, spirit\")\n",
    "# input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89, olen=olen) # k = 25 also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for too long (in this case ~6:30 hours) overfits\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"beer, juice, soda, liquor, wine, tequila, spirits, alcohol, cocktail, martini, whiskey, rum, vodka\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 15/04/2021 11am: Found learning rate 1e-7, max_listlen 15, min_nw 0.7, max_nw 0.9, lidstone_e 0.01 ACTUALLY WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No fine tuning (testing gpt2) (old append function):\n",
    "# input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake\"\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89)\n",
    "# A list of types of drink: juice, tea, cider, lemonade, milk, beer, hot chocolate,âž¡ ice cold milk. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working (reproducible) examples using various non-fine-tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT3 (via AI Dungeon) (Randomness = 2.0, model = Dragon):\n",
    "# sentence = \"A list of ML algorithms: inverse reinforcement learning, ELMo, decision tree, LDA, \"\n",
    "# expected_completion = \"MLP, MLL, MMM. You can't believe you're actually using these things!\"\n",
    "\n",
    "# sentence = \"A list of animals seen in the wild: wolffish, woodlouse, sheep, zebra, yak, \"\n",
    "# expected_completion = \"goat, fox, dog, rat. You're guessing that a lot of other animals have been seen as well; maybe even all the animals on your list except for wolf and rat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 (via Write with Transformer) (Top-p = 0.67, temperature = 1.89, max time = 1.9):\n",
    "# sentence = \"A list of round fruits: peach, apricot, lime, plum, blackberry, cantaloupe, nectarine, pitaya, persimmon, \"\n",
    "# expected_completion = \"mango, papaya and raspberry, as also many\"\n",
    "\n",
    "# sentence = \"A list of chemical elements: hydrogen, carbon, oxygen, nitrogen, gold, \"\n",
    "# expected_completion = \"silver, aluminum, potassium and phosphorus; atomic number.\"\n",
    "\n",
    "# sentence = \"A list of microbes found on earth: bacteria, virus, prokaryote, amoeba, \"\n",
    "# expected_completion = \"archaea, algae, nematode, euk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
