{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned language model for pictionary word list completion (topic/category phrase + example words -> list of 30 examples). For example, one may complete the list\n",
    "\n",
    "\"A list of round fruits: peach, apricot, lime, plum,\"\n",
    "\n",
    "with\n",
    "\n",
    "\"mango, cherry, pineapple, strawberry, pumpkin, watermelon, orange, pomegranate, melon, apple, pear, grapefruit, papaya, lemon, kiwi, passionfruit, blueberry, raspberry, blackberry, cantaloupe, nectarine, pitaya, persimmon, durian, guava, jackfruit, avocado, lychee, soursop, guarana, mangosteen, blackcurrant, cranberry\"\n",
    "\n",
    "using this model. These words should be compatible with pictionary/skribbl.io; i.e., \"sketchable\" within a few minutes, and easily recognisable. Scroll to the end for more examples, or see the file `data/examples.txt`. Sketchability parameter estimation examples can also be found in `data/data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../../openai-api-org.txt', 'r') as f:\n",
    "    openai.organization = f.read()\n",
    "with open('../../openai-api-key.txt', 'r') as f:\n",
    "    openai.api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0915 00:45:18.282470 21332 modeling_bert.py:226] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I0915 00:45:18.294436 21332 modeling_xlnet.py:339] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alfew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import string\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from bayes_opt import BayesianOptimization\n",
    "from IPython.utils import io\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, GPT2LMHeadModel, ReformerModelWithLMHead, \\\n",
    "                         get_linear_schedule_with_warmup\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from transformers import GPT2TokenizerFast\n",
    "from Learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ###   Options   ###\n",
    "\n",
    "model_name = \"ernst_one\"\n",
    "# gpt2_modelkey = \"gpt2\"               # Pretrained model to start from\n",
    "gpt2_modelkey = \"gpt2-xl\"            # Pretrained model to start from\n",
    "test_set_frac = 0.25                 # Fraction of samples to keep as separate test set (word lists)\n",
    "TsN = 200                            # Number of randomly generated prompts for each sample when validating model\n",
    "log_period_batches = 10               # Batches per iteration\n",
    "# learning_rate = 5e-7                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "learning_rate = 7e-5                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "# learning_rate = 4e-6                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "adam_epsilon = 1e-8                  # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                   # Linear scheduler for optimizer number of warmup steps\n",
    "# batch_size = bsz = 8                 # Samples per batch\n",
    "batch_size = bsz = 64                # Samples per batch\n",
    "# batch_size = bsz = 128                # Samples per batch\n",
    "N_train_batches = int(1e7 / bsz)     # Total number of batches to show model\n",
    "max_listlen = 256                    # Maximum number of list phrases for creating a training prompt (at least prior to * max_nw)\n",
    "# max_listlen = 17                   # Maximum number of list phrases for creating a training prompt (at least prior to * max_nw)\n",
    "max_len = 512                        # Max n. tokens applied prior to *max_nw (tokens)\n",
    "# max_len = 16                       # Max n. tokens applied prior to *max_nw (tokens)\n",
    "lidstone_e = 0.01                    # Smoothing for possible words/subwords which are not in the missing list words set\n",
    "lastcomma_repl = ',' # 'EOS', ','    # Token optionally used to replace the final comma that ends the generated phrase\n",
    "use_correct_nouns = True             # Whether to use only correct singular or plural form of category nouns for the given prompt\n",
    "swap_noun = False                    # Whether to swap plural and singular nouns in prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda\" if pt.cuda.is_available() else \"cpu\"  # Setup torch device(s)\n",
    "d = device = pt.device(dev)\n",
    "# world_size = 1\n",
    "# rank = 0\n",
    "# def setup(rank, world_size): \n",
    "#     os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "#     os.environ['MASTER_PORT'] = find_free_port()\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)  # initialize the process group\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "# # mp.spawn(setup, args=(rank, world_size), nprocs=world_size)\n",
    "# setup(rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [273, 6231, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_tokenizer = GPT2TokenizerFast.from_pretrained((\"gpt2-large\"), padding=True)\n",
    "with io.capture_output() as captured:\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(gpt2_modelkey.replace(\"-xl\", \"-large\"), padding=True)\n",
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    tokenizer.encode(\"oranges, pears,\"), \\\n",
    "  gpt3_tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "      gpt3_tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "      gpt3_tokenizer.encode(\"oranges, pears,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[tokenizer.encode(prompt), \"types of\" in prompt] for prompt in lprompts]\n",
    "cats_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e = [[tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "comma_token = pt.tensor(tokenizer.encode(\",\")[0], device=d)\n",
    "lprompts_encoded3 = [[gpt3_tokenizer.encode(prompt), \"types of\" in prompt] for prompt in lprompts]\n",
    "cats_e3 = [[gpt3_tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e3 = [[gpt3_tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e3 = [[gpt3_tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "comma_token3 = pt.tensor(gpt3_tokenizer.encode(\",\")[0], device=d)\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "lprompts_sing_encoded = [(prmpt, typesof) for (prmpt, typesof) in lprompts_encoded if typesof ^ swap_noun]\n",
    "lprompts_sing = [tokenizer.decode(prmpt[0].detach().cpu().numpy()) for prmpt in lprompts_sing_encoded]\n",
    "lprompts_encoded3 = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded3]\n",
    "cats_e3 = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e3]\n",
    "cats_sing_e3 = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e3]\n",
    "phrases_e3 = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e3]\n",
    "lprompts_sing3_encoded = [(prmpt, typesof) for (prmpt, typesof) in lprompts_encoded3 if typesof ^ swap_noun]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "# lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "# cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "# cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "# phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "lidstone_e = pt.tensor(lidstone_e, device=d)\n",
    "lid_val = lidstone_e / N_tokens\n",
    "y_zero = (lid_val).repeat(N_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk, using. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p, rng=[0, max_listlen], mlen=max_len):  # prmt = prompt tokens, p = list word/phrase tokens\n",
    "    tkzs, sent, tkix, wordix = [], [], 0, -1   # rng is the inclusive range of list lengths to generate (number of phrases)\n",
    "    min_nw, max_nw, min_nt, max_nt = rng[0], int(rng[1]), 0, int(mlen) - len(prmt)\n",
    "#     incl_words = pt.randperm(len(p))[:min(max_listlen, len(p))]\n",
    "    incl_words = np.random.choice(len(p), min(len(p), max_nw), replace=False)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc, wordix = p[phz_i], wordix + 1\n",
    "        tkzs.append((tkix, phz_enc))\n",
    "        tkix += len(phz_enc)\n",
    "        sent.append(phz_enc)\n",
    "        if wordix < min_nw: min_nt = tkix\n",
    "        if tkix >= max_nt:\n",
    "            tkix = max_nt\n",
    "            break\n",
    "    sent = pt.hstack(sent)[:max_nt]\n",
    "    missing_w = [p[i] for i in range(len(p)) if i not in incl_words]\n",
    "    trunc_ix = np.random.randint(min_nt, tkix)\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if len(enc) >= trunc_n and all(enc[:trunc_n] == partial_phr)]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_e)\n",
    "    tunit, y_ = pt.tensor(1 / norm, device=d), y_zero.clone()\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return pt.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def gen_samples_uniform(xcp, xcs, xp, n,\n",
    "                        rng=[0, max_listlen], prompt=None, tknzr=tokenizer, verbose=False, inds=False, mlen=1e9):\n",
    "    xs, ys, sqlens, j, prmt = [], [], [], 0, None              # Weight testing samples (word lists) exactly uniformly\n",
    "    if prompt is not None: prmt = pt.tensor(tknzr.encode(prompt), device=d)\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        for m in range(n):\n",
    "#             prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "#             cat_ix = np.random.randint(len(cp))\n",
    "#             x_, y_ = gen_truncated_list(pt.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "            cat_ix = np.random.randint(len(cp_cs))  # First uniformly sample a category title\n",
    "            sing = cat_ix >= len(cp)\n",
    "            if prompt is None:\n",
    "                lprmpts = lprompts_sing_encoded if sing else lprompts_encoded\n",
    "                prmt, _ = lprmpts[np.random.randint(len(lprmpts))]\n",
    "            x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p, rng=rng, mlen=mlen)\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "            sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0:\n",
    "                sys_print(\"\\rDone: \" + str(j))\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        sqlens.append(sqlen)\n",
    "    if inds: xs, ys = sum(xs, []), sum(ys, [])\n",
    "    if verbose: sys_print(\"\\rDone: \" + str(j) + \", finished!\\n\")\n",
    "    return (xs, ys, sqlens, np.arange(len(xcp)).repeat(n)) if inds else (xs, ys, sqlens)\n",
    "def gen_samples(xcp, xcs, xp, n,\n",
    "                rng=[0, max_listlen], prompt=None, tknzr=tokenizer, inds=False, mlen=1e9):\n",
    "    xs, ys, sqlens, j, prmt = [], [], [], 0, None   # Maximise per-batch training diversity by randomly sampling the word lists\n",
    "    if prompt is not None: prmt = pt.tensor(tokenizer.encode(prompt), device=d)\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets, indices = len(xcp), []\n",
    "    for m in range(n):\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        cat_ix = np.random.randint(len(cp_cs))  # First uniformly sample a category title\n",
    "        sing = cat_ix >= len(cp)\n",
    "        if prompt is None:\n",
    "            lprmpts = lprompts_sing_encoded if sing else lprompts_encoded\n",
    "            prmt, _ = lprmpts[np.random.randint(len(lprmpts))]\n",
    "        x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p, rng=rng, mlen=mlen)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "        sqlens.append(len(x_))\n",
    "        indices.append(i)\n",
    "    return (xs, ys, sqlens, np.asarray(indices)) if inds else (xs, ys, sqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "['round fruits', 'wild animals', 'microorganisms', 'outback experiences', 'buildings', 'hats', 'holed pasta', 'rod shaped pasta', 'construction sounds', 'sounds of a building', 'biological examples of math in nature', 'non-biological examples of math in nature', 'timbers', 'woodland ecoregions', 'handcrafts', 'communication media', 'storage media', 'winds', 'scientific principles behind showers', 'scientific principles behind rain showers', 'spacecraft types', 'real spacecrafts', 'interpersonal tokens of trust', 'physical tokens that confer trust', 'digital tokens that confer trust']\n",
      "Test:\n",
      "['chemical elements', 'dramatic and literature elements', 'vehicles referred to as crafts', 'music', 'scientific cycles', 'machine learning algorithms', 'glassware', 'windings']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 1600, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test = int(test_set_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "test_idx = np.random.choice(N_wordlists, N_test, replace=False)\n",
    "# save_ld(test_idx, \"test.data\")\n",
    "test_idx = load_ld(\"test.data\")\n",
    "# test_idx = np.array([0, 2])  # Round fruits and chemical elements\n",
    "train_idx = [i for i in range(N_wordlists) if i not in test_idx]\n",
    "print(\"Train:\")\n",
    "print([cats[i][0] for i in train_idx])\n",
    "print(\"Test:\")\n",
    "print([cats[i][0] for i in test_idx])\n",
    "cats_train, cats_test = [cats[i] for i in train_idx], [cats[i] for i in test_idx]\n",
    "cats_sing_train, cats_sing_test = [cats_sing[i] for i in train_idx], [cats_sing[i] for i in test_idx]\n",
    "phrases_train, phrases_test = [phrases[i] for i in train_idx], [phrases[i] for i in test_idx]\n",
    "cats_e_test, cats_sing_e_test = [cats_e[i] for i in test_idx], [cats_sing_e[i] for i in test_idx]\n",
    "phrases_e_test = [phrases_e[i] for i in test_idx]\n",
    "cats_e_train, cats_sing_e_train = [cats_e[i] for i in train_idx], [cats_sing_e[i] for i in train_idx]\n",
    "phrases_e_train = [phrases_e[i] for i in train_idx]\n",
    "test_cats = [cats[i][0] for i in test_idx]\n",
    "test_xs, test_ys, test_sqlens= gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, TsN, mlen=max_len,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function that takes a prompt, existing list and sampling params and returns gpt3's next token probs\n",
    "default_msp = {\n",
    "  \"best_of\": 1,\n",
    "}\n",
    "default_sp = {\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "#   \"top_k\": -1.0,                 # todo: add code to apply this to gpt3 output (top100), max k ~=90, min = 2?\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "}\n",
    "default_params = {\n",
    "  \"engine\": \"davinci\",\n",
    "  \"max_tokens\": 1,\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "#   \"top_k\": -1.0,\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "  \"n\": 1,\n",
    "  \"stream\": False,\n",
    "  \"logprobs\": 100,\n",
    "#       \"logit_bias\": {\"50256\": -100},\n",
    "  \"stop\": [\",\", \"\\n\"],\n",
    "}\n",
    "stop_tokens_e = tokenizer.encode(''.join(default_params[\"stop\"]))\n",
    "# Define and test the OpenAI API next token probability request (response-token-efficient streaming version)\n",
    "def format_gpt3_probs(choice, tokenize):\n",
    "    res, r = [], sorted([(np.e**v, k) for (k, v) in choice[\"logprobs\"][\"top_logprobs\"][0].items()])[::-1]\n",
    "    for i in range(len(r)):\n",
    "        k = gpt3_tokenizer.encode(r[i][1])\n",
    "        if len(k) == 1: res.append((r[i][0], k if tokenize else r[i][1]))\n",
    "    return res\n",
    "def p_req(s, tokenize=False, **kwargs):\n",
    "    use_stream = \"max_tokens\" in kwargs and kwargs[\"max_tokens\"] != 1\n",
    "    kwargs[\"prompt\"], kwargs[\"stream\"] = s, use_stream\n",
    "    with io.capture_output() as captured:\n",
    "        response, result = openai.Completion.create(**{**default_params, **kwargs}), []\n",
    "    return [(np.e**resp[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0], resp[\"choices\"][0][\"logprobs\"][\"tokens\"][0],\n",
    "             format_gpt3_probs(resp[\"choices\"][0], tokenize)) for resp in (response if use_stream else [response])]\n",
    "# todo: version to handle multiple choices for phrase level evaluation (response-token-expensive)\n",
    "def p_req_m(s, tokenize=False, **kwargs):\n",
    "    if \"max_tokens\" not in kwargs: kwargs[\"max_tokens\"] = 8\n",
    "    if \"n\" not in kwargs: kwargs[\"n\"] = 5\n",
    "    if \"best_of\" in kwargs:\n",
    "        kwargs[\"best_of\"] = int(round(kwargs[\"best_of\"]))\n",
    "        if kwargs[\"n\"] != 1: kwargs[\"best_of\"], kwargs[\"n\"] = kwargs[\"n\"], kwargs[\"best_of\"]\n",
    "    kwargs[\"prompt\"] = s\n",
    "    with io.capture_output() as captured:\n",
    "        response, tokens, probs = openai.Completion.create(**{**default_params, **kwargs}), [], []\n",
    "    for choice in response[\"choices\"]:\n",
    "        tks = [np.e**v for v in choice[\"logprobs\"][\"token_logprobs\"]]\n",
    "        tks = [(choice[\"logprobs\"][\"tokens\"][i], tks[i]) for i in range(len(tks))]\n",
    "        tokens.append(tks)\n",
    "        probs.append(format_gpt3_probs(choice, tokenize))\n",
    "    return tokens, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47171274389095824\n",
      " whirlpool, flutter echoes,, and more.⏎⏎⏎⏎Gravity, supernova explosion, spinning Frisbee, the butterfly effect, solar cell, cosmic, whirlpool, whirlwind, El Niño, orbitation of the planets\n"
     ]
    }
   ],
   "source": [
    "a = p_req(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "b = p_req_m(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "print(sum([a_[0] for a_ in a[0][2]]))\n",
    "print(','.join([''.join([b__[0] for b__ in b_]) for b_ in b[0]] + [''.join([a_[1] for a_ in a])]).replace('\\n', '⏎'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a completion distribution (top 100) and target next token distribution (multinomial) and computes the\n",
    "# probability that the completion produces a desired output token\n",
    "def prob_corr(pred_p, target_p):\n",
    "    r = 0\n",
    "    if isinstance(pred_p, list):\n",
    "        for (p, token) in pred_p:\n",
    "            if target_p[token] > (lid_val + 1e-10): r += p\n",
    "    else:\n",
    "        r = np.sum(target_p[np.nonzero(pred_p > (lid_val + 1e-10))[0]])\n",
    "    return r\n",
    "# directly computes the similarity between target and predicted token distributions\n",
    "def score_corr(pred_p, target_p, distance=\"cross-entropy\", redistribute_mass=False, include_negatives=False):  \n",
    "    r = 0\n",
    "    if isinstance(pred_p, list) and not redistribute_mass:\n",
    "        for (p, token) in pred_p:\n",
    "            targ = target_p[token]\n",
    "            if targ > (lid_val + 1e-10) or include_negatives:\n",
    "                if   distance == \"unnormalized\":  r -= p * targ\n",
    "                elif distance == \"cross-entropy\": r -= p * np.log(targ)\n",
    "                elif distance == \"kl-divergence\": r += p * np.log(p / targ)\n",
    "                elif distance == \"bhattacharyya\": r += np.sqrt(p * targ)\n",
    "        if distance == \"bhattacharyya\": r = -np.log(r)\n",
    "    else:\n",
    "        p = pred_p\n",
    "        if isinstance(pred_p, list):\n",
    "            p_ = np.asarray([p for (p, _) in pred_p])\n",
    "            ts = np.asarray([t for (_, t) in pred_p])\n",
    "            unaccounted_mass = 1.0 - sum(p_)\n",
    "            n_missing_tokens = N_tokens - len(pred_p)\n",
    "            p = np.repeat(unaccounted_mass / n_missing_tokens, N_tokens)\n",
    "            p[ts] = p_\n",
    "        if not include_negatives:\n",
    "            pos = np.nonzero(target_p > (lid_val + 1e-10))[0]\n",
    "            p, target_p = p[pos], target_p[pos]\n",
    "        if   distance == \"unnormalized\":  r = -np.sum(p * targ)\n",
    "        elif distance == \"cross-entropy\": r = -np.sum(p * np.log(target_p))\n",
    "        elif distance == \"kl-divergence\": r =  np.sum(p * np.log(p / target_p))\n",
    "        elif distance == \"bhattacharyya\": r = -np.log(np.sum(np.sqrt(p * target_p)))\n",
    "    return -r\n",
    "# probability that a completion phrase is a desired missing list entry\n",
    "def prob_msp(outs, missing):\n",
    "    correct = 0\n",
    "    missing = set([phrase.lower() for phrase in missing])\n",
    "    for i in range(len(outs)):\n",
    "        out = outs[i].strip().lower()\n",
    "        if out not in missing and (out[:4] == 'the '): out = out[4:]\n",
    "        if out in missing: correct += 1\n",
    "    return correct / len(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   ' Fermi-Pasta-Ulam problem,',\n",
      "        array([  376,  7780,    72,    12, 34533,    64,    12,    52,  2543,\n",
      "        1917,    11], dtype=int64),\n",
      "        11),\n",
      "    (   ' maccheroncini di campofilone,',\n",
      "        array([8352, 2044,  261,   66, 5362, 2566, 1413, 1659,  346,  505,   11],\n",
      "      dtype=int64),\n",
      "        11)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = sum([[len(p) for p in p_ if len(p) < 1000] for p_ in phrases_e], [])  # Print longest list elements in dataset, get max\n",
    "phrs = sum([[p for p in p_ if len(p) < 1000] for p_ in phrases_e], [])\n",
    "m = np.max(lens)\n",
    "inds = [i for i in range(len(phrs)) if lens[i] == m]\n",
    "ree = [(tokenizer.decode(phrs[i].cpu().detach().numpy()), phrs[i].cpu().detach().numpy(), lens[i]) for i in inds]\n",
    "phrl_max = len(ree[0][1]) - 1\n",
    "pr(ree)\n",
    "phrl_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes sampling parameters, then generates n random incomplete list prompts (of length l), obtains completion\n",
    "# distributions (top 100 tokens or full multinomial) and evaluates the average score across the n prompts. n = 20 by default\n",
    "# All samples generated are stored fully for later training of sample-dependent sampling parameter (mixture) distribution\n",
    "sps_ = [\"top_p\", \"temperature\", \"presence_penalty\", \"frequency_penalty\"]  # sampling params                          #top_k\n",
    "msps_= sps_#[\"best_of\"] + sps_                                                 # meta sampling params\n",
    "create_folder(data_dir + learning_data_dir)\n",
    "create_folder(data_dir + learning_data_dir + \"sp_samples\")\n",
    "create_folder(data_dir + learning_data_dir + \"sp_samples_test\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_samples_nb\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_samples_nb_test\")\n",
    "def eval_sp(params, min_l=0, max_l=1e9, n=20, prmt=None, phase=\"train\", uniform=True, mdl='gpt3'):\n",
    "    res, max_l = [], int(max_l)\n",
    "    tknzr = gpt3_tokenizer if mdl == \"gpt3\" else tokenizer\n",
    "    xcp, xcs, xp = \\\n",
    "      ((cats_e3_test,  cats_sing_e3_test,  phrases_e3_test) if phase == \"test\" else \\\n",
    "       (cats_e3_train, cats_sing_e3_train, phrases_e3_train)) if mdl == \"gpt3\" else \\\n",
    "      ((cats_e_test,  cats_sing_e_test,  phrases_e_test) if phase == \"test\" else \\\n",
    "       (cats_e_train, cats_sing_e_train, phrases_e_train))\n",
    "    xs, ys, sqlens, inds = gen_samples_uniform(xcp, xcs, xp, n, prompt=prmt, tknzr=tknzr, inds=True, rng=[min_l, max_l]) \\\n",
    "           if uniform else gen_samples        (xcp, xcs, xp, n, prompt=prmt, tknzr=tknzr, inds=True, rng=[min_l, max_l])\n",
    "    if mdl == 'gpt3': r = [p_req(gpt3_tokenizer.decode(x_.detach().cpu().numpy()), **params) for x_ in xs] \n",
    "    else:             r = mdl.probabilities(xs, ys, sqlens, **params)\n",
    "    for i in np.unique(inds):\n",
    "        create_folder(data_dir + learning_data_dir + \"sp_samples/\" + str(i))\n",
    "        ix, mdl_name = np.nonzero(inds == i)[0], mdl if isinstance(mdl, str) else mdl.name\n",
    "        fn = str(time.time()) + '_' + '_'.join([str(v) for v in [params[k] for k in sps_] + [min_l, max_l]]) + '_' + mdl_name\n",
    "        save_ld((params, xs[ix], ys[ix], sqlens[ix], [r[j] for j in ix], str(mdl)), \"sp_samples/\"+ str(i) +\"/\" + fn, compress=9)\n",
    "    return np.mean([score_corr(r[i], ys[i]) for i in range(len(r))])\n",
    "def eval_sp_conv(params, tol=0.01, **kwargs):\n",
    "    center, samples = np.inf, []\n",
    "    while True:\n",
    "        samples.append(eval_sp(params, n=2, **kwargs))\n",
    "        new_center = np.mean(samples)\n",
    "        if abs(center - new_center) < tol: return new_center, samples\n",
    "        new_center = center\n",
    "# This metric differs depending on tokenisation, so for the testing of models, a full phrase accuracy function is required\n",
    "strip_comma = lambda x: x[:-1] if len(x) > 1 else x\n",
    "def test_sp(params, min_l=0, max_l=1e9, n1=3, n2=10, prmt=None, phase=\"train\", uniform=True, mdl='gpt3', max_tokens=phrl_max):\n",
    "    dfvhjgf, max_l = [], int(max_l)\n",
    "#     cp, cs, p = ((cats_test, cats_sing_test, phrases_test) if phase == \"test\" else (cats_train, cats_sing_train, phrases_train))\n",
    "#     for i in range(len(cp)):\n",
    "#         x, y, sqlen = [], [], []\n",
    "#         cp_, cs_, p_ = cp[i], cs[i], p[i]\n",
    "#         cp_cs = cp_ + cs_\n",
    "#         for m in range(n1):\n",
    "#             cat_ix = np.random.randint(len(cp_cs))  # uniformly sample a category title\n",
    "#             sing = cat_ix >= len(cp_)\n",
    "#             prompt = prmt\n",
    "#             if prompt is None:\n",
    "#                 lprmpts = lprompts_sing if sing else lprompts\n",
    "#                 prompt = lprmpts[np.random.randint(len(lprmpts))]\n",
    "#             phr_ix = np.random.choice(len(p_), np.random.randint(min_l, min(max_l, len(p_) - 1)), replace=False)\n",
    "#             missing_ix = [i for i in range(len(p_)) if i not in phr_ix]\n",
    "#             prompt += ' ' + cp_cs[cat_ix] + ': ' + ''.join([p_[j] + ', ' for j in phr_ix])\n",
    "#             d.append([prompt[:-1], [p_[j] for j in missing_ix]])\n",
    "#     params['n'], params[\"max_tokens\"] = n2, max_tokens\n",
    "#     if mdl == 'gpt3': r = [p_req_m(d_[0], **params)[0] for d_ in d]  # Convert to strings and request predictions from OpenAI\n",
    "#     else:             r = mdl.completions(d, **params)\n",
    "#     for i in range(len(cp)):\n",
    "#         create_folder(data_dir + learning_data_dir + \"msp_samples_nb/\" + str(i))\n",
    "#         ix, mdl_name = range(i * n1, (i + 1) * n1), mdl if isinstance(mdl, str) else mdl.name\n",
    "#         fn = str(time.time()) + '_' + '_'.join([str(v) for v in [params[k] for k in msps_] + [min_l, max_l]]) + '_' + mdl_name\n",
    "#         save_ld((params, [d[j] for j in ix], [r[j] for j in ix], str(mdl)), \"msp_samples_nb/\" + str(i) + \"/\" + fn, compress=9)\n",
    "#     r = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_], []) for r_ in r]\n",
    "#     r = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(','))[:max_l - min_l] for r__ in r_], []) for r_ in r]\n",
    "\n",
    "    # for testing, output the test accuracy\n",
    "    if phase == \"train\":\n",
    "        d_test = []\n",
    "        cp, cs, p = (cats_test, cats_sing_test, phrases_test)\n",
    "        for i in range(len(cp)):\n",
    "            x, y, sqlen = [], [], []\n",
    "            cp_, cs_, p_ = cp[i], cs[i], p[i]\n",
    "            cp_cs = cp_ + cs_\n",
    "            for m in range(n1):\n",
    "                cat_ix = np.random.randint(len(cp_cs))  # uniformly sample a category title\n",
    "                sing = cat_ix >= len(cp_)\n",
    "                prompt = prmt\n",
    "                if prompt is None:\n",
    "                    lprmpts = lprompts_sing if sing else lprompts\n",
    "                    prompt = lprmpts[np.random.randint(len(lprmpts))]\n",
    "                phr_ix = np.random.choice(len(p_), np.random.randint(min_l, min(max_l, len(p_) - 1)), replace=False)\n",
    "                missing_ix = [i for i in range(len(p_)) if i not in phr_ix]\n",
    "                prompt += ' ' + cp_cs[cat_ix] + ': ' + ''.join([p_[j] + ', ' for j in phr_ix])\n",
    "                d_test.append([prompt[:-1], [p_[j] for j in missing_ix]])\n",
    "        r_test = [p_req_m(d_[0], **params)[0] for d_ in d_test]\n",
    "        for i in range(len(cp)):\n",
    "            create_folder(data_dir + learning_data_dir + \"msp_samples_nb_test/\" + str(i))\n",
    "            ix, mdl_name = range(i * n1, (i + 1) * n1), mdl if isinstance(mdl, str) else mdl.name\n",
    "            fn = str(time.time()) + '_' + '_'.join([str(v) for v in [params[k] for k in msps_] + [min_l, max_l]]) + '_' + mdl_name\n",
    "            save_ld((params, [d_test[j] for j in ix], [r_test[j] for j in ix], str(mdl)), \"msp_samples_nb_test/\" + str(i) + \"/\" + fn, compress=9)\n",
    "        r_test = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_], []) for r_ in r_test]\n",
    "#r_test = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(','))[:max_l - min_l] for r__ in r_], []) for r_ in r_test]\n",
    "        return np.mean([prob_msp(r_test[i], d_test[i][1]) for i in range(len(r_test))])\n",
    "#         print(\"Test accuracy:\", np.mean([prob_msp(r_test[i], d_test[i][1]) for i in range(len(r_test))]))      \n",
    "\n",
    "    return np.mean([prob_msp(r[i], d[i][1]) for i in range(len(r))])\n",
    "def test_sp_conv(params, tol=0.01, **kwargs):\n",
    "    center, samples = np.inf, []\n",
    "    while True:\n",
    "        samples.append(test_sp(params, n1=1, **kwargs))\n",
    "        new_center = np.mean(samples)\n",
    "        if abs(center - new_center) < tol: return new_center, samples\n",
    "        center = new_center\n",
    "# eval_sp(default_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"1631684474.311199_0.3927985526497844_0.6421494235732755_1.7265195117562264_1.7813531396798368_5_27_gpt3\"\n",
    "r_ = load_ld(\"msp_samples_nb/\" + str(11) + \"/\" + fn)\n",
    "params, d, r, mdl = r_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frequency_penalty': 1.7813531396798368,\n",
       " 'presence_penalty': 1.7265195117562264,\n",
       " 'top_p': 0.3927985526497844,\n",
       " 'temperature': 0.6421494235732755,\n",
       " 'best_of': 5.0,\n",
       " 'n': 10,\n",
       " 'max_tokens': 8}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d), len(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' double helix',\n",
       " ' logarithmic spiral',\n",
       " ' golden ratio',\n",
       " ' golden ratio',\n",
       " ' golden ratio']"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray([gpt3_tokenizer.encode(r__ + ',') for r__ in r[0]])\n",
    "remaining_phrases = data.tolist()\n",
    "com_token = tokenizer.encode(',')\n",
    "pd_token = gpt3_tokenizer.encode(\"<|endoftext|>\")[0]\n",
    "constrs = []\n",
    "while remaining_phrases != []:\n",
    "    # first add tokens until we hit max_tokens\n",
    "    constr, n_phr = [], 0\n",
    "    while (len(constr) - 0) < 8 and remaining_phrases != []:\n",
    "        n_phr += 1\n",
    "        new_constr = constr + (com_token if constr != [] else []) + remaining_phrases[0]\n",
    "        if (len(new_constr) - 1) <= 8:\n",
    "            constr = new_constr[:-1]\n",
    "            remaining_phrases = remaining_phrases[1:]\n",
    "        else:\n",
    "            constr = constr + ([pd_token] * ((8) - len(constr)))\n",
    "    constrs.append(constr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add example ids to dataset, add subtext 'parent', fix format: just use the fp_tags to create a list of tuples for the fp groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement top k for gpt3... even if it doesnt work i obviously need to to try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either it generates the same thing multiple times before realising it's generated it already or it stores the entire list\n",
    "# in the embedding at each iteration... it might actually be more efficient to do the first thing... after 30 words you have\n",
    "# enough diversity to find new words, and then you can mix them in to find even more. the whole list obviously doesn't need to\n",
    "# go in with it, even if it is technically feasible, exact, and communicates perfectly the problem of searching for the next\n",
    "# least abstract example of the concept, it is a diminishing return that has exhausted itself by the time 30 examples are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the batch size smaller until you are able to fit 30 (or the next round number below the smallest list's length) words in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that uses bayesian optimisation or similar method to quickly find the maxima of the above function (find best params)\n",
    "def evaluate_gpt3_msp_lumped(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "    ps = locals()\n",
    "    ps[\"best_of\"] = 5.0\n",
    "    return test_sp_conv(ps, min_l=3, max_l=30, tol=0.02, phase=\"train\", uniform=True, mdl='gpt3')[0]\n",
    "bounds = {\n",
    "  \"temperature\": [0.05, 1.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.05, 0.9],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.1, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.1, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  best_of  | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------------------\n",
      "|  1        |  0.5403   |  3.504    |  1.335    |  0.505    |  0.6833   |  0.07352  |\n",
      "|  2        |  0.5378   |  2.267    |  1.983    |  0.5014   |  0.5817   |  0.5436   |\n",
      "|  3        |  0.5496   |  3.273    |  0.398    |  0.7146   |  0.204    |  0.5657   |\n",
      "|  4        |  0.5413   |  4.984    |  1.589    |  0.5826   |  0.555    |  0.197    |\n",
      "|  5        |  0.4978   |  2.928    |  0.369    |  0.633    |  1.763    |  0.3513   |\n",
      "|  6        |  0.555    |  1.207    |  1.776    |  0.6096   |  1.502    |  0.2797   |\n",
      "|  7        |  0.4652   |  3.212    |  1.463    |  1.268    |  1.528    |  0.4235   |\n",
      "|  8        |  0.5943   |  5.023    |  1.8      |  1.886    |  0.196    |  0.2943   |\n",
      "|  9        |  0.2692   |  4.806    |  0.87     |  0.4969   |  1.941    |  0.7742   |\n",
      "|  10       |  0.5731   |  5.118    |  1.918    |  0.2899   |  1.787    |  0.1759   |\n",
      "|  11       |  0.55     |  2.366    |  1.913    |  0.8036   |  1.537    |  0.2008   |\n",
      "|  12       |  0.18     |  1.277    |  1.193    |  0.7267   |  1.613    |  0.9577   |\n",
      "|  13       |  0.5084   |  1.737    |  1.369    |  0.487    |  0.6677   |  0.4482   |\n",
      "|  14       |  0.6306   |  4.982    |  1.779    |  1.852    |  0.239    |  0.2627   |\n",
      "|  15       |  0.5507   |  4.889    |  1.699    |  1.548    |  0.3931   |  0.179    |\n",
      "|  16       |  0.5808   |  4.737    |  1.737    |  2.0      |  0.361    |  0.1021   |\n",
      "|  17       |  0.6554   |  5.092    |  1.586    |  1.939    |  0.5428   |  0.2596   |\n",
      "|  18       |  0.6109   |  5.118    |  1.956    |  1.904    |  0.6295   |  0.1545   |\n",
      "|  19       |  0.4837   |  4.876    |  1.75     |  1.91     |  0.6136   |  0.5729   |\n",
      "|  20       |  0.5667   |  5.269    |  1.596    |  1.852    |  0.3651   |  0.05     |\n",
      "|  21       |  0.618    |  5.115    |  1.54     |  2.0      |  0.8681   |  0.05     |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                 \u001b[0mx_probe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Queue is empty, no more objects to retrieve.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-178-6313498f4bbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluate_gpt3_msp_lumped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                 \u001b[0mx_probe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[1;34m(self, utility_function)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0my_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         )\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\util.py\u001b[0m in \u001b[0;36macq_max\u001b[1;34m(ac, gp, y_max, bounds, random_state, n_warmup, n_iter)\u001b[0m\n\u001b[0;32m     56\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                        method=\"L-BFGS-B\")\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# See if success\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 610\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx_try\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_seeds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m# Find the minimum of minus the acquisition function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp, y_max=y_max),\n\u001b[0m\u001b[0;32m     56\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\util.py\u001b[0m in \u001b[0;36mutility\u001b[1;34m(self, x, gp, y_max)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ucb'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ucb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkappa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ei'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ei\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\util.py\u001b[0m in \u001b[0;36m_ucb\u001b[1;34m(x, gp, kappa)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkappa\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Predict based on GP posterior\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mK_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[0my_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha_\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Line 4 (y_mean = f_star)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[1;31m# undo normalisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = BayesianOptimization(f=evaluate_gpt3_msp_lumped, pbounds=bounds, verbose=1000)\n",
    "optimizer.maximize(init_points=10, n_iter=100)\n",
    "ps = optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
    "-------------------------------------------------------------------------\n",
    "|  1        |  0.2752   |  1.659    |  1.462    |  1.207    |  0.5746   |\n",
    "|  2        |  0.1552   |  1.406    |  1.371    |  1.53     |  0.8488   |\n",
    "|  3        |  0.3852   |  1.277    |  1.543    |  0.6489   |  0.1219   |\n",
    "|  4        |  0.3582   |  1.562    |  0.9592   |  0.3661   |  0.9952   |\n",
    "|  5        |  0.2971   |  1.973    |  0.9642   |  0.1205   |  0.3274   |\n",
    "|   iter    |  target   |  best_of  | freque... | presen... | temper... |   top_p   |\n",
    "-------------------------------------------------------------------------------------\n",
    "|  1        |  0.5403   |  3.504    |  1.335    |  0.505    |  0.6833   |  0.07352  |\n",
    "|  2        |  0.5378   |  2.267    |  1.983    |  0.5014   |  0.5817   |  0.5436   |\n",
    "|  3        |  0.5496   |  3.273    |  0.398    |  0.7146   |  0.204    |  0.5657   |\n",
    "|  4        |  0.5413   |  4.984    |  1.589    |  0.5826   |  0.555    |  0.197    |\n",
    "|  5        |  0.4978   |  2.928    |  0.369    |  0.633    |  1.763    |  0.3513   |\n",
    "|  6        |  0.555    |  1.207    |  1.776    |  0.6096   |  1.502    |  0.2797   |\n",
    "|  7        |  0.4652   |  3.212    |  1.463    |  1.268    |  1.528    |  0.4235   |\n",
    "|  8        |  0.5943   |  5.023    |  1.8      |  1.886    |  0.196    |  0.2943   |\n",
    "|  9        |  0.2692   |  4.806    |  0.87     |  0.4969   |  1.941    |  0.7742   |\n",
    "|  10       |  0.5731   |  5.118    |  1.918    |  0.2899   |  1.787    |  0.1759   |\n",
    "|  11       |  0.55     |  2.366    |  1.913    |  0.8036   |  1.537    |  0.2008   |\n",
    "|  12       |  0.18     |  1.277    |  1.193    |  0.7267   |  1.613    |  0.9577   |\n",
    "|  13       |  0.5084   |  1.737    |  1.369    |  0.487    |  0.6677   |  0.4482   |\n",
    "|  14       |  0.6306   |  4.982    |  1.779    |  1.852    |  0.239    |  0.2627   |\n",
    "|  15       |  0.5507   |  4.889    |  1.699    |  1.548    |  0.3931   |  0.179    |\n",
    "|  16       |  0.5808   |  4.737    |  1.737    |  2.0      |  0.361    |  0.1021   |\n",
    "|  17       |  0.6554   |  5.092    |  1.586    |  1.939    |  0.5428   |  0.2596   |\n",
    "|  18       |  0.6109   |  5.118    |  1.956    |  1.904    |  0.6295   |  0.1545   |\n",
    "|  19       |  0.4837   |  4.876    |  1.75     |  1.91     |  0.6136   |  0.5729   |\n",
    "|  20       |  0.5667   |  5.269    |  1.596    |  1.852    |  0.3651   |  0.05     |\n",
    "|  21       |  0.618    |  5.115    |  1.54     |  2.0      |  0.8681   |  0.05     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same above but for the single best_of parameter on phrase completions (secondary phase) once we have the other params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.05244  |  1.67     |  1.61     |  0.8742   |  0.1703   |\n",
      "|  2        |  0.12     |  1.581    |  1.471    |  0.915    |  0.8607   |\n",
      "|  3        |  0.07194  |  1.826    |  1.922    |  0.8147   |  0.3481   |\n",
      "|  4        |  0.06533  |  1.894    |  1.669    |  0.4993   |  0.2044   |\n",
      "|  5        |  0.07474  |  1.682    |  1.74     |  0.9075   |  0.3704   |\n",
      "|  6        |  0.02383  |  1.675    |  1.424    |  0.3665   |  0.8321   |\n",
      "|  7        |  0.07945  |  1.753    |  1.6      |  0.7492   |  0.8382   |\n",
      "|  8        |  0.05533  |  1.761    |  1.536    |  0.363    |  0.1422   |\n",
      "|  9        |  0.07776  |  1.431    |  1.602    |  1.0      |  0.8559   |\n",
      "|  10       |  0.1097   |  1.676    |  1.414    |  0.9789   |  0.8515   |\n",
      "|  11       |  0.05005  |  1.554    |  1.4      |  0.8894   |  0.7108   |\n",
      "|  12       |  0.07069  |  1.644    |  1.504    |  0.9488   |  0.9      |\n",
      "|  13       |  0.09267  |  1.608    |  1.442    |  0.9348   |  0.8509   |\n",
      "|  14       |  0.103    |  1.553    |  1.456    |  0.9071   |  0.872    |\n",
      "|  15       |  0.09919  |  1.572    |  1.495    |  0.8953   |  0.8371   |\n",
      "|  16       |  0.1032   |  1.563    |  1.489    |  0.9465   |  0.8617   |\n",
      "|  17       |  0.0867   |  1.587    |  1.487    |  0.8928   |  0.8935   |\n",
      "|  18       |  0.09887  |  1.562    |  1.459    |  0.9271   |  0.8276   |\n",
      "=========================================================================\n",
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.3763   |  1.724    |  1.781    |  0.6791   |  0.8211   |\n",
      "|  2        |  0.5176   |  1.968    |  1.797    |  0.7303   |  0.4939   |\n",
      "|  3        |  0.4861   |  1.558    |  1.549    |  0.3211   |  0.07074  |\n",
      "|  4        |  0.4857   |  1.711    |  1.559    |  0.2234   |  0.6757   |\n",
      "|  5        |  0.4686   |  1.507    |  1.696    |  0.4465   |  0.3506   |\n",
      "|  6        |  0.5428   |  1.611    |  1.837    |  0.127    |  0.2623   |\n",
      "|  7        |  0.5158   |  1.875    |  1.893    |  0.6705   |  0.06003  |\n",
      "|  8        |  0.5088   |  1.595    |  1.7      |  0.1568   |  0.8465   |\n",
      "|  9        |  0.4925   |  1.469    |  1.704    |  0.3842   |  0.6176   |\n",
      "|  10       |  0.4895   |  1.746    |  1.665    |  0.9932   |  0.3114   |\n",
      "|  11       |  0.4937   |  1.915    |  1.955    |  0.224    |  0.3352   |\n",
      "|  12       |  0.5205   |  1.616    |  1.483    |  0.9745   |  0.2321   |\n",
      "|  13       |  0.503    |  1.516    |  1.895    |  0.446    |  0.3688   |\n",
      "|  14       |  0.4955   |  1.517    |  1.866    |  0.3805   |  0.6377   |\n",
      "|  15       |  0.4838   |  1.474    |  1.511    |  0.4352   |  0.4388   |\n",
      "|  16       |  0.5094   |  1.4      |  1.938    |  0.4652   |  0.4039   |\n",
      "|  17       |  0.5456   |  1.487    |  1.988    |  0.0885   |  0.3297   |\n",
      "|  18       |  0.5139   |  1.535    |  1.995    |  0.05     |  0.07202  |\n",
      "=========================================================================\n",
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.516    |  1.57     |  1.988    |  0.681    |  0.4038   |\n",
      "|  2        |  0.6387   |  1.721    |  1.444    |  0.3722   |  0.113    |\n",
      "|  3        |  0.4309   |  1.616    |  1.717    |  0.331    |  0.8982   |\n",
      "|  4        |  0.4713   |  1.444    |  1.533    |  0.8393   |  0.5813   |\n",
      "|  5        |  0.6455   |  1.747    |  1.93     |  0.4046   |  0.1315   |\n",
      "|  6        |  0.5893   |  1.405    |  1.956    |  0.4923   |  0.2576   |\n",
      "|  7        |  0.4357   |  1.452    |  1.711    |  0.7217   |  0.861    |\n",
      "|  8        |  0.5257   |  1.868    |  1.711    |  0.431    |  0.8367   |\n",
      "|  9        |  0.5367   |  2.0      |  1.714    |  0.05     |  0.05     |\n",
      "|  10       |  0.5806   |  1.718    |  1.933    |  0.407    |  0.1221   |\n",
      "|  11       |  0.6346   |  1.769    |  1.934    |  0.4114   |  0.1628   |\n",
      "|  12       |  0.6403   |  1.8      |  1.917    |  0.3869   |  0.1117   |\n",
      "|  13       |  0.5983   |  1.767    |  1.857    |  0.3976   |  0.1442   |\n",
      "|  14       |  0.5269   |  1.77     |  1.951    |  0.3335   |  0.1446   |\n",
      "|  15       |  0.6015   |  1.787    |  1.923    |  0.4504   |  0.1106   |\n",
      "|  16       |  0.511    |  1.729    |  1.509    |  0.3847   |  0.09703  |\n",
      "|  17       |  0.526    |  1.753    |  1.935    |  0.3904   |  0.1327   |\n",
      "|  18       |  0.6154   |  1.526    |  1.499    |  0.2078   |  0.8141   |\n",
      "=========================================================================\n",
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.5947   |  1.484    |  1.955    |  0.7249   |  0.05145  |\n",
      "|  2        |  0.5916   |  1.568    |  1.583    |  0.2755   |  0.431    |\n",
      "|  3        |  0.4914   |  1.644    |  1.491    |  0.9863   |  0.605    |\n",
      "|  4        |  0.4733   |  1.752    |  1.589    |  0.8368   |  0.3881   |\n",
      "|  5        |  0.5496   |  1.638    |  1.805    |  0.7482   |  0.4766   |\n",
      "|  6        |  0.5266   |  1.625    |  1.907    |  0.7316   |  0.5872   |\n",
      "|  7        |  0.6207   |  1.85     |  1.845    |  0.1905   |  0.2976   |\n",
      "|  8        |  0.5749   |  1.711    |  1.638    |  0.356    |  0.719    |\n",
      "|  9        |  0.5919   |  1.611    |  1.911    |  0.3276   |  0.1758   |\n",
      "|  10       |  0.537    |  1.687    |  1.894    |  0.05     |  0.4889   |\n",
      "|  11       |  0.5364   |  1.832    |  1.668    |  0.2559   |  0.1743   |\n",
      "|  12       |  0.4729   |  1.82     |  1.972    |  0.2712   |  0.2706   |\n",
      "|  13       |  0.5643   |  1.756    |  1.433    |  0.07116  |  0.102    |\n",
      "|  14       |  0.4743   |  1.484    |  1.973    |  0.8096   |  0.586    |\n",
      "|  15       |  0.5352   |  1.862    |  1.543    |  0.08111  |  0.6513   |\n",
      "|  16       |  0.5908   |  1.487    |  1.757    |  0.5733   |  0.5865   |\n",
      "|  17       |  0.5551   |  1.649    |  1.402    |  0.8523   |  0.5089   |\n",
      "|  18       |  0.4867   |  1.659    |  1.431    |  0.902    |  0.6382   |\n",
      "=========================================================================\n",
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.5539   |  1.816    |  1.888    |  0.4689   |  0.2373   |\n",
      "|  2        |  0.4038   |  1.528    |  1.729    |  0.82     |  0.6559   |\n",
      "|  3        |  0.4492   |  1.414    |  1.917    |  0.8685   |  0.6143   |\n",
      "|  4        |  0.674    |  1.487    |  1.937    |  0.8983   |  0.1458   |\n",
      "|  5        |  0.5381   |  1.7      |  1.844    |  0.5491   |  0.3281   |\n",
      "|  6        |  0.6401   |  1.848    |  1.716    |  0.4647   |  0.1431   |\n",
      "|  7        |  0.47     |  1.612    |  1.868    |  0.6607   |  0.6628   |\n",
      "|  8        |  0.512    |  1.506    |  1.67     |  0.4245   |  0.7087   |\n",
      "|  9        |  0.5569   |  1.496    |  1.94     |  0.8974   |  0.1526   |\n",
      "|  10       |  0.5771   |  1.49     |  1.919    |  0.8798   |  0.1395   |\n",
      "|  11       |  0.5115   |  1.486    |  1.933    |  0.8941   |  0.1431   |\n",
      "|  12       |  0.4259   |  1.944    |  1.634    |  0.7019   |  0.8472   |\n",
      "|  13       |  0.498    |  1.727    |  1.963    |  0.6063   |  0.4104   |\n",
      "|  14       |  0.6696   |  1.696    |  1.674    |  0.1788   |  0.1021   |\n",
      "|  15       |  0.6231   |  1.667    |  1.535    |  0.5503   |  0.1171   |\n",
      "|  16       |  0.5837   |  1.501    |  1.948    |  0.1044   |  0.5839   |\n",
      "|  17       |  0.5285   |  1.781    |  1.727    |  0.6421   |  0.3928   |\n",
      "|  18       |  0.5602   |  1.713    |  1.729    |  0.3156   |  0.6786   |\n",
      "=========================================================================\n",
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (1.6181174499024538, 1.5113546974216774, 0.6133867974154082, 0.6043052747059814)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-188-914e449b32be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0moptimizers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-188-914e449b32be>\u001b[0m in \u001b[0;36mfun\u001b[1;34m(temperature, top_p, presence_penalty, frequency_penalty)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"best_of\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0moptimizers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-179-370b925bead5>\u001b[0m in \u001b[0;36mtest_sp_conv\u001b[1;34m(params, tol, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mnew_center\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-179-370b925bead5>\u001b[0m in \u001b[0;36mtest_sp\u001b[1;34m(params, min_l, max_l, n1, n2, prmt, phase, uniform, mdl, max_tokens)\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlprmpts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlprmpts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmax_l\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mphr_ix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mmissing_ix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mphr_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mprompt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcp_cs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat_ix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mphr_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mbounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random.bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "# function that uses the l argument to do the bayesian optimisation once for each \"length group\"\n",
    "lgroups = [[1], [2], [3], [4, 5], [6, 27], [28, 500]] # optimise\n",
    "# lgroups = [[4, 5], [9, 12]] # optimise\n",
    "# lgroups = [[4, 5], [6, 8], [9, 12], [13, 20], [21, 28], [28, 500]] # optimise\n",
    "# lgroups = [[1], [2], [3], [4, 5], [6, 8], [9, 12], [13, 20], [21, 28], [28, 500]] # optimise\n",
    "# lgroups = [[1], [2], [3], [4], [5], [6, 7], [8, 9], [10, 11], [12, 14], [15, 17], [18, 20] [21, 24], [25, 28]]\n",
    "optimizers, results = [], []\n",
    "for lgroup in lgroups:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.02, phase=\"train\", uniform=True, mdl='gpt3')[0]\n",
    "    optimizers.append(BayesianOptimization(f=fun, pbounds=bounds, verbose=1000))\n",
    "    optimizers[-1].maximize(init_points=8, n_iter=10)\n",
    "    results.append(optimizers[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phase in [\"train\", \"test\"]:\n",
    "    n, min_l, max_l, max_train_phrases, prmt, d = 10, 4, 5, 5, None, []\n",
    "    cp, cs, p = ((cats_test, cats_sing_test, phrases_test) if phase == \"test\" else (cats_train, cats_sing_train, phrases_train))\n",
    "    for i in range(len(cp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp_, cs_, p_ = cp[i], cs[i], p[i]\n",
    "        cp_cs = cp_ + cs_\n",
    "        for m in range(n):\n",
    "            cat_ix = np.random.randint(len(cp_cs))  # uniformly sample a category title\n",
    "            sing = cat_ix >= len(cp_)\n",
    "            prompt = prmt\n",
    "            if prompt is None:\n",
    "                lprmpts = lprompts_sing if sing else lprompts\n",
    "                prompt = lprmpts[np.random.randint(len(lprmpts))]\n",
    "            phr_ix = np.random.choice(len(p_), np.random.randint(min_l, min(max_l, len(p_) - 1)), replace=False)\n",
    "            missing_ix = [i for i in range(len(p_)) if i not in phr_ix]\n",
    "            np.random.shuffle(missing_ix)\n",
    "            prompt += ' ' + cp_cs[cat_ix] + ': ' + ''.join([p_[j] + ', ' for j in phr_ix])\n",
    "            d.append((prompt[:-1], ' ' + ''.join([p_[j] + ', ' for j in missing_ix[:max_train_phrases]])[:-2] + '\\n'))\n",
    "    np.random.shuffle(d)\n",
    "    with jsonlines.open(data_dir + learning_data_dir + 'finetuning-buffer-' + phase + '.jsonl', mode='w') as writer:\n",
    "        for (x, y) in d:\n",
    "            writer.write({\"prompt\": x, \"completion\": y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python C:\\Python36\\Scripts\\openai api fine_tunes.create -t data/learning_data/finetuning-buffer-train.jsonl\n",
    "#                                                         -v data/learning_data/finetuning-buffer-test.jsonl -m curie\n",
    "gpt3ft_model = \"curie:ft-user-bshjrj6tekemuk5bv9p3uolr-2021-09-21-06-16-25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.4396   |  0.05784  |  0.5751   |  1.745    |  0.471    |\n",
      "|  2        |  0.4209   |  0.1584   |  1.905    |  1.023    |  0.1991   |\n",
      "|  3        |  0.4124   |  0.7035   |  1.793    |  1.44     |  0.4241   |\n",
      "|  4        |  0.4077   |  0.2573   |  1.528    |  0.5478   |  0.4779   |\n",
      "|  5        |  0.4568   |  0.2063   |  0.2723   |  1.727    |  0.2076   |\n",
      "|  6        |  0.3046   |  1.537    |  1.369    |  1.714    |  0.8905   |\n",
      "|  7        |  0.3934   |  0.8835   |  1.483    |  0.4428   |  0.9264   |\n",
      "|  8        |  0.3673   |  1.05     |  1.543    |  1.624    |  0.5242   |\n",
      "|  9        |  0.3646   |  0.0      |  0.0      |  0.7817   |  0.01     |\n",
      "|  10       |  0.35     |  0.7927   |  0.0      |  2.0      |  0.01     |\n",
      "|  11       |  0.4219   |  0.0      |  0.5277   |  1.964    |  0.01     |\n",
      "|  12       |  0.3585   |  0.0      |  0.0138   |  1.792    |  0.5446   |\n",
      "|  13       |  0.4305   |  0.2369   |  0.539    |  1.608    |  0.1751   |\n",
      "|  14       |  0.3494   |  0.3052   |  0.4556   |  1.935    |  0.316    |\n",
      "|  15       |  0.3546   |  0.2067   |  0.366    |  1.669    |  0.1922   |\n",
      "|  16       |  0.3508   |  1.795    |  0.6647   |  1.358    |  0.08602  |\n",
      "|  17       |  0.457    |  0.1509   |  0.8864   |  1.297    |  0.3689   |\n",
      "|  18       |  0.434    |  1.235    |  1.911    |  0.2685   |  0.6427   |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# measure accuracy of gpt3 openai api fine tuned curie model (default hyperparameters)\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_ft = {\n",
    "  \"temperature\": [0.01, 2.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.01, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_ft, results_ft = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"], ps[\"model\"], ps[\"engine\"] = 5.0, gpt3ft_model, None\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.02, phase=\"train\", uniform=True, mdl='gpt3', max_tokens=8)[0]\n",
    "    optimizers_ft.append(BayesianOptimization(f=fun, pbounds=bounds_ft, verbose=1000))\n",
    "    optimizers_ft[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_ft.append(optimizers_ft[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.0832   |  0.241    |  1.172    |  1.188    |  0.4998   |\n",
      "|  2        |  0.1423   |  1.06     |  1.406    |  1.076    |  0.9812   |\n",
      "|  3        |  0.09635  |  1.57     |  1.713    |  0.121    |  0.2358   |\n",
      "|  4        |  0.05476  |  0.7741   |  1.072    |  1.026    |  0.276    |\n"
     ]
    }
   ],
   "source": [
    "# test the non fine tuned davinci\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_davinci = {\n",
    "  \"temperature\": [0.01, 2.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.01, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_davinci, results_davinci = [], []\n",
    "for lgroup in lgroups:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.02, phase=\"train\", uniform=True, mdl='gpt3')[0]\n",
    "    optimizers_davinci.append(BayesianOptimization(f=fun, pbounds=bounds_davinci, verbose=1000))\n",
    "    optimizers_davinci[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_davinci.append(optimizers_davinci[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.1236   |  0.2921   |  1.882    |  1.445    |  0.5009   |\n",
      "|  2        |  0.02976  |  0.855    |  0.5611   |  1.4      |  0.1178   |\n",
      "|  3        |  0.0      |  1.377    |  1.691    |  0.3455   |  0.08807  |\n",
      "|  4        |  0.04762  |  1.725    |  1.014    |  0.2963   |  0.4642   |\n",
      "|  5        |  0.04573  |  0.8284   |  1.922    |  0.9965   |  0.4441   |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (1.0601197517864018, 0.405159294186769, 1.0976727900115424, 0.41767515734057764)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-414-3de5f65f11bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0moptimizers_curie\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds_curie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0moptimizers_curie\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mresults_curie\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers_curie\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-414-3de5f65f11bc>\u001b[0m in \u001b[0;36mfun\u001b[1;34m(temperature, top_p, presence_penalty, frequency_penalty)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"best_of\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"engine\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"curie\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0moptimizers_curie\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds_curie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0moptimizers_curie\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-412-e9f27886a202>\u001b[0m in \u001b[0;36mtest_sp_conv\u001b[1;34m(params, tol, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mnew_center\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-412-e9f27886a202>\u001b[0m in \u001b[0;36mtest_sp\u001b[1;34m(params, min_l, max_l, n1, n2, prmt, phase, uniform, mdl, max_tokens)\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mprompt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcp_cs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat_ix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mphr_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[0md_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmissing_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mr_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mcreate_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlearning_data_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"msp_samples_nb_test/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-412-e9f27886a202>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mprompt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcp_cs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat_ix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mphr_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[0md_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmissing_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mr_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mcreate_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlearning_data_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"msp_samples_nb_test/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-a86d5fa7f561>\u001b[0m in \u001b[0;36mp_req_m\u001b[1;34m(s, tokenize, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"prompt\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcaptured\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchoice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"choices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mtks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchoice\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"logprobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_logprobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, idempotency_key, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midempotency_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         response, _, api_key = requestor.request(\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         )\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, stream)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         rbody, rcode, rheaders, stream, my_api_key = self.request_raw(\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         )\n\u001b[0;32m    129\u001b[0m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[1;34m(self, method, url, params, supplied_headers, stream)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         rbody, rcode, rheaders, stream = self._client.request_with_retries(\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabs_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         )\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\http_client.py\u001b[0m in \u001b[0;36mrequest_with_retries\u001b[1;34m(self, method, url, headers, post_data, stream)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                 \u001b[0mconnection_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPIConnectionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\http_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, headers, post_data, stream)\u001b[0m\n\u001b[0;32m    219\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m                     \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m                 )\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mcontent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    751\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \"\"\"\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\";\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1007\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1009\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1010\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    869\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test the non fine tuned curie\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_curie = {\n",
    "  \"temperature\": [0.01, 2.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.01, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_curie, results_curie = [], []\n",
    "for lgroup in lgroups:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"], ps[\"engine\"] = 5.0, \"curie\"\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.02, phase=\"train\", uniform=True, mdl='gpt3')[0]\n",
    "    optimizers_curie.append(BayesianOptimization(f=fun, pbounds=bounds_curie, verbose=1000))\n",
    "    optimizers_curie[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_curie.append(optimizers_curie[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective here: use the above for each prompt and figure out the best prompt multinomial (probably still \"A list of\") for all l\n",
    "# then use bayesian optimisation to train a gaussian mixture for each length group (this would be valuable at least for visuals)\n",
    "# can also see if random prompt requires more samples to converge, l dependence, and score vs fixed prompt for each l group.\n",
    "# if it works better, use a random prompt each time; we may benefit if the prompt-dependent vars can be learned.\n",
    "# also, eventually, we can experiment with choosing a prompt for the query, however this is inherently anti-diversity GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 0.5538552188552189,\n",
       "  'params': {'frequency_penalty': 1.8159357141443189,\n",
       "   'presence_penalty': 1.887962354835711,\n",
       "   'temperature': 0.46886191009848616,\n",
       "   'top_p': 0.23733880842395083}},\n",
       " {'target': 0.4037619047619047,\n",
       "  'params': {'frequency_penalty': 1.5280931380664584,\n",
       "   'presence_penalty': 1.7285046103448438,\n",
       "   'temperature': 0.8199913532449122,\n",
       "   'top_p': 0.6558571929857558}},\n",
       " {'target': 0.4492299182299182,\n",
       "  'params': {'frequency_penalty': 1.4137719948002616,\n",
       "   'presence_penalty': 1.9174054523343083,\n",
       "   'temperature': 0.8684616625250122,\n",
       "   'top_p': 0.6142724806352498}},\n",
       " {'target': 0.674,\n",
       "  'params': {'frequency_penalty': 1.4871334419588376,\n",
       "   'presence_penalty': 1.9374914811309927,\n",
       "   'temperature': 0.8983162351239804,\n",
       "   'top_p': 0.14582013833550703}},\n",
       " {'target': 0.5380634920634921,\n",
       "  'params': {'frequency_penalty': 1.7002176679442573,\n",
       "   'presence_penalty': 1.8436907253673605,\n",
       "   'temperature': 0.5490601850577943,\n",
       "   'top_p': 0.3280703543705671}},\n",
       " {'target': 0.6400634920634921,\n",
       "  'params': {'frequency_penalty': 1.8482707527222852,\n",
       "   'presence_penalty': 1.7157089346584788,\n",
       "   'temperature': 0.4647333564122236,\n",
       "   'top_p': 0.14313364108199306}},\n",
       " {'target': 0.47004761904761905,\n",
       "  'params': {'frequency_penalty': 1.6116021201992288,\n",
       "   'presence_penalty': 1.8684459020599973,\n",
       "   'temperature': 0.6606748763758789,\n",
       "   'top_p': 0.6627791165435665}},\n",
       " {'target': 0.5120317460317461,\n",
       "  'params': {'frequency_penalty': 1.5061831789148012,\n",
       "   'presence_penalty': 1.6697426354304072,\n",
       "   'temperature': 0.4244530965162179,\n",
       "   'top_p': 0.708690952045342}},\n",
       " {'target': 0.5568571428571428,\n",
       "  'params': {'frequency_penalty': 1.496097142250671,\n",
       "   'presence_penalty': 1.9403045371546457,\n",
       "   'temperature': 0.8973707585921517,\n",
       "   'top_p': 0.15263476021912795}},\n",
       " {'target': 0.577111111111111,\n",
       "  'params': {'frequency_penalty': 1.490491359521723,\n",
       "   'presence_penalty': 1.919322950630304,\n",
       "   'temperature': 0.8797709796191453,\n",
       "   'top_p': 0.1395479876168354}},\n",
       " {'target': 0.511468253968254,\n",
       "  'params': {'frequency_penalty': 1.4863422748815989,\n",
       "   'presence_penalty': 1.9326953346376443,\n",
       "   'temperature': 0.894095857376612,\n",
       "   'top_p': 0.14313081669049857}},\n",
       " {'target': 0.4259047619047619,\n",
       "  'params': {'frequency_penalty': 1.9436211838453539,\n",
       "   'presence_penalty': 1.6339301690739623,\n",
       "   'temperature': 0.7018658218088311,\n",
       "   'top_p': 0.847218644389218}},\n",
       " {'target': 0.49797619047619046,\n",
       "  'params': {'frequency_penalty': 1.7273647640697347,\n",
       "   'presence_penalty': 1.9627345675233214,\n",
       "   'temperature': 0.6063340645314709,\n",
       "   'top_p': 0.4104487884210244}},\n",
       " {'target': 0.6695661375661376,\n",
       "  'params': {'frequency_penalty': 1.6964594421844428,\n",
       "   'presence_penalty': 1.6743751439968761,\n",
       "   'temperature': 0.17882448322740224,\n",
       "   'top_p': 0.10208032521230702}},\n",
       " {'target': 0.6231111111111111,\n",
       "  'params': {'frequency_penalty': 1.6674421583041157,\n",
       "   'presence_penalty': 1.5347730378003066,\n",
       "   'temperature': 0.5503023756699277,\n",
       "   'top_p': 0.1171094449529564}},\n",
       " {'target': 0.5836825396825397,\n",
       "  'params': {'frequency_penalty': 1.5009927021004852,\n",
       "   'presence_penalty': 1.9475596838760532,\n",
       "   'temperature': 0.10440754505888511,\n",
       "   'top_p': 0.5838950242321175}},\n",
       " {'target': 0.5284761904761904,\n",
       "  'params': {'frequency_penalty': 1.7813531396798368,\n",
       "   'presence_penalty': 1.7265195117562264,\n",
       "   'temperature': 0.6421494235732755,\n",
       "   'top_p': 0.3927985526497844}},\n",
       " {'target': 0.5601798941798941,\n",
       "  'params': {'frequency_penalty': 1.7133245765093355,\n",
       "   'presence_penalty': 1.7285453098323829,\n",
       "   'temperature': 0.31561491810942216,\n",
       "   'top_p': 0.6785659490116206}}]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " optimizers[-2].res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 'global evaluator' function that compares the previous two methods using the same code, next token score (and next word?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a GP/density net/MDN model of length feats (+cond.prob. features) vs sampling params (mt), mu sigma, mixture dist., eps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include gpt2/gpt-neo embeddings (next step gpt3 embeddings (?)) (and see if a mixture distribution is (still) necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if fine-tuning a tertiary post-completion filter phase improves accuracy (aim for as few false negatives as possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with typical one-hot fine-tuning of gpt2, gpt-neo & gpt3 (optimise sampling params & filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with multinomial fine-tuning of gpt2, gpt-neo (next step gpt3 multinomial) (optimise sampling params & filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use an ensemble of the most successful of the above methods to create candidate outputs, then train a\n",
    "# joint filter to distinguish between correct and erroneous list completions (gpt2/gpt-neo/gpt3-prompt) (next step gpt3) 0FNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using the joint filter trained with the ensemble outputs to filter the responses of the best single model from the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "def adapt_form(xs, ys, sqlens, mlen=max_len, repl_finalcomma=True):\n",
    "    xs = pt.vstack([F.pad(x, (0, max(0, mlen - len(x))), mode='constant', value=pad_token)[:mlen] for x in xs])\n",
    "    _ys = pt.vstack(ys) if ys is not None else None\n",
    "    if repl_finalcomma and (lastcomma_repl != ',') and ys is not None:\n",
    "        _ys[:, repl_token] += _ys[:, comma_token] - lid_val\n",
    "        _ys[:, comma_token] = lid_val\n",
    "    return xs, _ys, pt.tensor(sqlens, device=d)\n",
    "def next_batch(sz):\n",
    "    global cats_e_train, cats_sing_e_train, phrases_e_train\n",
    "    return adapt_form(*gen_samples(cats_e_train, cats_sing_e_train, phrases_e_train, sz, mlen=max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "GPT2 device: cuda:0\n",
      "Pretrained parameters loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1271"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "pt.cuda.empty_cache()\n",
    "print(gc.collect())\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2LMHead\")\n",
    "# model_ = GPT2ForSequenceClassification.from_pretrained('gpt2-large',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-xl',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-large',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-medium',\n",
    "model_ = GPT2LMHeadModel.from_pretrained(gpt2_modelkey,\n",
    "    output_hidden_states=False, output_attentions=False, \n",
    "    cache_dir=\"models/pretrained/GPT2LMHead\")\n",
    "if pt.cuda.device_count() > 1:\n",
    "    # model_.parallelize()\n",
    "    device_map = {0: [0, 1, 2],\n",
    "                  1: [3, 4, 5, 6, 7, 8],\n",
    "                  2: [9, 10, 11, 12, 13, 14],\n",
    "                  3: [15, 16, 17, 18, 19, 20],\n",
    "                  4: [21, 22, 23, 24, 25, 26, 27],\n",
    "                  5: [28, 29, 30, 31, 32, 33, 34],\n",
    "                  6: [35, 36, 37, 38, 39, 40, 41],\n",
    "                  7: [42, 43, 44, 45, 46, 47],\n",
    "                 }\n",
    "    # device_map = {0: [0, 1, 2],\n",
    "    #               1: [3, 4, 5, 6, 7, 8],\n",
    "    #               2: [9, 10, 11, 12, 13, 14],\n",
    "    #               3: [15, 16, 17, 18, 19, 20],\n",
    "    #               4: [21, 22, 23, 24, 25, 26, 27],\n",
    "    #               5: [28, 29, 30, 31, 32, 33, 34],\n",
    "    #               6: [35, 36, 37, 38, 39, 40, 41],\n",
    "    #               7: [42, 43, 44, 45, 46, 47],\n",
    "    #              }\n",
    "    model_.parallelize(device_map)\n",
    "else:\n",
    "    model_ = model_.to(d)\n",
    "print(\"GPT2 device:\", model_.device)\n",
    "model_.resize_token_embeddings(N_tokens)\n",
    "pad_token = model_.config.pad_token_id = model_.config.eos_token_id\n",
    "pad_token = pt.tensor(pad_token, device=d)\n",
    "repl_token = pt.tensor(tokenizer.encode(lastcomma_repl)[0], device=d) if lastcomma_repl != 'EOS' else pad_token\n",
    "n_embd = pt.tensor(model_.config.n_embd, device=d)\n",
    "# model = nn.parallel.DistributedDataParallel(model_, device_ids=[d])\n",
    "# model = nn.DataParallel(\n",
    "#     model_, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else model_\n",
    "model = model_\n",
    "mname_fn = gpt2_modelkey\n",
    "print(\"Pretrained parameters loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = None #nn.Linear(n_embd, N_tokens, bias=False).to(d)#.cpu()\n",
    "# nn.init.xavier_uniform_(llayer.weight)\n",
    "# llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else llayer\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()#.to(d)#.cpu()\n",
    "# bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d) if dev != \"cpu\" else bcewl_loss\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1, device=d)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, bsz, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(bsz)\n",
    "\n",
    "#     for x in x_batch.cpu().detach().numpy():\n",
    "#         print(tokenizer.decode(x))\n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)  # Get logits\n",
    "    logits = outputs[0][[pt.arange(x_batch.shape[0]), sqlens - 1]]\n",
    "#     out_idx = pt.unsqueeze(pt.unsqueeze(sqlens_batch - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "#     outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     outs = outputs[0][:, -1]\n",
    "#     logits = llayer(outs)\n",
    "#     logits = outs\n",
    "    \n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lid_val + 1e-10)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "\n",
    "def inference(x, sqlens, past=None, return_states=False, seq_maxlen=max_len):\n",
    "    global model, llayer\n",
    "\n",
    "    multitoken = x.shape[1] > 1\n",
    "    mask = sequence_mask(sqlens, seq_maxlen) if multitoken else None\n",
    "    outputs = model(x.long(), attention_mask=mask, use_cache=None if not return_states else True, past_key_values=past)\n",
    "    logits = outputs[0][[pt.arange(x.shape[0]), sqlens - 1]] if multitoken else outputs[0].squeeze(1)\n",
    "#     out_idx = pt.unsqueeze(pt.unsqueeze(sqlens - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "#     outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     outs = outputs[0][:, -1]\n",
    "#     logits = llayer(outs)\n",
    "#     logits = outs\n",
    "    if return_states:  # Optionally return the last set of past states needed to restore the computation when appending to stream\n",
    "        if not multitoken: return logits, outputs[1]\n",
    "        st, last = outputs[1], []\n",
    "        for i in range(len(st)):\n",
    "            l = []\n",
    "            for j in range(len(st[i])):\n",
    "                l.append(st[i][j][:, :, -1:])\n",
    "            last.append(l)\n",
    "        return logits, last\n",
    "    return logits\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())#.to(d)#.cpu()\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lid_val + 1e-10)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = -1  # Batch 0 is the first iteration, where testing occurs without any training\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "out_str = ''\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, test_loss, test_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, test_loss, test_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        if batch_i > 0:\n",
    "            gc.collect()\n",
    "            if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "            b_loss, b_accuracy = train_step()\n",
    "            mname_fn = model_name\n",
    "            if verbose:\n",
    "                sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                          ' @ batch '+ str(batch_i) + ' (' + str(batch_i * batch_size) + ' samples) complete.                  ')\n",
    "            iter_loss.append(b_loss)\n",
    "            iter_accuracy.append(b_accuracy)\n",
    "\n",
    "        if batch_i % log_period_batches == 0:  # Test on test set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            out_str = '\\n'\n",
    "            for i in range(N_test):\n",
    "                test_X, test_Y, test_Sqlens = adapt_form(test_xs[i], test_ys[i], test_sqlens[i], repl_finalcomma=batch_i > 0)\n",
    "                feed_batches = [range(len(test_X))[i * bsz:(i + 1) * bsz] for i in range((len(test_X) // bsz) + \\\n",
    "                                                                                        (1 if (len(test_X) % bsz) != 0 else 0))]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(test_X[inds], test_Y[inds], test_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls))\n",
    "                accuracy.append(np.mean(cs))\n",
    "                out_str += test_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]) + '\\n'\n",
    "            \n",
    "            test_l, test_a = np.mean(loss), np.mean(accuracy)\n",
    "            test_loss.append(test_l)\n",
    "            test_accuracy.append(test_a)\n",
    "            if batch_i == 0:\n",
    "                iter_loss, iter_accuracy = [test_l], [test_a]\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l)\n",
    "            train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "            \n",
    "            val_a = 0\n",
    "            if test_a > best_acc:      # Save best accuracy model\n",
    "                best_acc = test_a\n",
    "                best_loss = test_l\n",
    "                best_acc_idx = batch_i // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "#                          \"llayer\": llayer.state_dict(),\n",
    "#                          \"softrmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(out_str + \"Batch\", batch_i, ':', train_a, test_a, \"loss:\", train_l, test_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(test_accuracy, label='test acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                g.plot(test_loss, label='test loss')\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, test_accuracy, train_loss, test_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hats: 0.00010320337, 0.671875\n",
      "chemical elements: 8.422259e-05, 0.46875\n",
      "dramatic and literature elements: 0.0001090692, 0.84375\n",
      "Batch 650 : 0.9140625 0.6614583 loss: 5.7221092e-05 9.883172e-05 Best: 0.7135417 9.9054414e-05 idx: 37\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, accuracy: 5.4148517e-05, 0.9375 @ batch 652 (41728 samples) complete.                  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ff61b84ca1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miterate_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-b95603c8b01a>\u001b[0m in \u001b[0;36miterate_training\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mb_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
      "\u001b[0;32m<ipython-input-13-1d36f3133d92>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlens_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mout_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlens_batch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    919\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    758\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m                 )\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add cross attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model (checkpoint)\n",
    "pt.cuda.empty_cache()\n",
    "gc.collect()\n",
    "cpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 2k ts' + \"/\" + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 3k ts' + \"/\" + model_name)  # ~3000 training samples observed has current optimum\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 30k ts' + \"/\" + model_name)\n",
    "model.load_state_dict(cpoint['model'])\n",
    "bcewl_loss.load_state_dict(cpoint['bcewl_loss'])\n",
    "optimizer.load_state_dict(cpoint['optimizer'])\n",
    "scheduler.load_state_dict(cpoint['scheduler'])\n",
    "# llayer.load_state_dict(cpoint['llayer'])\n",
    "mname_fn = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_temperature_filtering(logits, tcounts=None, filter_value=-float('Inf'),\n",
    "                                      top_k=0, top_p=0.0, temperature=1.0, frequency_penalty=0.0, presence_penalty=0.0):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if tcounts is not None: logits -= (tcounts * frequency_penalty) + ((tcounts > 0) * presence_penalty)\n",
    "    logits /= temperature\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = int(pad_token.detach().cpu().numpy())\n",
    "# stop_tokens_e = [tokenizer.encode(t)[0] for t in [\"<|endoftext|>\"]]\n",
    "def gprobs(s, past=None, return_sts=False, tcounts=None, **kwargs):  # Inference and sampling for tokens\n",
    "    global model\n",
    "    xs, mlen = None, None\n",
    "    if isinstance(s, tuple):    # s either list of token tensors or tuple of preformatted 2d tensors\n",
    "        xs, _, sqlen = s\n",
    "        mlen = xs.shape[1]\n",
    "    else:\n",
    "        sqlen = [len(s_) for s_ in s]\n",
    "        mlen = max(sqlen)\n",
    "        xs, _, sqlen = adapt_form(xs, None, sqlen, mlen=mlen)\n",
    "    if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    y_hat = inference(xs, sqlen, seq_maxlen=mlen, past=past, return_states=return_sts)\n",
    "    if return_sts: y_hat, states = y_hat\n",
    "    y_hat = pt.vstack([F.softmax(top_k_top_p_temperature_filtering(y_hat[i], tcounts[i] if tcounts is not None else None,\n",
    "                                                                   **kwargs), dim=0) for i in range(len(s))])\n",
    "    return (y_hat, states) if return_sts else y_hat\n",
    "def append_next_token(sent, olen=None, top_k=-1, top_p=0.9, temperature=1.0):  # Interface for field testing\n",
    "    print(\"k =\", top_k, \", p =\", top_p, \", temp =\", temperature)\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    ou = tokens.copy()\n",
    "    tcounts = pt.zeros(N_tokens, dtype=int)\n",
    "    for token in tokens: tcounts[token] += 1\n",
    "    probs = gprobs([tokens], top_k=top_k, top_p=top_p, temperature=temperature, tcounts=[tcounts])[0]\n",
    "    token = pt.multinomial(probs, 1).detach().cpu().numpy()[0]\n",
    "    ou += [token]\n",
    "    prev_len = len(sent) if olen is None else olen\n",
    "    sent_new = tokenizer.decode(ou)\n",
    "    print(sent[:prev_len] + '➡' + sent_new[prev_len:])\n",
    "    return sent_new\n",
    "def gen_probs(s, **kwargs):  # Adapter for strings\n",
    "    inp = [tokenizer.encode(s_) for s_ in s]\n",
    "    return gprobs(inp, **kwargs)\n",
    "# bszinf = 256\n",
    "bszinf = bsz * 16\n",
    "def gen_completions(s, n=1, max_tokens=8, best_of=1, **kwargs):  # Completion generator equivalent to OpenAI's for GPT3\n",
    "    probs, states, tcounts, n_outer_batches = [], [], [], int(np.ceil(len(s) / (bsz // 2)))\n",
    "    for i in range(n_outer_batches):\n",
    "        s_batch = s[i * (bsz // 2):(i + 1) * (bsz // 2)]\n",
    "        tc_b = []\n",
    "        for s_ in s_batch:\n",
    "            tc = pt.zeros(N_tokens, dtype=int)\n",
    "            for t in s_: tc[t] += 1\n",
    "            tc_b.append(tc)\n",
    "        p, st = gen_probs(s_batch, return_sts=True, t_counts=t_counts, **kwargs)\n",
    "        probs.append(p)\n",
    "        states.append(st)\n",
    "        tcounts.append(tc_b)\n",
    "    probs = pt.vstack(probs)\n",
    "    inner_bsz = int(bszinf / ((bsz // 2) * n))\n",
    "    n_inner_batches = int(np.ceil(n_outer_batches / inner_bsz))\n",
    "    outputs = []\n",
    "    for i in range(n_inner_batches):\n",
    "        p_b, st_b = probs[i * inner_bsz:(i + 1) * inner_bsz], states[i * inner_bsz:(i + 1) * inner_bsz]\n",
    "        tc_b = sum(tcounts[i * inner_bsz:(i + 1) * inner_bsz], [])\n",
    "        p_b, states = pt.vstack(p_b) = []\n",
    "        for st_i in range(len(st_b[0])):\n",
    "            sts = []\n",
    "            for st_j in range(len(st_b[0][0])): sts.append(pt.vstack([st[st_i][st_j] for st in st_b]).repeat_interleave(n, 0))\n",
    "            states.append(tuple(sts))\n",
    "        states = tuple(states)\n",
    "        tokens = pt.multinomial(p_b, n * best_of, replacement=True).reshape(p_b.shape[0], best_of, n)\n",
    "        for j in range(len(tc_b)): tc_b[j][tokens[j]] += 1\n",
    "        outs, avg_logprobs = [], []\n",
    "        for itr in range(best_of):\n",
    "            out, tc_b_ = [], tc_b.copy()\n",
    "            tks, ts, su, ls = tokens[:, itr].reshape(p_b.shape[0] * n), [], pt.zeros(p_b.shape[0]), np.zeros(p_b.shape[0])\n",
    "            p, st = gprobs(tks, past=states, return_sts=True, tcounts=tc_b, **kwargs)\n",
    "            for token_i in range(max_tokens):\n",
    "                t = pt.multinomial(p, 1)\n",
    "                for j in range(len(tc_b_)): tc_b_[j][t[j]] += 1\n",
    "                out.append(t)\n",
    "                cont = t != pad_token\n",
    "                ls += cont.int()\n",
    "                su += cont * pt.log(p[t])\n",
    "                if t == max_tokens - 1: break\n",
    "                p, st = gprobs(t, past=st, return_sts=True, tcounts=tc_b_, **kwargs)\n",
    "            outs.append([o.reshape(p_b.shape[0], n) for o in out])\n",
    "            avg_logprobs.append((su / ls).reshape(p_b.shape[0], n))\n",
    "        if best_of == 1:\n",
    "            outs = outs[0]\n",
    "        else:\n",
    "            outs = pt.stack(outs)\n",
    "            s1, s2 = outs.shape[1], outs.shape[2]\n",
    "            outs = outs[[pt.argmin(outs, 0).view(-1), pt.arange(s1).repeat_interleave(s2), pt.arange(s2).repeat(s1, 1).view(-1)]]\n",
    "        outputs.append(outs)\n",
    "    outputs = [tokenizer.decode(x).split(\"\\n\")[0] for x in pt.vstack(outputs)]\n",
    "    return outputs\n",
    "mdl = {\"completions\": gen_completions, \"probabilities\": gprobs, \"name\": mname_fn + ':' + gpt2_modelkey, \"mstr\": str(model)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "\"reinterpretation, harmony, character progression, reading circle\")\n",
    "# \"monolith, elevator effect, time loop, survival, desert resort, town watchman\")\n",
    "# \"monolith, allegro, soundtrack, chord, classical, opera\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 25 , p = 0.6 , temp = 15.0\n",
      " A list of types of element of drama and writing: attention, surprise, fourth wall, diversion, fate, silence, pace, cliffhanger, character progression, monologuereinterpretation,➡, reading circle, cliffhaft-style character progression\n"
     ]
    }
   ],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.6, temperature=15.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "\"watermelon juice, cherry juice, blackcurrant mixture, kava, orangeade, lemon juice, cherryade, cranberry juice\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 , p = 0.8 , temp = 5.0\n",
      "A list of types of element of drama and writing: kava, lemonade, coffee, milkshakewatermelon juice, coke, orangeade, blackcurrant mixture, water, cherry juice, lemon juice, ➡ black\n"
     ]
    }
   ],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=10, top_p=0.8, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "# \"\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider, yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider\" + \\\n",
    "# \", yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5pm: Using log_period=1 (max_len=96) reliably finds improvement, need more data and larger gpt2 (medium+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" milk, vodka, beer, ice water, soda, lassi, juice, alcohol, whiskey\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" wine, soda, alcohol, beer, liquor, apple cider, whiskey, milk, bourbon, vodka, cider, lemon juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:6])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=3.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" beer, milk, juice, wine, spirits, alcohol, soda, whiskey, brandy, apple juice, liquor, ice tea, watermelon juice, vodka,\" + \\\n",
    "# \" lemon tea, apple cider, ale, lager, fruit tea, lime cider, cocktail, mocha, red wine, apple soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5am: lr=1e-5, max_len=80, log_period_batches=5 increased accuracy by 8%. Need to add a bunch more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 5 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"soda, milk, juice, wine, vodka, gin, lime juice, beer, hot chocolate, cider, whiskey, fruit juice, cocktail, liquor, \" + \\\n",
    "# \"spirits, watermelon juice, martini, rum, chocolate milk, orangeade\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fine tuning (regular GPT-2):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model on 2nd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, juice, fruit juice, soda, wine, beer, hot chocolate, chocolate milk, alcohol, cider, ice tea, liquor, spirit\")\n",
    "# input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89, olen=olen) # k = 25 also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for too long (in this case ~6:30 hours) overfits\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"beer, juice, soda, liquor, wine, tequila, spirits, alcohol, cocktail, martini, whiskey, rum, vodka\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 15/04/2021 11am: Found learning rate 1e-7, max_listlen 15, min_nw 0.7, max_nw 0.9, lidstone_e 0.01 ACTUALLY WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No fine tuning (testing gpt2) (old append function):\n",
    "# input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake\"\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89)\n",
    "# A list of types of drink: juice, tea, cider, lemonade, milk, beer, hot chocolate,➡ ice cold milk. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working (reproducible) examples using various non-fine-tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT3 (via AI Dungeon) (Randomness = 2.0, model = Dragon):\n",
    "# sentence = \"A list of ML algorithms: inverse reinforcement learning, ELMo, decision tree, LDA, \"\n",
    "# expected_completion = \"MLP, MLL, MMM. You can't believe you're actually using these things!\"\n",
    "\n",
    "# sentence = \"A list of animals seen in the wild: wolffish, woodlouse, sheep, zebra, yak, \"\n",
    "# expected_completion = \"goat, fox, dog, rat. You're guessing that a lot of other animals have been seen as well; maybe even all the animals on your list except for wolf and rat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 (via Write with Transformer) (Top-p = 0.67, temperature = 1.89, max time = 1.9):\n",
    "# sentence = \"A list of round fruits: peach, apricot, lime, plum, blackberry, cantaloupe, nectarine, pitaya, persimmon, \"\n",
    "# expected_completion = \"mango, papaya and raspberry, as also many\"\n",
    "\n",
    "# sentence = \"A list of chemical elements: hydrogen, carbon, oxygen, nitrogen, gold, \"\n",
    "# expected_completion = \"silver, aluminum, potassium and phosphorus; atomic number.\"\n",
    "\n",
    "# sentence = \"A list of microbes found on earth: bacteria, virus, prokaryote, amoeba, \"\n",
    "# expected_completion = \"archaea, algae, nematode, euk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4717125622130082\n",
      "0.9274901414219993\n",
      "0.9708372719995181\n",
      "0.9749693956398692\n",
      "0.9634897148058369\n",
      "0.9896781399013229\n",
      "0.49241673846869144\n",
      " laser 0.13 <100| warming 0.00 <100| of 13.07 2| the 66.63 1| earth 11.92 2|, 68.96 1| vortex 0.12 <100\n",
      "0.4717126591849034\n",
      "0.9892794505344922\n",
      "0.7311559539240653\n",
      "0.9564361800508027\n",
      "0.9806930894447073\n",
      "0.9902743788718463\n",
      "0.40462574025242265\n",
      " peaks 0.00 <100| of 46.80 1| power 0.03 <100| distribution 0.86 17| systems 3.02 3|, 81.74 1| thunder 0.31 38\n",
      "0.4717126591849034\n",
      "0.9953395055269428\n",
      "0.9999771481604979\n",
      "0.9590532795958426\n",
      "0.3408734530984889\n",
      "0.8934024084657903\n",
      "0.9621786642515812\n",
      " ping 0.01 <100| p 33.01 2|ong 99.66 1|, 14.11 2| sound 0.25 42| stimuli 0.00 <100| and 4.08 3\n",
      "0.47171274389095824\n",
      "0.9298754919398827\n",
      "0.9241370285266322\n",
      "0.9774319808776988\n",
      "0.969552997269808\n",
      "0.9904618264585953\n",
      "0.9982023300946802\n",
      " bird 0.01 <100| flipping 0.01 <100| its 16.03 2| wing 6.92 3| sixty 0.00 <100| times 69.92 1| a 57.81 1\n",
      "0.4717125622130082\n",
      "0.9986656739204779\n",
      "0.9997999485940596\n",
      "0.8628570462541978\n",
      "0.9867071412680777\n",
      "0.5666820798309762\n",
      "0.8700021823837326\n",
      " seaf 0.01 <100|o 2.18 2|am 98.58 1| piles 0.05 100| of 1.02 7| atmospheric 0.19 83| extinction 0.06 <100\n"
     ]
    }
   ],
   "source": [
    "# This result shows why we need not redistribute the mass when evaluating gpt3 accuracy\n",
    "# response = openai.Completion.create(**{**default_params,\n",
    "#   \"prompt\": \"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\",\n",
    "#   \"temperature\": 1.5,\n",
    "#   \"top_p\": 1.0,\n",
    "#   \"n\": 5,\n",
    "#   \"best_of\": 20,\n",
    "#   \"max_tokens\": 7,\n",
    "#   \"stop\": [\",\", \"\\n\"],\n",
    "# })\n",
    "# for choice in response[\"choices\"]:\n",
    "#     d = {}\n",
    "#     tokens = choice[\"logprobs\"][\"tokens\"]\n",
    "#     t_i = -1\n",
    "#     for t in tokens:\n",
    "#         t_i += 1\n",
    "#         r = [(np.e**v, k) for (k, v) in choice[\"logprobs\"][\"top_logprobs\"][t_i].items()]\n",
    "#         r.sort(reverse=True)\n",
    "#         print(sum([v for (v, k) in r]))\n",
    "#         rd = dict([(k, v) for (v, k) in r])\n",
    "#         r = [k for (v, k) in r]\n",
    "#         d[t] = (rd, r, np.e**choice[\"logprobs\"][\"token_logprobs\"][t_i])\n",
    "#     print('|'.join([' '.join((s.replace(\"\\n\", \"⏎\"),'%.2f' % (d[s][2] * 100),\n",
    "#                               str(d[s][1].index(s) + 1) if s in d[s][1] else \"<100\")) for s in tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]],\n",
      "\n",
      "        [[16, 17, 18, 19],\n",
      "         [20, 21, 22, 23],\n",
      "         [24, 25, 26, 27],\n",
      "         [28, 29, 30, 31]],\n",
      "\n",
      "        [[32, 33, 34, 35],\n",
      "         [36, 37, 38, 39],\n",
      "         [40, 41, 42, 43],\n",
      "         [44, 45, 46, 47]]])\n",
      "tensor([[ 4,  5,  6,  7],\n",
      "        [28, 29, 30, 31],\n",
      "        [40, 41, 42, 43]])\n"
     ]
    }
   ],
   "source": [
    "C, H, W = 3, 4, 4\n",
    "x = pt.arange(C*H*W).view(C, H, W)\n",
    "print(x)\n",
    "idx = pt.tensor([[0, 0],\n",
    "                    [1, 1],\n",
    "                    [2, 2],\n",
    "                    [3, 3]])\n",
    "\n",
    "# print(x[list((pt.arange(x.shape[0]), *idx.chunk(2, 1)))])\n",
    "print(x[[pt.arange(3), [1, 3, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' what is this, he said.'"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        else:            outs = pt.gather(pt.stack(outs), 0, pt.unsqueeze(pt.unsqueeze(\n",
    "                           pt.argmin(pt.stack(avg_logprobs), 0), dim=0), dim=3).repeat_interleave(max_tokens, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pt.tensor(np.array(5)) != pt.tensor(np.array([5, 5, 7]))).int() + (pt.tensor(np.array(5)) != pt.tensor(np.array([5, 5, 7]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9, -9,  0],\n",
       "          [ 8, -8,  0],\n",
       "          [ 7, -7,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]]],\n",
       "\n",
       "\n",
       "        [[[ 1, -1,  0],\n",
       "          [ 9, -9,  0],\n",
       "          [ 9, -9,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.stack([pt.tensor(np.array([[[9,-9,0],[8,-8,0],[7,-7,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]]])), pt.tensor(np.array([[[1,-1,0],[9,-9,0],[9,-9,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]]]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]]]])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.unsqueeze(pt.unsqueeze(pt.argmax(pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]]))]), 0), dim=0),dim=3).repeat_interleave(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]])"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.unsqueeze(pt.unsqueeze(pt.argmax(pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]]))]), 0), dim=0),dim=0).transpose(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_tensor.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]]))]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-494-5882981bfa7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "z[[pt.arange(z.shape[0]).repeat_interleave(18//z.shape[0], 0), pt.arange(z.shape[1]).repeat_interleave(z.shape[1]), ind_tensor.view(-1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, -9,  0],\n",
       "        [ 9, -9,  0],\n",
       "        [ 9, -9,  0],\n",
       "        [ 1, -1,  0],\n",
       "        [ 2, -2,  0],\n",
       "        [ 3, -3,  0],\n",
       "        [ 1, -1,  0],\n",
       "        [ 2, -2,  0],\n",
       "        [ 3, -3,  0],\n",
       "        [10, -7,  0],\n",
       "        [ 6, -7,  0],\n",
       "        [ 6, -6,  0],\n",
       "        [74, -4,  0],\n",
       "        [ 5, -5,  0],\n",
       "        [ 6, -6,  0],\n",
       "        [ 4, -4,  0],\n",
       "        [ 5, -5,  0],\n",
       "        [ 6, -6,  0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[[ind_tensor.view(-1), pt.arange(z.shape[1]).repeat_interleave(z.shape[2]),\n",
    "                        pt.arange(z.shape[2]).repeat(z.shape[1], 1).view(-1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3, 3])"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.arange(z.shape[2]).repeat(18//z.shape[2], 1).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.arange(z.shape[1]).repeat_interleave(18//z.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9, -9,  0],\n",
       "          [ 9, -9,  0],\n",
       "          [ 9, -9,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[10, -7,  0],\n",
       "          [ 6, -7,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[74, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = pt.stack([pt.tensor(np.array([[[9,-9,0],[8,-8,0],[7,-7,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]]])), pt.tensor(np.array([[[1,-1,0],[9,-9,0],[9,-9,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[10,-7,0],[6,-7,0],[6,-6,0]], [[74,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[6,-5,0],[6,-6,0]]]))])\n",
    "ind_tensor = pt.argmax(pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [12,9,6], [80,5,6], [4,5,6]]))]), 0)\n",
    "pt.gather(z, 0, pt.unsqueeze(pt.unsqueeze(ind_tensor, dim=0), dim=3).repeat_interleave(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Size does not match at dimension 2 expected index [3, 1, 6, 1] to be smaller than src [3, 6, 3, 2] apart from dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-469-3c786eac2655>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mind_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Size does not match at dimension 2 expected index [3, 1, 6, 1] to be smaller than src [3, 6, 3, 2] apart from dimension 0"
     ]
    }
   ],
   "source": [
    "z = pt.stack([pt.tensor(np.array([[[9,-9,0],[8,-8,0],[7,-7,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]]])), pt.tensor(np.array([[[1,-1,0],[9,-9,0],[9,-9,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[10,-7,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]]]))])\n",
    "ind_tensor = pt.argmax(pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [10,5,6], [4,5,6], [4,5,6]]))]), 0)\n",
    "pt.gather(z.transpose(0, 3), 0, pt.unsqueeze(pt.unsqueeze(ind_tensor, dim=0), dim=0).transpose(0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9,  1],\n",
       "          [ 8,  9],\n",
       "          [ 7,  9]],\n",
       "\n",
       "         [[ 1,  1],\n",
       "          [ 2,  2],\n",
       "          [ 3,  3]],\n",
       "\n",
       "         [[ 1,  1],\n",
       "          [ 2,  2],\n",
       "          [ 3,  3]],\n",
       "\n",
       "         [[ 4, 10],\n",
       "          [ 5,  5],\n",
       "          [ 6,  6]],\n",
       "\n",
       "         [[ 4,  4],\n",
       "          [ 5,  5],\n",
       "          [ 6,  6]],\n",
       "\n",
       "         [[ 4,  4],\n",
       "          [ 5,  5],\n",
       "          [ 6,  6]]],\n",
       "\n",
       "\n",
       "        [[[-9, -1],\n",
       "          [-8, -9],\n",
       "          [-7, -9]],\n",
       "\n",
       "         [[-1, -1],\n",
       "          [-2, -2],\n",
       "          [-3, -3]],\n",
       "\n",
       "         [[-1, -1],\n",
       "          [-2, -2],\n",
       "          [-3, -3]],\n",
       "\n",
       "         [[-4, -7],\n",
       "          [-5, -5],\n",
       "          [-6, -6]],\n",
       "\n",
       "         [[-4, -4],\n",
       "          [-5, -5],\n",
       "          [-6, -6]],\n",
       "\n",
       "         [[-4, -4],\n",
       "          [-5, -5],\n",
       "          [-6, -6]]],\n",
       "\n",
       "\n",
       "        [[[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.transpose(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.argmax(pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]]))]), 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 4],\n",
       "        [5, 4],\n",
       "        [5, 4],\n",
       "        [5, 4],\n",
       "        [5, 4],\n",
       "        [5, 7],\n",
       "        [5, 7],\n",
       "        [5, 7],\n",
       "        [5, 7],\n",
       "        [5, 7]], dtype=torch.int32)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.tensor(np.array([[5, 4], [5, 7]])).repeat_interleave(5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 2, 1, 2, 0, 1, 0])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pt.multinomial(pt.tensor(np.array([[1.,0,0], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), 3, replacement=True).reshape(3, 2, 3)[:, 0].reshape(9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
