{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned language model for pictionary word list completion (topic/category phrase + example words -> list of 30 examples). For example, one may complete the list\n",
    "\n",
    "\"A list of round fruits: peach, apricot, lime, plum,\"\n",
    "\n",
    "with\n",
    "\n",
    "\"mango, cherry, pineapple, strawberry, pumpkin, watermelon, orange, pomegranate, melon, apple, pear, grapefruit, papaya, lemon, kiwi, passionfruit, blueberry, raspberry, blackberry, cantaloupe, nectarine, pitaya, persimmon, durian, guava, jackfruit, avocado, lychee, soursop, guarana, mangosteen, blackcurrant, cranberry\"\n",
    "\n",
    "using this model. These words should be compatible with pictionary/skribbl.io; i.e., \"sketchable\" within a few minutes, and easily recognisable. Scroll to the end for more examples, or see the file `data/examples.txt`. Sketchability parameter estimation examples can also be found in `data/data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../../openai-api-org.txt', 'r') as f:\n",
    "    openai.organization = f.read()\n",
    "with open('../../openai-api-key.txt', 'r') as f:\n",
    "    openai.api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0922 00:56:19.389209 94548 modeling_bert.py:226] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I0922 00:56:19.400181 94548 modeling_xlnet.py:339] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alfew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import string\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from bayes_opt import BayesianOptimization\n",
    "from IPython.utils import io\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, GPT2LMHeadModel, GPTNeoForCausalLM, ReformerModelWithLMHead, \\\n",
    "                         get_linear_schedule_with_warmup\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from transformers import GPT2TokenizerFast\n",
    "from Learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ###   Options   ###\n",
    "\n",
    "model_name = \"ernst_one\"\n",
    "gpt2_modelkey = \"gpt2\"               # Pretrained model to start from\n",
    "# gpt2_modelkey = \"gpt2-xl\"\n",
    "test_set_frac = 0.25                 # Fraction of samples to keep as separate test set (word lists)\n",
    "TsN = 200                            # Number of randomly generated prompts for each sample when validating model\n",
    "log_period_batches = 10               # Batches per iteration\n",
    "# learning_rate = 5e-7                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "learning_rate = 7e-5\n",
    "# learning_rate = 4e-6\n",
    "adam_epsilon = 1e-8                  # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                   # Linear scheduler for optimizer number of warmup steps\n",
    "# batch_size = bsz = 64                 # Samples per batch\n",
    "# batch_size = bsz = 16\n",
    "batch_size = bsz = 8\n",
    "N_train_batches = int(1e7 / bsz)     # Total number of batches to show model\n",
    "max_listlen = 256                    # Maximum number of list phrases for creating a training prompt (at least prior to * max_nw)\n",
    "# max_len = 512                        # Max n. tokens applied prior to *max_nw (tokens)\n",
    "max_len = 32\n",
    "lidstone_e = 0.01                    # Smoothing for possible words/subwords which are not in the missing list words set\n",
    "lastcomma_repl = ',' # 'EOS', ','    # Token optionally used to replace the final comma that ends the generated phrase\n",
    "use_correct_nouns = True             # Whether to use only correct singular or plural form of category nouns for the given prompt\n",
    "swap_noun = False                    # Whether to swap plural and singular nouns in prompt\n",
    "# rng_train = [0, max_listlen]       # Range of prompt list lengths (number of phrases) to generate for training data\n",
    "rng_train = [3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda\" if pt.cuda.is_available() else \"cpu\"  # Setup torch device(s)\n",
    "d = device = pt.device(dev)\n",
    "# world_size = 1\n",
    "# rank = 0\n",
    "# def setup(rank, world_size): \n",
    "#     os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "#     os.environ['MASTER_PORT'] = find_free_port()\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)  # initialize the process group\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "# # mp.spawn(setup, args=(rank, world_size), nprocs=world_size)\n",
    "# setup(rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [32, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [273, 6231, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_tokenizer = GPT2TokenizerFast.from_pretrained((\"gpt2-large\"), padding=True)\n",
    "with io.capture_output() as captured:\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(gpt2_modelkey.replace(\"-xl\", \"-large\"), padding=True)\n",
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    tokenizer.encode(\"oranges, pears,\"), \\\n",
    "  gpt3_tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "      gpt3_tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "      gpt3_tokenizer.encode(\"oranges, pears,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[tokenizer.encode(prompt), \"types of\" in prompt] for prompt in lprompts]\n",
    "cats_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e = [[tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "comma_token = pt.tensor(tokenizer.encode(\",\")[0], device=d)\n",
    "lprompts_encoded3 = [[gpt3_tokenizer.encode(prompt), \"types of\" in prompt] for prompt in lprompts]\n",
    "cats_e3 = [[gpt3_tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e3 = [[gpt3_tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e3 = [[gpt3_tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "comma_token3 = pt.tensor(gpt3_tokenizer.encode(\",\")[0], device=d)\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "lprompts_sing_encoded = [(prmpt, typesof) for (prmpt, typesof) in lprompts_encoded if typesof ^ swap_noun]\n",
    "lprompts_sing = [tokenizer.decode(prmpt[0].detach().cpu().numpy()) for prmpt in lprompts_sing_encoded]\n",
    "lprompts_encoded3 = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded3]\n",
    "cats_e3 = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e3]\n",
    "cats_sing_e3 = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e3]\n",
    "phrases_e3 = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e3]\n",
    "lprompts_sing3_encoded = [(prmpt, typesof) for (prmpt, typesof) in lprompts_encoded3 if typesof ^ swap_noun]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "# lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "# cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "# cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "# phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "lidstone_e = pt.tensor(lidstone_e, device=d)\n",
    "lid_val = lidstone_e / N_tokens\n",
    "y_zero = (lid_val).repeat(N_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk, using. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p, rng=rng_train, mlen=max_len):  # prmt = prompt tokens, p = list word/phrase tokens\n",
    "    tkzs, sent, tkix, wordix = [], [], 0, -1   # rng is the inclusive range of list lengths to generate (number of phrases)\n",
    "    min_nw, max_nw, min_nt, max_nt = rng[0], int(rng[1]), 0, int(mlen) - len(prmt)\n",
    "#     incl_words = pt.randperm(len(p))[:min(max_listlen, len(p))]\n",
    "    incl_words = np.random.choice(len(p), min(len(p), max_nw), replace=False)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc, wordix = p[phz_i], wordix + 1\n",
    "        tkzs.append((tkix, phz_enc))\n",
    "        tkix += len(phz_enc)\n",
    "        sent.append(phz_enc)\n",
    "        if wordix < min_nw: min_nt = tkix\n",
    "        if tkix >= max_nt:\n",
    "            tkix = max_nt\n",
    "            break\n",
    "    if min_nt - 1 >= tkix:\n",
    "        return gen_truncated_list(prmt, p, rng=rng, mlen=mlen)  # rare when max_len is large enough (0.5x max phrase length)\n",
    "#         print(tkix, min_nt, max_nt, sent)\n",
    "    sent = pt.hstack(sent)[:max_nt]\n",
    "    missing_w = [p[i] for i in range(len(p)) if i not in incl_words]\n",
    "    trunc_ix = np.random.randint(min_nt - 1, tkix)\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if len(enc) >= trunc_n and all(enc[:trunc_n] == partial_phr)]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_e)\n",
    "    tunit, y_ = pt.tensor(1 / norm, device=d), y_zero.clone()\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return pt.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def gen_samples_uniform(xcp, xcs, xp, n,\n",
    "                        rng=rng_train, prompt=None, tknzr=tokenizer, verbose=False, inds=False, mlen=1e9):\n",
    "    xs, ys, sqlens, j, prmt = [], [], [], 0, None              # Weight testing samples (word lists) exactly uniformly\n",
    "    if prompt is not None: prmt = pt.tensor(tknzr.encode(prompt), device=d)\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        for m in range(n):\n",
    "#             prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "#             cat_ix = np.random.randint(len(cp))\n",
    "#             x_, y_ = gen_truncated_list(pt.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "            cat_ix = np.random.randint(len(cp_cs))  # First uniformly sample a category title\n",
    "            sing = cat_ix >= len(cp)\n",
    "            if prompt is None:\n",
    "                lprmpts = lprompts_sing_encoded if sing else lprompts_encoded\n",
    "                prmt, _ = lprmpts[np.random.randint(len(lprmpts))]\n",
    "            x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p, rng=rng, mlen=mlen)\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "            sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0:\n",
    "                sys_print(\"\\rDone: \" + str(j))\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        sqlens.append(sqlen)\n",
    "    if inds: xs, ys = sum(xs, []), sum(ys, [])\n",
    "    if verbose: sys_print(\"\\rDone: \" + str(j) + \", finished!\\n\")\n",
    "    return (xs, ys, sqlens, np.arange(len(xcp)).repeat(n)) if inds else (xs, ys, sqlens)\n",
    "def gen_samples(xcp, xcs, xp, n,\n",
    "                rng=rng_train, prompt=None, tknzr=tokenizer, inds=False, mlen=1e9):\n",
    "    xs, ys, sqlens, j, prmt = [], [], [], 0, None   # Maximise per-batch training diversity by randomly sampling the word lists\n",
    "    if prompt is not None: prmt = pt.tensor(tokenizer.encode(prompt), device=d)\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets, indices = len(xcp), []\n",
    "    for m in range(n):\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        cp_cs = cp + cs\n",
    "        cat_ix = np.random.randint(len(cp_cs))  # First uniformly sample a category title\n",
    "        sing = cat_ix >= len(cp)\n",
    "        if prompt is None:\n",
    "            lprmpts = lprompts_sing_encoded if sing else lprompts_encoded\n",
    "            prmt, _ = lprmpts[np.random.randint(len(lprmpts))]\n",
    "        x_, y_ = gen_truncated_list(pt.hstack([prmt, cp_cs[cat_ix]]), p, rng=rng, mlen=mlen)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "        sqlens.append(len(x_))\n",
    "        indices.append(i)\n",
    "    return (xs, ys, sqlens, np.asarray(indices)) if inds else (xs, ys, sqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "['round fruits', 'wild animals', 'microorganisms', 'outback experiences', 'buildings', 'hats', 'holed pasta', 'rod shaped pasta', 'construction sounds', 'sounds of a building', 'biological examples of math in nature', 'non-biological examples of math in nature', 'timbers', 'woodland ecoregions', 'handcrafts', 'communication media', 'storage media', 'winds', 'scientific principles behind showers', 'scientific principles behind rain showers', 'spacecraft types', 'real spacecrafts', 'interpersonal tokens of trust', 'physical tokens that confer trust', 'digital tokens that confer trust']\n",
      "Test:\n",
      "['chemical elements', 'dramatic and literature elements', 'vehicles referred to as crafts', 'music', 'scientific cycles', 'machine learning algorithms', 'glassware', 'windings']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 1600, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test = int(test_set_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "test_idx = np.random.choice(N_wordlists, N_test, replace=False)\n",
    "# save_ld(test_idx, \"test.data\")\n",
    "test_idx = load_ld(\"test.data\")\n",
    "# test_idx = np.array([0, 2])  # Round fruits and chemical elements\n",
    "train_idx = [i for i in range(N_wordlists) if i not in test_idx]\n",
    "print(\"Train:\")\n",
    "print([cats[i][0] for i in train_idx])\n",
    "print(\"Test:\")\n",
    "print([cats[i][0] for i in test_idx])\n",
    "cats_train, cats_test = [cats[i] for i in train_idx], [cats[i] for i in test_idx]\n",
    "cats_sing_train, cats_sing_test = [cats_sing[i] for i in train_idx], [cats_sing[i] for i in test_idx]\n",
    "phrases_train, phrases_test = [phrases[i] for i in train_idx], [phrases[i] for i in test_idx]\n",
    "cats_e_test, cats_sing_e_test = [cats_e[i] for i in test_idx], [cats_sing_e[i] for i in test_idx]\n",
    "phrases_e_test = [phrases_e[i] for i in test_idx]\n",
    "cats_e_train, cats_sing_e_train = [cats_e[i] for i in train_idx], [cats_sing_e[i] for i in train_idx]\n",
    "phrases_e_train = [phrases_e[i] for i in train_idx]\n",
    "test_cats = [cats[i][0] for i in test_idx]\n",
    "test_xs, test_ys, test_sqlens= gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, TsN, mlen=max_len,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function that takes a prompt, existing list and sampling params and returns gpt3's next token probs\n",
    "default_msp = {\n",
    "  \"best_of\": 1,\n",
    "}\n",
    "default_sp = {\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "#   \"top_k\": -1.0,                 # todo: add code to apply this to gpt3 output (top100), max k ~=90, min = 2?\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "}\n",
    "default_params = {\n",
    "  \"engine\": \"davinci\",\n",
    "  \"model\": None,\n",
    "  \"max_tokens\": 1,\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "#   \"top_k\": -1.0,\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "  \"n\": 1,\n",
    "  \"stream\": False,\n",
    "  \"logprobs\": 100,\n",
    "#       \"logit_bias\": {\"50256\": -100},\n",
    "  \"stop\": [\",\", \"\\n\"],\n",
    "}\n",
    "stop_tokens_e = tokenizer.encode(''.join(default_params[\"stop\"]))\n",
    "# Define and test the OpenAI API next token probability request (response-token-efficient streaming version)\n",
    "def format_gpt3_probs(choice, tokenize):\n",
    "    res, r = [], sorted([(np.e**v, k) for (k, v) in choice[\"logprobs\"][\"top_logprobs\"][0].items()])[::-1]\n",
    "    for i in range(len(r)):\n",
    "        k = gpt3_tokenizer.encode(r[i][1])\n",
    "        if len(k) == 1: res.append((r[i][0], k if tokenize else r[i][1]))\n",
    "    return res\n",
    "def p_req(s, tokenize=False, **kwargs):\n",
    "    use_stream = \"max_tokens\" in kwargs and kwargs[\"max_tokens\"] != 1\n",
    "    kwargs[\"prompt\"], kwargs[\"stream\"] = s, use_stream\n",
    "    with io.capture_output() as captured:\n",
    "        response, result = openai.Completion.create(**{**default_params, **kwargs}), []\n",
    "    return [(np.e**resp[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0], resp[\"choices\"][0][\"logprobs\"][\"tokens\"][0],\n",
    "             format_gpt3_probs(resp[\"choices\"][0], tokenize)) for resp in (response if use_stream else [response])]\n",
    "# todo: version to handle multiple choices for phrase level evaluation (response-token-expensive)\n",
    "def p_req_m(s, tokenize=False, **kwargs):\n",
    "    if \"max_tokens\" not in kwargs: kwargs[\"max_tokens\"] = 8\n",
    "    if \"n\" not in kwargs: kwargs[\"n\"] = 5\n",
    "    if \"best_of\" in kwargs:\n",
    "        kwargs[\"best_of\"] = int(round(kwargs[\"best_of\"]))\n",
    "        if kwargs[\"n\"] != 1: kwargs[\"best_of\"], kwargs[\"n\"] = kwargs[\"n\"], kwargs[\"best_of\"]\n",
    "    kwargs[\"prompt\"] = s\n",
    "    with io.capture_output() as captured:\n",
    "        response, tokens, probs = openai.Completion.create(**{**default_params, **kwargs}), [], []\n",
    "    for choice in response[\"choices\"]:\n",
    "        tks = [np.e**v for v in choice[\"logprobs\"][\"token_logprobs\"]]\n",
    "        tks = [(choice[\"logprobs\"][\"tokens\"][i], tks[i]) for i in range(len(tks))]\n",
    "        tokens.append(tks)\n",
    "        probs.append(format_gpt3_probs(choice, tokenize))\n",
    "    return tokens, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47171274389095824\n",
      " whirlpool, flutter echoes,, and more.⏎⏎⏎⏎Gravity, supernova explosion, spinning Frisbee, the butterfly effect, solar cell, cosmic, whirlpool, whirlwind, El Niño, orbitation of the planets\n"
     ]
    }
   ],
   "source": [
    "a = p_req(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "b = p_req_m(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "print(sum([a_[0] for a_ in a[0][2]]))\n",
    "print(','.join([''.join([b__[0] for b__ in b_]) for b_ in b[0]] + [''.join([a_[1] for a_ in a])]).replace('\\n', '⏎'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47171274389095824\n",
      " self-entourlping cloud,, muscle fatigue, fatigue failure, harmonic oscill, harmonic oscillator, pitch hawthorn, terrorist bombs⏎⏎Many natural objects oscill, Moore's Law? Eclectic set?, water\n"
     ]
    }
   ],
   "source": [
    "a = p_req(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "b = p_req_m(\"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\")\n",
    "print(sum([a_[0] for a_ in a[0][2]]))\n",
    "print(','.join([''.join([b__[0] for b__ in b_]) for b_ in b[0]] + [''.join([a_[1] for a_ in a])]).replace('\\n', '⏎'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a completion distribution (top 100) and target next token distribution (multinomial) and computes the\n",
    "# probability that the completion produces a desired output token\n",
    "def prob_corr(pred_p, target_p):\n",
    "    r = 0\n",
    "    if isinstance(pred_p, list):\n",
    "        for (p, token) in pred_p:\n",
    "            if target_p[token] > (lid_val + 1e-10): r += p\n",
    "    else:\n",
    "        r = np.sum(target_p[np.nonzero(pred_p > (lid_val + 1e-10))[0]])\n",
    "    return r\n",
    "# directly computes the similarity between target and predicted token distributions\n",
    "def score_corr(pred_p, target_p, distance=\"cross-entropy\", redistribute_mass=False, include_negatives=False):  \n",
    "    r = 0\n",
    "    if isinstance(pred_p, list) and not redistribute_mass:\n",
    "        for (p, token) in pred_p:\n",
    "            targ = target_p[token]\n",
    "            if targ > (lid_val + 1e-10) or include_negatives:\n",
    "                if   distance == \"unnormalized\":  r -= p * targ\n",
    "                elif distance == \"cross-entropy\": r -= p * np.log(targ)\n",
    "                elif distance == \"kl-divergence\": r += p * np.log(p / targ)\n",
    "                elif distance == \"bhattacharyya\": r += np.sqrt(p * targ)\n",
    "        if distance == \"bhattacharyya\": r = -np.log(r)\n",
    "    else:\n",
    "        p = pred_p\n",
    "        if isinstance(pred_p, list):\n",
    "            p_ = np.asarray([p for (p, _) in pred_p])\n",
    "            ts = np.asarray([t for (_, t) in pred_p])\n",
    "            unaccounted_mass = 1.0 - sum(p_)\n",
    "            n_missing_tokens = N_tokens - len(pred_p)\n",
    "            p = np.repeat(unaccounted_mass / n_missing_tokens, N_tokens)\n",
    "            p[ts] = p_\n",
    "        if not include_negatives:\n",
    "            pos = np.nonzero(target_p > (lid_val + 1e-10))[0]\n",
    "            p, target_p = p[pos], target_p[pos]\n",
    "        if   distance == \"unnormalized\":  r = -np.sum(p * targ)\n",
    "        elif distance == \"cross-entropy\": r = -np.sum(p * np.log(target_p))\n",
    "        elif distance == \"kl-divergence\": r =  np.sum(p * np.log(p / target_p))\n",
    "        elif distance == \"bhattacharyya\": r = -np.log(np.sum(np.sqrt(p * target_p)))\n",
    "    return -r\n",
    "# probability that a completion phrase is a desired missing list entry\n",
    "def prob_msp(outs, missing):\n",
    "    correct = 0\n",
    "    missing = set([phrase.lower() for phrase in missing])\n",
    "    for i in range(len(outs)):\n",
    "        out = outs[i].strip().lower()\n",
    "        if out not in missing and (out[:4] == 'the '): out = out[4:]\n",
    "        if out in missing: correct += 1\n",
    "    return correct / len(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   ' Fermi-Pasta-Ulam problem,',\n",
      "        array([  376,  7780,    72,    12, 34533,    64,    12,    52,  2543,\n",
      "        1917,    11], dtype=int64),\n",
      "        11),\n",
      "    (   ' maccheroncini di campofilone,',\n",
      "        array([8352, 2044,  261,   66, 5362, 2566, 1413, 1659,  346,  505,   11],\n",
      "      dtype=int64),\n",
      "        11)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = sum([[len(p) for p in p_ if len(p) < 1000] for p_ in phrases_e], [])  # Print longest list elements in dataset, get max\n",
    "phrs = sum([[p for p in p_ if len(p) < 1000] for p_ in phrases_e], [])\n",
    "m = np.max(lens)\n",
    "inds = [i for i in range(len(phrs)) if lens[i] == m]\n",
    "ree = [(tokenizer.decode(phrs[i].cpu().detach().numpy()), phrs[i].cpu().detach().numpy(), lens[i]) for i in inds]\n",
    "phrl_max = len(ree[0][1]) - 1\n",
    "pr(ree)\n",
    "phrl_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes sampling parameters, then generates n random incomplete list prompts (of length l), obtains completion\n",
    "# distributions (top 100 tokens or full multinomial) and evaluates the average score across the n prompts. n = 20 by default\n",
    "# All samples generated are stored fully for later training of sample-dependent sampling parameter (mixture) distribution\n",
    "sps_ = [\"top_p\", \"temperature\", \"presence_penalty\", \"frequency_penalty\"]  # sampling params                          #top_k\n",
    "msps_= sps_#[\"best_of\"] + sps_                                                 # meta sampling params\n",
    "create_folder(data_dir + learning_data_dir)\n",
    "create_folder(data_dir + learning_data_dir + \"sp_samples\")\n",
    "create_folder(data_dir + learning_data_dir + \"sp_samples_test\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_samples_nb\")\n",
    "create_folder(data_dir + learning_data_dir + \"msp_samples_nb_test\")\n",
    "def eval_sp(params, min_l=0, max_l=1e9, n=20, prmt=None, phase=\"train\", uniform=True, mdl='gpt3'):\n",
    "    res, max_l, engine_str = [], int(max_l), ':'.join([str(params[k]) for k in [\"engine\", \"model\"]])\n",
    "    tknzr = gpt3_tokenizer if mdl == \"gpt3\" else tokenizer\n",
    "    xcp, xcs, xp = \\\n",
    "      ((cats_e3_test,  cats_sing_e3_test,  phrases_e3_test) if phase == \"test\" else \\\n",
    "       (cats_e3_train, cats_sing_e3_train, phrases_e3_train)) if mdl == \"gpt3\" else \\\n",
    "      ((cats_e_test,  cats_sing_e_test,  phrases_e_test) if phase == \"test\" else \\\n",
    "       (cats_e_train, cats_sing_e_train, phrases_e_train))\n",
    "    xs, ys, sqlens, inds = gen_samples_uniform(xcp, xcs, xp, n, prompt=prmt, tknzr=tknzr, inds=True, rng=[min_l, max_l]) \\\n",
    "           if uniform else gen_samples        (xcp, xcs, xp, n, prompt=prmt, tknzr=tknzr, inds=True, rng=[min_l, max_l])\n",
    "    if mdl == 'gpt3': r = [p_req(gpt3_tokenizer.decode(x_.detach().cpu().numpy()), **params) for x_ in xs] \n",
    "    else:             r = mdl[\"probabilities\"](xs, ys, sqlens, **params)\n",
    "    for i in np.unique(inds):\n",
    "        create_folder(data_dir + learning_data_dir + \"sp_samples/\" + str(i))\n",
    "        ix, mdl_name = np.nonzero(inds == i)[0], (mdl if isinstance(mdl, str) else mdl[\"name\"]) + ':' + engine_str\n",
    "        fn = str(time.time()) + '_' + '_'.join([str(v) for v in [params[k] for k in sps_] + [min_l, max_l]]) + '_' + mdl_name\n",
    "        save_ld((params, xs[ix], ys[ix], sqlens[ix], [r[j] for j in ix], str(mdl)), \"sp_samples/\"+ str(i) +\"/\" + fn, compress=9)\n",
    "    return np.mean([score_corr(r[i], ys[i]) for i in range(len(r))])\n",
    "def eval_sp_conv(params, tol=0.01, **kwargs):\n",
    "    center, samples = np.inf, []\n",
    "    while True:\n",
    "        samples.append(eval_sp(params, n=2, **kwargs))\n",
    "        new_center = np.mean(samples)\n",
    "        if abs(center - new_center) < tol: return new_center, samples\n",
    "        new_center = center\n",
    "# This metric differs depending on tokenisation, so for the testing of models, a full phrase accuracy function is required\n",
    "strip_comma = lambda x: x[:-1] if len(x) > 1 else x\n",
    "def test_sp(params, min_l=0, max_l=1e9, n1=3, n2=10, prmt=None, phase=\"train\", uniform=True, mdl='gpt3', max_tokens=phrl_max):\n",
    "    d, max_l, engine_str = [], int(max_l), ':'.join([str(params[k]) for k in [\"engine\", \"model\"] if k in params])\n",
    "    cp, cs, p = ((cats_test, cats_sing_test, phrases_test) if phase == \"test\" else (cats_train, cats_sing_train, phrases_train))\n",
    "    for i in range(len(cp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp_, cs_, p_ = cp[i], cs[i], p[i]\n",
    "        cp_cs = cp_ + cs_\n",
    "        for m in range(n1):\n",
    "            cat_ix = np.random.randint(len(cp_cs))  # uniformly sample a category title\n",
    "            sing = cat_ix >= len(cp_)\n",
    "            prompt = prmt\n",
    "            if prompt is None:\n",
    "                lprmpts = lprompts_sing if sing else lprompts\n",
    "                prompt = lprmpts[np.random.randint(len(lprmpts))]\n",
    "            phr_ix = np.random.choice(len(p_), np.random.randint(min_l, min(max_l, len(p_) - 1)), replace=False)\n",
    "            missing_ix = [i for i in range(len(p_)) if i not in phr_ix]\n",
    "            prompt += ' ' + cp_cs[cat_ix] + ': ' + ''.join([p_[j] + ', ' for j in phr_ix])\n",
    "            d.append([prompt[:-1], [p_[j] for j in missing_ix]])\n",
    "    params['n'], params[\"max_tokens\"] = n2, max_tokens\n",
    "    if mdl == 'gpt3': r = [p_req_m(d_[0], **params)[0] for d_ in d]  # Convert to strings and request predictions from OpenAI\n",
    "    else:             r = mdl[\"completions\"]([d_[0] for d_ in d], **params)\n",
    "    for i in range(len(cp)):\n",
    "        create_folder(data_dir + learning_data_dir + \"msp_samples_nb/\" + str(i))\n",
    "        ix, mdl_name = range(i * n1, (i + 1) * n1), mdl if isinstance(mdl, str) else mdl[\"name\"]\n",
    "        fn = str(time.time()) + '_' + '_'.join([str(v) for v in [params[k] for k in msps_] + [min_l, max_l]]) + '_' + mdl_name\n",
    "        save_ld((params, [d[j] for j in ix], [r[j] for j in ix], str(mdl)), \"msp_samples_nb/\" + str(i) + \"/\" + fn, compress=9)\n",
    "    r = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_], []) for r_ in r]\n",
    "#     r = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(','))[:max_l - min_l] for r__ in r_], []) for r_ in r]\n",
    "\n",
    "    # for testing, output the test accuracy\n",
    "    if phase == \"train\":\n",
    "        d_test = []\n",
    "        cp, cs, p = (cats_test, cats_sing_test, phrases_test)\n",
    "        for i in range(len(cp)):\n",
    "            x, y, sqlen = [], [], []\n",
    "            cp_, cs_, p_ = cp[i], cs[i], p[i]\n",
    "            cp_cs = cp_ + cs_\n",
    "            for m in range(n1):\n",
    "                cat_ix = np.random.randint(len(cp_cs))  # uniformly sample a category title\n",
    "                sing = cat_ix >= len(cp_)\n",
    "                prompt = prmt\n",
    "                if prompt is None:\n",
    "                    lprmpts = lprompts_sing if sing else lprompts\n",
    "                    prompt = lprmpts[np.random.randint(len(lprmpts))]\n",
    "                phr_ix = np.random.choice(len(p_), np.random.randint(min_l, min(max_l, len(p_) - 1)), replace=False)\n",
    "                missing_ix = [i for i in range(len(p_)) if i not in phr_ix]\n",
    "                prompt += ' ' + cp_cs[cat_ix] + ': ' + ''.join([p_[j] + ', ' for j in phr_ix])\n",
    "                d_test.append([prompt[:-1], [p_[j] for j in missing_ix]])\n",
    "        if mdl == 'gpt3': r_test = [p_req_m(d_[0], **params)[0] for d_ in d_test]\n",
    "        else:             r_test = mdl[\"completions\"]([d_[0] for d_ in d_test], **params)\n",
    "        for i in range(len(cp)):\n",
    "            create_folder(data_dir + learning_data_dir + \"msp_samples_nb_test/\" + str(i))\n",
    "            ix, mdl_name = range(i * n1, (i + 1) * n1), (mdl if isinstance(mdl, str) else mdl[\"name\"]) + ':' + engine_str\n",
    "            fn = str(time.time()) + '_' + '_'.join([str(v) for v in [params[k] for k in msps_] + [min_l, max_l]]) + \\\n",
    "                '_' + mdl_name\n",
    "            save_ld((params, [d_test[j] for j in ix], [r_test[j] for j in ix], str(mdl)),\n",
    "                    \"msp_samples_nb_test/\" + str(i) + \"/\" + fn, compress=9)\n",
    "        r_test = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(',')) for r__ in r_], []) for r_ in r_test]\n",
    "#r_test = [sum([strip_comma(''.join([r___[0] for r___ in r__]).split(','))[:max_l - min_l] for r__ in r_], []) for r_ in r_test]\n",
    "#         return np.mean([prob_msp(r_test[i], d_test[i][1]) for i in range(len(r_test))])\n",
    "        sys_print(str((\"Test accuracy:\",np.mean([prob_msp(r_test[i], d_test[i][1]) for i in range(len(r_test))])))+\"\\n\", False)\n",
    "\n",
    "    return np.mean([prob_msp(r[i], d[i][1]) for i in range(len(r))])\n",
    "def test_sp_conv(params, tol=0.01, **kwargs):\n",
    "    center, samples, i = np.inf, [], 1\n",
    "    while True:\n",
    "        samples.append(test_sp(params, n1=1, **kwargs))\n",
    "        new_center = np.mean(samples)\n",
    "        if abs(center - new_center) < tol and i >= 3: return new_center, samples\n",
    "        center = new_center\n",
    "        i += 1\n",
    "# eval_sp(default_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"1631684474.311199_0.3927985526497844_0.6421494235732755_1.7265195117562264_1.7813531396798368_5_27_gpt3\"\n",
    "r_ = load_ld(\"msp_samples_nb/\" + str(11) + \"/\" + fn)\n",
    "params, d, r, mdl = r_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frequency_penalty': 1.7813531396798368,\n",
       " 'presence_penalty': 1.7265195117562264,\n",
       " 'top_p': 0.3927985526497844,\n",
       " 'temperature': 0.6421494235732755,\n",
       " 'best_of': 5.0,\n",
       " 'n': 10,\n",
       " 'max_tokens': 8}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d), len(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' double helix',\n",
       " ' logarithmic spiral',\n",
       " ' golden ratio',\n",
       " ' golden ratio',\n",
       " ' golden ratio']"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray([gpt3_tokenizer.encode(r__ + ',') for r__ in r[0]])\n",
    "remaining_phrases = data.tolist()\n",
    "com_token = tokenizer.encode(',')\n",
    "pd_token = gpt3_tokenizer.encode(\"<|endoftext|>\")[0]\n",
    "constrs = []\n",
    "while remaining_phrases != []:\n",
    "    # first add tokens until we hit max_tokens\n",
    "    constr, n_phr = [], 0\n",
    "    while (len(constr) - 0) < 8 and remaining_phrases != []:\n",
    "        n_phr += 1\n",
    "        new_constr = constr + (com_token if constr != [] else []) + remaining_phrases[0]\n",
    "        if (len(new_constr) - 1) <= 8:\n",
    "            constr = new_constr[:-1]\n",
    "            remaining_phrases = remaining_phrases[1:]\n",
    "        else:\n",
    "            constr = constr + ([pd_token] * ((8) - len(constr)))\n",
    "    constrs.append(constr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add example ids to dataset, add subtext 'parent', fix format: just use the fp_tags to create a list of tuples for the fp groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement top k for gpt3... even if it doesnt work i obviously need to to try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either it generates the same thing multiple times before realising it's generated it already or it stores the entire list\n",
    "# in the embedding at each iteration... it might actually be more efficient to do the first thing... after 30 words you have\n",
    "# enough diversity to find new words, and then you can mix them in to find even more. the whole list obviously doesn't need to\n",
    "# go in with it, even if it is technically feasible, exact, and communicates perfectly the problem of searching for the next\n",
    "# least abstract example of the concept, it is a diminishing return that has exhausted itself by the time 30 examples are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the batch size smaller until you are able to fit 30 (or the next round number below the smallest list's length) words in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that uses bayesian optimisation or similar method to quickly find the maxima of the above function (find best params)\n",
    "def evaluate_gpt3_msp_lumped(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "    ps = locals()\n",
    "    ps[\"best_of\"] = 5.0\n",
    "    return test_sp_conv(ps, min_l=3, max_l=30, tol=0.02, phase=\"train\", uniform=True, mdl='gpt3')[0]\n",
    "bounds = {\n",
    "  \"temperature\": [0.05, 1.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.05, 0.9],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.1, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.1, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  best_of  | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------------------\n",
      "|  1        |  0.5403   |  3.504    |  1.335    |  0.505    |  0.6833   |  0.07352  |\n",
      "|  2        |  0.5378   |  2.267    |  1.983    |  0.5014   |  0.5817   |  0.5436   |\n",
      "|  3        |  0.5496   |  3.273    |  0.398    |  0.7146   |  0.204    |  0.5657   |\n",
      "|  4        |  0.5413   |  4.984    |  1.589    |  0.5826   |  0.555    |  0.197    |\n",
      "|  5        |  0.4978   |  2.928    |  0.369    |  0.633    |  1.763    |  0.3513   |\n",
      "|  6        |  0.555    |  1.207    |  1.776    |  0.6096   |  1.502    |  0.2797   |\n",
      "|  7        |  0.4652   |  3.212    |  1.463    |  1.268    |  1.528    |  0.4235   |\n",
      "|  8        |  0.5943   |  5.023    |  1.8      |  1.886    |  0.196    |  0.2943   |\n",
      "|  9        |  0.2692   |  4.806    |  0.87     |  0.4969   |  1.941    |  0.7742   |\n",
      "|  10       |  0.5731   |  5.118    |  1.918    |  0.2899   |  1.787    |  0.1759   |\n",
      "|  11       |  0.55     |  2.366    |  1.913    |  0.8036   |  1.537    |  0.2008   |\n",
      "|  12       |  0.18     |  1.277    |  1.193    |  0.7267   |  1.613    |  0.9577   |\n",
      "|  13       |  0.5084   |  1.737    |  1.369    |  0.487    |  0.6677   |  0.4482   |\n",
      "|  14       |  0.6306   |  4.982    |  1.779    |  1.852    |  0.239    |  0.2627   |\n",
      "|  15       |  0.5507   |  4.889    |  1.699    |  1.548    |  0.3931   |  0.179    |\n",
      "|  16       |  0.5808   |  4.737    |  1.737    |  2.0      |  0.361    |  0.1021   |\n",
      "|  17       |  0.6554   |  5.092    |  1.586    |  1.939    |  0.5428   |  0.2596   |\n",
      "|  18       |  0.6109   |  5.118    |  1.956    |  1.904    |  0.6295   |  0.1545   |\n",
      "|  19       |  0.4837   |  4.876    |  1.75     |  1.91     |  0.6136   |  0.5729   |\n",
      "|  20       |  0.5667   |  5.269    |  1.596    |  1.852    |  0.3651   |  0.05     |\n",
      "|  21       |  0.618    |  5.115    |  1.54     |  2.0      |  0.8681   |  0.05     |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                 \u001b[0mx_probe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Queue is empty, no more objects to retrieve.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-178-6313498f4bbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluate_gpt3_msp_lumped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                 \u001b[0mx_probe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[1;34m(self, utility_function)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0my_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         )\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\util.py\u001b[0m in \u001b[0;36macq_max\u001b[1;34m(ac, gp, y_max, bounds, random_state, n_warmup, n_iter)\u001b[0m\n\u001b[0;32m     56\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                        method=\"L-BFGS-B\")\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# See if success\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 610\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx_try\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_seeds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m# Find the minimum of minus the acquisition function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp, y_max=y_max),\n\u001b[0m\u001b[0;32m     56\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\util.py\u001b[0m in \u001b[0;36mutility\u001b[1;34m(self, x, gp, y_max)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ucb'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ucb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkappa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ei'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ei\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\util.py\u001b[0m in \u001b[0;36m_ucb\u001b[1;34m(x, gp, kappa)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkappa\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Predict based on GP posterior\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mK_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[0my_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha_\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Line 4 (y_mean = f_star)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[1;31m# undo normalisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = BayesianOptimization(f=evaluate_gpt3_msp_lumped, pbounds=bounds, verbose=1000)\n",
    "optimizer.maximize(init_points=10, n_iter=100)\n",
    "ps = optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
    "-------------------------------------------------------------------------\n",
    "|  1        |  0.2752   |  1.659    |  1.462    |  1.207    |  0.5746   |\n",
    "|  2        |  0.1552   |  1.406    |  1.371    |  1.53     |  0.8488   |\n",
    "|  3        |  0.3852   |  1.277    |  1.543    |  0.6489   |  0.1219   |\n",
    "|  4        |  0.3582   |  1.562    |  0.9592   |  0.3661   |  0.9952   |\n",
    "|  5        |  0.2971   |  1.973    |  0.9642   |  0.1205   |  0.3274   |\n",
    "|   iter    |  target   |  best_of  | freque... | presen... | temper... |   top_p   |\n",
    "-------------------------------------------------------------------------------------\n",
    "|  1        |  0.5403   |  3.504    |  1.335    |  0.505    |  0.6833   |  0.07352  |\n",
    "|  2        |  0.5378   |  2.267    |  1.983    |  0.5014   |  0.5817   |  0.5436   |\n",
    "|  3        |  0.5496   |  3.273    |  0.398    |  0.7146   |  0.204    |  0.5657   |\n",
    "|  4        |  0.5413   |  4.984    |  1.589    |  0.5826   |  0.555    |  0.197    |\n",
    "|  5        |  0.4978   |  2.928    |  0.369    |  0.633    |  1.763    |  0.3513   |\n",
    "|  6        |  0.555    |  1.207    |  1.776    |  0.6096   |  1.502    |  0.2797   |\n",
    "|  7        |  0.4652   |  3.212    |  1.463    |  1.268    |  1.528    |  0.4235   |\n",
    "|  8        |  0.5943   |  5.023    |  1.8      |  1.886    |  0.196    |  0.2943   |\n",
    "|  9        |  0.2692   |  4.806    |  0.87     |  0.4969   |  1.941    |  0.7742   |\n",
    "|  10       |  0.5731   |  5.118    |  1.918    |  0.2899   |  1.787    |  0.1759   |\n",
    "|  11       |  0.55     |  2.366    |  1.913    |  0.8036   |  1.537    |  0.2008   |\n",
    "|  12       |  0.18     |  1.277    |  1.193    |  0.7267   |  1.613    |  0.9577   |\n",
    "|  13       |  0.5084   |  1.737    |  1.369    |  0.487    |  0.6677   |  0.4482   |\n",
    "|  14       |  0.6306   |  4.982    |  1.779    |  1.852    |  0.239    |  0.2627   |\n",
    "|  15       |  0.5507   |  4.889    |  1.699    |  1.548    |  0.3931   |  0.179    |\n",
    "|  16       |  0.5808   |  4.737    |  1.737    |  2.0      |  0.361    |  0.1021   |\n",
    "|  17       |  0.6554   |  5.092    |  1.586    |  1.939    |  0.5428   |  0.2596   |\n",
    "|  18       |  0.6109   |  5.118    |  1.956    |  1.904    |  0.6295   |  0.1545   |\n",
    "|  19       |  0.4837   |  4.876    |  1.75     |  1.91     |  0.6136   |  0.5729   |\n",
    "|  20       |  0.5667   |  5.269    |  1.596    |  1.852    |  0.3651   |  0.05     |\n",
    "|  21       |  0.618    |  5.115    |  1.54     |  2.0      |  0.8681   |  0.05     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same above but for the single best_of parameter on phrase completions (secondary phase) once we have the other params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.05244  |  1.67     |  1.61     |  0.8742   |  0.1703   |\n",
      "|  2        |  0.12     |  1.581    |  1.471    |  0.915    |  0.8607   |\n",
      "|  3        |  0.07194  |  1.826    |  1.922    |  0.8147   |  0.3481   |\n",
      "|  4        |  0.06533  |  1.894    |  1.669    |  0.4993   |  0.2044   |\n",
      "|  5        |  0.07474  |  1.682    |  1.74     |  0.9075   |  0.3704   |\n",
      "|  6        |  0.02383  |  1.675    |  1.424    |  0.3665   |  0.8321   |\n",
      "|  7        |  0.07945  |  1.753    |  1.6      |  0.7492   |  0.8382   |\n",
      "|  8        |  0.05533  |  1.761    |  1.536    |  0.363    |  0.1422   |\n",
      "|  9        |  0.07776  |  1.431    |  1.602    |  1.0      |  0.8559   |\n",
      "|  10       |  0.1097   |  1.676    |  1.414    |  0.9789   |  0.8515   |\n",
      "|  11       |  0.05005  |  1.554    |  1.4      |  0.8894   |  0.7108   |\n",
      "|  12       |  0.07069  |  1.644    |  1.504    |  0.9488   |  0.9      |\n",
      "|  13       |  0.09267  |  1.608    |  1.442    |  0.9348   |  0.8509   |\n",
      "|  14       |  0.103    |  1.553    |  1.456    |  0.9071   |  0.872    |\n",
      "|  15       |  0.09919  |  1.572    |  1.495    |  0.8953   |  0.8371   |\n",
      "|  16       |  0.1032   |  1.563    |  1.489    |  0.9465   |  0.8617   |\n",
      "|  17       |  0.0867   |  1.587    |  1.487    |  0.8928   |  0.8935   |\n",
      "|  18       |  0.09887  |  1.562    |  1.459    |  0.9271   |  0.8276   |\n",
      "=========================================================================\n",
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.3763   |  1.724    |  1.781    |  0.6791   |  0.8211   |\n",
      "|  2        |  0.5176   |  1.968    |  1.797    |  0.7303   |  0.4939   |\n",
      "|  3        |  0.4861   |  1.558    |  1.549    |  0.3211   |  0.07074  |\n",
      "|  4        |  0.4857   |  1.711    |  1.559    |  0.2234   |  0.6757   |\n",
      "|  5        |  0.4686   |  1.507    |  1.696    |  0.4465   |  0.3506   |\n",
      "|  6        |  0.5428   |  1.611    |  1.837    |  0.127    |  0.2623   |\n",
      "|  7        |  0.5158   |  1.875    |  1.893    |  0.6705   |  0.06003  |\n",
      "|  8        |  0.5088   |  1.595    |  1.7      |  0.1568   |  0.8465   |\n",
      "|  9        |  0.4925   |  1.469    |  1.704    |  0.3842   |  0.6176   |\n",
      "|  10       |  0.4895   |  1.746    |  1.665    |  0.9932   |  0.3114   |\n",
      "|  11       |  0.4937   |  1.915    |  1.955    |  0.224    |  0.3352   |\n",
      "|  12       |  0.5205   |  1.616    |  1.483    |  0.9745   |  0.2321   |\n",
      "|  13       |  0.503    |  1.516    |  1.895    |  0.446    |  0.3688   |\n",
      "|  14       |  0.4955   |  1.517    |  1.866    |  0.3805   |  0.6377   |\n",
      "|  15       |  0.4838   |  1.474    |  1.511    |  0.4352   |  0.4388   |\n",
      "|  16       |  0.5094   |  1.4      |  1.938    |  0.4652   |  0.4039   |\n",
      "|  17       |  0.5456   |  1.487    |  1.988    |  0.0885   |  0.3297   |\n",
      "|  18       |  0.5139   |  1.535    |  1.995    |  0.05     |  0.07202  |\n",
      "=========================================================================\n",
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.516    |  1.57     |  1.988    |  0.681    |  0.4038   |\n",
      "|  2        |  0.6387   |  1.721    |  1.444    |  0.3722   |  0.113    |\n",
      "|  3        |  0.4309   |  1.616    |  1.717    |  0.331    |  0.8982   |\n",
      "|  4        |  0.4713   |  1.444    |  1.533    |  0.8393   |  0.5813   |\n",
      "|  5        |  0.6455   |  1.747    |  1.93     |  0.4046   |  0.1315   |\n",
      "|  6        |  0.5893   |  1.405    |  1.956    |  0.4923   |  0.2576   |\n",
      "|  7        |  0.4357   |  1.452    |  1.711    |  0.7217   |  0.861    |\n",
      "|  8        |  0.5257   |  1.868    |  1.711    |  0.431    |  0.8367   |\n",
      "|  9        |  0.5367   |  2.0      |  1.714    |  0.05     |  0.05     |\n",
      "|  10       |  0.5806   |  1.718    |  1.933    |  0.407    |  0.1221   |\n",
      "|  11       |  0.6346   |  1.769    |  1.934    |  0.4114   |  0.1628   |\n",
      "|  12       |  0.6403   |  1.8      |  1.917    |  0.3869   |  0.1117   |\n",
      "|  13       |  0.5983   |  1.767    |  1.857    |  0.3976   |  0.1442   |\n",
      "|  14       |  0.5269   |  1.77     |  1.951    |  0.3335   |  0.1446   |\n",
      "|  15       |  0.6015   |  1.787    |  1.923    |  0.4504   |  0.1106   |\n",
      "|  16       |  0.511    |  1.729    |  1.509    |  0.3847   |  0.09703  |\n",
      "|  17       |  0.526    |  1.753    |  1.935    |  0.3904   |  0.1327   |\n",
      "|  18       |  0.6154   |  1.526    |  1.499    |  0.2078   |  0.8141   |\n",
      "=========================================================================\n",
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.5947   |  1.484    |  1.955    |  0.7249   |  0.05145  |\n",
      "|  2        |  0.5916   |  1.568    |  1.583    |  0.2755   |  0.431    |\n",
      "|  3        |  0.4914   |  1.644    |  1.491    |  0.9863   |  0.605    |\n",
      "|  4        |  0.4733   |  1.752    |  1.589    |  0.8368   |  0.3881   |\n",
      "|  5        |  0.5496   |  1.638    |  1.805    |  0.7482   |  0.4766   |\n",
      "|  6        |  0.5266   |  1.625    |  1.907    |  0.7316   |  0.5872   |\n",
      "|  7        |  0.6207   |  1.85     |  1.845    |  0.1905   |  0.2976   |\n",
      "|  8        |  0.5749   |  1.711    |  1.638    |  0.356    |  0.719    |\n",
      "|  9        |  0.5919   |  1.611    |  1.911    |  0.3276   |  0.1758   |\n",
      "|  10       |  0.537    |  1.687    |  1.894    |  0.05     |  0.4889   |\n",
      "|  11       |  0.5364   |  1.832    |  1.668    |  0.2559   |  0.1743   |\n",
      "|  12       |  0.4729   |  1.82     |  1.972    |  0.2712   |  0.2706   |\n",
      "|  13       |  0.5643   |  1.756    |  1.433    |  0.07116  |  0.102    |\n",
      "|  14       |  0.4743   |  1.484    |  1.973    |  0.8096   |  0.586    |\n",
      "|  15       |  0.5352   |  1.862    |  1.543    |  0.08111  |  0.6513   |\n",
      "|  16       |  0.5908   |  1.487    |  1.757    |  0.5733   |  0.5865   |\n",
      "|  17       |  0.5551   |  1.649    |  1.402    |  0.8523   |  0.5089   |\n",
      "|  18       |  0.4867   |  1.659    |  1.431    |  0.902    |  0.6382   |\n",
      "=========================================================================\n",
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.5539   |  1.816    |  1.888    |  0.4689   |  0.2373   |\n",
      "|  2        |  0.4038   |  1.528    |  1.729    |  0.82     |  0.6559   |\n",
      "|  3        |  0.4492   |  1.414    |  1.917    |  0.8685   |  0.6143   |\n",
      "|  4        |  0.674    |  1.487    |  1.937    |  0.8983   |  0.1458   |\n",
      "|  5        |  0.5381   |  1.7      |  1.844    |  0.5491   |  0.3281   |\n",
      "|  6        |  0.6401   |  1.848    |  1.716    |  0.4647   |  0.1431   |\n",
      "|  7        |  0.47     |  1.612    |  1.868    |  0.6607   |  0.6628   |\n",
      "|  8        |  0.512    |  1.506    |  1.67     |  0.4245   |  0.7087   |\n",
      "|  9        |  0.5569   |  1.496    |  1.94     |  0.8974   |  0.1526   |\n",
      "|  10       |  0.5771   |  1.49     |  1.919    |  0.8798   |  0.1395   |\n",
      "|  11       |  0.5115   |  1.486    |  1.933    |  0.8941   |  0.1431   |\n",
      "|  12       |  0.4259   |  1.944    |  1.634    |  0.7019   |  0.8472   |\n",
      "|  13       |  0.498    |  1.727    |  1.963    |  0.6063   |  0.4104   |\n",
      "|  14       |  0.6696   |  1.696    |  1.674    |  0.1788   |  0.1021   |\n",
      "|  15       |  0.6231   |  1.667    |  1.535    |  0.5503   |  0.1171   |\n",
      "|  16       |  0.5837   |  1.501    |  1.948    |  0.1044   |  0.5839   |\n",
      "|  17       |  0.5285   |  1.781    |  1.727    |  0.6421   |  0.3928   |\n",
      "|  18       |  0.5602   |  1.713    |  1.729    |  0.3156   |  0.6786   |\n",
      "=========================================================================\n",
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (1.6181174499024538, 1.5113546974216774, 0.6133867974154082, 0.6043052747059814)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-188-914e449b32be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0moptimizers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-188-914e449b32be>\u001b[0m in \u001b[0;36mfun\u001b[1;34m(temperature, top_p, presence_penalty, frequency_penalty)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"best_of\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0moptimizers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-179-370b925bead5>\u001b[0m in \u001b[0;36mtest_sp_conv\u001b[1;34m(params, tol, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mnew_center\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-179-370b925bead5>\u001b[0m in \u001b[0;36mtest_sp\u001b[1;34m(params, min_l, max_l, n1, n2, prmt, phase, uniform, mdl, max_tokens)\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlprmpts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlprmpts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmax_l\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mphr_ix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mmissing_ix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mphr_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mprompt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcp_cs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat_ix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mphr_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mbounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random.bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "# function that uses the l argument to do the bayesian optimisation once for each \"length group\"\n",
    "lgroups = [[1], [2], [3], [4, 5], [6, 27], [28, 500]] # optimise\n",
    "# lgroups = [[4, 5], [9, 12]] # optimise\n",
    "# lgroups = [[4, 5], [6, 8], [9, 12], [13, 20], [21, 28], [28, 500]] # optimise\n",
    "# lgroups = [[1], [2], [3], [4, 5], [6, 8], [9, 12], [13, 20], [21, 28], [28, 500]] # optimise\n",
    "# lgroups = [[1], [2], [3], [4], [5], [6, 7], [8, 9], [10, 11], [12, 14], [15, 17], [18, 20] [21, 24], [25, 28]]\n",
    "optimizers, results = [], []\n",
    "for lgroup in lgroups:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.02, phase=\"train\", uniform=True, mdl='gpt3')[0]\n",
    "    optimizers.append(BayesianOptimization(f=fun, pbounds=bounds, verbose=1000))\n",
    "    optimizers[-1].maximize(init_points=8, n_iter=10)\n",
    "    results.append(optimizers[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phase in [\"train\", \"test\"]:\n",
    "    n, min_l, max_l, max_train_phrases, prmt, d = 10, 4, 5, 5, None, []\n",
    "    cp, cs, p = ((cats_test, cats_sing_test, phrases_test) if phase == \"test\" else (cats_train, cats_sing_train, phrases_train))\n",
    "    for i in range(len(cp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp_, cs_, p_ = cp[i], cs[i], p[i]\n",
    "        cp_cs = cp_ + cs_\n",
    "        for m in range(n):\n",
    "            cat_ix = np.random.randint(len(cp_cs))  # uniformly sample a category title\n",
    "            sing = cat_ix >= len(cp_)\n",
    "            prompt = prmt\n",
    "            if prompt is None:\n",
    "                lprmpts = lprompts_sing if sing else lprompts\n",
    "                prompt = lprmpts[np.random.randint(len(lprmpts))]\n",
    "            phr_ix = np.random.choice(len(p_), np.random.randint(min_l, min(max_l, len(p_) - 1)), replace=False)\n",
    "            missing_ix = [i for i in range(len(p_)) if i not in phr_ix]\n",
    "            np.random.shuffle(missing_ix)\n",
    "            prompt += ' ' + cp_cs[cat_ix] + ': ' + ''.join([p_[j] + ', ' for j in phr_ix])\n",
    "            d.append((prompt[:-1], ' ' + ''.join([p_[j] + ', ' for j in missing_ix[:max_train_phrases]])[:-2] + '\\n'))\n",
    "    np.random.shuffle(d)\n",
    "    with jsonlines.open(data_dir + learning_data_dir + 'finetuning-buffer-' + phase + '.jsonl', mode='w') as writer:\n",
    "        for (x, y) in d:\n",
    "            writer.write({\"prompt\": x, \"completion\": y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python C:\\Python36\\Scripts\\openai api fine_tunes.create -t data/learning_data/finetuning-buffer-train.jsonl\n",
    "#                                                         -v data/learning_data/finetuning-buffer-test.jsonl -m curie\n",
    "gpt3ft_model = \"curie:ft-user-bshjrj6tekemuk5bv9p3uolr-2021-09-21-06-16-25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot validation accuracy to see if adjusting the hyperparameters and stopping criterion should help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.4396   |  0.05784  |  0.5751   |  1.745    |  0.471    |\n",
      "|  2        |  0.4209   |  0.1584   |  1.905    |  1.023    |  0.1991   |\n",
      "|  3        |  0.4124   |  0.7035   |  1.793    |  1.44     |  0.4241   |\n",
      "|  4        |  0.4077   |  0.2573   |  1.528    |  0.5478   |  0.4779   |\n",
      "|  5        |  0.4568   |  0.2063   |  0.2723   |  1.727    |  0.2076   |\n",
      "|  6        |  0.3046   |  1.537    |  1.369    |  1.714    |  0.8905   |\n",
      "|  7        |  0.3934   |  0.8835   |  1.483    |  0.4428   |  0.9264   |\n",
      "|  8        |  0.3673   |  1.05     |  1.543    |  1.624    |  0.5242   |\n",
      "|  9        |  0.3646   |  0.0      |  0.0      |  0.7817   |  0.01     |\n",
      "|  10       |  0.35     |  0.7927   |  0.0      |  2.0      |  0.01     |\n",
      "|  11       |  0.4219   |  0.0      |  0.5277   |  1.964    |  0.01     |\n",
      "|  12       |  0.3585   |  0.0      |  0.0138   |  1.792    |  0.5446   |\n",
      "|  13       |  0.4305   |  0.2369   |  0.539    |  1.608    |  0.1751   |\n",
      "|  14       |  0.3494   |  0.3052   |  0.4556   |  1.935    |  0.316    |\n",
      "|  15       |  0.3546   |  0.2067   |  0.366    |  1.669    |  0.1922   |\n",
      "|  16       |  0.3508   |  1.795    |  0.6647   |  1.358    |  0.08602  |\n",
      "|  17       |  0.457    |  0.1509   |  0.8864   |  1.297    |  0.3689   |\n",
      "|  18       |  0.434    |  1.235    |  1.911    |  0.2685   |  0.6427   |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# measure accuracy of gpt3 openai api fine tuned curie model (default hyperparameters)\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_ft = {\n",
    "  \"temperature\": [0.01, 2.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.01, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_ft, results_ft = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"], ps[\"model\"], ps[\"engine\"] = 5.0, gpt3ft_model, None\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.02, phase=\"train\", uniform=True, mdl='gpt3', max_tokens=8)[0]\n",
    "    optimizers_ft.append(BayesianOptimization(f=fun, pbounds=bounds_ft, verbose=1000))\n",
    "    optimizers_ft[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_ft.append(optimizers_ft[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.5735   |  0.5488   |  0.7391   |  0.7718   |  0.6072   |\n",
      "|  2        |  0.5498   |  0.1444   |  1.373    |  0.1119   |  0.8559   |\n",
      "|  3        |  0.5621   |  0.5332   |  0.2498   |  0.2249   |  0.5882   |\n",
      "|  4        |  0.4821   |  0.7964   |  1.403    |  0.9806   |  0.5268   |\n",
      "|  5        |  0.629    |  1.116    |  1.189    |  0.7263   |  0.3687   |\n",
      "|  6        |  0.548    |  0.2327   |  1.55     |  0.8007   |  0.1494   |\n",
      "|  7        |  0.5908   |  0.1401   |  1.616    |  0.5753   |  0.2917   |\n",
      "|  8        |  0.4719   |  0.1607   |  0.1332   |  0.8452   |  0.6975   |\n",
      "|  9        |  0.5209   |  1.759    |  1.245    |  0.4905   |  0.6025   |\n",
      "|  10       |  0.5291   |  1.17     |  1.18     |  0.708    |  0.356    |\n",
      "|  11       |  0.6459   |  1.167    |  0.9098   |  0.6324   |  0.1117   |\n",
      "|  12       |  0.6193   |  0.3506   |  0.2109   |  0.02645  |  0.09465  |\n",
      "|  13       |  0.541    |  1.875    |  1.067    |  0.1942   |  0.1302   |\n",
      "|  14       |  0.7753   |  0.2186   |  0.175    |  0.3551   |  0.341    |\n",
      "|  15       |  0.5103   |  1.978    |  1.289    |  0.5473   |  0.5667   |\n",
      "|  16       |  0.4585   |  1.246    |  1.61     |  0.3621   |  0.2858   |\n",
      "|  17       |  0.5729   |  0.06954  |  1.728    |  0.01373  |  0.5262   |\n",
      "|  18       |  0.5735   |  0.3188   |  1.054    |  0.1942   |  0.06931  |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# test the non fine tuned davinci (these are test set results with a lot of low-n samples noise which I forgot to account for)\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_davinci = {\n",
    "  \"temperature\": [0.01, 1.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.05, 0.9],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_davinci, results_davinci = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.02, phase=\"train\", uniform=True, mdl='gpt3')[0]\n",
    "    optimizers_davinci.append(BayesianOptimization(f=fun, pbounds=bounds_davinci, verbose=1000))\n",
    "    optimizers_davinci[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_davinci.append(optimizers_davinci[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "('Test accuracy:', 0.5333333333333333)\n",
      "('Test accuracy:', 0.5240079365079365)\n",
      "('Test accuracy:', 0.5895833333333333)\n",
      "('Test accuracy:', 0.5085470085470085)\n",
      "('Test accuracy:', 0.6797943376068376)\n",
      "|  1        |  0.5689   |  0.2187   |  1.427    |  0.4646   |  0.3569   |\n",
      "('Test accuracy:', 0.6552083333333334)\n",
      "('Test accuracy:', 0.22142857142857142)\n",
      "('Test accuracy:', 0.49404761904761907)\n",
      "('Test accuracy:', 0.5164141414141414)\n",
      "('Test accuracy:', 0.5154761904761905)\n",
      "|  2        |  0.6038   |  1.079    |  1.581    |  0.535    |  0.1709   |\n",
      "('Test accuracy:', 0.7041666666666666)\n",
      "('Test accuracy:', 0.5785714285714285)\n",
      "('Test accuracy:', 0.6107371794871795)\n",
      "('Test accuracy:', 0.75)\n",
      "('Test accuracy:', 0.625)\n",
      "('Test accuracy:', 0.5977678571428571)\n",
      "('Test accuracy:', 0.9113095238095238)\n",
      "('Test accuracy:', 0.6826388888888889)\n",
      "('Test accuracy:', 0.5450892857142857)\n",
      "|  3        |  0.5484   |  1.592    |  0.9546   |  0.2079   |  0.4967   |\n",
      "('Test accuracy:', 0.4203869047619047)\n",
      "('Test accuracy:', 0.38870506535947713)\n",
      "('Test accuracy:', 0.6125)\n",
      "('Test accuracy:', 0.5246212121212122)\n",
      "|  4        |  0.5941   |  0.917    |  0.2134   |  0.328    |  0.6653   |\n",
      "('Test accuracy:', 0.534375)\n",
      "('Test accuracy:', 0.6083333333333334)\n",
      "('Test accuracy:', 0.42638888888888893)\n",
      "('Test accuracy:', 0.725)\n",
      "('Test accuracy:', 0.459375)\n",
      "('Test accuracy:', 0.7347222222222223)\n",
      "('Test accuracy:', 0.5791666666666666)\n",
      "|  5        |  0.5318   |  1.49     |  1.591    |  0.1543   |  0.3382   |\n",
      "('Test accuracy:', 0.37023809523809526)\n",
      "('Test accuracy:', 0.4498071373071373)\n",
      "('Test accuracy:', 0.4770326895326895)\n",
      "('Test accuracy:', 0.4144119769119769)\n",
      "|  6        |  0.3983   |  0.2078   |  0.8455   |  0.8107   |  0.8046   |\n",
      "('Test accuracy:', 0.24027777777777776)\n",
      "('Test accuracy:', 0.3651785714285714)\n",
      "('Test accuracy:', 0.625)\n",
      "('Test accuracy:', 0.593547077922078)\n",
      "('Test accuracy:', 0.790625)\n",
      "('Test accuracy:', 0.5958333333333333)\n",
      "('Test accuracy:', 0.7534722222222223)\n",
      "('Test accuracy:', 0.5845238095238094)\n",
      "('Test accuracy:', 0.5145833333333333)\n",
      "|  7        |  0.5354   |  1.091    |  1.746    |  0.2065   |  0.2528   |\n",
      "('Test accuracy:', 0.5982142857142857)\n",
      "('Test accuracy:', 0.375)\n",
      "('Test accuracy:', 0.375)\n",
      "|  8        |  0.5386   |  1.602    |  1.496    |  0.05069  |  0.8479   |\n",
      "('Test accuracy:', 0.5823232323232324)\n",
      "('Test accuracy:', 0.5564236111111112)\n",
      "('Test accuracy:', 0.5338255494505495)\n",
      "|  9        |  0.5664   |  0.4271   |  0.3114   |  0.4116   |  0.2195   |\n",
      "('Test accuracy:', 0.6295138888888889)\n",
      "('Test accuracy:', 0.5164682539682539)\n",
      "('Test accuracy:', 0.47638888888888886)\n",
      "('Test accuracy:', 0.46388888888888885)\n",
      "|  10       |  0.566    |  1.92     |  0.9819   |  0.7127   |  0.3324   |\n",
      "('Test accuracy:', 0.5462121212121211)\n",
      "('Test accuracy:', 0.7226641414141415)\n",
      "('Test accuracy:', 0.5055555555555555)\n",
      "('Test accuracy:', 0.5026785714285714)\n",
      "('Test accuracy:', 0.4896780303030303)\n",
      "('Test accuracy:', 0.6354166666666667)\n",
      "|  11       |  0.5207   |  1.227    |  1.279    |  0.4341   |  0.89     |\n",
      "('Test accuracy:', 0.3125)\n",
      "('Test accuracy:', 0.3626779470529471)\n",
      "('Test accuracy:', 0.5581168831168831)\n",
      "('Test accuracy:', 0.6011904761904762)\n",
      "('Test accuracy:', 0.5068181818181818)\n",
      "('Test accuracy:', 0.6104166666666666)\n",
      "('Test accuracy:', 0.296875)\n",
      "('Test accuracy:', 0.5066964285714286)\n",
      "|  12       |  0.5637   |  0.5831   |  1.834    |  0.2815   |  0.2762   |\n",
      "('Test accuracy:', 0.43333333333333335)\n",
      "('Test accuracy:', 0.5)\n",
      "('Test accuracy:', 0.5833333333333333)\n",
      "('Test accuracy:', 0.5625)\n",
      "('Test accuracy:', 0.65625)\n",
      "('Test accuracy:', 0.5625)\n",
      "|  13       |  0.505    |  1.323    |  0.929    |  0.02305  |  0.4599   |\n",
      "('Test accuracy:', 0.8)\n",
      "('Test accuracy:', 0.5208333333333333)\n",
      "('Test accuracy:', 0.6319444444444444)\n",
      "('Test accuracy:', 0.4097222222222222)\n",
      "('Test accuracy:', 0.5)\n",
      "('Test accuracy:', 0.8125)\n",
      "('Test accuracy:', 0.5625)\n",
      "|  14       |  0.5247   |  0.8399   |  1.207    |  0.8495   |  0.07713  |\n",
      "('Test accuracy:', 0.4833333333333333)\n",
      "('Test accuracy:', 0.48125)\n",
      "('Test accuracy:', 0.4067640692640692)\n",
      "('Test accuracy:', 0.5118055555555556)\n",
      "('Test accuracy:', 0.2791666666666667)\n",
      "|  15       |  0.4682   |  1.127    |  1.811    |  0.8374   |  0.6957   |\n",
      "('Test accuracy:', 0.5827380952380952)\n",
      "('Test accuracy:', 0.7425137362637363)\n",
      "('Test accuracy:', 0.7035173160173159)\n",
      "|  16       |  0.561    |  0.4612   |  0.9989   |  0.3888   |  0.4608   |\n",
      "('Test accuracy:', 0.4775252525252525)\n",
      "('Test accuracy:', 0.44345238095238093)\n",
      "('Test accuracy:', 0.5278273809523809)\n",
      "('Test accuracy:', 0.5236111111111111)\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "you exceeded your current quota, please check your plan and billing details",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (1.6103157420466807, 1.623285116407665, 0.8295588177667365, 0.6067669372541233)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-9f166ec85380>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0moptimizers_davinci_bf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds_davinci_bf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0moptimizers_davinci_bf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mresults_davinci_bf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers_davinci_bf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-97-9f166ec85380>\u001b[0m in \u001b[0;36mfun\u001b[1;34m(temperature, top_p, presence_penalty, frequency_penalty)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#         ps[\"best_of\"] = 5.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0moptimizers_davinci_bf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds_davinci_bf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0moptimizers_davinci_bf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-40541267c49c>\u001b[0m in \u001b[0;36mtest_sp_conv\u001b[1;34m(params, tol, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mnew_center\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtol\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-40541267c49c>\u001b[0m in \u001b[0;36mtest_sp\u001b[1;34m(params, min_l, max_l, n1, n2, prmt, phase, uniform, mdl, max_tokens)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmissing_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_tokens\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mmdl\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Convert to strings and request predictions from OpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"completions\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-40541267c49c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmissing_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_tokens\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mmdl\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Convert to strings and request predictions from OpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"completions\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-a0044cfacc25>\u001b[0m in \u001b[0;36mp_req_m\u001b[1;34m(s, tokenize, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"prompt\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcaptured\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchoice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"choices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mtks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchoice\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"logprobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_logprobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, idempotency_key, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midempotency_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         response, _, api_key = requestor.request(\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         )\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, stream)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         )\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_api_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36minterpret_response\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    346\u001b[0m             )\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpret_response_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minterpret_response_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36minterpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             raise self.handle_error_response(\n\u001b[1;32m--> 368\u001b[1;33m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             )\n\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: you exceeded your current quota, please check your plan and billing details"
     ]
    }
   ],
   "source": [
    "# test the non fine tuned davinci model (no best_of/best_of=1)\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_davinci_bf1 = {\n",
    "  \"temperature\": [0.01, 1.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.05, 0.9],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_davinci_bf1, results_davinci_bf1 = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "#         ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, n2=5, tol=0.005, phase=\"train\", uniform=True, mdl='gpt3')[0]\n",
    "    optimizers_davinci_bf1.append(BayesianOptimization(f=fun, pbounds=bounds_davinci_bf1, verbose=1000))\n",
    "    optimizers_davinci_bf1[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_davinci_bf1.append(optimizers_davinci_bf1[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "('Test accuracy:', 0.5180322128851541)\n",
      "('Test accuracy:', 0.6575757575757576)\n",
      "('Test accuracy:', 0.6978178071928072)\n",
      "('Test accuracy:', 0.42820512820512824)\n",
      "|  1        |  0.5919   |  0.1949   |  0.2221   |  0.3226   |  0.3348   |\n",
      "('Test accuracy:', 0.6486111111111111)\n",
      "('Test accuracy:', 0.7268781565656566)\n",
      "('Test accuracy:', 0.6553207467197406)\n",
      "('Test accuracy:', 0.5233134920634921)\n",
      "('Test accuracy:', 0.6407986111111111)\n",
      "|  2        |  0.6171   |  0.1909   |  0.1618   |  0.381    |  0.3126   |\n",
      "('Test accuracy:', 0.5881944444444445)\n",
      "('Test accuracy:', 0.5876893939393939)\n",
      "('Test accuracy:', 0.550189393939394)\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "The server experienced an error while processing your request. Sorry about that! You can retry your request, or contact support@openai.com if the error persists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.15067784537364293, 0.15496628379746158, 0.37198699505885424, 0.39588471991510366)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-441-aa560142bee5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0moptimizers_davinci_box\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds_davinci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0moptimizers_davinci_box\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mresults_davinci_box\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers_davinci_box\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-441-aa560142bee5>\u001b[0m in \u001b[0;36mfun\u001b[1;34m(temperature, top_p, presence_penalty, frequency_penalty)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"best_of\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0moptimizers_davinci_box\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds_davinci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0moptimizers_davinci_box\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-440-cc5ea2a39bb9>\u001b[0m in \u001b[0;36mtest_sp_conv\u001b[1;34m(params, tol, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mnew_center\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-440-cc5ea2a39bb9>\u001b[0m in \u001b[0;36mtest_sp\u001b[1;34m(params, min_l, max_l, n1, n2, prmt, phase, uniform, mdl, max_tokens)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmissing_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_tokens\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mmdl\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Convert to strings and request predictions from OpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-440-cc5ea2a39bb9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmissing_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_tokens\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mmdl\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Convert to strings and request predictions from OpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-a86d5fa7f561>\u001b[0m in \u001b[0;36mp_req_m\u001b[1;34m(s, tokenize, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"prompt\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcaptured\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchoice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"choices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mtks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchoice\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"logprobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_logprobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, idempotency_key, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midempotency_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         response, _, api_key = requestor.request(\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         )\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, stream)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         )\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_api_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36minterpret_response\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    346\u001b[0m             )\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpret_response_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minterpret_response_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36minterpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             raise self.handle_error_response(\n\u001b[1;32m--> 368\u001b[1;33m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             )\n\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAPIError\u001b[0m: The server experienced an error while processing your request. Sorry about that! You can retry your request, or contact support@openai.com if the error persists."
     ]
    }
   ],
   "source": [
    "# test the non fine tuned davinci\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_davinci = {\n",
    "  \"temperature\": [0.3, 0.4],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.3, 0.4],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.15, 0.25],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.15, 0.25],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_davinci_box, results_davinci_box = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.005, phase=\"train\", uniform=True, mdl='gpt3')[0]\n",
    "    optimizers_davinci_box.append(BayesianOptimization(f=fun, pbounds=bounds_davinci, verbose=1000))\n",
    "    optimizers_davinci_box[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_davinci_box.append(optimizers_davinci_box[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389844235142224"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.6486111111111111+0.7268781565656566+0.6553207467197406+0.5233134920634921+0.6407986111111111)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n",
      "|  1        |  0.4519   |  1.995    |  0.2834   |  1.056    |  0.1811   |\n",
      "|  2        |  0.4083   |  0.7263   |  0.3713   |  0.2898   |  0.9283   |\n",
      "|  3        |  0.4409   |  1.156    |  0.1299   |  0.05551  |  0.7137   |\n",
      "|  4        |  0.372    |  1.701    |  0.5557   |  1.16     |  0.6606   |\n",
      "|  5        |  0.2361   |  0.8887   |  1.62     |  1.029    |  0.9866   |\n",
      "|  6        |  0.4471   |  0.4209   |  1.705    |  0.8261   |  0.7319   |\n",
      "|  7        |  0.4265   |  1.672    |  1.324    |  0.7057   |  0.4788   |\n",
      "|  8        |  0.3132   |  0.5174   |  1.645    |  0.8541   |  0.9556   |\n",
      "|  9        |  0.1826   |  0.1497   |  0.4119   |  1.119    |  0.9765   |\n",
      "|  10       |  0.5016   |  0.8572   |  0.6555   |  0.6083   |  0.4133   |\n",
      "|  11       |  0.3438   |  0.1001   |  1.874    |  1.773    |  0.03896  |\n",
      "|  12       |  0.4958   |  1.655    |  1.1      |  0.1683   |  0.2678   |\n",
      "|  13       |  0.3894   |  1.134    |  1.96     |  0.6033   |  0.9399   |\n",
      "|  14       |  0.4117   |  0.4373   |  1.216    |  1.825    |  0.4379   |\n",
      "|  15       |  0.3261   |  1.651    |  0.7446   |  1.395    |  0.7844   |\n",
      "|  16       |  0.4398   |  1.191    |  0.7964   |  0.4159   |  0.3712   |\n",
      "|  17       |  0.5293   |  0.9398   |  0.3362   |  0.4675   |  0.3451   |\n",
      "|  18       |  0.2153   |  0.7256   |  0.4712   |  0.4638   |  0.01701  |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# test the non fine tuned curie\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_curie = {\n",
    "  \"temperature\": [0.01, 2.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.01, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.0, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.0, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_curie, results_curie = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"], ps[\"engine\"] = 5.0, \"curie\"\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.02, phase=\"train\", uniform=True, mdl='gpt3')[0]\n",
    "    optimizers_curie.append(BayesianOptimization(f=fun, pbounds=bounds_curie, verbose=1000))\n",
    "    optimizers_curie[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_curie.append(optimizers_curie[-1].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0921 22:24:01.283439 87152 filelock.py:274] Lock 2186489647848 acquired on C:\\Users\\alfew/.cache\\huggingface\\transformers\\42252c2220ae3f9f1ea86a994b63e1dcab20953ba8982117c2384587f7c01c5d.102e6e06599c480a8e55be9ba8dc6226140c958f3cd489f61627520db6817595.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab679ef9f4643d3b7bdd6d45d31c346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1347, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0921 22:24:01.689368 87152 filelock.py:318] Lock 2186489647848 released on C:\\Users\\alfew/.cache\\huggingface\\transformers\\42252c2220ae3f9f1ea86a994b63e1dcab20953ba8982117c2384587f7c01c5d.102e6e06599c480a8e55be9ba8dc6226140c958f3cd489f61627520db6817595.lock\n",
      "I0921 22:24:02.102262 87152 filelock.py:274] Lock 2186489648800 acquired on C:\\Users\\alfew/.cache\\huggingface\\transformers\\7c5fac9d60b015cbc7c007ab8fe6d0512787fbaef81968922959898c49468d73.4c6a483fbfb5a25ac384bfcd71a1ff15245f06583a00c4ab4c44ed0f761f0b08.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634b5ac274374affa1a4287b1f1ba04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=5312753599, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0921 22:46:09.977987 87152 filelock.py:318] Lock 2186489648800 released on C:\\Users\\alfew/.cache\\huggingface\\transformers\\7c5fac9d60b015cbc7c007ab8fe6d0512787fbaef81968922959898c49468d73.4c6a483fbfb5a25ac384bfcd71a1ff15245f06583a00c4ab4c44ed0f761f0b08.lock\n",
      "I0921 22:46:27.701773 87152 tokenization_utils.py:317] Model name 'EleutherAI/gpt-neo-1.3B' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large). Assuming 'EleutherAI/gpt-neo-1.3B' is a path or url to a directory containing tokenizer files.\n",
      "I0921 22:46:27.704766 87152 tokenization_utils.py:328] Didn't find file EleutherAI/gpt-neo-1.3B. We won't load it.\n",
      "I0921 22:46:27.707758 87152 tokenization_utils.py:328] Didn't find file EleutherAI/gpt-neo-1.3B. We won't load it.\n",
      "I0921 22:46:27.709753 87152 tokenization_utils.py:346] Didn't find file EleutherAI/gpt-neo-1.3B\\added_tokens.json. We won't load it.\n",
      "I0921 22:46:27.712745 87152 tokenization_utils.py:346] Didn't find file EleutherAI/gpt-neo-1.3B\\special_tokens_map.json. We won't load it.\n",
      "I0921 22:46:27.714740 87152 tokenization_utils.py:346] Didn't find file EleutherAI/gpt-neo-1.3B\\tokenizer_config.json. We won't load it.\n",
      "E0921 22:46:27.716734 87152 tokenization_utils.py:356] Model name 'EleutherAI/gpt-neo-1.3B' was not found in model name list (gpt2, gpt2-medium, gpt2-large). We assumed 'EleutherAI/gpt-neo-1.3B' was a path or url but couldn't find tokenizer filesat this path or url.\n"
     ]
    }
   ],
   "source": [
    "# test gpt2-neo-2.7B and the same model fine tuned for lgroup [4, 5] and max_tokens=8 using our code ()\n",
    "m_neo = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "gptneo_tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In a shocking finding, scientists discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\\n\\nThe discovery was made by two biologists at the Smithsonian’s National Zoo in Washington, DC, John O’Hara and Brian Leung. The pair made the discovery after conducting a series of scientific tests to determine if a herd of 12 unicorns were living among the mountains in this remote valley.\\n\\nThe herd’s size was just one of many variables that could have potentially affected the wildlife’s survival. But if the scientists were right that the herd was inhabited by unicorns, it may have represented an ecological connection that was crucial to the survival of the species.\\n\\nIn fact, the researchers hypothesized that the herd of unicorns appeared to be so small that they likely could not have made the connection with humans from their environment'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"In a shocking finding, scientists discovered a herd of unicorns living in a remote, \" \\\n",
    "          \"previously unexplored valley, in the Andes Mountains. Even more surprising to the \" \\\n",
    "          \"researchers was the fact that the unicorns spoke perfect English.\"\n",
    "input_ids = gptneo_tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "gen_tokens = m_neo.generate(input_ids, do_sample=True, temperature=0.9, max_length=200,)\n",
    "gen_text = gptneo_tokenizer.batch_decode(gen_tokens)[0]\n",
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective here: use the above for each prompt and figure out the best prompt multinomial (probably still \"A list of\") for all l\n",
    "# then use bayesian optimisation to train a gaussian mixture for each length group (this would be valuable at least for visuals)\n",
    "# can also see if random prompt requires more samples to converge, l dependence, and score vs fixed prompt for each l group.\n",
    "# if it works better, use a random prompt each time; we may benefit if the prompt-dependent vars can be learned.\n",
    "# also, eventually, we can experiment with choosing a prompt for the query, however this is inherently anti-diversity GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 'global evaluator' function that compares the previous two methods using the same code, next token score (and next word?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a GP/density net/MDN model of length feats (+cond.prob. features) vs sampling params (mt), mu sigma, mixture dist., eps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include gpt2/gpt-neo embeddings (next step gpt3 embeddings (?)) (and see if a mixture distribution is (still) necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if fine-tuning a tertiary post-completion filter phase improves accuracy (aim for as few false negatives as possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with typical one-hot fine-tuning of gpt2, gpt-neo & gpt3 (optimise sampling params & filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with multinomial fine-tuning of gpt2, gpt-neo (next step gpt3 multinomial) (optimise sampling params & filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use an ensemble of the most successful of the above methods to create candidate outputs, then train a\n",
    "# joint filter to distinguish between correct and erroneous list completions (gpt2/gpt-neo/gpt3-prompt) (next step gpt3) 0FNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using the joint filter trained with the ensemble outputs to filter the responses of the best single model from the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "def adapt_form(xs, ys, sqlens, mlen=max_len, repl_finalcomma=True):\n",
    "    xs = pt.vstack([F.pad(x, (0, max(0, mlen - len(x))), mode='constant', value=pad_token)[:mlen] for x in xs])\n",
    "    _ys = pt.vstack(ys) if ys is not None else None\n",
    "    if repl_finalcomma and (lastcomma_repl != ',') and ys is not None:\n",
    "        _ys[:, repl_token] += _ys[:, comma_token] - lid_val\n",
    "        _ys[:, comma_token] = lid_val\n",
    "    return xs, _ys, pt.tensor(sqlens, device=d)\n",
    "def next_batch(sz):\n",
    "    global cats_e_train, cats_sing_e_train, phrases_e_train\n",
    "    return adapt_form(*gen_samples(cats_e_train, cats_sing_e_train, phrases_e_train, sz, mlen=max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2039\n",
      "GPT2 device: cuda:0\n",
      "Pretrained parameters loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "pt.cuda.empty_cache()\n",
    "print(gc.collect())\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2LMHead\")\n",
    "model_ = GPT2LMHeadModel.from_pretrained(gpt2_modelkey,\n",
    "    output_hidden_states=False, output_attentions=False, \n",
    "    cache_dir=\"models/pretrained/GPT2LMHead\")\n",
    "if pt.cuda.device_count() > 1:\n",
    "    device_map = {0: [0, 1, 2],\n",
    "                  1: [3, 4, 5, 6, 7, 8],\n",
    "                  2: [9, 10, 11, 12, 13, 14],\n",
    "                  3: [15, 16, 17, 18, 19, 20],\n",
    "                  4: [21, 22, 23, 24, 25, 26, 27],\n",
    "                  5: [28, 29, 30, 31, 32, 33, 34],\n",
    "                  6: [35, 36, 37, 38, 39, 40, 41],\n",
    "                  7: [42, 43, 44, 45, 46, 47],\n",
    "                 }\n",
    "    model_.parallelize(device_map)\n",
    "else:\n",
    "    model_ = model_.to(d)\n",
    "print(\"GPT2 device:\", model_.device)\n",
    "model_.resize_token_embeddings(N_tokens)\n",
    "pad_token = model_.config.pad_token_id = model_.config.eos_token_id\n",
    "pad_token = pt.tensor(pad_token, device=d)\n",
    "repl_token = pt.tensor(tokenizer.encode(lastcomma_repl)[0], device=d) if lastcomma_repl != 'EOS' else pad_token\n",
    "n_embd = pt.tensor(model_.config.n_embd, device=d)\n",
    "# model = nn.parallel.DistributedDataParallel(model_, device_ids=[d])\n",
    "# model = nn.DataParallel model_, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else model_\n",
    "model = model_\n",
    "mname_fn = gpt2_modelkey\n",
    "print(\"Pretrained parameters loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = None #nn.Linear(n_embd, N_tokens, bias=False).to(d)#.cpu()\n",
    "# nn.init.xavier_uniform_(llayer.weight)\n",
    "# llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else llayer\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()#.to(d)#.cpu()\n",
    "# bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d) if dev != \"cpu\" else bcewl_loss\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1, device=d)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, bsz, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(bsz)\n",
    "\n",
    "#     for x in x_batch.cpu().detach().numpy():\n",
    "#         print(tokenizer.decode(x))\n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)  # Get logits\n",
    "    logits = outputs[0][[pt.arange(x_batch.shape[0]), sqlens_batch - 1]]\n",
    "    \n",
    "#     out_idx = pt.unsqueeze(pt.unsqueeze(sqlens_batch - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "#     outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     print(pt.all(outs == logits).cpu().detach().numpy())\n",
    "#     outs = outputs[0][:, -1]\n",
    "\n",
    "#     logits = llayer(logits)\n",
    "#     logits = outs\n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lid_val + 1e-10)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "\n",
    "def inference(x, sqlens, past=None, return_states=False, seq_maxlen=max_len):\n",
    "    global model, llayer\n",
    "\n",
    "    multitoken = x.shape[1] > 1\n",
    "    mask = sequence_mask(sqlens, seq_maxlen) if multitoken else None\n",
    "    outputs = model(x.long(), attention_mask=mask, use_cache=None if not return_states else True, past_key_values=past)\n",
    "    logits = outputs[0][[pt.arange(x.shape[0]), sqlens - 1]] if multitoken else outputs[0].squeeze(1)\n",
    "\n",
    "    if return_states:  # Optionally return the last set of past states needed to restore the computation when appending to stream\n",
    "        if not multitoken: return logits, outputs[1]\n",
    "        st, last = outputs[1], []\n",
    "        for i in range(len(st)):\n",
    "            l = []\n",
    "            for j in range(len(st[i])):\n",
    "                l.append(st[i][j][:, :, -1:])\n",
    "            last.append(l)\n",
    "        return logits, last\n",
    "    return logits\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())#.to(d)#.cpu()\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lid_val + 1e-10)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = -1  # Batch 0 is the first iteration, where testing occurs without any training\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "out_str = ''\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, test_loss, test_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, test_loss, test_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        if batch_i > 0:\n",
    "            gc.collect()\n",
    "            if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "            b_loss, b_accuracy = train_step()\n",
    "            mname_fn = model_name\n",
    "            if verbose:\n",
    "                sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                          ' @ batch '+ str(batch_i) + ' (' + str(batch_i * batch_size) + ' samples) complete.                  ')\n",
    "            iter_loss.append(b_loss)\n",
    "            iter_accuracy.append(b_accuracy)\n",
    "\n",
    "        if batch_i % log_period_batches == 0:  # Test on test set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            out_str = '\\n'\n",
    "            for i in range(N_test):\n",
    "                test_X, test_Y, test_Sqlens = adapt_form(test_xs[i], test_ys[i], test_sqlens[i], repl_finalcomma=batch_i > 0)\n",
    "                feed_batches = [range(len(test_X))[i * bsz:(i + 1) * bsz] for i in range((len(test_X) // bsz) + \\\n",
    "                                                                                        (1 if (len(test_X) % bsz) != 0 else 0))]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(test_X[inds], test_Y[inds], test_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls))\n",
    "                accuracy.append(np.mean(cs))\n",
    "                out_str += test_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]) + '\\n'\n",
    "            \n",
    "            test_l, test_a = np.mean(loss), np.mean(accuracy)\n",
    "            test_loss.append(test_l)\n",
    "            test_accuracy.append(test_a)\n",
    "            if batch_i == 0:\n",
    "                iter_loss, iter_accuracy = [test_l], [test_a]\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l)\n",
    "            train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "            \n",
    "            val_a = 0\n",
    "            if test_a > best_acc:      # Save best accuracy model\n",
    "                best_acc = test_a\n",
    "                best_loss = test_l\n",
    "                best_acc_idx = batch_i // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "#                          \"llayer\": llayer.state_dict(),\n",
    "#                          \"softrmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(out_str + \"Batch\", batch_i, ':', train_a, test_a, \"loss:\", train_l, test_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(test_accuracy, label='test acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                plt.yscale(\"log\")\n",
    "                g.plot(test_loss, label='test loss')\n",
    "                plt.yscale(\"log\")\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, test_accuracy, train_loss, test_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "chemical elements: 0.00047280302, 0.64\n",
      "dramatic and literature elements: 0.0004884577, 0.505\n",
      "vehicles referred to as crafts: 0.00047934064, 0.615\n",
      "music: 0.00049096224, 0.45\n",
      "scientific cycles: 0.0004916513, 0.455\n",
      "machine learning algorithms: 0.00054296234, 0.34\n",
      "glassware: 0.00050270767, 0.465\n",
      "windings: 0.00052776106, 0.425\n",
      "Batch 370 : 0.35 0.486875 loss: 0.00056242204 0.00049958075 Best: 0.630625 0.001117534 idx: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, accuracy: 0.00047021123, 0.875 @ batch 375 (3000 samples) complete.                  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-5ff61b84ca1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0miterate_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-722920898fdb>\u001b[0m in \u001b[0;36miterate_training\u001b[1;34m(verbose)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mdev\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mb_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mmname_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model (checkpoint)\n",
    "pt.cuda.empty_cache()\n",
    "gc.collect()\n",
    "cpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 2k ts' + \"/\" + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 3k ts' + \"/\" + model_name)  # ~3000 training samples observed has current optimum\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 30k ts' + \"/\" + model_name)\n",
    "model.load_state_dict(cpoint['model'])\n",
    "bcewl_loss.load_state_dict(cpoint['bcewl_loss'])\n",
    "optimizer.load_state_dict(cpoint['optimizer'])\n",
    "scheduler.load_state_dict(cpoint['scheduler'])\n",
    "# llayer.load_state_dict(cpoint['llayer'])\n",
    "mname_fn = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_temperature_filtering(logits, tcounts=None, filter_value=-float('Inf'),\n",
    "                                      top_k=0, top_p=0.0, temperature=1.0, frequency_penalty=0.0, presence_penalty=0.0):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if tcounts is not None: logits -= (tcounts * frequency_penalty) + ((tcounts > 0) * presence_penalty)\n",
    "    logits /= temperature\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = int(pad_token.detach().cpu().numpy())\n",
    "# stop_tokens_e = [tokenizer.encode(t)[0] for t in [\"<|endoftext|>\"]]\n",
    "def gprobs(s, past=None, return_sts=False, tcounts=None, **kwargs):  # Inference and sampling for tokens\n",
    "    global model\n",
    "    xs, mlen = None, None\n",
    "    if isinstance(s, tuple):    # s either list of token tensors or tuple of preformatted 2d tensors\n",
    "        xs, _, sqlen = s\n",
    "        mlen = xs.shape[1]\n",
    "    else:\n",
    "        sqlen = [len(s_) for s_ in s]\n",
    "        mlen = max(sqlen)\n",
    "        xs, _, sqlen = adapt_form([pt.tensor(s_).to(d) for s_ in s], None, sqlen, mlen=mlen)\n",
    "    if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    y_hat = inference(xs, sqlen, seq_maxlen=mlen, past=past, return_states=return_sts)\n",
    "    if return_sts: y_hat, states = y_hat\n",
    "    y_hat = pt.vstack([F.softmax(top_k_top_p_temperature_filtering(y_hat[i], tcounts[i] if tcounts is not None else None,\n",
    "                                                                   **kwargs), dim=0) for i in range(len(s))])\n",
    "    return (y_hat, states) if return_sts else y_hat\n",
    "def append_next_token(sent, olen=None, top_k=-1, top_p=0.9, temperature=1.0):  # Interface for field testing\n",
    "    print(\"k =\", top_k, \", p =\", top_p, \", temp =\", temperature)\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    ou = tokens.copy()\n",
    "    tcounts = pt.zeros(N_tokens, dtype=int).to(d)\n",
    "    for token in tokens: tcounts[token] += 1\n",
    "    probs = gprobs([tokens], top_k=top_k, top_p=top_p, temperature=temperature, tcounts=[tcounts])[0]\n",
    "    token = pt.multinomial(probs, 1).detach().cpu().numpy()[0]\n",
    "    ou += [token]\n",
    "    prev_len = len(sent) if olen is None else olen\n",
    "    sent_new = tokenizer.decode(ou)\n",
    "    print(sent[:prev_len] + '➡' + sent_new[prev_len:])\n",
    "    return sent_new\n",
    "def gen_probs(s, **kwargs):  # Adapter for strings\n",
    "    inp = [tokenizer.encode(s_) for s_ in s]\n",
    "    return gprobs(inp, **kwargs)\n",
    "# bszinf = 256\n",
    "bszinf = bsz * 16\n",
    "def gen_completions(s, n=1, max_tokens=8, best_of=1, **kwargs):  # Completion generator equivalent to OpenAI's for GPT3\n",
    "    probs, states, tcounts, n_outer_batches, best_of = [], [], [], int(np.ceil(len(s) / (bsz // 2))), int(round(best_of))\n",
    "    best_of_inner = 1 if (best_of != 1 and n != 1) else best_of\n",
    "#     if best_of != 1 and n != 1: n, best_of, best_of_inner = best_of, n, 1\n",
    "    for i in range(n_outer_batches):\n",
    "        s_batch = s[i * (bsz // 2):(i + 1) * (bsz // 2)]\n",
    "        tc_b = []\n",
    "        for s_ in s_batch:\n",
    "            tc = pt.zeros(N_tokens, dtype=int).to(d)\n",
    "            for t in tokenizer.encode(s_): tc[t] += 1\n",
    "            tc_b.append(tc)\n",
    "        p, st = gen_probs(s_batch, return_sts=True, tcounts=tc_b, **kwargs)\n",
    "        probs.append(p)\n",
    "        states.append(st)\n",
    "        tcounts.append(tc_b)\n",
    "    inner_bsz = int(bszinf / ((bsz // 2) * n))\n",
    "    n_inner_batches = int(np.ceil(n_outer_batches / inner_bsz))\n",
    "    outputs = []\n",
    "    for i in range(n_inner_batches):\n",
    "        p_b, st_b = probs[i * inner_bsz:(i + 1) * inner_bsz], states[i * inner_bsz:(i + 1) * inner_bsz]\n",
    "        tc_b = sum(tcounts[i * inner_bsz:(i + 1) * inner_bsz], [])\n",
    "        p_b, states = pt.vstack(p_b), []\n",
    "        for st_i in range(len(st_b[0])):\n",
    "            sts = []\n",
    "            for st_j in range(len(st_b[0][0])): sts.append(pt.vstack([st[st_i][st_j] for st in st_b]).repeat_interleave(n, 0))\n",
    "            states.append(tuple(sts))\n",
    "        states = tuple(states)\n",
    "        tokens = pt.multinomial(p_b, n * best_of_inner, replacement=True).reshape(p_b.shape[0], best_of_inner, n).to(d)\n",
    "        for j in range(len(tc_b)): tc_b[j][tokens[j]] += 1\n",
    "        outs, avg_logprobs = [], []\n",
    "        for itr in range(best_of_inner):\n",
    "            out, tc_b_ = [], tc_b.copy()\n",
    "            tks, ts, su, ls = tokens[:, itr].reshape(p_b.shape[0] * n), [], pt.zeros(p_b.shape[0]), np.zeros(p_b.shape[0])\n",
    "            p, st = gprobs(tks, past=states, return_sts=True, tcounts=tc_b, **kwargs)\n",
    "            for token_i in range(max_tokens):\n",
    "                t = pt.multinomial(p, 1).to(d)\n",
    "                for j in range(len(tc_b_)): tc_b_[j][t[j]] += 1\n",
    "                out.append(t)\n",
    "                cont = t != pad_token\n",
    "                ls += cont.int()\n",
    "                su += cont * pt.log(p[t])\n",
    "                if t == max_tokens - 1: break\n",
    "                p, st = gprobs(t, past=st, return_sts=True, tcounts=tc_b_, **kwargs)\n",
    "            outs.append([o.reshape(p_b.shape[0], n) for o in out])\n",
    "            avg_logprobs.append((su / ls).reshape(p_b.shape[0], n))\n",
    "        if best_of == 1:\n",
    "            outs = pt.stack(outs[0], dim=1)\n",
    "        elif n == 1:\n",
    "            outs, lps = pt.stack([pt.stack(o, dim=1) for o in outs]), pt.stack(avg_logprobs)\n",
    "            s1, s2 = outs.shape[1], outs.shape[2]\n",
    "            outs = outs[[pt.argmin(lps, 0).view(-1), pt.arange(s1).repeat_interleave(s2), pt.arange(s2).repeat(s1, 1).view(-1)]]\n",
    "        else:\n",
    "            outs = pt.stack(outs[0], dim=1)\n",
    "            s1 = outs.shape[1]\n",
    "            idx = pt.argsort(avg_logprobs[0], axis=1)[:, :best_of].repeat((1, 1, max_tokens)).reshape(s1, max_tokens, best_of)\n",
    "            outs = pt.gather(outs, 2, idx)\n",
    "        outputs.append(outs)\n",
    "    outputs = [tokenizer.decode(x).split(\"\\n\")[0] for x in pt.vstack(outputs)]\n",
    "    return outputs\n",
    "mdl = {\"completions\": gen_completions, \"probabilities\": gprobs, \"name\": mname_fn + ':' + gpt2_modelkey, \"mstr\": str(model)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.arange(8).repeat(10).reshape(10, 8)[pt.arange(10), pt.arange(5).repeat(10).reshape(5, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,  -2,  -4,  -6,  -8, -10, -12, -14],\n",
       "        [  0,  -2,  -4,  -6,  -8, -10, -12, -14],\n",
       "        [  0,  -2,  -4,  -6,  -8, -10, -12, -14],\n",
       "        [  0,  -2,  -4,  -6,  -8, -10, -12, -14],\n",
       "        [  0,  -2,  -4,  -6,  -8, -10, -12, -14],\n",
       "        [  0,   2,   4,   6,   8,  10,  12,  14],\n",
       "        [  0,   2,   4,   6,   8,  10,  12,  14],\n",
       "        [  0,   2,   4,   6,   8,  10,  12,  14],\n",
       "        [  0,   2,   4,   6,   8,  10,  12,  14],\n",
       "        [  0,   2,   4,   6,   8,  10,  12,  14]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testa = pt.arange(8).repeat(10).reshape(10, 8) * 2\n",
    "testa[:5] = -testa[:5]\n",
    "testa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3, 8]),\n",
       " tensor([[[   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14],\n",
       "          [   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14],\n",
       "          [-100, -102, -104, -106, -108, -110, -112, -114]],\n",
       " \n",
       "         [[   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14],\n",
       "          [   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14],\n",
       "          [   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14]],\n",
       " \n",
       "         [[   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14],\n",
       "          [   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14],\n",
       "          [   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14]],\n",
       " \n",
       "         [[   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14],\n",
       "          [   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14],\n",
       "          [   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14]],\n",
       " \n",
       "         [[   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14],\n",
       "          [   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14],\n",
       "          [   0,   -2,   -4,   -6,   -8,  -10,  -12,  -14]],\n",
       " \n",
       "         [[   0,    2,    4,    6,    8,   10,   12,   14],\n",
       "          [   0,    2,    4,    6,    8,   10,   12,   14],\n",
       "          [   0,    2,    4,    6,    8,   10,   12,   14]],\n",
       " \n",
       "         [[   0,    2,    4,    6,    8,   10,   12,   14],\n",
       "          [   0,    2,    4,    6,    8,   10,   12,   14],\n",
       "          [   0,    2,    4,    6,    8,   10,   12,   14]],\n",
       " \n",
       "         [[   0,    2,    4,    6,    8,   10,   12,   14],\n",
       "          [   0,    2,    4,    6,    8,   10,   12,   14],\n",
       "          [   0,    2,    4,    6,    8,   10,   12,   14]],\n",
       " \n",
       "         [[   0,    2,    4,    6,    8,   10,   12,   14],\n",
       "          [   0,    2,    4,    6,    8,   10,   12,   14],\n",
       "          [   0,    2,    4,    6,    8,   10,   12,   14]],\n",
       " \n",
       "         [[   0,    2,    4,    6,    8,   10,   12,   14],\n",
       "          [   0,    2,    4,    6,    8,   10,   12,   14],\n",
       "          [   0,    2,    4,    6,    8,   10,   12,   14]]]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testa_data = pt.stack([testa, testa, testa], dim=1)\n",
    "testa_data[0, 2] -= 100\n",
    "testa_data.shape, testa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3, 5]), tensor([[[7, 6, 5, 4, 3],\n",
       "          [7, 6, 5, 4, 3],\n",
       "          [7, 6, 5, 4, 3]],\n",
       " \n",
       "         [[7, 6, 5, 4, 3],\n",
       "          [7, 6, 5, 4, 3],\n",
       "          [7, 6, 5, 4, 3]],\n",
       " \n",
       "         [[7, 6, 5, 4, 3],\n",
       "          [7, 6, 5, 4, 3],\n",
       "          [7, 6, 5, 4, 3]],\n",
       " \n",
       "         [[7, 6, 5, 4, 3],\n",
       "          [7, 6, 5, 4, 3],\n",
       "          [7, 6, 5, 4, 3]],\n",
       " \n",
       "         [[7, 6, 5, 4, 3],\n",
       "          [7, 6, 5, 4, 3],\n",
       "          [7, 6, 5, 4, 3]],\n",
       " \n",
       "         [[0, 1, 2, 3, 4],\n",
       "          [0, 1, 2, 3, 4],\n",
       "          [0, 1, 2, 3, 4]],\n",
       " \n",
       "         [[0, 1, 2, 3, 4],\n",
       "          [0, 1, 2, 3, 4],\n",
       "          [0, 1, 2, 3, 4]],\n",
       " \n",
       "         [[0, 1, 2, 3, 4],\n",
       "          [0, 1, 2, 3, 4],\n",
       "          [0, 1, 2, 3, 4]],\n",
       " \n",
       "         [[0, 1, 2, 3, 4],\n",
       "          [0, 1, 2, 3, 4],\n",
       "          [0, 1, 2, 3, 4]],\n",
       " \n",
       "         [[0, 1, 2, 3, 4],\n",
       "          [0, 1, 2, 3, 4],\n",
       "          [0, 1, 2, 3, 4]]]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = pt.argsort(testa, axis=1)[:, :5].repeat((1, 1, 3)).reshape(10, 3, 5)\n",
    "ind.shape, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -14,  -12,  -10,   -8,   -6],\n",
       "         [ -14,  -12,  -10,   -8,   -6],\n",
       "         [-114, -112, -110, -108, -106]],\n",
       "\n",
       "        [[ -14,  -12,  -10,   -8,   -6],\n",
       "         [ -14,  -12,  -10,   -8,   -6],\n",
       "         [ -14,  -12,  -10,   -8,   -6]],\n",
       "\n",
       "        [[ -14,  -12,  -10,   -8,   -6],\n",
       "         [ -14,  -12,  -10,   -8,   -6],\n",
       "         [ -14,  -12,  -10,   -8,   -6]],\n",
       "\n",
       "        [[ -14,  -12,  -10,   -8,   -6],\n",
       "         [ -14,  -12,  -10,   -8,   -6],\n",
       "         [ -14,  -12,  -10,   -8,   -6]],\n",
       "\n",
       "        [[ -14,  -12,  -10,   -8,   -6],\n",
       "         [ -14,  -12,  -10,   -8,   -6],\n",
       "         [ -14,  -12,  -10,   -8,   -6]],\n",
       "\n",
       "        [[   0,    2,    4,    6,    8],\n",
       "         [   0,    2,    4,    6,    8],\n",
       "         [   0,    2,    4,    6,    8]],\n",
       "\n",
       "        [[   0,    2,    4,    6,    8],\n",
       "         [   0,    2,    4,    6,    8],\n",
       "         [   0,    2,    4,    6,    8]],\n",
       "\n",
       "        [[   0,    2,    4,    6,    8],\n",
       "         [   0,    2,    4,    6,    8],\n",
       "         [   0,    2,    4,    6,    8]],\n",
       "\n",
       "        [[   0,    2,    4,    6,    8],\n",
       "         [   0,    2,    4,    6,    8],\n",
       "         [   0,    2,    4,    6,    8]],\n",
       "\n",
       "        [[   0,    2,    4,    6,    8],\n",
       "         [   0,    2,    4,    6,    8],\n",
       "         [   0,    2,    4,    6,    8]]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.gather(testa_data, 2, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | freque... | presen... | temper... |   top_p   |\n",
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "multinomial(): argument 'num_samples' (position 2) must be int, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.06816656991447732, 0.2644650221375302, 0.5766885795123, 0.872231136632317)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-b1b4920aada6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds_gptxl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mresults_gpt2xl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers_gpt2xl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-93-b1b4920aada6>\u001b[0m in \u001b[0;36mfun\u001b[1;34m(temperature, top_p, presence_penalty, frequency_penalty)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"best_of\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtest_sp_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds_gptxl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0moptimizers_gpt2xl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-96998b689d90>\u001b[0m in \u001b[0;36mtest_sp_conv\u001b[1;34m(params, tol, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mnew_center\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-96998b689d90>\u001b[0m in \u001b[0;36mtest_sp\u001b[1;34m(params, min_l, max_l, n1, n2, prmt, phase, uniform, mdl, max_tokens)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_tokens\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmdl\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gpt3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp_req_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Convert to strings and request predictions from OpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"completions\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mcreate_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlearning_data_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"msp_samples_nb/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-92-b5f1a134d1eb>\u001b[0m in \u001b[0;36mgen_completions\u001b[1;34m(s, n, max_tokens, best_of, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mstates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbest_of\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_of\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtc_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtc_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_logprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: multinomial(): argument 'num_samples' (position 2) must be int, not float"
     ]
    }
   ],
   "source": [
    "# evaluate un-fine-tuned model\n",
    "# test the non fine tuned davinci\n",
    "lgroups_ft = [[4, 5]]\n",
    "bounds_gptxl = {\n",
    "  \"temperature\": [0.01, 2.0],  # a temp of 0 selects the top completion every time due to the infinitely larger logit\n",
    "  \"top_p\": [0.01, 1.0],        # same with this but more obvious\n",
    "#   \"top_k\": [1, 100],        # fix this to be a log of the input value so that lower values are sampled with high resolution?\n",
    "  \"presence_penalty\": [0.01, 2.0],   # both presence and frequency penalty have optimal values\n",
    "  \"frequency_penalty\": [0.01, 2.0],  # this can also go down to -2.0, probably not useful for our case...\n",
    "#   \"best_of\": [0.51, 5.49], # to do\n",
    "}\n",
    "optimizers_gpt2xl, results_gpt2xl = [], []\n",
    "for lgroup in lgroups_ft:\n",
    "    min_l, max_l = min(lgroup) - 1, max(lgroup)\n",
    "    def fun(temperature, top_p, presence_penalty, frequency_penalty):\n",
    "        global min_l, max_l\n",
    "        ps = locals()\n",
    "        ps[\"best_of\"] = 5.0\n",
    "        return test_sp_conv(ps, min_l=min_l, max_l=max_l, tol=0.005, phase=\"train\", uniform=True, mdl=mdl)[0]\n",
    "    optimizers_gpt2xl.append(BayesianOptimization(f=fun, pbounds=bounds_gptxl, verbose=1000))\n",
    "    optimizers_gpt2xl[-1].maximize(init_points=8, n_iter=10)\n",
    "    results_gpt2xl.append(optimizers_gpt2xl[-1].max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "\"reinterpretation, harmony, character progression, reading circle\")\n",
    "# \"monolith, elevator effect, time loop, survival, desert resort, town watchman\")\n",
    "# \"monolith, allegro, soundtrack, chord, classical, opera\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 25 , p = 0.6 , temp = 15.0\n",
      " A list of types of element of drama and writing: attention, surprise, fourth wall, diversion, fate, silence, pace, cliffhanger, character progression, monologuereinterpretation,➡, reading circle, cliffhaft-style character progression\n"
     ]
    }
   ],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.6, temperature=15.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "\"watermelon juice, cherry juice, blackcurrant mixture, kava, orangeade, lemon juice, cherryade, cranberry juice\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', '\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 , p = 0.8 , temp = 5.0\n",
      "A list of types of element of drama and writing: kava, lemonade, coffee, milkshakewatermelon juice, coke, orangeade, blackcurrant mixture, water, cherry juice, lemon juice, ➡ black\n"
     ]
    }
   ],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=10, top_p=0.8, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"pace, silence, diversion, attention, plot twist, cliffhanger, surprise, fate, fourth wall, monologue\" + \\\n",
    "# \"\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of element of drama and writing: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=5, top_p=0.9, temperature=5.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider, yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider\" + \\\n",
    "# \", yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5pm: Using log_period=1 (max_len=96) reliably finds improvement, need more data and larger gpt2 (medium+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" milk, vodka, beer, ice water, soda, lassi, juice, alcohol, whiskey\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" wine, soda, alcohol, beer, liquor, apple cider, whiskey, milk, bourbon, vodka, cider, lemon juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:6])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=3.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" beer, milk, juice, wine, spirits, alcohol, soda, whiskey, brandy, apple juice, liquor, ice tea, watermelon juice, vodka,\" + \\\n",
    "# \" lemon tea, apple cider, ale, lager, fruit tea, lime cider, cocktail, mocha, red wine, apple soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5am: lr=1e-5, max_len=80, log_period_batches=5 increased accuracy by 8%. Need to add a bunch more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 5 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"soda, milk, juice, wine, vodka, gin, lime juice, beer, hot chocolate, cider, whiskey, fruit juice, cocktail, liquor, \" + \\\n",
    "# \"spirits, watermelon juice, martini, rum, chocolate milk, orangeade\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fine tuning (regular GPT-2):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model on 2nd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, juice, fruit juice, soda, wine, beer, hot chocolate, chocolate milk, alcohol, cider, ice tea, liquor, spirit\")\n",
    "# input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89, olen=olen) # k = 25 also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for too long (in this case ~6:30 hours) overfits\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"beer, juice, soda, liquor, wine, tequila, spirits, alcohol, cocktail, martini, whiskey, rum, vodka\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 15/04/2021 11am: Found learning rate 1e-7, max_listlen 15, min_nw 0.7, max_nw 0.9, lidstone_e 0.01 ACTUALLY WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No fine tuning (testing gpt2) (old append function):\n",
    "# input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake\"\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89)\n",
    "# A list of types of drink: juice, tea, cider, lemonade, milk, beer, hot chocolate,➡ ice cold milk. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working (reproducible) examples using various non-fine-tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT3 (via AI Dungeon) (Randomness = 2.0, model = Dragon):\n",
    "# sentence = \"A list of ML algorithms: inverse reinforcement learning, ELMo, decision tree, LDA, \"\n",
    "# expected_completion = \"MLP, MLL, MMM. You can't believe you're actually using these things!\"\n",
    "\n",
    "# sentence = \"A list of animals seen in the wild: wolffish, woodlouse, sheep, zebra, yak, \"\n",
    "# expected_completion = \"goat, fox, dog, rat. You're guessing that a lot of other animals have been seen as well; maybe even all the animals on your list except for wolf and rat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 (via Write with Transformer) (Top-p = 0.67, temperature = 1.89, max time = 1.9):\n",
    "# sentence = \"A list of round fruits: peach, apricot, lime, plum, blackberry, cantaloupe, nectarine, pitaya, persimmon, \"\n",
    "# expected_completion = \"mango, papaya and raspberry, as also many\"\n",
    "\n",
    "# sentence = \"A list of chemical elements: hydrogen, carbon, oxygen, nitrogen, gold, \"\n",
    "# expected_completion = \"silver, aluminum, potassium and phosphorus; atomic number.\"\n",
    "\n",
    "# sentence = \"A list of microbes found on earth: bacteria, virus, prokaryote, amoeba, \"\n",
    "# expected_completion = \"archaea, algae, nematode, euk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4717125622130082\n",
      "0.9274901414219993\n",
      "0.9708372719995181\n",
      "0.9749693956398692\n",
      "0.9634897148058369\n",
      "0.9896781399013229\n",
      "0.49241673846869144\n",
      " laser 0.13 <100| warming 0.00 <100| of 13.07 2| the 66.63 1| earth 11.92 2|, 68.96 1| vortex 0.12 <100\n",
      "0.4717126591849034\n",
      "0.9892794505344922\n",
      "0.7311559539240653\n",
      "0.9564361800508027\n",
      "0.9806930894447073\n",
      "0.9902743788718463\n",
      "0.40462574025242265\n",
      " peaks 0.00 <100| of 46.80 1| power 0.03 <100| distribution 0.86 17| systems 3.02 3|, 81.74 1| thunder 0.31 38\n",
      "0.4717126591849034\n",
      "0.9953395055269428\n",
      "0.9999771481604979\n",
      "0.9590532795958426\n",
      "0.3408734530984889\n",
      "0.8934024084657903\n",
      "0.9621786642515812\n",
      " ping 0.01 <100| p 33.01 2|ong 99.66 1|, 14.11 2| sound 0.25 42| stimuli 0.00 <100| and 4.08 3\n",
      "0.47171274389095824\n",
      "0.9298754919398827\n",
      "0.9241370285266322\n",
      "0.9774319808776988\n",
      "0.969552997269808\n",
      "0.9904618264585953\n",
      "0.9982023300946802\n",
      " bird 0.01 <100| flipping 0.01 <100| its 16.03 2| wing 6.92 3| sixty 0.00 <100| times 69.92 1| a 57.81 1\n",
      "0.4717125622130082\n",
      "0.9986656739204779\n",
      "0.9997999485940596\n",
      "0.8628570462541978\n",
      "0.9867071412680777\n",
      "0.5666820798309762\n",
      "0.8700021823837326\n",
      " seaf 0.01 <100|o 2.18 2|am 98.58 1| piles 0.05 100| of 1.02 7| atmospheric 0.19 83| extinction 0.06 <100\n"
     ]
    }
   ],
   "source": [
    "# This result shows why we need not redistribute the mass when evaluating gpt3 accuracy\n",
    "# response = openai.Completion.create(**{**default_params,\n",
    "#   \"prompt\": \"A list of cyclic phenomena: day and night, induction coil, self-oscillation, tornado, runaway greenhouse effect,\",\n",
    "#   \"temperature\": 1.5,\n",
    "#   \"top_p\": 1.0,\n",
    "#   \"n\": 5,\n",
    "#   \"best_of\": 20,\n",
    "#   \"max_tokens\": 7,\n",
    "#   \"stop\": [\",\", \"\\n\"],\n",
    "# })\n",
    "# for choice in response[\"choices\"]:\n",
    "#     d = {}\n",
    "#     tokens = choice[\"logprobs\"][\"tokens\"]\n",
    "#     t_i = -1\n",
    "#     for t in tokens:\n",
    "#         t_i += 1\n",
    "#         r = [(np.e**v, k) for (k, v) in choice[\"logprobs\"][\"top_logprobs\"][t_i].items()]\n",
    "#         r.sort(reverse=True)\n",
    "#         print(sum([v for (v, k) in r]))\n",
    "#         rd = dict([(k, v) for (v, k) in r])\n",
    "#         r = [k for (v, k) in r]\n",
    "#         d[t] = (rd, r, np.e**choice[\"logprobs\"][\"token_logprobs\"][t_i])\n",
    "#     print('|'.join([' '.join((s.replace(\"\\n\", \"⏎\"),'%.2f' % (d[s][2] * 100),\n",
    "#                               str(d[s][1].index(s) + 1) if s in d[s][1] else \"<100\")) for s in tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]],\n",
      "\n",
      "        [[16, 17, 18, 19],\n",
      "         [20, 21, 22, 23],\n",
      "         [24, 25, 26, 27],\n",
      "         [28, 29, 30, 31]],\n",
      "\n",
      "        [[32, 33, 34, 35],\n",
      "         [36, 37, 38, 39],\n",
      "         [40, 41, 42, 43],\n",
      "         [44, 45, 46, 47]]])\n",
      "tensor([[ 4,  5,  6,  7],\n",
      "        [28, 29, 30, 31],\n",
      "        [40, 41, 42, 43]])\n"
     ]
    }
   ],
   "source": [
    "C, H, W = 3, 4, 4\n",
    "x = pt.arange(C*H*W).view(C, H, W)\n",
    "print(x)\n",
    "idx = pt.tensor([[0, 0],\n",
    "                    [1, 1],\n",
    "                    [2, 2],\n",
    "                    [3, 3]])\n",
    "\n",
    "# print(x[list((pt.arange(x.shape[0]), *idx.chunk(2, 1)))])\n",
    "print(x[[pt.arange(3), [1, 3, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' what is this, he said.'"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        else:            outs = pt.gather(pt.stack(outs), 0, pt.unsqueeze(pt.unsqueeze(\n",
    "                           pt.argmin(pt.stack(avg_logprobs), 0), dim=0), dim=3).repeat_interleave(max_tokens, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pt.tensor(np.array(5)) != pt.tensor(np.array([5, 5, 7]))).int() + (pt.tensor(np.array(5)) != pt.tensor(np.array([5, 5, 7]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9, -9,  0],\n",
       "          [ 8, -8,  0],\n",
       "          [ 7, -7,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]]],\n",
       "\n",
       "\n",
       "        [[[ 1, -1,  0],\n",
       "          [ 9, -9,  0],\n",
       "          [ 9, -9,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.stack([pt.tensor(np.array([[[9,-9,0],[8,-8,0],[7,-7,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]]])), pt.tensor(np.array([[[1,-1,0],[9,-9,0],[9,-9,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]]]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]]]])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.unsqueeze(pt.unsqueeze(pt.argmax(pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]]))]), 0), dim=0),dim=3).repeat_interleave(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]])"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.unsqueeze(pt.unsqueeze(pt.argmax(pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]]))]), 0), dim=0),dim=0).transpose(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_tensor.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]]))]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-494-5882981bfa7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "z[[pt.arange(z.shape[0]).repeat_interleave(18//z.shape[0], 0), pt.arange(z.shape[1]).repeat_interleave(z.shape[1]), ind_tensor.view(-1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, -9,  0],\n",
       "        [ 9, -9,  0],\n",
       "        [ 9, -9,  0],\n",
       "        [ 1, -1,  0],\n",
       "        [ 2, -2,  0],\n",
       "        [ 3, -3,  0],\n",
       "        [ 1, -1,  0],\n",
       "        [ 2, -2,  0],\n",
       "        [ 3, -3,  0],\n",
       "        [10, -7,  0],\n",
       "        [ 6, -7,  0],\n",
       "        [ 6, -6,  0],\n",
       "        [74, -4,  0],\n",
       "        [ 5, -5,  0],\n",
       "        [ 6, -6,  0],\n",
       "        [ 4, -4,  0],\n",
       "        [ 5, -5,  0],\n",
       "        [ 6, -6,  0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[[ind_tensor.view(-1), pt.arange(z.shape[1]).repeat_interleave(z.shape[2]),\n",
    "                        pt.arange(z.shape[2]).repeat(z.shape[1], 1).view(-1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3, 3])"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.arange(z.shape[2]).repeat(18//z.shape[2], 1).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.arange(z.shape[1]).repeat_interleave(18//z.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9, -9,  0],\n",
       "          [ 9, -9,  0],\n",
       "          [ 9, -9,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[ 1, -1,  0],\n",
       "          [ 2, -2,  0],\n",
       "          [ 3, -3,  0]],\n",
       "\n",
       "         [[10, -7,  0],\n",
       "          [ 6, -7,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[74, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]],\n",
       "\n",
       "         [[ 4, -4,  0],\n",
       "          [ 5, -5,  0],\n",
       "          [ 6, -6,  0]]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = pt.stack([pt.tensor(np.array([[[9,-9,0],[8,-8,0],[7,-7,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]]])), pt.tensor(np.array([[[1,-1,0],[9,-9,0],[9,-9,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[10,-7,0],[6,-7,0],[6,-6,0]], [[74,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[6,-5,0],[6,-6,0]]]))])\n",
    "ind_tensor = pt.argmax(pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [12,9,6], [80,5,6], [4,5,6]]))]), 0)\n",
    "pt.gather(z, 0, pt.unsqueeze(pt.unsqueeze(ind_tensor, dim=0), dim=3).repeat_interleave(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Size does not match at dimension 2 expected index [3, 1, 6, 1] to be smaller than src [3, 6, 3, 2] apart from dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-469-3c786eac2655>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mind_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Size does not match at dimension 2 expected index [3, 1, 6, 1] to be smaller than src [3, 6, 3, 2] apart from dimension 0"
     ]
    }
   ],
   "source": [
    "z = pt.stack([pt.tensor(np.array([[[9,-9,0],[8,-8,0],[7,-7,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]]])), pt.tensor(np.array([[[1,-1,0],[9,-9,0],[9,-9,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[1,-1,0],[2,-2,0],[3,-3,0]], [[10,-7,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]], [[4,-4,0],[5,-5,0],[6,-6,0]]]))])\n",
    "ind_tensor = pt.argmax(pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [10,5,6], [4,5,6], [4,5,6]]))]), 0)\n",
    "pt.gather(z.transpose(0, 3), 0, pt.unsqueeze(pt.unsqueeze(ind_tensor, dim=0), dim=0).transpose(0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9,  1],\n",
       "          [ 8,  9],\n",
       "          [ 7,  9]],\n",
       "\n",
       "         [[ 1,  1],\n",
       "          [ 2,  2],\n",
       "          [ 3,  3]],\n",
       "\n",
       "         [[ 1,  1],\n",
       "          [ 2,  2],\n",
       "          [ 3,  3]],\n",
       "\n",
       "         [[ 4, 10],\n",
       "          [ 5,  5],\n",
       "          [ 6,  6]],\n",
       "\n",
       "         [[ 4,  4],\n",
       "          [ 5,  5],\n",
       "          [ 6,  6]],\n",
       "\n",
       "         [[ 4,  4],\n",
       "          [ 5,  5],\n",
       "          [ 6,  6]]],\n",
       "\n",
       "\n",
       "        [[[-9, -1],\n",
       "          [-8, -9],\n",
       "          [-7, -9]],\n",
       "\n",
       "         [[-1, -1],\n",
       "          [-2, -2],\n",
       "          [-3, -3]],\n",
       "\n",
       "         [[-1, -1],\n",
       "          [-2, -2],\n",
       "          [-3, -3]],\n",
       "\n",
       "         [[-4, -7],\n",
       "          [-5, -5],\n",
       "          [-6, -6]],\n",
       "\n",
       "         [[-4, -4],\n",
       "          [-5, -5],\n",
       "          [-6, -6]],\n",
       "\n",
       "         [[-4, -4],\n",
       "          [-5, -5],\n",
       "          [-6, -6]]],\n",
       "\n",
       "\n",
       "        [[[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.transpose(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.argmax(pt.stack([pt.tensor(np.array([[9,8,7], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), pt.tensor(np.array([[1,9,9], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]]))]), 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 4],\n",
       "        [5, 4],\n",
       "        [5, 4],\n",
       "        [5, 4],\n",
       "        [5, 4],\n",
       "        [5, 7],\n",
       "        [5, 7],\n",
       "        [5, 7],\n",
       "        [5, 7],\n",
       "        [5, 7]], dtype=torch.int32)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.tensor(np.array([[5, 4], [5, 7]])).repeat_interleave(5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 2, 1, 2, 0, 1, 0])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pt.multinomial(pt.tensor(np.array([[1.,0,0], [1,2,3], [1,2,3], [4,5,6], [4,5,6], [4,5,6]])), 3, replacement=True).reshape(3, 2, 3)[:, 0].reshape(9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
